---
layout: post 
title: AI Breakfast S2 Ep 1 생각정리
subtitle: AI의 판도를 뒤집다 - Google I/O 2025 클라우드 업데이트
categories: AI
tags: AI DevOps Google 생각정리
thumb: https://i.ytimg.com/vi/Dm1V-ODwb1Q/hq720.jpg
custom-excerpt: AI DevOps 전문가가 되기 위한 배경지식 쌓기 노력 중...! 
banner:
  # video: https://vjs.zencdn.net/v/oceans.mp4
  video: https://cdn.pixabay.com/video/2019/10/04/27539-364430966_large.mp4
  loop: true
  volume: 0.8
  muted: true                 # For mobile device background music play 
  start_at: 8.5
  image: https://wallpapers.com/images/featured-full/running-wl9pg3zeygysq0ps.jpg
  opacity: 0.618
  background: "#000"
  height: "100vh"
  min_height: "38vh"
  heading_style: "font-size: 4.25em; font-weight: bold; text-decoration: underline"
  subheading_style: "color: gold"
---

## 영상 보기
[![비디오 제목](https://i.ytimg.com/vi/Dm1V-ODwb1Q/hq720.jpg)](https://youtu.be/Dm1V-ODwb1Q?si=aoeugkXlpHokwMNd)

## 요약
구글 I/O 2025 행사는 **구글이 인공지능(AI) 분야의 주도권을 확실히 잡고 나아간다는 분위기**였다. 

이번 구글 I/O에서 가장 인상 깊었던 핵심 기술 및 발표 내용은 다음과 같다:

*   **Gemini 2.5 모델**이 발표되었다. 이 모델은 **Thinking 모델 기반에서 멀티모달리티를 강화한 모델**이다. 기업에서 Gemini 모델을 사용할 때 더욱 정확하고 복잡한 문제를 풀 수 있을 것으로 기대된다. Gemini 2.5는 Deep research의 근간을 이루고 있으며, 복잡한 문제들을 쉽게 풀 수 있는 AI 모델이다.
*   **Thinking 모델**은 기존의 Instruction 모델과 달리, 한 번 더 단계적으로 추론하고 생각을 깊게 할 수 있도록 사전 학습된 모델이다. 이는 모델 훈련 과정에서 Thinking 과정을 추가하여 요청이 들어왔을 때 그 프로세스를 거치면서 답을 내도록 트레이닝된 것이다. 이를 통해 AI가 더 깊은 추론 능력을 갖게 되었다고 한다. Gemini 2.5 Pro는 LM Arena와 같은 공신력 있는 웹사이트에서 모든 영역에서 1위를 차지하며, Deep research 영역에서도 계속 상위에 올라와 있다고 언급된다.
*   **Project Astra**는 구글이 AI의 미래를 어떻게 이끌어갈 것인가에 대한 프로토타입 프로젝트이다. 이는 **구글이 꿈꾸는 미래 AI의 모습, 즉 AGI(Artificial General Intelligence) 수준의 AI 비서**를 보여준다. 사람처럼 커뮤니케이션할 수 있는 멀티모달리티 기능이 탑재되어 있다. Project Astra는 **Live API**를 기반으로 만들어지고 있다.
*   **멀티모달리티(Multimodality)**는 사람이 일반적으로 커뮤니케이션하는 방법과 동일하게 다양한 감각이나 유형의 정보를 컴퓨터가 학습하여 사고할 수 있게 만든 AI이다. 보이스, 시각(눈으로 보는 것), 텍스트, 문서 읽기 등 사람이 할 수 있는 일들을 AI가 할 수 있게 된 것이다. Gemini 2.5부터 Thinking 모델과 함께 멀티모달리티 기능이 매우 강화되었다.
*   **생성형 미디어 모델들**이 다양해졌다. 특히 **Veo 3**가 포함된 비디오 생성 모델과 Imagen을 통한 이미지 생성, 음악 생성 기능 등이 소개되었다. 이러한 미디어 제품들은 미디어 산업과 광고 분야에서 많이 활용될 것이라고 예상된다.
*   **Code Assistance**는 Gemini 2.5 버전을 기반으로 6월 12일에 출시되었으며, 개발자들의 반복적인 코드 작업을 해소하고 아키텍처 및 설계에 더 많은 시간을 할애할 수 있도록 도울 것이다.
*   **Workspace**에 다양한 AI 기술들이 도입되었다. Gmail에서 기존 메일 스레드를 참조하여 메일을 대신 작성해 주는 개인 맞춤형(personalization) 기능이 그 예시이다. 이는 AI가 어시스턴트 역할을 하는 방향으로 발전하고 있음을 보여준다.
*   **ADK(AI Agent Development Kit)**는 구글 넥스트 행사에서 처음 소개된 오픈 소스 프레임워크로, AI Agent 생태계를 키우고 기업들이 쉽게 Agent를 만들 수 있도록 지원하는 것을 목적으로 한다.
*   **Firebase Studio**는 개발자를 위한 프로토타이핑 툴로, 기존에 일주일에서 열흘 걸리던 프로토타이핑 작업을 몇 분 만에 가능하게 하여 개발자와 현업 간의 커뮤니케이션 및 생산성을 크게 향상시킬 것이다.
*   **Live API**는 짧은 지연 시간으로 양방향 음성 및 동영상 상호작용을 지원하며, 파운데이션 모델(예: Gemini)에 실시간 음성 및 동영상 스트리밍이 다이렉트하게 들어갈 수 있는 기술이다. 이는 사용자가 음성 명령이나 카메라를 통해 모델에 직접 정보를 전달하고 응답을 받을 수 있게 한다. Project Astra가 이 Live API를 기반으로 개발되고 있으며, 이는 미래의 일이 아니라 조만간 상용화될 것이라고 언급된다.

AI의 발전 방향은 강화된 추론 능력 및 기획 능력, 멀티모달리티 및 라이브 커뮤니케이션의 진화, 그리고 온디바이스 및 오픈 소스 모델 쪽으로 진행되고 있다. 또한 AI는 헬스케어와 같은 분야에서도 데이터 분석 및 질병 패턴 파악에 큰 도움이 될 수 있으며, 개인 정보 보호(프라이버시), 컴플라이언스, 규제 등 윤리적인 측면도 매우 중요하게 다루고 있다고 한다.

## 내 생각 정리
WA!

사실 엄청난 뒷북일 수 있다. 하지만 2.5 Pro 를 아주 잘 활용하고 있고, 조만간 Gemini CLI 사용 한 것에 대한 후기도 남길 생각이지만, 2025년의 구글은 확실히 뭐가 달라도 다르다는 느낌이다. 

TPU 사용이 가능하게 AI 를 구성하고, 플랫폼 모델을 기반으로 얼마나 다양한 프로젝트를 준비중인지, 결정적으로 API 비용이 싸다는 점을 포함하면 OpenAI가 ChatGPT 로 충격을 준 이래로 이만큼 괜찮은 업데이트가 있을까? 하는 생각이 들 정도의 충격이었다.

특히나 AI에 대한 노하우가 있기에 가능한 다양한 특화 서비스들은 당장 찾아보지 않았음에도, 일부 테스트만으로도 그 수준이 얼마나 괜찮은지 새삼 느꼈고, 단순히 웹 클라우드 프로바이저로 끝이 아닌, AI 를 위한 진짜 플랫폼이 되려는 의지가 확고하다는 것은 거를 타선이 없는 영역이리라 생각된다. 

이번 내용을 기반으로 테스트 간단하게 해본 것들 중, 가장 흥미로웠던 것 두 가지를 뽑자면 다음과 같다. 

1. AI Studio 를 활용한 Project Astra 데모 시연 
2. Firebase Studio를 활용한 진정한 딸깍(?)의 프로토타이핑 

![](/assets/images/posts/2025-08/2025-08-06-001.png)
> 캬...

우선 AI 스튜디오에서 Stream Realtime 을 활용하면 Project Astra의 정말 기능적 데모를 써볼 수 있다. 보면 알 수 있듯 웹캠을 활용한 것인데, 확실한건 2.5 기반으로 데모시 정말 아주 빠른 반응속도로 상황을 해석하고, 표정도 읽어준다. 

특히나 2.5 기반의 모델들은 구글의 워크스페이스, 일정이나 다양한 서비스 연동이 되는데, 이미 에이전트로 해야할 매우 큰 서비스들이 다 연결이 된다는 점에서 Project Astra 안경이 나온다면 정말 엄청난 일이 벌어지지 않을까? 솔직히 XR 보단 안경이 얼마이든 구매를 하고 싶단 생각이다(...)

두번째로 Firebase Studio, 요 친구도 아주 물건인데. 설명처럼 프로토 타이핑용으로 아주 제격인 서비스이다. 
서비스 자체는 대화형이라는 차원은 동일하고, 문서를 찾아보니 Project IDX 라는 구글의 웹기반 IDE 서비스 관련하던 것이 통합된 것으로 전에는 크게 신경을 쓰지 않았었는데, 이번 내용은 생각 이상이었다. 

![](/assets/images/posts/2025-08/2025-08-06-002.png)
> 메인 화면 

![](/assets/images/posts/2025-08/2025-08-06-003.png)
> 슬쩍 프롬프트 넣어주고

![](/assets/images/posts/2025-08/2025-08-06-004.png)
> 에러가 나오면 확인하고 처리를 하거나 하면 된다. API 키가 없어서 에러가 났다. 하지만 요청만 하면...

![](/assets/images/posts/2025-08/2025-08-06-005.png)
> 적당히 수정해서, 기다리면 찰떡같이 알아 먹곤 프로토 웹 데모를 보여준다.

5분 걸렸을까? 기초적인 기능 구현에서 이정도면 충분하게 동작하고, 무엇보다 대중적인 기술로 쉽게 구현 + 바로바로 에러 핸들링, 수정 결과까지 이정도 생산성의 증대는 과연 누가 생각이나 했을까? 기존의 IDX 프로젝트 때는 실질적으로 IDE 를 굳이 바꿔야 하나? 클라우드로 불편하게? 라는 의구심이 들었다면, 이정도라면 프로토타입을 만들기 위해 구태여 내가 AI 를 쓸 이유가 있을까?

물론 gemini-cli 를 활용한다는 건 로컬 환경에서 굉장히 효과적인 사용이 가능한 것은 맞다. 하지만 불편함이 없냐? 하면 사실 충분히 있다. MCP 의 연결이나, 세팅 등, 여러 면에서 번거롭게 일을 수행할 이유 보단 철저하게 '딸깍'을 하고 나온 내용을 스스로 분석하고 해석하는게 빠르지 않을까? 

![](/assets/images/posts/2025-08/2025-08-06-006.png)
> 기존에 써보게 되었든 '스티치 AI' 디자인용 AI 다

기존 스티치 AI 라는 웹 퍼블리싱, 웹 디자인을 위한 툴이 있었는데 이것만으로도 훌륭했지만, 이젠 정말 에이전트의 개념이 충분히 녹아든 서비스가 나오며, 그걸 활용할 줄 아냐 모르느냐의 차이는 명백한 생산성, 무엇보다 기본 실력과 경험의 차이를 이끌 수 있겠다.

내가 필요한 서비스를 만들거나, 내가 필요한 기능을 구체화 한다. 거기서 핵심은 '내가 필요한' 것이 아닌 것들을 AI에게 맡긴다면, 나는 내가 원하는 수준의 내 도메인을 위한 필요에 따른 스킵, 빠른 진행을 가능케 만들 수 있다는 것이다.... 진짜 멈춰 있을 틈이 없을 것 같다.