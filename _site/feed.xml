<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" hreflang="ko" /><updated>2025-08-08T07:14:48+00:00</updated><id>http://0.0.0.0:4000/feed.xml</id><title type="html">Paul’s Archives</title><subtitle>성장하는 개발자, 소통하는 개발자, 빠른 적용을 최 우선으로 삼는 개발자. 다음을 항상 생각하며, 개발 속에서 가치를 만들어내는 것을 목표로 합니다.</subtitle><author><name>Paul2021-R</name></author><entry><title type="html">GPT v5 공개…! 현재 상태 좀 볼까?</title><link href="http://0.0.0.0:4000/ai/2025/08/07/00-chat-gpt-v5-introduction.html" rel="alternate" type="text/html" title="GPT v5 공개…! 현재 상태 좀 볼까?" /><published>2025-08-07T00:00:00+00:00</published><updated>2025-08-07T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/07/00-chat-gpt-v5-introduction</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/07/00-chat-gpt-v5-introduction.html"><![CDATA[<p><img src="/assets/images/posts/2025-08/2025-08-07-002.png" alt="" /></p>

<h2 id="gpt-5를-뜯어보자">GPT-5를 뜯어보자!</h2>
<p>OpenAI의 GPT-5가 드디어 공개되었다. 이번 출시는 GPT-4 라는 모델의 충격 때문일까, 확실히 여기저기, 특히나 유튜브에서 관심을 다들 가지는 느낌이 들었다. 그러니 그 변화에 탑승해서(?) GPT-5라는 새로운 버전에 대해 제대로 파악하고자 먼저, 기업이란 거시적인 관점의 조망해보고, 그 후 구체적인 기능을 살펴보면서, 씹고 뜯고 맛보고 즐겨보자(?).</p>

<h3 id="gpt-5를-통해-볼-수-있는-openai">GPT-5를 통해 볼 수 있는 OpenAI</h3>
<p>GPT-5의 등장은 몇 가지 핵심적인 전략적 전환을 의미한다. 이는 기술의 방향성과 AI 산업의 미래를 암시하는 거대한 흐름이다.</p>

<ul>
  <li>
    <p>GPT-5는 개별 도구의 집합에서 단일 통합 지능 시스템으로의 패러다임 전환이다.
과거 사용자는 GPT-4, GPT-4o 등 복잡한 ‘모델 선택기(model picker)’ 앞에서 어떤 모델이 자신의 작업에 최적인지 직접 고민해야 했다. GPT-5는 이 불편함을 완전히 해소한다. 사용자의 질문 의도를 실시간으로 분석해 가장 적합한 추론 능력을 자동으로 할당하는 지능형 라우터를 탑재한 통일된 플랫폼으로 진화했다. 이는 AI를 마치 하나의 운영체제(OS)처럼 만들어, 경쟁자들이 쉽게 넘볼 수 없는 기술적 ‘해자(moat)’를 구축하려는 OpenAI의 핵심 전략이다.</p>

    <p>개발자들이나, 파워 유저의 경우 특정 룰을 가지고 에이전틱한 사용성을 보장해주는 것을 필요로 한다 말하지만, 일반 사용자가 AI 를 사용할 때는, 그러한 영역들이 상당한 장애물이 될 수 있다. 그런 점을 볼 때 엔드 유저를 생각할 때의 핵심은 ‘알잘딱’하게 알아 맞추는 것이며, 이것이 곧 락인(lock-In) 효과의 핵심이라고 판단한 것으로 보인다.(사실 개발자라도, 쉽고 빠르게 쓰고 싶다는 점에선, 이 점은 여전히 중요하리라 본다.)</p>
  </li>
  <li>
    <p>이번 출시는 점진적 개선을 넘어 ‘박사급 전문가’ 수준의 질적 도약을 의미한다.
샘 알트먼 CEO는 GPT-3를 “고등학생”, GPT-4를 “대학생”에 비유하며, GPT-5와의 대화는 “어떤 분야에서든 합법적인 박사급 전문가와 이야기하는 느낌”이라고 표현했다. 이는 단순 정보 검색을 넘어, 복잡한 문제 해결을 위한 심층적인 사고 파트너로서의 역할을 목표로 함을 의미한다. AI의 지능 수준이 이전 세대와는 근본적으로 다른 차원에 도달했음을 시사하는 대목이다. 이는 기존의 gemini 2.5 Pro를 포함하여 지속적으로 나오는 다른 서비스들의 심층 추론이를 보다 명시적이고 전문성이 있다고 강조한 걸로 보인다.</p>
  </li>
  <li>
    <p>기술의 최전선에서 신뢰성과 안전성을 최우선으로 하여 엔터프라이즈 시장을 정조준한다.
기업이 AI 도입을 주저했던 가장 큰 이유는 ‘환각(Hallucination)’ 현상, 즉 AI가 그럴듯한 거짓말을 하는 문제였다. GPT-5는 이 문제를 정면으로 겨냥해, 사실 기반 벤치마크에서 이전 모델보다 오류를 최대 80%까지 줄였다. 이러한 신뢰성 향상은 금융 분석, 법률 실사, 헬스케어와 같이 정확성이 생명인 고위험 분야에서 AI를 실용적인 비즈니스 도구로 도입하기 위한 필수적인 기반이다. 이미 SAP, Relativity 같은 기업들은 GPT-5를 활용해 비즈니스 혁신을 가속하고 있다.</p>

    <p>이러한 지점은 기존 다른 업체들의 모델들이 자기 나름의 방법으로 할루시네이션을 극복하고, 특히나 비즈니스에서 사용시 이러한 문제를 해결하지 못하면 안된다라는 아주 구조적 킬포인트를, 그들도 이미 공감하고 최우선으로 생각했다는 공감의 표시라고 생각된다. Gemini 2.5 pro의 경우에도 구글 서치 그라운딩고 같이, 정확한 정보인가 아닌가? 를 검증한다는 점을 강하게 어필했고, 지금껏 AI 관련된 공식 팟캐스트에서도 구글 측의 입장은 한결같이 ‘기업이 신뢰할만한가?’ 라는 명제에 최대한 답을 하려고 했단 점은 GPT 역시 동일한 결론이라는 걸 보여준다.</p>
  </li>
</ul>

<h3 id="요약해본-gpt-5의-핵심-업데이트-내용">요약해본 GPT-5의 핵심 업데이트 내용</h3>
<p>OpenAI 의 전략, 상황, 그리고 AI 트랜드의 편린을 보았으니, GPT 5의 개선 사항들을 정리해보자. GPT-5의 강력한 성능은 다음과 같은 핵심 기능들의 비약적인 발전에 기반한다.</p>

<ul>
  <li><strong>통합 아키텍처는 실시간 라우터를 통해 질문에 따라 최적의 모델을 자동 할당</strong></li>
</ul>

<p>내부적으로 GPT-5는 빠른 응답을 위한 효율적인 모델과, 복잡한 문제 해결을 위한 심층 “사고(Thinking)” 모델로 나뉘어 있다. 사용자가 “이 문제에 대해 깊이 생각해봐”라고 명시하거나 질문이 복잡하다고 판단되면, 시스템의 중추인 ‘실시간 라우터’가 즉시 ‘사고’ 모델을 활성화한다. 덕분에 사용자는 속도와 깊이를 모두 자연스럽고 빠르게 경험할 수 있다.</p>

<ul>
  <li><strong>‘주문형 소프트웨어(Software-on-Demand)’ 개념을 현실화하는 강력한 코딩 능력</strong></li>
</ul>

<p>코딩 지식이 없는 사용자도 “프랑스어 학습 앱을 만들어줘. 단어 퀴즈랑 플래시카드 기능도 넣어줘”와 같은 자연어 설명만으로 몇 분 만에 실제 작동하는 앱을 만들 수 있다고 전했다. 전문 개발자에게는 더욱 강력한 도구가 된다. SWE-bench와 Aider Polyglot 같은 주요 코딩 벤치마크에서 각각 74.9%, 88%라는 압도적인 점수를 기록했으며, 이는 대규모 코드베이스를 이해하고 복잡한 버그를 수정하는 능력이 탁월함을 증명했고, 데모를 제공해준다.</p>

<ul>
  <li><strong>환각(Hallucination) 현상이 이전 모델 대비 최대 80%까지 감소하여 답변의 신뢰성이 비약적으로 향상</strong></li>
</ul>

<p>GPT-5의 전체적인 환각 발생률은 이전 모델의 20% 이상에서 4.8%로 크게 줄었다. 특히 민감한 의료 관련 질문에서는 오류율이 1.6%까지 떨어졌으며, 모르는 내용에 대해 억지로 꾸며내는 ‘기만적 행동’은 이전 모델의 86.7%에서 단 9%로 대폭 감소했다. 존재하지 않는 이미지에 대해 질문했을 때 GPT-4 세대가 86.7%의 확률로 자신있게 거짓말을 했던 반면, GPT-5는 단 9%만이 그런 반응을 보여, 모르는 것에 대해 솔직하게 인정하도록 훈련되었음을 보여준다.</p>

<ul>
  <li><strong>이미지와 텍스트를 동시에 이해하는 멀티모달 능력과 최대 40만 토큰의 컨텍스트 처리 능력</strong></li>
</ul>

<p>최대 40만 토큰의 컨텍스트 창은 책 한 권 전체나 몇 주간의 대화 기록을 하나의 대화 안에서 일관성 있게 처리할 수 있음을 의미한다. 또한, 사용자의 구글 캘린더나 Gmail과 연동하여 “지난주에 놓친 중요한 이메일 요약해줘”와 같은 개인화된 작업도 수행할 수 있다. 아직 구글의 그것이 정말 말이 안될 사이즈로 제공해주긴 하지만, 이 역시 훌륭한 컨텍스트 양이라고 볼 수 있을 것이다.</p>

<ul>
  <li><strong>‘취향’이 개선된 작문 능력과 ‘성격(Personalities)’ 기능으로 더 인간적인 상호작용이 가능</strong></li>
</ul>

<p>“문학적 깊이와 리듬”을 갖춘 설득력 있는 글을 생성하며, 사용자의 비위를 맞추려는 ‘아첨(sycophancy)’ 경향은 14.5%에서 6% 미만으로 줄었다. 또한 ‘냉소주의자(Cynic)’, ‘로봇(Robot)’, ‘너드(Nerd)’ 등 네 가지 사전 설정된 ‘성격’으로 AI의 응답 톤을 간편하게 조절할 수 있다. Gemini 2.5 Pro 에 대한 사용자 평가에서 이부분의 필요성이 대두되었는데, 이점은 보다 ‘객관성’과 ‘신뢰성’ 확보를 위해 필요하다고 생각되는 강조점이라고 볼 수 있겠다.</p>

<ul>
  <li><strong>‘안전한 완료(Safe Completions)’라는 새로운 안전 철학을 도입</strong></li>
</ul>

<p>민감한 질문에 대해 무조건 답변을 거부하는 ‘강경한 거절’ 방식에서 벗어나, 유해할 수 있는 내용을 제거하면서도 최대한 유용한 정보를 제공하려 노력한다. 예를 들어 위험 물질에 대한 질문에 제조법을 알려주는 대신, 그것의 위험성과 안전한 취급 방법에 대한 정보를 제공하는 식이다.</p>

<ul>
  <li><strong>자율적으로 다단계 작업을 수행하는 ‘에이전트(Agentic)’ 능력이 강화</strong></li>
</ul>

<p>단순 응답을 넘어, “레스토랑 웹사이트를 만들어줘”라는 요청에 스스로 전체 프로젝트 계획을 세우고, 필요한 도구(브라우저, 코드 실행기 등)를 연속적으로 호출하여 과업을 완수하는, 마치 프로젝트 매니저와 같은 역할을 수행한다.</p>

<ul>
  <li><strong>개발자를 위해 API 기능이 세분화되고 가격 경쟁력을 갖추었다.</strong></li>
</ul>

<p>용도에 맞게 최고 성능의 <code class="language-plaintext highlighter-rouge">gpt-5</code>부터 비용 효율적인 <code class="language-plaintext highlighter-rouge">gpt-5-mini</code>, 초저지연에 특화된 <code class="language-plaintext highlighter-rouge">gpt-5-nano</code> 모델까지 선택할 수 있다. 가격 또한 GPT-4o 대비 입력 비용이 절반으로 줄어든 100만 토큰당 1.25달러로 책정되었으며, 반복 호출 시 비용을 90% 절감해주는 캐싱 할인도 제공된다. 이러한 부분은 가격 경쟁력 부분이 필요하다는 수요를 나름 인지한 것으로 보인다.</p>

<ul>
  <li><strong>모두를 위한 사용자 경험(UX) 개선과 생태계 통합:</strong></li>
</ul>

<p>이제 무료 사용자를 포함한 모든 유저가 개선된 음성 모드를 사용할 수 있으며, 여러 아이디어를 시각적으로 펼쳐놓고 작업하는 ‘캔버스(Canvas)’ 기능도 추가되었다. 또한, GPT-5 출시와 함께 GPT-4o 등 모든 구형 모델이 플랫폼에서 제거되어, 모든 사용자와 개발자가 GPT-5라는 단일 생태계로 통합된다.</p>

<ul>
  <li><strong>주요 외부 도구와의 통합 심화:</strong></li>
</ul>

<p>GPT-5는 Microsoft 365 Copilot에 깊숙이 통합되어 사용자의 이메일, 문서 등 개인 업무 데이터를 기반으로 매우 맥락에 맞는 분석을 제공하며, GitHub Copilot과 Visual Studio Code에도 직접 통합되어 개발자들이 코드를 작성하고 디버깅하는 전 과정을 실시간으로 돕는다.</p>

<h3 id="gpt-5-그리고-그-다음은-써보니">GPT 5 그리고 그 다음은…? 써보니..</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: left">모델</th>
      <th style="text-align: left">강점 포인트</th>
      <th style="text-align: left">주요 스펙</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">GPT‑5 (OpenAI)</td>
      <td style="text-align: left">“박사급 전문가” 수준의 추론• 매우 적은 환각률, 안전한 응답• 뛰어난 도구 연동 및 에이전트 작업• SWE‑bench 74.9%, Aider Polyglot 88% 성능</td>
      <td style="text-align: left">컨텍스트 윈도우 최대 256k 토큰- variants: standard, mini, nano / Pro, Plus 등- verbosity, reasoning_effort API 옵션 제공</td>
    </tr>
    <tr>
      <td style="text-align: left">Gemini 2.5 Pro (Google)</td>
      <td style="text-align: left">“생각하는 라우팅” 탑재, 추론 기반 응답• WebDev Arena 등 코딩 벤치마크에서 탁월• 영상→코드, UI 자동 생성에 강점• 멀티모달 + 긴 문맥 + 노이즈 인식</td>
      <td style="text-align: left">컨텍스트 최대 1백만 토큰- Deep Think 모드 제공- 기능: 멀티모달, 오디오, 도구 연동, 스타일 제어</td>
    </tr>
    <tr>
      <td style="text-align: left">Claude (Anthropic) 최신 모델 (Opus 4.1, Sonnet 4)</td>
      <td style="text-align: left">고급 추론·코딩 능력• 긴 문맥 처리 (200k 토큰)• 확장 추론 모드와 멀티모달 지원</td>
      <td style="text-align: left">Opus 4.1: 최고 성능 모델, 복잡한 논리/코딩에 강함- Sonnet 4: 효율적이고 반응 빠름- 둘 다 텍스트+이미지 입력 가능, 200k 컨텍스트 윈도우</td>
    </tr>
  </tbody>
</table>

<p>GPT 5 의 변화 내용을 여러 시사점, 특히 다른 플랫폼들에 대해 경쟁 지점에 대한 나름의 전략들이 녹아든 개선점이 보이는 것 같아, 그만큼 괜찮은데? 싶었다. 일반 유저들 입장에선 일단 무조건 chatGPT 쓰고 본다- 의 효과를 어떻게든 더 유지하기 위함이 나름 느껴지는 개선포인트가 아니었나 생각한다. 특히나 몇 차례 5를 활용한 심층 분석 시 무엇을 위해 어떤 대상, 어떤 도구, 어떤 범위 등 자신이 해야할 일들을 단순히 ‘판단’ 하고 확신하지 않고, 한번더 물어 본 뒤 작업을 하는 것, 이후 딱 요청한 것들을 정확히 알려준다는 점은 생각 이상으로 4 버전보다 확실히 나아졌다. 오히려 기계스럽게 일을 잘한다는 느낌을 받을 수 있었다.</p>

<p>AWS Bedrock 이 현재 기업 시장에서 나름 인지도를 쌓아간다고 하고, Gemini 와 다양한 모델들, 압도적인 가성비로 Google 역시 기업시장에서 계속 입지를 다져가는 상황, 개발자들은 Claude 의 메모리 성능과 문맥 이해력, Claude Code 의 안정적인 성능 등, 어쩌면 선구자로 입지가 위태위태 하지만, 그럼에도 여전히 GPT 가 살아 있음을 호소한다는 느낌을 강하게 들었다.</p>

<p>다만 결과에 대하여 내가 쓴 경우를 제외하더라도, 다른 분들의 평가나 분석한 내용을 볼 때, 모든게 1등이냐? 라는 차원에서는 여전히 한계는 있어 보였다.</p>

<p>연속적인 이해나, 대화 내용에 대한 안정적인 이해도는 여전히 Claude 가 앞서가고 있고, Gemini 2.5 는 다소 떨어지는 부분은 있지만, 할루시네이션을 구글 검색 그라운딩과 합쳐 놓아 충분히 완성도 있게 해주었다. 토큰 허용치는 정말 타의 추종을 불허한다는 엄청난 장점을 갖고 있다. 또한 코딩 실력 역시 결과적으로 요즘 모델들이 너무 잘 만들어주는 것은 사실이지만, 결국 과거 문맥을 이해하고, 실수가 없는가! 라는 차원의 비교에선 Claude Code가 보다 안정적이었다는, 실무적 결과들을 볼 때, 가닥을 잘 따라 완성도 있게 나온 것은 사실이지만 GPT 5가 엔드 유저가 아닌 다른 유저들에게 얼마나 어필 될까? 는 고민해볼 여지가 있는 영역이라고 보인다. (물론, 링크드인의 다양한 평가들 중에선, ‘전문성’의 키워드에 대한 해결 능력은 뛰어나다는 이야기도 있었다. 즉, 복잡하고 어려운 건 오히려 잘 해낸다고 볼 수도 있을것 같다. 개발 실무 보단, 진짜 연구 개발에 가까운 영역은 호평인듯)</p>

<p>오히려 조사 과정에서 Gemini CLI + Claude Code 라는 미친 조합으로 정보 분석 + 정보 요약은 Gemini에게 시키고, 실 결과물은 Claude 를 쓰게 만드는 끔찍한 혼종을 만들어 쓰는 분들의 결과물을 봤을 때, AI 의 전쟁은 진짜 더욱 더 치열해진다는 점을 새삼 느낄 수 있었다.</p>

<h3 id="참고-문헌">참고 문헌</h3>
<ul>
  <li><a href="https://openai.com/index/introducing-gpt-5/">https://openai.com/index/introducing-gpt-5/</a></li>
  <li><a href="https://openai.com/index/introducing-gpt-5-for-developers/">https://openai.com/index/introducing-gpt-5-for-developers/</a></li>
  <li><a href="https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/">https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/</a></li>
  <li><a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/08/07/available-today-gpt-5-in-microsoft-365-copilot/">https://www.microsoft.com/en-us/microsoft-365/blog/2025/08/07/available-today-gpt-5-in-microsoft-365-copilot/</a></li>
  <li><a href="https://news.microsoft.com/source/features/ai/openai-gpt-5/">https://news.microsoft.com/source/features/ai/openai-gpt-5/</a></li>
  <li><a href="https://simonwillison.net/2025/Aug/7/gpt-5/">https://simonwillison.net/2025/Aug/7/gpt-5/</a></li>
  <li><a href="https://the-decoder.com/openai-claims-gpt-5-offers-its-best-coding-performance-yet-for-complex-programming-tasks/">https://the-decoder.com/openai-claims-gpt-5-offers-its-best-coding-performance-yet-for-complex-programming-tasks/</a></li>
  <li><a href="https://apnews.com/article/gpt5-openai-chatgpt-artificial-intelligence-d12cd2d6310a2515042067b5d3965aa1">https://apnews.com/article/gpt5-openai-chatgpt-artificial-intelligence-d12cd2d6310a2515042067b5d3965aa1</a></li>
  <li><a href="https://mashable.com/article/best-new-gpt-5-ai-features">https://mashable.com/article/best-new-gpt-5-ai-features</a></li>
  <li><a href="https://mashable.com/article/chatgpt-5-coolest-feature-vibe-coding">https://mashable.com/article/chatgpt-5-coolest-feature-vibe-coding</a></li>
  <li><a href="https://www.techradar.com/news/live/openai-chatgpt5-launch">https://www.techradar.com/news/live/openai-chatgpt5-launch</a></li>
  <li><a href="https://www.pcmag.com/news/with-gpt-5-openai-promises-access-to-phd-level-ai-expertise">https://www.pcmag.com/news/with-gpt-5-openai-promises-access-to-phd-level-ai-expertise</a></li>
  <li><a href="https://economictimes.indiatimes.com/magazines/panache/openai-introduces-chatgpt-5-features-performance-access-pricing-heres-all-you-need-to-know/articleshow/123174283.cms">https://economictimes.indiatimes.com/magazines/panache/openai-introduces-chatgpt-5-features-performance-access-pricing-heres-all-you-need-to-know/articleshow/123174283.cms</a></li>
  <li><a href="https://timesofindia.indiatimes.com/technology/tech-news/what-have-we-done-sam-altman-says-i-feel-useless-compares-chatgpt-5s-power-to-the-manhattan-project/articleshow/123112813.cms">https://timesofindia.indiatimes.com/technology/tech-news/what-have-we-done-sam-altman-says-i-feel-useless-compares-chatgpt-5s-power-to-the-manhattan-project/articleshow/123112813.cms</a></li>
  <li><a href="https://wandb.ai/byyoung3/ml-news/reports/GPT-5-Benchmark-Scores---VmlldzoxMzkwMTYyMg">https://wandb.ai/byyoung3/ml-news/reports/GPT-5-Benchmark-Scores—VmlldzoxMzkwMTYyMg</a></li>
  <li><a href="https://www.vellum.ai/blog/gpt-5-benchmarks">https://www.vellum.ai/blog/gpt-5-benchmarks</a></li>
  <li><a href="https://metr.github.io/autonomy-evals-guide/gpt-5-report/">https://metr.github.io/autonomy-evals-guide/gpt-5-report/</a></li>
  <li><a href="https://www.youtube.com/watch?v=0Uu_VJeVVfo">https://www.youtube.com/watch?v=0Uu_VJeVVfo</a></li>
  <li><a href="https://www.youtube.com/watch?v=tqPQB5sleHY">https://www.youtube.com/watch?v=tqPQB5sleHY</a></li>
  <li><a href="https://www.youtube.com/watch?v=2jqS7JD0hrY">https://www.youtube.com/watch?v=2jqS7JD0hrY</a></li>
</ul>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="학습" /><category term="ChatGPT" /><category term="OpenAI" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">AI Breakfast S2 Ep 1 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/08/06/00-AI-trend-with-google-s2-01.html" rel="alternate" type="text/html" title="AI Breakfast S2 Ep 1 생각정리" /><published>2025-08-06T00:00:00+00:00</published><updated>2025-08-06T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/06/00-AI-trend-with-google-s2-01</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/06/00-AI-trend-with-google-s2-01.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://youtu.be/Dm1V-ODwb1Q?si=aoeugkXlpHokwMNd"><img src="https://i.ytimg.com/vi/Dm1V-ODwb1Q/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>구글 I/O 2025 행사는 <strong>구글이 인공지능(AI) 분야의 주도권을 확실히 잡고 나아간다는 분위기</strong>였다.</p>

<p>이번 구글 I/O에서 가장 인상 깊었던 핵심 기술 및 발표 내용은 다음과 같다:</p>

<ul>
  <li><strong>Gemini 2.5 모델</strong>이 발표되었다. 이 모델은 <strong>Thinking 모델 기반에서 멀티모달리티를 강화한 모델</strong>이다. 기업에서 Gemini 모델을 사용할 때 더욱 정확하고 복잡한 문제를 풀 수 있을 것으로 기대된다. Gemini 2.5는 Deep research의 근간을 이루고 있으며, 복잡한 문제들을 쉽게 풀 수 있는 AI 모델이다.</li>
  <li><strong>Thinking 모델</strong>은 기존의 Instruction 모델과 달리, 한 번 더 단계적으로 추론하고 생각을 깊게 할 수 있도록 사전 학습된 모델이다. 이는 모델 훈련 과정에서 Thinking 과정을 추가하여 요청이 들어왔을 때 그 프로세스를 거치면서 답을 내도록 트레이닝된 것이다. 이를 통해 AI가 더 깊은 추론 능력을 갖게 되었다고 한다. Gemini 2.5 Pro는 LM Arena와 같은 공신력 있는 웹사이트에서 모든 영역에서 1위를 차지하며, Deep research 영역에서도 계속 상위에 올라와 있다고 언급된다.</li>
  <li><strong>Project Astra</strong>는 구글이 AI의 미래를 어떻게 이끌어갈 것인가에 대한 프로토타입 프로젝트이다. 이는 <strong>구글이 꿈꾸는 미래 AI의 모습, 즉 AGI(Artificial General Intelligence) 수준의 AI 비서</strong>를 보여준다. 사람처럼 커뮤니케이션할 수 있는 멀티모달리티 기능이 탑재되어 있다. Project Astra는 <strong>Live API</strong>를 기반으로 만들어지고 있다.</li>
  <li><strong>멀티모달리티(Multimodality)</strong>는 사람이 일반적으로 커뮤니케이션하는 방법과 동일하게 다양한 감각이나 유형의 정보를 컴퓨터가 학습하여 사고할 수 있게 만든 AI이다. 보이스, 시각(눈으로 보는 것), 텍스트, 문서 읽기 등 사람이 할 수 있는 일들을 AI가 할 수 있게 된 것이다. Gemini 2.5부터 Thinking 모델과 함께 멀티모달리티 기능이 매우 강화되었다.</li>
  <li><strong>생성형 미디어 모델들</strong>이 다양해졌다. 특히 <strong>Veo 3</strong>가 포함된 비디오 생성 모델과 Imagen을 통한 이미지 생성, 음악 생성 기능 등이 소개되었다. 이러한 미디어 제품들은 미디어 산업과 광고 분야에서 많이 활용될 것이라고 예상된다.</li>
  <li><strong>Code Assistance</strong>는 Gemini 2.5 버전을 기반으로 6월 12일에 출시되었으며, 개발자들의 반복적인 코드 작업을 해소하고 아키텍처 및 설계에 더 많은 시간을 할애할 수 있도록 도울 것이다.</li>
  <li><strong>Workspace</strong>에 다양한 AI 기술들이 도입되었다. Gmail에서 기존 메일 스레드를 참조하여 메일을 대신 작성해 주는 개인 맞춤형(personalization) 기능이 그 예시이다. 이는 AI가 어시스턴트 역할을 하는 방향으로 발전하고 있음을 보여준다.</li>
  <li><strong>ADK(AI Agent Development Kit)</strong>는 구글 넥스트 행사에서 처음 소개된 오픈 소스 프레임워크로, AI Agent 생태계를 키우고 기업들이 쉽게 Agent를 만들 수 있도록 지원하는 것을 목적으로 한다.</li>
  <li><strong>Firebase Studio</strong>는 개발자를 위한 프로토타이핑 툴로, 기존에 일주일에서 열흘 걸리던 프로토타이핑 작업을 몇 분 만에 가능하게 하여 개발자와 현업 간의 커뮤니케이션 및 생산성을 크게 향상시킬 것이다.</li>
  <li><strong>Live API</strong>는 짧은 지연 시간으로 양방향 음성 및 동영상 상호작용을 지원하며, 파운데이션 모델(예: Gemini)에 실시간 음성 및 동영상 스트리밍이 다이렉트하게 들어갈 수 있는 기술이다. 이는 사용자가 음성 명령이나 카메라를 통해 모델에 직접 정보를 전달하고 응답을 받을 수 있게 한다. Project Astra가 이 Live API를 기반으로 개발되고 있으며, 이는 미래의 일이 아니라 조만간 상용화될 것이라고 언급된다.</li>
</ul>

<p>AI의 발전 방향은 강화된 추론 능력 및 기획 능력, 멀티모달리티 및 라이브 커뮤니케이션의 진화, 그리고 온디바이스 및 오픈 소스 모델 쪽으로 진행되고 있다. 또한 AI는 헬스케어와 같은 분야에서도 데이터 분석 및 질병 패턴 파악에 큰 도움이 될 수 있으며, 개인 정보 보호(프라이버시), 컴플라이언스, 규제 등 윤리적인 측면도 매우 중요하게 다루고 있다고 한다.</p>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>WA!</p>

<p>사실 엄청난 뒷북일 수 있다. 하지만 2.5 Pro 를 아주 잘 활용하고 있고, 조만간 Gemini CLI 사용 한 것에 대한 후기도 남길 생각이지만, 2025년의 구글은 확실히 뭐가 달라도 다르다는 느낌이다.</p>

<p>TPU 사용이 가능하게 AI 를 구성하고, 플랫폼 모델을 기반으로 얼마나 다양한 프로젝트를 준비중인지, 결정적으로 API 비용이 싸다는 점을 포함하면 OpenAI가 ChatGPT 로 충격을 준 이래로 이만큼 괜찮은 업데이트가 있을까? 하는 생각이 들 정도의 충격이었다.</p>

<p>특히나 AI에 대한 노하우가 있기에 가능한 다양한 특화 서비스들은 당장 찾아보지 않았음에도, 일부 테스트만으로도 그 수준이 얼마나 괜찮은지 새삼 느꼈고, 단순히 웹 클라우드 프로바이저로 끝이 아닌, AI 를 위한 진짜 플랫폼이 되려는 의지가 확고하다는 것은 거를 타선이 없는 영역이리라 생각된다.</p>

<p>이번 내용을 기반으로 테스트 간단하게 해본 것들 중, 가장 흥미로웠던 것 두 가지를 뽑자면 다음과 같다.</p>

<ol>
  <li>AI Studio 를 활용한 Project Astra 데모 시연</li>
  <li>Firebase Studio를 활용한 진정한 딸깍(?)의 프로토타이핑</li>
</ol>

<p><img src="/assets/images/posts/2025-08/2025-08-06-001.png" alt="" /></p>
<blockquote>
  <p>캬…</p>
</blockquote>

<p>우선 AI 스튜디오에서 Stream Realtime 을 활용하면 Project Astra의 정말 기능적 데모를 써볼 수 있다. 보면 알 수 있듯 웹캠을 활용한 것인데, 확실한건 2.5 기반으로 데모시 정말 아주 빠른 반응속도로 상황을 해석하고, 표정도 읽어준다.</p>

<p>특히나 2.5 기반의 모델들은 구글의 워크스페이스, 일정이나 다양한 서비스 연동이 되는데, 이미 에이전트로 해야할 매우 큰 서비스들이 다 연결이 된다는 점에서 Project Astra 안경이 나온다면 정말 엄청난 일이 벌어지지 않을까? 솔직히 XR 보단 안경이 얼마이든 구매를 하고 싶단 생각이다(…)</p>

<p>두번째로 Firebase Studio, 요 친구도 아주 물건인데. 설명처럼 프로토 타이핑용으로 아주 제격인 서비스이다. 
서비스 자체는 대화형이라는 차원은 동일하고, 문서를 찾아보니 Project IDX 라는 구글의 웹기반 IDE 서비스 관련하던 것이 통합된 것으로 전에는 크게 신경을 쓰지 않았었는데, 이번 내용은 생각 이상이었다.</p>

<p><img src="/assets/images/posts/2025-08/2025-08-06-002.png" alt="" /></p>
<blockquote>
  <p>메인 화면</p>
</blockquote>

<p><img src="/assets/images/posts/2025-08/2025-08-06-003.png" alt="" /></p>
<blockquote>
  <p>슬쩍 프롬프트 넣어주고</p>
</blockquote>

<p><img src="/assets/images/posts/2025-08/2025-08-06-004.png" alt="" /></p>
<blockquote>
  <p>에러가 나오면 확인하고 처리를 하거나 하면 된다. API 키가 없어서 에러가 났다. 하지만 요청만 하면…</p>
</blockquote>

<p><img src="/assets/images/posts/2025-08/2025-08-06-005.png" alt="" /></p>
<blockquote>
  <p>적당히 수정해서, 기다리면 찰떡같이 알아 먹곤 프로토 웹 데모를 보여준다.</p>
</blockquote>

<p>5분 걸렸을까? 기초적인 기능 구현에서 이정도면 충분하게 동작하고, 무엇보다 대중적인 기술로 쉽게 구현 + 바로바로 에러 핸들링, 수정 결과까지 이정도 생산성의 증대는 과연 누가 생각이나 했을까? 기존의 IDX 프로젝트 때는 실질적으로 IDE 를 굳이 바꿔야 하나? 클라우드로 불편하게? 라는 의구심이 들었다면, 이정도라면 프로토타입을 만들기 위해 구태여 내가 AI 를 쓸 이유가 있을까?</p>

<p>물론 gemini-cli 를 활용한다는 건 로컬 환경에서 굉장히 효과적인 사용이 가능한 것은 맞다. 하지만 불편함이 없냐? 하면 사실 충분히 있다. MCP 의 연결이나, 세팅 등, 여러 면에서 번거롭게 일을 수행할 이유 보단 철저하게 ‘딸깍’을 하고 나온 내용을 스스로 분석하고 해석하는게 빠르지 않을까?</p>

<p><img src="/assets/images/posts/2025-08/2025-08-06-006.png" alt="" /></p>
<blockquote>
  <p>기존에 써보게 되었든 ‘스티치 AI’ 디자인용 AI 다</p>
</blockquote>

<p>기존 스티치 AI 라는 웹 퍼블리싱, 웹 디자인을 위한 툴이 있었는데 이것만으로도 훌륭했지만, 이젠 정말 에이전트의 개념이 충분히 녹아든 서비스가 나오며, 그걸 활용할 줄 아냐 모르느냐의 차이는 명백한 생산성, 무엇보다 기본 실력과 경험의 차이를 이끌 수 있겠다.</p>

<p>내가 필요한 서비스를 만들거나, 내가 필요한 기능을 구체화 한다. 거기서 핵심은 ‘내가 필요한’ 것이 아닌 것들을 AI에게 맡긴다면, 나는 내가 원하는 수준의 내 도메인을 위한 필요에 따른 스킵, 빠른 진행을 가능케 만들 수 있다는 것이다…. 진짜 멈춰 있을 틈이 없을 것 같다.</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">python AI 개발환경 설정(가상환경) + Jupyter lab (colab)</title><link href="http://0.0.0.0:4000/ai/2025/08/06/01-setting-python-for-ai-study.html" rel="alternate" type="text/html" title="python AI 개발환경 설정(가상환경) + Jupyter lab (colab)" /><published>2025-08-06T00:00:00+00:00</published><updated>2025-08-06T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/06/01-setting-python-for-ai-study</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/06/01-setting-python-for-ai-study.html"><![CDATA[<h2 id="python-ai-개발-환경-구축-로컬uv-vs-클라우드colab">Python AI 개발 환경 구축: 로컬(uv) vs. 클라우드(Colab)</h2>

<h3 id="1-개요">1. 개요</h3>

<p>이 문서는 파이썬 AI 개발을 위한 두 가지 주요 환경 구축 방법을 정리한 것이다. 첫 번째는 <code class="language-plaintext highlighter-rouge">uv</code>를 활용해 개인 PC에 구축하는 <strong>로컬(Local) 환경</strong>의 핵심 도구인 <strong>JupyterLab</strong>이고, 두 번째는 별도 설치가 필요 없는 <strong>클라우드(Cloud) 환경</strong>인 <strong>Google Colab</strong>이다. 각 환경의 개념과 특징을 이해하여 상황에 맞는 최적의 도구를 선택하고 활용하는 것을 목표로 한다.</p>

<hr />

<h3 id="2--로컬-개발-환경-uv--jupyterlab">2. 🚀 로컬 개발 환경 (<code class="language-plaintext highlighter-rouge">uv</code> + JupyterLab)</h3>

<h4 id="가-jupyterlab-이란">가. JupyterLab 이란?</h4>

<p><strong>JupyterLab</strong>은 웹 브라우저에서 실행되는 **통합 개발 환경(IDE)**이다. 단순히 코드를 작성하고 실행하는 노트북(<code class="language-plaintext highlighter-rouge">ipynb</code>) 기능을 넘어, 파일 탐색기, 터미널, 텍스트 편집기 등 데이터 과학 작업에 필요한 여러 도구를 하나의 작업 공간에 통합하여 제공한다.</p>

<blockquote>
  <p><strong>쉽게 비유하자면,</strong> JupyterLab은 데이터 과학자를 위한 **‘디지털 작업실’**과 같다. 작업실 안에서 코드가 담긴 노트북, 각종 데이터 파일, 명령어 창을 한눈에 펼쳐놓고 유기적으로 오가며 전체 프로젝트를 관리할 수 있는 유연한 공간이다.</p>
</blockquote>

<h4 id="나-로컬-환경-도구로-uv를-선택한-이유">나. 로컬 환경 도구로 <code class="language-plaintext highlighter-rouge">uv</code>를 선택한 이유</h4>

<p>전통적인 <code class="language-plaintext highlighter-rouge">conda</code>나 <code class="language-plaintext highlighter-rouge">pip</code>+<code class="language-plaintext highlighter-rouge">venv</code> 조합 대신 <code class="language-plaintext highlighter-rouge">uv</code>를 선택한 이유는 <strong>속도와 간결함</strong>을 통해 현대적이고 효율적인 개발 환경을 구성하기 위함이다.</p>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">uv</code>의 핵심 장점</strong>:
    <ol>
      <li><strong>압도적인 속도</strong>: <code class="language-plaintext highlighter-rouge">uv</code>는 Rust로 작성되어 기존 <code class="language-plaintext highlighter-rouge">pip</code>이나 <code class="language-plaintext highlighter-rouge">conda</code> 대비 수십 배에서 수백 배 빠른 패키지 설치 및 의존성 해결 속도를 보여준다. 기다리는 시간을 극적으로 줄여준다.</li>
      <li><strong>통합된 도구</strong>: 가상 환경 생성(<code class="language-plaintext highlighter-rouge">venv</code>)과 패키지 설치(<code class="language-plaintext highlighter-rouge">pip</code>) 기능을 <code class="language-plaintext highlighter-rouge">uv</code> 명령어 하나로 통합하여 관리의 복잡성을 낮춘다.</li>
      <li><strong>간결함과 표준</strong>: 파이썬 표준 패키지 인덱스(PyPI)를 사용하면서도 미니멀하고 빠른 환경 구축을 가능하게 한다.</li>
    </ol>
  </li>
</ul>

<h4 id="다-환경-구축-절차-uv-활용">다. 환경 구축 절차 (<code class="language-plaintext highlighter-rouge">uv</code> 활용)</h4>

<ol>
  <li><strong>Python 3.9 설치 (사전 조건)</strong>
Homebrew를 통해 특정 버전의 파이썬을 설치한다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>python@3.9
</code></pre></div>    </div>
  </li>
  <li><strong><code class="language-plaintext highlighter-rouge">uv</code> 가상 환경 설정</strong>
프로젝트 폴더를 생성 후, <code class="language-plaintext highlighter-rouge">uv</code>로 Python 3.9 기반의 가상 환경(<code class="language-plaintext highlighter-rouge">.venv</code>)을 만든다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir </span>my-local-project <span class="o">&amp;&amp;</span> <span class="nb">cd </span>my-local-project
uv venv <span class="nt">--python</span> 3.9
<span class="nb">source</span> .venv/bin/activate
</code></pre></div>    </div>
  </li>
  <li><strong>JupyterLab 설치 및 실행</strong>
활성화된 가상 환경 내에서 <code class="language-plaintext highlighter-rouge">uv pip</code>으로 JupyterLab을 설치하고 실행한다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>uv pip <span class="nb">install </span>jupyterlab
jupyter lab
</code></pre></div>    </div>
  </li>
</ol>

<h4 id="라-주요-단축키">라. 주요 단축키</h4>

<p>Jupyter의 작업 효율은 <strong>명령 모드</strong>와 <strong>입력 모드</strong>의 이해에서 시작된다.</p>

<ul>
  <li><strong>명령 모드 (Command Mode)</strong>: 셀 테두리가 <strong>파란색</strong>. 셀 자체를 하나의 블록 단위로 다룬다. (<code class="language-plaintext highlighter-rouge">Esc</code>로 진입)</li>
  <li><strong>입력 모드 (Edit Mode)</strong>: 셀 테두리가 <strong>초록색</strong>. 셀 내부에 코드를 입력하고 수정한다. (<code class="language-plaintext highlighter-rouge">Enter</code>로 진입)</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: left">기능</th>
      <th style="text-align: left">단축키 (Win/Linux: Ctrl)</th>
      <th style="text-align: left">설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">**(필수) 셀 실행**</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Shift + Enter</code></td>
      <td style="text-align: left">현재 셀 실행 후, 아래 셀로 이동한다.</td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Cmd + Enter</code></td>
      <td style="text-align: left">현재 셀 실행 후, 커서는 그대로 유지된다.</td>
    </tr>
    <tr>
      <td style="text-align: left">**셀 추가**</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">A</code> (명령 모드)</td>
      <td style="text-align: left">현재 셀 **위에** 새 셀을 추가한다.</td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">B</code> (명령 모드)</td>
      <td style="text-align: left">현재 셀 **아래에** 새 셀을 추가한다.</td>
    </tr>
    <tr>
      <td style="text-align: left">**셀 관리**</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">D, D</code> (명령 모드)</td>
      <td style="text-align: left">현재 셀을 삭제한다. (D를 두 번 누름)</td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">X</code> / <code class="language-plaintext highlighter-rouge">C</code> / <code class="language-plaintext highlighter-rouge">V</code> (명령 모드)</td>
      <td style="text-align: left">셀을 잘라내기 / 복사 / 붙여넣기 한다.</td>
    </tr>
    <tr>
      <td style="text-align: left">**셀 타입 변경**</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">M</code> (명령 모드)</td>
      <td style="text-align: left">셀을 마크다운 타입으로 변경한다.</td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Y</code> (명령 모드)</td>
      <td style="text-align: left">셀을 코드 타입으로 변경한다.</td>
    </tr>
    <tr>
      <td style="text-align: left">**코드 편집**</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Cmd + /</code> (입력 모드)</td>
      <td style="text-align: left">선택한 코드 라인을 주석 처리/해제한다.</td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Shift + Tab</code> (입력 모드)</td>
      <td style="text-align: left">함수 괄호 안에서 함수의 설명(Docstring)을 본다.</td>
    </tr>
  </tbody>
</table>

<hr />

<h3 id="3-️-클라우드-개발-환경-google-colaboratory">3. ☁️ 클라우드 개발 환경 (Google Colaboratory)</h3>

<h4 id="가-google-colab-이란">가. Google Colab 이란?</h4>

<p>**Google Colaboratory(Colab)**는 구글이 제공하는 <strong>클라우드 기반의 무료 Jupyter Notebook 환경</strong>이다. 모든 연산이 구글의 서버에서 이루어지므로 별도의 설치 과정 없이 웹 브라우저만으로 강력한 개발 환경을 이용할 수 있다.</p>

<blockquote>
  <p><strong>쉽게 비유하자면,</strong> Colab은 **‘구글이 제공하는 고사양 컴퓨터를 인터넷을 통해 무료로 빌려 쓰는 것’**과 같다. 내 컴퓨터 사양과 무관하게 딥러닝 모델을 학습시킬 수 있는 것이 최대 장점이다.</p>
</blockquote>

<ul>
  <li><strong>핵심 장점</strong>:
    <ul>
      <li><strong>설치 불필요 (Zero Setup)</strong>: 웹 브라우저와 구글 계정만 있으면 즉시 사용 가능하다.</li>
      <li><strong>무료 GPU/TPU 제공</strong>: 딥러닝 등 고사양 연산에 필수적인 하드웨어를 무료로 제공한다.</li>
      <li><strong>쉬운 공유와 협업</strong>: 링크 하나로 노트북을 공유하고 실시간으로 함께 편집할 수 있다.</li>
    </ul>
  </li>
</ul>

<h4 id="나-주요-단축키">나. 주요 단축키</h4>

<p>Colab은 Jupyter와 많은 단축키를 공유하지만, <code class="language-plaintext highlighter-rouge">Ctrl + M</code> (macOS: <code class="language-plaintext highlighter-rouge">Cmd + M</code>) 조합을 사용하는 고유한 단축키가 많다.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">기능</th>
      <th style="text-align: left">단축키 (Win: Ctrl, Mac: Cmd)</th>
      <th style="text-align: left">설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">**(필수) 셀 실행**</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Shift + Enter</code> / <code class="language-plaintext highlighter-rouge">Cmd + Enter</code></td>
      <td style="text-align: left">Jupyter와 동일하다.</td>
    </tr>
    <tr>
      <td style="text-align: left">**셀 추가**</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Cmd + M, A</code></td>
      <td style="text-align: left">현재 셀 **위에** 새 셀을 추가한다.</td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Cmd + M, B</code></td>
      <td style="text-align: left">현재 셀 **아래에** 새 셀을 추가한다.</td>
    </tr>
    <tr>
      <td style="text-align: left">**셀 삭제**</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Cmd + M, D</code></td>
      <td style="text-align: left">현재 셀을 삭제한다.</td>
    </tr>
    <tr>
      <td style="text-align: left">**셀 타입 변경**</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Cmd + M, M</code></td>
      <td style="text-align: left">셀을 텍스트(마크다운) 타입으로 변경한다.</td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Cmd + M, Y</code></td>
      <td style="text-align: left">셀을 코드 타입으로 변경한다.</td>
    </tr>
    <tr>
      <td style="text-align: left">**명령어 팔레트**</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Cmd + Shift + P</code></td>
      <td style="text-align: left">모든 기능을 검색하고 실행할 수 있는 창을 연다.</td>
    </tr>
  </tbody>
</table>

<hr />

<h3 id="4--로컬-vs-클라우드-언제-무엇을-쓸까">4. 💡 로컬 vs. 클라우드: 언제 무엇을 쓸까?</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: left">구분</th>
      <th style="text-align: left">**로컬 환경 (<code class="language-plaintext highlighter-rouge">uv</code> + JupyterLab)**</th>
      <th style="text-align: left">**클라우드 환경 (Google Colab)**</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">**초기 설정**</td>
      <td style="text-align: left">**필요** (Python, uv, 라이브러리 설치)</td>
      <td style="text-align: left">**불필요** (웹 브라우저로 접속하면 끝)</td>
    </tr>
    <tr>
      <td style="text-align: left">**성능**</td>
      <td style="text-align: left">내 PC 사양에 의존</td>
      <td style="text-align: left">**무료 GPU/TPU 제공** (고성능)</td>
    </tr>
    <tr>
      <td style="text-align: left">**인터넷 연결**</td>
      <td style="text-align: left">오프라인 작업 가능</td>
      <td style="text-align: left">**필수**</td>
    </tr>
    <tr>
      <td style="text-align: left">**파일 관리**</td>
      <td style="text-align: left">자유롭고 빠름 (로컬 파일 시스템)</td>
      <td style="text-align: left">구글 드라이브 연동 또는 업로드/다운로드 필요</td>
    </tr>
    <tr>
      <td style="text-align: left">**적합한 작업**</td>
      <td style="text-align: left">- 인터넷이 없는 환경에서의 작업&lt;br&gt;- 맞춤형 환경 구축&lt;br&gt;- 가벼운 데이터 분석 및 스크립팅</td>
      <td style="text-align: left">- **딥러닝 모델 학습**&lt;br&gt;- 빠른 프로토타이핑&lt;br&gt;- 팀원과의 코드 공유 및 협업</td>
    </tr>
  </tbody>
</table>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="학습" /><category term="Python" /><category term="Jupyter-lab" /><category term="colab" /><category term="google" /><category term="UV" /><summary type="html"><![CDATA[Python AI 개발 환경 구축: 로컬(uv) vs. 클라우드(Colab)]]></summary></entry><entry><title type="html">AI Breakfast Ep 11 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/08/05/00-AI-trend-with-google-11.html" rel="alternate" type="text/html" title="AI Breakfast Ep 11 생각정리" /><published>2025-08-05T00:00:00+00:00</published><updated>2025-08-05T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/05/00-AI-trend-with-google-11</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/05/00-AI-trend-with-google-11.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=P7TzvAJ6n_w"><img src="https://i.ytimg.com/vi/P7TzvAJ6n_w/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>이번 내용은 AI와 대규모 언어 모델(LLM)이 코딩 및 개발자 역할에 미치는 영향, 그리고 현재의 한계와 미래 전망에 대한 논의이다.</p>

<ul>
  <li><strong>대규모 언어 모델(LLM)과 코딩의 미래</strong>:
    <ul>
      <li>LLM은 기존 자연어 처리(NLP) 솔루션과 달리 <strong>단일 모델로 다양한 NLP 작업을 수행할 수 있으며</strong>, 수 테라바이트의 레이블 없는 데이터로 학습된 <strong>기초 모델</strong>이다.</li>
      <li>현재의 구조화된 프로그래밍 언어는 LLM에 비적합하며, 미래에는 <strong>자동 회귀(auto-regressive) 방식으로 한 줄씩 진화하는 새로운 프로그래밍 언어가 등장할 수 있다</strong>고 예상된다. 이는 토큰 사용량을 대폭 줄일 것이다. =&gt; 이 인사이트는 염두해 둬야 하는, 어쩌면 개선해야할 AI 영역일 것임.</li>
      <li>LLM은 언어를 ‘이해’하는 것이 아니라 학습된 패턴을 기반으로 <strong>다음에 올 가장 확률 높은 토큰을 예측하는 정교한 수학적 함수</strong>이며, 트랜스포머 아키텍처와 어텐션 메커니즘을 사용한다.</li>
    </ul>
  </li>
  <li><strong>개발자의 역할 변화와 비즈니스 영향</strong>:
    <ul>
      <li>먼 미래에는 개발자 직업이 사라질 수 있다는 예측에 동의하며, 5년 이내에도 개발 인력이 크게 줄어들 수 있다고 보았다.</li>
      <li>LLM은 개발자의 <strong>생산성을 10배 이상 향상</strong>시켜, 개발자가 기획보다 빠르게 결과물을 내놓는 시대로 전환시키고 있다.</li>
      <li>코딩은 상품화를 위한 중간 과정이며, <strong>AI를 통해 대체 가능한 부분</strong>으로 여겨진다.</li>
      <li>앞으로는 큰 도메인 지식을 갖춘 <strong>‘빅픽처 전문가’ 또는 ‘프로덕트 엔지니어’가 중요</strong>해질 것이며, AI에게 명확한 요구사항을 전달하는 능력이 핵심이다.</li>
      <li>비개발자들도 코딩에 참여하는 <strong>개발의 ‘민주화’ 현상</strong>이 나타나고 있다.</li>
      <li><strong>인간과 기술은 공존해야 하며</strong>, AI를 받아들이고 경험하는 정도가 개인의 대체 여부를 결정하는 중요한 요소이다.</li>
    </ul>
  </li>
  <li><strong>바이브 코딩의 실제 적용과 한계</strong>:
    <ul>
      <li>바이브 코딩은 <strong>빠르게 데모를 만들고 결과물을 검증하는 데 효과적</strong>이다.</li>
      <li>그러나 <strong>보안이 매우 취약할 수 있어</strong> 금융 등 중요한 분야에서는 도입에 거부감이 크다.</li>
      <li>큰 범위의 프로젝트에는 아직 적용하기 어렵다.</li>
      <li>AI가 생성한 코드는 방대하여 인간이 리뷰하기 어렵고, <strong>AI 생성 코드에 대한 신뢰도가 아직 높지 않다</strong>.</li>
      <li>LLM의 한계로 인해 복잡한 문제 해결 시에는 <strong>인간이 직접 고치는 것이 더 빠르다</strong>.</li>
      <li>LLM은 학습된 지식 내에서만 작동하며 <strong>메타인지 능력이 부족하여 새로운 지식에 대한 업데이트나 함수 생성에 어려움</strong>이 있다.</li>
      <li>정확한 결과물을 얻기 위해서는 <strong>요구사항을 아주 세분화하여 명확하게 설계하고, 테스트를 잘 작성하는 능력</strong>이 중요해졌다.</li>
      <li>생성된 코드를 다시 설계 문서 등으로 <strong>‘리버스 엔지니어링’하여 저장하고 관리하는 방식</strong>이 활용될 수 있다.</li>
      <li>사용자는 <strong>‘프롬프트 문해력’을 길러야</strong> 하며, 생성된 결과를 올바르게 이해하고 검증해야 한다. =&gt; 결국 프롬프트 문해력이란것이 무엇인가? 프롬프트를 잘 작성한다는 게 무엇인가? 를 이해해야 한다.</li>
    </ul>
  </li>
  <li><strong>결론 및 시사점</strong>:
    <ul>
      <li>LLM 시대에는 <strong>인간의 도메인 지식과 노하우, 그리고 비판적 사고가 더욱 중요</strong>해지며, LLM의 명확한 한계를 인지하고 이를 보완하는 것이 필요하다.</li>
      <li>개개인은 <strong>‘언어의 경계가 곧 세계의 경계’라는 철학자의 말처럼</strong>, 어떤 언어(프롬프트)를 구사하느냐에 따라 자신의 가능성이 달라지므로, <strong>무한히 도전해 볼 것</strong>이 권장된다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>Gemini 의 성능을 약간 보여주는 화 같아서(물론 그래도 잘 만들긴 하더라 ㅋㅋ), 핵심적인 내용들, 개발자로 가져야 하는 태도에 대해 다시 한번 생각해본 시간이었다.</p>

<p>여전히 한계로 지적되는 부분, 즉 구조적으로 현 AI 는 코딩을 하기에 효율적인 도구가 아니고, ‘효율적인 척’ 하면서 GPU 를 녹이고 있다는 사실을 다시 한 번 강조했다.</p>

<p>생각해보면 그정도로 자기 회귀적으로 진행되는 구조로 가는 건 어쩌면 모든 점에서 더 나을 건데, 과연 그런 형태의 예측이나, 알고리즘 개선이 되는지는 잘 모르겠다는 생각이 든다. (수알못이라…)</p>

<p>어쨌든 모델의 개선도 지속적으로 이루어지고 있으니, 어쩌면 그러한 부분까지 언젠가는 개선이 되지 않을까 하는 생각은 해본다. 메타가 거의 백억단위 연봉을 주며 개발자를 데려가고 AGI 그 이상의 초 인공지능을 만들겠다고 하니, 결국 AI 는 양과 질의 향상이 계속 될 것은 맞고, 그런걸 실현 가능한 사람이 되는게 1티어 급 인사가 되는 길이 아닐까?</p>

<p>어쨌든, 일단 현 개발자라는 차원에서 본다면 사용 방법에 대해, 내 방법이 틀린게 아니었구나 ~ 하는 생각이 들었다.</p>

<p>무조건 맡기는 식으론 매우 위험하고, MVP 그 이상으로 빠르게 구현이 되지만 보안의 문제는 확실하게 존재한다. 더불어 회사가 그걸 용인해주는 곳인가? 여러 면에서 편리함, 효용성에 +로 고려할 것을 미리미리 고려하는 것은 매우 중요한 부분이라고 생각된다.</p>

<p>어쩌면 나만의 검증 절차를 AI 로 체계화 하는 것, 그리고 그걸 내 작업 루틴에 넣는 것이 포함되면 좋지 않을까? 하는 생각을 하게 된다. 그리고 그걸 종합해서 적절하게 코드 리포트 형태로 만든다거나 하는 것도 괜찮지 않을까?</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI는 집에서 만들지 말고 사서 쓰세요 | 스케일링 법칙</title><link href="http://0.0.0.0:4000/ai/2025/08/05/01-do-not-make-ai.html" rel="alternate" type="text/html" title="AI는 집에서 만들지 말고 사서 쓰세요 | 스케일링 법칙" /><published>2025-08-05T00:00:00+00:00</published><updated>2025-08-05T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/05/01-do-not-make-ai</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/05/01-do-not-make-ai.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=QkPeMzr3Qz4"><img src="/assets/images/posts/2025-08/2025-08-05-001.png" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>인공지능(AI) 발전의 핵심 원동력 중 하나는 <strong>‘스케일링 법칙(Scaling Laws)’</strong>이며, 이 법칙은 AI 모델의 성능이 <strong>연산량(Compute), 모델 크기(Model Size), 데이터 크기(Data Size)</strong>의 세 가지 핵심 요소에 따라 일정한 패턴으로 예측 가능하게 변화하는 원리이다.</p>

<h3 id="1-스케일링-법칙의-발견과-핵심-개념">1. 스케일링 법칙의 발견과 핵심 개념</h3>

<ul>
  <li><strong>성능의 한계와 최적의 경계선(Compute Optimal Frontier)</strong>: AI 모델을 훈련할 때 처음에는 오류(Loss)가 급격히 줄지만, 어느 순간부터는 더 이상 줄지 않는다. 모델 크기를 키우면 오류는 더 줄지만 그만큼 더 많은 연산이 필요하다. 로그 스케일로 보면 모델 크기를 늘려도 넘어설 수 없는 명확한 선이 보이는데, 이것을 <strong>‘최적의 경계선’</strong>이라고 부른다. 스케일링 법칙은 AI 성능이 연산량, 모델 크기, 데이터 크기에 따라 일정하게 줄어드는 것을 보여준다.</li>
  <li><strong>OpenAI의 발견 (2020년)</strong>: OpenAI는 2020년 논문을 통해 언어 모델 성능에 일정한 패턴이 있음을 발견했으며, 성능이 컴퓨팅 파워, 데이터 크기, 모델 크기에 따라 일정하게 감소함을 확인했다. 이 패턴은 아주 큰 스케일에서도 동일하게 적용된다는 것을 깨달았다. 가장 큰 테스트 모델은 15억 개의 파라미터를 가졌고 약 10 페타플롭/일의 계산 능력이 필요했다.</li>
  <li><strong>오류 측정: 크로스 엔트로피(Cross-Entropy)</strong>:
    <ul>
      <li>GPT-3와 같은 언어 모델은 이전 단어들을 받아 다음 단어나 단어의 조각을 예측하는 방식으로 학습된다. 다음에 올 단어들의 확률을 예측하는데, 이 값들은 ‘소프트맥스’ 과정을 거쳐 모든 확률의 합이 1이 되도록 조정된다. 참고로 GPT-3는 사용할 어휘를 총 52,571개 단어로 미리 구성했다.</li>
      <li>훈련 과정에서 모델의 예측이 실제 정답과 얼마나 일치하는지 <strong>‘로스(Loss)’</strong> 값을 계산하는데, 이 로스 값을 줄이는 것이 비싼 GPU들이 하는 핵심 작업이다.</li>
      <li>일반적으로 L1 로스보다 <strong>‘크로스 엔트로피’</strong>라는 로스 함수를 더 자주 사용한다. 크로스 엔트로피는 모델이 예측한 확률값에 로그를 씌우고 음수로 바꿔 계산하는데, 모델의 예측이 정답과 다를수록 로스값이 훨씬 빠르게 증가하여 더 많은 페널티를 부여한다.</li>
      <li>우리가 보는 성능 그래프는 대부분 테스트셋에서 측정한 평균 크로스 엔트로피 값으로, 모델이 다음 단어를 더 높은 확률로 맞출수록 평균 크로스 엔트로피는 0에 가까워지며 이는 모델이 더 똑똑해진다는 것을 의미한다.</li>
    </ul>
  </li>
  <li><strong>자연어의 엔트로피와 성능의 한계</strong>: 모델이 똑똑해져도 로스(오류)가 0이 되지 않는 이유는 주어진 문장에서 다음에 올 단어가 실제로 여러 개 있을 수 있기 때문이고, 그것 모두 정답이 될 수 있다. 이러한 특성을 <strong>‘자연어에서의 엔트로피’</strong>라고 부른다.
    <ul>
      <li>OpenAI 내부적으로 이러한 내용에 대해 언급이 이루어지고, Google 딥마인드 팀이 언어에서의 성능 한계를 예측할 수 있는 단서를 내놓았고, 이를 통해 언어에서도 모델과 데이터 크기에 따라 성능을 예측할 수 있는 스케일링 법칙을 크로스 엔트로피 상수항 <strong>1.69</strong>를 포함해 완성할 수 있었다. 이는 아무리 모델을 키우고 데이터를 늘려 훈련해도 크로스 엔트로피 로스를 결국 1.69 이상 낮출 수 없다는 것을 발견하게 된 것이었다.</li>
    </ul>
  </li>
</ul>

<h3 id="2-llm-개발과-투자의-지형-변화">2. LLM 개발과 투자의 지형 변화</h3>

<ul>
  <li><strong>막대한 투자와 예측의 중요성</strong>: OpenAI는 GPT-3 훈련에 1,750억 개의 파라미터와 3,640 페타플롭/일의 연산이 필요했으며, 훈련용 GPU 가격만 한화 약 1,400억 원 가량이 필요했다. GPT-4는 그보다 5배가 넘는 20만 페타플롭/일의 연산을 사용했고, A100 GPU 25,000개를 석 달 동안 사용하며 GPU 가격만 6,000억 원이 넘게 들었다고 알려졌다.</li>
  <li><strong>투자의 정당성 확보</strong>: 스케일링 법칙은 이처럼 막대한 자본 지출(CapEx)을 하기 전에 모델의 성능 향상 정도를 <strong>정확히 예측</strong>할 수 있게 해주었다. 2020년 초 10^-8 페타플롭/일 규모에서 GPT-4의 20만 페타플롭/일까지 약 13자리가 넘는 차이에서도 정교하게 작동하는 스케일링 법칙이 이러한 투자를 가능하게 했다. OpenAI는 GPT-4 훈련을 위해 약 1,400억 원 이상을 투자하기 전 조그만 실험들을 돌려 그만큼 투자했을 때 얼마나 성능을 뽑을 수 있는지 먼저 확인했다.</li>
</ul>

<h3 id="3-스케일링-법칙의-이론적-배경-매니폴드-가설">3. 스케일링 법칙의 이론적 배경: 매니폴드 가설</h3>

<ul>
  <li><strong>고차원 데이터와 매니폴드</strong>: 머신러닝에서는 모델이 학습하는 데이터들이 어떤 ‘곡면’, <strong>‘매니폴드(Manifold)’</strong> 위에 놓인다고 가정한다. 이미지나 텍스트와 같은 주변의 모든 데이터는 이 고차원 공간의 한 점들로 생각할 수 있다. 예를 들어, 28x28 크기의 손글씨 이미지들도 각 위치를 축으로 하는 784차원 공간의 점으로 생각할 수 있다. 하지만 이 거대한 고차원 공간의 대부분은 <code class="language-plaintext highlighter-rouge">손글씨 숫자와 전혀 무관</code>하며, <code class="language-plaintext highlighter-rouge">무작위로 공간의 점을 선택하면 의미 없는 노이즈</code>일 뿐이다.</li>
  <li><strong>차원 축소와 매니폴드의 중요성</strong>: AI 모델의 학습은 고차원의 데이터를 알기 쉽고 의미 있는 저차원의 공간으로 이동시키는 과정이다. 매니폴드는 단순히 데이터의 차원을 줄이는 것 이상의 의미를 가지는데, 바로 이 매니폴드의 기하 구조 자체가 데이터를 설명하는 중요한 정보를 담고 있기 때문이다. 비슷한 이미지나 개념을 가진 단어가 매니폴드 위에서 서로 가까워지는 것을 확인할 수 있다.</li>
  <li><strong>데이터 밀도와 오류 예측</strong>: 매니폴드 가설에 따르면 모델은 고차원 공간의 훈련 데이터를 매니폴드 위에 점으로 옮기는 학습을 한다. 훈련 데이터가 매니폴드 위에 얼마나 촘촘하게 분포하는지는 데이터의 양과 매니폴드의 차원에 따라 달라지며, 차원이 높을수록 같은 데이터 개수에도 포인트 간 거리가 멀어져 ‘듬성듬성’해진다.</li>
  <li><strong>해상도 제한 스케일링</strong>: 테스트할 점에서 생길 오류는 해당 점으로부터 가장 가까운 훈련 점의 거리보다 커질 수 없다. 모델이 훈련 데이터를 완벽하게 학습했다고 가정하면, 훈련된 데이터 지점에서만큼은 오차 없이 실제 데이터의 매니폴드를 정확하게 맞출 것이다. AI 모델은 훈련 포인트들을 선형적으로 보간하여 <code class="language-plaintext highlighter-rouge">보지 않은 지점도 예측한다고</code> 볼 수 있다. 매니폴드가 충분히 매끄럽다고 가정하면 오류는 가장 가까운 훈련 포인트와 테스트 포인트 간의 거리의 제곱에 비례하며, 최종적으로 오류는 데이터셋 크기(D)의 마이너스 (매니폴드 차원 d / 4) 제곱에 비례한다. 이것을 <strong>‘해상도 제한 스케일링’</strong>이라고 부르는데, 데이터가 많을수록 데이터 매니폴드를 더 선명하게 볼 수 있음을 뜻한다.</li>
  <li><strong>이론과 실제의 일치</strong>: 흥미로운 점은 데이터 차원뿐만 아니라 모델 크기로 수식을 만들어도 똑같이 거듭제곱에 4가 들어간다는 것이다. OpenAI는 2020년 논문에서 크로스 엔트로피 로스가 데이터셋 크기의 -0.095제곱에 비례한다고 발표했는데, 이론대로라면 이 값은 데이터 차원의 최소 네 배 이상이어야 한다. 자연어의 고유 차원은 약 42 정도로 계산되지만, 실제 언어 모델이 학습한 매니폴드의 고유 차원은 약 100 정도로 훨씬 높게 나왔다. 이는 이론적으로는 문제없는 범위에 놓이지만, 자연어에서는 합성 및 작은 데이터셋에서만큼 정확히 맞추지 못했다고 볼 수도 있다. 따라서 지금까지 설명한 이론은 잘 작동하지만, 아직 AI를 완벽히 통합할 만한 이론이라고 보기엔 이르다는 평가다.</li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>LLM의 배경지식을 위하여 AI 에 대한 좋은 영상들을 계속해서 보고, 학습하고 있다. 아직 실질적인 학습까진 아니긴하지만, 어쨌든 기존에 겉핧기로 이해하던 영역을 좀더 구체화하여 이해하고, 이 복잡하고 큰 AI 라는 영역에 대해 어떻게 투자하고, 어떻게 가이드를 잡는지에 대해 저렇게 수학적, 수치적으로 나타내는 것. 그리고 거기까지 앞서가는 이들이 있다는 생각을 하게 되니, 정말 세상이 미친듯이 빠르게 돌아가고 있구나를 새삼 느꼈다.</p>

<p>또한 동시에, 결국 수학적 방식을 통해 저러한 수치적 한계점이 나온다는 것이, 단순한 한계점이 아니라, 오히려 투자를 왜 그렇게 해야만 하는가를 나타내는 시각은 매우 신선한 영역이었다고 생각한다.</p>

<p>동시에, 왜 죽기살기로 거대한 규모를 만들어야 하고, 소버린 AI 라는 차원으로 뭔가 해보려고 하는 국내 업체들에 대한 요최근의 뉴스를 보면 시사하는 지점이 많다는 생각을 하게도 된다.</p>

<p>여담이지만 해당 유튭 내용은 정말 하나하나 엄청나게 주옥같은 내용이라, 엄청나게 도움이 된다고 느낀다…</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="LLM" /><category term="학습" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">난 글로벌 인재일까?</title><link href="http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/05/02-what-is-global-power-to-man.html" rel="alternate" type="text/html" title="난 글로벌 인재일까?" /><published>2025-08-05T00:00:00+00:00</published><updated>2025-08-05T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/05/02-what-is-global-power-to-man</id><content type="html" xml:base="http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/05/02-what-is-global-power-to-man.html"><![CDATA[<h2 id="들어가면서">들어가면서</h2>
<p>나는 글로벌 회사에 들어가서 살아남을 만한 인재일까?</p>

<p>경험도 있고,</p>

<p>영어도 좀 하고,</p>

<p>무엇보다 지금까지의 과정을 통해 결과를 만들어 내왔다는 내 자신감을 보여줄 수 있다고 나 스스로 생각한다.</p>

<p>물론 아직 부족해서 한참 남았지만 (….)</p>

<p>정말 제대로 하고 싶은일을 한다면 행복할까?</p>

<p>그런 생각을 하던 도중, 유튭에 괜찮은 영상이 있어, 참고용으로 생각되어 정리해보았다.</p>

<h2 id="요약">요약</h2>
<p>본 내용은 황성현 교수님의 경험, 생각을 ‘지식 인사이드’ 라는 유튜브 채널에 나와서 공유한 내용에 대해 요약한 것이다.</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=bn9nhe7w9xc">영상 보러가기 - 직급을 없앤다며 영어 이름 쓰는 회사들의 공통점 지식인초대석 EP.49 (황성현 교수 1부)</a></li>
  <li><a href="https://www.youtube.com/watch?v=-TYSiaWpIB4">영상 보러가기 - 전 구글 인사담당자가 면접에서 반드시 물어보는 질문 지식인초대석 EP.50 (황성현 교수 2부)</a></li>
</ul>

<h3 id="1-구글의-채용-기준-및-인재상">1. 구글의 채용 기준 및 인재상</h3>
<ul>
  <li>구글은 채용 시 <strong>네 가지 명확한 기준</strong>을 가지고 있다.
    <ul>
      <li><strong>GCA (General Cognitive Ability)</strong>: 문제 해결 역량으로, 방대한 정보 속에서 문제의 핵심을 찾아내고 해결하는 능력이다. 과거에는 좋은 학교 출신이 이를 잘할 것이라는 가설이 있었으나, 5년 후에는 그렇지 않다는 것을 깨달았다.</li>
      <li><strong>RRK (Role-Related Knowledge and Experience)</strong>: 업무 관련 지식과 경험, 즉 해당 분야의 전문가인지를 본다.</li>
      <li><strong>리더십</strong>: 일반적인 회사에서 임원급에게 요구하는 리더십과 달리, 모든 직원이 사원이라도 자신이 하는 일을 주도적으로 문제 해결해야 한다는 의미이다.</li>
      <li><strong>Cultural Fit (구글리니스 Googliness)</strong>: 회사의 문화와 잘 맞는지를 의미한다. 구글리니스는 수트를 입지 않고도 진지할 수 있으며, 문제가 생기면 팔 걷어붙이고 인류를 위해 헌신할 수 있는 기운을 가진 사람을 뜻한다. 구글은 문화적으로 맞지 않으면 절대 채용하지 않으며, 심지어 18년 동안 적합한 인재를 찾지 못해 채용하지 않은 경우도 있다. 구글의 모든 직원은 ‘구글리니스’의 의미를 이해하고 있으며, 이는 입사뿐만 아니라 진급이나 평가의 잣대가 된다.</li>
    </ul>
  </li>
</ul>

<h3 id="2-구직-전략-및-경력-관리">2. 구직 전략 및 경력 관리</h3>
<ul>
  <li><strong>링크드인(LinkedIn) 활용의 중요성</strong>: 구글과 같은 글로벌 기업에 취업하려면 링크드인을 적극적으로 활용해야 한다. 채용 담당자들은 링크드인에서 지원자의 경력, 네트워크, 성과를 모두 확인하며, 최근 학습한 내용까지 기록하여 지속적으로 발전하는 모습을 보여주는 것이 중요하다.</li>
  <li><strong>패시브 캔디데이트 선호</strong>: 구글은 적극적으로 직장을 구하는 ‘액티브 캔디데이트’보다 숨어있는 ‘패시브 캔디데이트’를 선호한다. 이력서를 보낸다고 해서 구글에 채용될 확률은 0.0 몇 %에 불과하다. 준비가 완전히 되어 있다면 회사 내부 알고리즘에 의해 발견될 수 있으므로, 지원서를 보내기보다는 구글의 눈에 띄도록 스스로를 준비하는 것이 더 효과적이다. 구글 코리아도 본사와 동일한 채용 기준을 적용한다.</li>
  <li><strong>신입 및 저연차 전략</strong>: 신입사원이나 저연차는 자신을 드러낼 경력이 적어 불리할 수 있다. 한국의 이력서는 미국 대학 입학 시 요구되는 활동들이 부족하여 글로벌 시각에서 무엇을 할 수 있는지 검증이 어렵다. 따라서, 전략적으로 국내 유수 IT 기업(네카라쿠배당토: 네이버, 카카오, 라인, 쿠팡, 배달의민족, 당근, 토스)에 먼저 들어가 경력을 쌓은 후 구글로 이직하는 것도 좋은 방법이다. 인턴십을 통해 인정을 받아 신입사원으로 전환되는 경우도 있다.</li>
  <li><strong>3년 후 이력서 작성</strong>: 3년 후의 자신의 이력서를 미리 작성하고, 현재 자신의 역량과 목표하는 역량 사이의 갭(Gap)을 파악하여 이를 채워나가는 노력을 해야 한다. 막연하게 ‘가고 싶다’는 생각보다는 ‘나는 3년 후에 그곳에 가 있다’는 최면을 걸어야 한다. 이는 구글뿐만 아니라 모든 인생에 적용되는 원리이다.</li>
</ul>

<h3 id="3-기업-문화-및-인재상-차이">3. 기업 문화 및 인재상 차이</h3>
<ul>
  <li><strong>구글과 애플의 철학 차이</strong>: 구글은 개방형 철학을 가진 반면, 애플은 폐쇄형 철학을 가진 회사이다. 이러한 철학적 차이는 인재 채용에도 영향을 미친다.
    <ul>
      <li><strong>구글 인재상</strong>: 미지의 세상에 기여하고, 없던 것을 만들어내며, 본인의 창의성을 극단적으로 끌어내고 싶은 사람에게 더 적합하다. 모든 조직이 방사형으로 연결되어 있어 정보 공유가 활발하며, 모든 사람이 서로에게 피드백을 주는 문화가 있다.</li>
      <li><strong>애플 인재상</strong>: 탁월성을 끝까지 추구하고 디테일을 중요시하며, 남들에게 보여주지 않더라도 혼자서 뭔가를 만들어 내기를 잘하는 사람에게 더 맞을 수 있다. 애플은 중앙 집권적인 조직 구조를 가지며, 정보가 상위 관리자를 통해서만 전달되는 경향이 있다.</li>
    </ul>
  </li>
  <li><strong>협업 능력의 중요성</strong>: 아무리 인지적 능력과 업무 전문성이 뛰어나도 구글 문화와 맞지 않는다면(예: 협업 불가) 오래 다니기 어렵다. 구글은 천재이면서도 겸손하고 타인과 협업이 잘 되는 인재를 선호한다.</li>
  <li><strong>IT 기업의 공통 인재상</strong>: IT 기업들은 ‘무엇을 공부했는가’보다는 <strong>일하는 태도</strong>를 중요하게 본다. 역량은 지식(Knowledge), 기술(Skill), 태도(Attitude)의 세 가지 요소(KSA)로 구성되는데, 특히 일을 대하는 태도가 중요하다. 문제를 적극적으로 해결하려는 사람들이 선호된다. 일반적인 수능 공부만 한 고등학생처럼 과거에 머물러 있지 않고 봉사활동, 코딩, 소규모 창업 등 다양한 경험을 통해 능동성을 보여주어야 한다.</li>
</ul>

<h3 id="4-면접-및-이직-관련-조언">4. 면접 및 이직 관련 조언</h3>
<ul>
  <li><strong>연봉 협상</strong>: 글로벌 기업들은 경쟁자보다 적게 주지 않는다는 원칙이 있다. 이전 직장에서 적게 받았더라도 적게 주지 않으며, 연봉 질문 시에는 현재 받는 연봉의 10~20% 내외를 더 요구하는 것이 일반적이다.</li>
  <li><strong>경력 부풀리기의 위험성</strong>: 면접에서 경력을 부풀리는 것은 가장 좋지 않다. 면접관이 특정 프로젝트에서의 역할과 해결한 문제를 5번 정도 깊게 질문하면 대부분 탄로 난다. 자신이 관리만 했던 외주 프로젝트를 자신이 직접 한 것처럼 부풀리는 경우가 많지만, 이는 3번 정도 질문하면 드러난다. 하나라도 거짓이 드러나면 합격하기 어렵다.</li>
  <li><strong>면접관의 태도 변화 감지</strong>: 면접관이 지원자를 공격하듯 질문하다가 어느 순간 회사 자랑을 하기 시작하면 이는 지원자를 놓치지 않으려는 긍정적인 신호이다. 이때부터 지원자는 줄다리기를 시작해야 한다. 반대로 끝까지 회사 자랑을 하지 않고 공격적인 태도를 유지한다면 긍정적인 신호는 아니다.</li>
  <li><strong>회사 선택 전 철저한 조사</strong>: 지원하기 전에 해당 회사의 문화나 내부 진실을 알려주는 사이트들을 통해 충분히 숙지하고 공부한 후 지원해야 한다. 지원서를 무작위로 복사-붙여넣기 하는 것보다는, 회사에 대한 이해를 바탕으로 진정성 있게 작성하는 것이 중요하다.</li>
  <li><strong>이직 판단 기준</strong>: 황성현 교수는 이직을 고려하는 개인적인 세 가지 기준을 제시한다.
    <ul>
      <li><strong>자신의 성장 여부</strong>: 성장이 멈추면 연봉이 아무리 높아도 의미가 없다.</li>
      <li><strong>회사의 성장 가능성</strong>: 회사가 성장하지 못하면 개인의 성장도 한계에 부딪힌다.</li>
      <li><strong>회사에 대한 기여도</strong>: 자신이 회사에 기여하고 있는지 여부도 중요하다.
셋 중 하나라도 빨간불이 들어오면 이직을 고려해야 한다.</li>
    </ul>
  </li>
  <li><strong>평생 직업 시대</strong>: 과거의 평생 직장 개념은 사라지고 있으며, 이제는 ‘평생 직업’ 또는 그마저도 없어질 수 있는 시대이다. 50대 이상은 기존의 기득권과 직장 내 타이틀, 과거의 지식을 내려놓고 새로운 것을 받아들일 준비를 해야 한다.</li>
</ul>

<h3 id="5-조직-문화-혁신과-글로벌-리더십">5. 조직 문화 혁신과 글로벌 리더십</h3>
<ul>
  <li><strong>한국과 서구 기업 문화의 차이</strong>: 한국 조직은 보통 인사팀이 인사를 관리하는 책임을 지지만, 서구권에서는 조직의 헤드(현업 매니저)가 채용부터 퇴직까지 모든 인사를 책임진다.
    <ul>
      <li>한국의 인사팀은 채용을 한직으로 여기고 전략 없이 진행하여, 채용 이후의 온보딩 및 관리 단계에서 어려움을 겪는 경우가 많다. 이는 회사의 성장을 저해하는 요소가 된다.</li>
      <li>구글 같은 회사는 채용에 90%의 노력을 투자하여 각 분야의 천재들을 데려오기 때문에, 채용 이후의 관리가 훨씬 쉬워진다.</li>
    </ul>
  </li>
  <li><strong>한국인의 글로벌 기업 임원 승진 난관 (‘뱀부 실링’ Bamboo Ceiling)</strong>: 한국인들이 글로벌 기업에 취업하는 확률은 높아졌지만, 임원까지 올라가는 비율은 1% 미만으로 매우 낮다. 이는 하드웨어/반도체 분야와 달리 IT/딥테크 섹터에서 두드러진다.
    <ul>
      <li><strong>‘뱀부 실링’의 세 가지 원인</strong>: 구글 본사의 연구 결과, 동북아시아 사람들이 고위직으로 승진하기 어려운 세 가지 이유가 밝혀졌다.
        <ol>
          <li><strong>권위에 대한 복종 (Deference to Authority)</strong>: ‘나는 자랑스러운 아들이 되고 싶었다’와 같이 자신의 주체적인 욕구보다는 타인의 인정을 중시한다. 이로 인해 윗사람의 지시에 익숙해져 새로운 것을 만들어내는 힘이 부족하다.</li>
          <li><strong>관계 형성의 어려움 (Relationship Building)</strong>: 아시아인들은 서구인들에게 ‘능력은 뛰어나지만 차갑다’고 인식된다. 우리는 동료들 간에 ‘정’을 중시하지만, 서구권에서는 감정이나 친밀감을 명시적으로 표현해야 관계가 형성된다고 생각한다. 업무 외적인 대화(스포츠, 연예인 등)에 잘 끼지 못하고 진정한 친구가 되기 어려워, 서구인들에게는 아시아인이 ‘위협적’으로 보일 수 있다.</li>
          <li><strong>취약성 노출의 어려움 (Vulnerability)</strong>: 자신의 약점을 드러내는 것을 두려워하고 숨기려 한다. 이는 ‘큰일 난다’는 트라우마와 체면 문화와 직결되며, 자신을 감추기 위해 ‘센 척, 아는 척’을 하며 갑옷을 입는 것과 같다. 이러한 태도는 진정한 관계 형성을 방해한다.</li>
        </ol>
      </li>
    </ul>
  </li>
  <li><strong>직급 체계와 수평 문화</strong>: 직급을 없애는 시도는 좋지만, ‘직위가 없으면 수평적이 될 것’이라는 착각은 문제이다. 구글은 13단계의 세분화된 직급 체계를 가지고 있음에도 불구하고 수평적인 소통이 가능하다. 수평 조직의 목적은 사람들의 머리를 열어 아이디어가 샘솟게 하는 것이며, 직급이 없다고 해서 사수 문화가 사라지고 경쟁 관계만 남는 것은 바람직하지 않다.</li>
  <li><strong>회의 문화의 혁신</strong>: 혁신적인 기업들은 회의를 최고위급 리더가 직접 주도하며, 어젠다를 설정하고 진행한다. 이는 리더십을 보여주고 시간을 효율적으로 활용하는 기회이다. 반면, 전통적인 회사들은 회의가 단순히 지시 사항 전달의 장이 되는 경우가 많다.
    <ul>
      <li><strong>구글 슬라이드의 의도적 불편함</strong>: 구글은 MS 오피스에서 벗어나기 위한 ‘아웃 오브 오피스(Out of Office)’ 프로젝트를 통해 구글 슬라이드 사용을 강제했다. 구글 슬라이드는 의도적으로 현란한 기교를 부리지 못하게 만들어, 보고의 핵심은 아이디어에 집중하도록 유도한다.</li>
      <li><strong>아마존의 ‘6-페이저’</strong>: 아마존은 ‘6-페이저(6-pager)’라는 보고서 방식을 사용한다. 이는 6장 이내의 워드 문서로, 도표나 다이어그램 없이 처음부터 글로 쓰는 보고서이다. 회의 전에 미리 공유하여 참가자들이 내용을 숙지하고 오며, 회의 시간에는 5분간 다시 읽고 질문만 하는 방식으로 진행되어 매우 효율적이다.</li>
    </ul>
  </li>
  <li><strong>무능한 자의 승진</strong>: 과거 선형적 성장 시대에는 범용 인재를 찾았고, 능력이 있든 없든 큰 차이가 없다고 여겨져 일 시키기 편한 사람을 승진시키는 경향이 있었다. 그러나 현재는 세상이 급변하여 능력이 없는 사람을 승진시키면 회사가 큰일 나기 때문에 이러한 현상이 줄어들고 있다.</li>
</ul>

<h3 id="6-경영자-및-개인의-삶에-대한-통찰">6. 경영자 및 개인의 삶에 대한 통찰</h3>
<ul>
  <li><strong>경영자의 역할 변화</strong>: 현재 경영자들은 과거의 성공 경험에 대한 확신 편향을 내려놓고, 세상 변화에 맞춰 일하는 방식을 배워야 한다. 넷플릭스나 애플, 구글 등 다른 회사의 방식을 무조건적으로 복사하기보다는, ‘우리는 어떤 일을 하려 하고, 어떤 철학을 가지며, 우리 사람들이 가장 신나게 일할 수 있는 환경은 무엇인가’에 대한 깊은 고민이 필요하다.</li>
  <li><strong>워라밸과 시간 관리</strong>: 황성현 교수 개인은 40대에 미국에서 자신의 삶을 돌아보고 정비하는 방법을 배웠다. 건강, 취미, 가족과의 시간을 달력에 미리 ‘Do not Schedule (DNS)’ 구역으로 설정하여 확보하는 것이 중요하다. 조급해하지 않고 긴 시각으로 미래를 준비하는 자세가 필요하다. 궁극적으로 AI는 반복적인 업무를 자동화하여 인간이 더욱 중요하고 전략적인 의사 결정에 집중할 수 있도록 시간을 아껴주는 도구가 될 것이라고 본다.</li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>

<p>나는 뭘 원하는가?</p>

<p>나는 내가 일하는 일이 신이 났으면 한다.</p>

<p>나는 내가 하는 일의 전문성을 갖길 원한다.</p>

<p>그리고 나는 내가 하는 일을 통해 세상에 뭔가 변화의 가치에 한 숟가락이라도 더 얹을 수 있는 사람이 되고 싶다고 생각한다.</p>

<p>솔직히 아직 부족하고, 나이도 좀 먹었고, 어쩌면 완전히 요즘 시대에 대세, 성공 가도를 달린다거나, 천재까진 아닐 거라고 생각은 든다.</p>

<p>하지만 생각보다 난 잘하고 있고, 가능성이 있으며, 무엇보다 스스로의 성장에 확신과 결과를 만들어왔다.</p>

<p>문제는 세상을 이해하는 것이리라 본다. 언제 어떤 흐름을 제대로 인지하고 있는가?</p>

<p>마라톤을 최적으로 돌아낼 힘, 최적으로 신뢰받을 힘, 최적으로 기회를 결과로 만드는 힘. 스스로를 지속적으로 성장시키는데, 설령 90살이 되더라도 멈추지 않을 수 있는 내 안의 에너지를 계속 만들어내고 싶다 생각한다.</p>

<p>왜그럴까?</p>

<p>언제부터 그런 생각을 더 깊이 하게 된건지는 사실 슬 가물가물 하긴 하다 ㅋㅋ.. 🤣</p>

<p>하지만 명확한건, 내 개인의 문제부터 사회, 조직, 나라에 이르기까지 좀더 좋은, 좀더 괜찮은, 좀더 편리한 세상은 오게 만들면 재밌지 않을까?</p>

<p>그때 신나게, 행복하게 살고 싶은게 내 꿈이다.</p>

<p>일단 더욱 전문가스러워지자. 😎</p>]]></content><author><name>Paul2021-R</name></author><category term="생각정리" /><category term="이직" /><category term="생각정리" /><category term="etc" /><category term="채용" /><category term="Google" /><category term="Apple" /><summary type="html"><![CDATA[들어가면서 나는 글로벌 회사에 들어가서 살아남을 만한 인재일까?]]></summary></entry><entry><title type="html">AI Breakfast Ep 10 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/08/04/00-AI-trend-with-google-10.html" rel="alternate" type="text/html" title="AI Breakfast Ep 10 생각정리" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/04/00-AI-trend-with-google-10</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/04/00-AI-trend-with-google-10.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=AuviDcSne9g"><img src="https://i.ytimg.com/vi/AuviDcSne9g/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>

<p>9화는 AI 와 관련된 특정 주제에 대한 내용이었기에 생략하고 10화 내용을 기반으로 요약해본다.</p>

<ul>
  <li><strong>AI 발전과 바이브 코딩의 등장</strong>: AI 기술은 하루가 다르게 빠르게 발전하며, 이 가운데 ‘바이브 코딩(vibe coding)’이 가장 뜨거운 아이템으로 주목받고 있다.</li>
  <li><strong>바이브 코딩의 의미와 확산</strong>: 바이브 코딩은 AI가 내놓은 답을 <strong>즉흥적으로 수용하여 원하는 결과물을 만들어내는 방식</strong>이다. 한국에서는 ‘입코딩’이나 ‘손코딩’이라고도 부른다. 2023년 초 인도 개발자가 AI로 가벼운 비행기 게임을 만들어 월 5만 달러 수익을 올린 사례가 바이럴되며 시작되었고, Andrej Karpathy가 X(트위터)에서 이 용어를 사용하며 확산되었다. 이 단어는 2025년 3월 Merriam-Webster 사전에 ‘유행하는 속어’로 등재될 예정이기도 하다. 박찬성 연구원의 바이브 코딩 관련 게시물이 데미스 허사비스(DeepMind CEO)와 제프 딘(Google AI Research 수장)의 리트윗과 좋아요를 받으며 <strong>AI 거장들의 인정</strong>을 받았다.</li>
  <li><strong>아이디어의 중요성 증대</strong>: 생성형 AI의 발전으로 초기 PoC(개념 증명) 수준의 아이디어 구현 비용이 크게 낮아졌다. 이는 <strong>특정 도메인 전문가의 전문 지식을 바탕으로 한 아이디어 자체의 중요성과 가치</strong>를 더욱 높이는 결과를 가져왔다. 박찬성 연구원이 자신의 네트워크 전문 지식을 녹여낸 바이브 코딩 결과물이 바이럴된 것이 좋은 예시이다.</li>
  <li><strong>바이브 코딩에 필요한 역량</strong>:
    <ul>
      <li><strong>반복(Iteration)</strong>: 프롬프트 엔지니어링에서 반복은 매우 중요한 요소이다. 확률에 의거하여 나오는 결과 도출이라는 기반을 가지기 때문에, 요구 사항에 대해 여러번의 반복은 그만큼 높은 확률로 좋은 결과물을 만들어낼 가능성이 생긴다.</li>
      <li><strong>시행착오와 집요함</strong>: 원하는 결과물이 나올 때까지 AI에 끊임없이 시도하고 개선하는 ‘시행착오(trial and error)’와 집요함이 중요하다.</li>
      <li><strong>전문 지식</strong>: 기존 개발 지식이나 특정 분야의 전문적인 키워드를 아는 것이 AI에게 정확한 요구사항을 전달하고 생산성을 높이는 데 매우 유용하다.</li>
      <li><strong>호기심과 흥미</strong>: AI 코딩에 대한 호기심과 즐거움을 느끼는 것이 시작의 중요한 단계이며, 자신이 무엇을 좋아하고 잘하는지를 알아가는 과정이 필요하다.</li>
    </ul>
  </li>
  <li><strong>개인 맞춤형 도구 개발 시대</strong>: 이제는 개인이 자신에게 최적화된 도구를 직접 개발하여 사용하는 시대가 도래하고 있다. 강수진 박사는 시중에 있는 도구들이 자신의 작업 환경에 맞지 않아 <strong>프롬프트 엔지니어링 실험을 위한 플레이그라운드를 직접 만들어 사용</strong>하고 있다고 언급했다.</li>
  <li><strong>프롬프트와 프로그래밍 역량의 미래</strong>:
    <ul>
      <li>자연어 엔지니어 관점에서는 ‘의미론적 응축(Sementic Condensation)’이나 ‘단어 대체(Word Substitution)’를 통해 핵심 의미를 압축하고 제어하는 기술이 활용될 수 있다.</li>
      <li>현재 AI는 개발자들이 사용하던 용어, 일반인들이 기존에 사용하던 언어 기반인 만큼, 바이브 코딩을 수행함에 있어 개발적 지식이 필요하거나, 단어가 필요시 될 수 있다. 하지만 이것 조차도 학습을 통해 개선될 수 있다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>바이브 코딩. 이제는 너무 익숙해진 단어이다. 하지만 동시에 여전히 중요하고, 이제는 개발의 중심에 침입하였고, MCP, A2A 를 만나면서 그저 간단하게 질문에 답을 한다 에서 실제 수행을 한다 라는 차원의 영역으로 발전하고 있다.</p>

<p>오늘의 내용은 어쩌면 보편적인 바이브코딩이라는 행위를 평가하는 간단한 내용이기는 했다.</p>

<p>그러나 동시에 전문가들의 이야기에서 그럼에도 인사이트로 얻을 수 있는 영역은 있었다.</p>

<p>예를 들어 한 개발자 분이 네트워크에 대한 시뮬레이터를 만들었다던지 하는 것들은, 상당히 인상 깊었고, 프롬프트 엔지니어링 전문가로 나온 패널은 자신이 직접 만든 프롬프터 테스터를 보여주었다.</p>

<p>그리고 한 마디 더 걸치니, ‘개발 지식이 있는 사람과 일반인의 개발의 차이’를 언급한 부분이다.</p>

<p>바이브코딩을 할 때 개발 지식은 보다 정확한 지시가 가능하다. 하지만 개발 지식의 부재는 어쩔 수 없이 동작 방식을 묘사해야하고, 그 묘사는 결국 확률적으로 어떤 구현 대상에 대해 100% 지목하는게 아니라 ‘가능성’으로 표현할 뿐인거고, 거기서 잘못된 지식이 있다면 이는 비효율적 개발이 이루어질 수 있다.</p>

<p>하지만 기술을 이해하고, 단어를 정확하게 아는 경우, 그 지식은 좀더 명확한 전달, 명확한 결과를 만들 수 있다.</p>

<p>AI 에 대해 명령을 내릴 때 언어적 방법에 대해 체계화가 잘 된 경우 명령을 잘 내리지만, 동시에 빼놓지 말고 기억해야 하는 부분이 있다면 역시나 도메인.</p>

<p>물론 개발자도 언급하길 바이브 코딩을 하는 과정을 통해 또 다시 AI 가 학습할 것들이 생성되고, AI 가 그걸 이해하고 다시 학습된 데이터를 기반이 된다면 더 찰떡같이 알아먹게 되겠지만</p>

<p>현재 가장 필요한 영역이자, 바이브 코딩을 제대로 내 무기화 하려면 필요한 것은 결국 ‘내 분야’ 혹은 ‘전문 지식’의 체계적인 내재화라는 생각은 이번 편을 통해 보다 선명하게 기억하게 되었다.</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">트랜스포머, AI 를 이해해보자</title><link href="http://0.0.0.0:4000/ai/2025/08/04/01-transformer-gpt-deepSeek-introduction.html" rel="alternate" type="text/html" title="트랜스포머, AI 를 이해해보자" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/04/01-transformer-gpt-deepSeek-introduction</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/04/01-transformer-gpt-deepSeek-introduction.html"><![CDATA[<h2 id="개요">개요</h2>
<p>현재 인공지능(AI) 기술 발전의 핵심에는 <strong>트랜스포머(Transformer)</strong> 아키텍처가 있으며, 2017년 구글의 ‘Attention Is All You Need’ 논문을 통해 소개된 이후 오늘날 가장 널리 사용되는 AI 모델 구조가 되었다. <strong>챗GPT(ChatGPT)</strong>의 ‘GPT’는 ‘Generative Pre-trained Transformer’의 약자로, 방대한 데이터를 통해 사전 학습된 트랜스포머 모델임을 의미한다. 트랜스포머 모델은 텍스트 번역을 넘어 이미지 생성, 음성 변환 등 다양한 AI 분야에 활용되며, 다음 단어나 내용을 예측하는 방식으로 작동한다. 몇 개의 단어를 입력하면 모델이 다음 단어를 예측하고, 그 예측된 단어를 다시 입력으로 사용하여 반복적으로 긴 문장을 생성할 수 있다.</p>

<p>AI 기술의 발전 속도는 전례가 없는데, AI 사용자 및 사용량 증가는 인터넷보다 훨씬 빠르게 나타나고 있으며, 관련 자본 지출(CapEx) 또한 급증하고 있다. ChatGPT는 불과 5일 만에 100만 사용자를 확보하며 역사상 가장 빠른 사용자 채택을 기록했다.</p>

<p>오늘은 이러한 내용들을 정리해보면서, GPT에서 시작해 DeepSeek 까지의 발전 과정을 조금(?) 훑어 보려고 한다. 문돌이 입장에서 AI 의 힘을 여실히 빌려서 만든 내용이긴 하지만 AI 를 좀더 깊게 이해하고 싶은 모든이들에게 도움이 되길 기원한다.</p>

<h3 id="llmlarge-language-model의-개요">LLM(Large Language Model)의 개요</h3>

<p><img src="/assets/images/posts/2025-08/2025-08-04-001.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/ko/llms/">Microsoft AI Tour</a></p>
</blockquote>

<p><strong>대규모 언어 모델(Large Language Model, LLM)</strong>은 주어진 텍스트가 있을 때 다음에 올 단어를 예측하는 매우 정교한 수학적 함수이다. 더 정확하게는, 딱 하나의 단어를 확정적으로 예측하는 대신 다음에 올 단어들에 대한 확률을 계속해서 구하는 함수이다.</p>

<ul>
  <li><strong>작동 방식</strong>: LLM은 몇 개의 단어를 입력으로 받아 다음 단어를 예측하고, 그 예측된 단어를 다시 입력으로 사용하여 반복적으로 긴 문장을 생성한다. 이는 챗GPT와 같은 모델과의 대화가 한 단어씩 생성되는 방식으로 이루어지는 이유이다.</li>
  <li><strong>학습 데이터</strong>: LLM은 인터넷에서 수집한 엄청난 양의 텍스트 데이터로 학습된다. 예를 들어, GPT-3가 학습한 텍스트 양은 사람이 24시간 쉬지 않고 읽었을 때 2,600년 이상이 걸릴 것이며, 요즘 모델들은 훨씬 더 많은 데이터로 훈련된다.</li>
  <li><strong>파라미터(매개변수) 및 훈련</strong>: 모델 속의 수많은 다이얼(파라미터 또는 가중치)을 조정해가며 학습이 이루어진다. LLM은 수백억 개에서 수천억 개까지 이르는 파라미터를 가지고 있으며, 처음엔 랜덤하게 설정된 이 값들이 훈련을 반복하며 점차 그럴듯한 예측을 할 수 있도록 조정된다.
    <ul>
      <li><strong>역전파(Backpropagation)</strong>: 훈련 시 마지막 단어를 제외한 나머지를 모델 입력으로 넣고, 모델이 마지막 단어를 어떻게 예측하는지 확인한 후, 그 예측이 정답에 가까워지도록 파라미터를 조정하는 알고리즘이다.</li>
      <li><strong>강화 학습(RLHF)</strong>: 사전 훈련된 모델은 사람이 모델의 잘못된 응답을 직접 수정하거나 더 나은 응답을 골라주는 RLHF(Reinforcement Learning from Human Feedback)와 같은 강화 학습을 통해 추가 학습된다.</li>
    </ul>
  </li>
</ul>

<h3 id="llm의-속성을-이해하자">LLM의 속성을 이해하자</h3>

<h4 id="llm-vs-nlp">LLM vs NLP</h4>
<p>기존 자연어 처리의 기술과 LLM 이 다른 점은 다음과 같이 설명할 수 있다.</p>

<ul>
  <li>기존 NLP 는 기능 당 하나의 모델이 필요하다.</li>
  <li>기존 NLP 는 한정된 레이블 데이터 셋에서 학습을 시킨다. (예시, 특정 물체 인식 AI 를 위해 특정 물체의 사진을 수십만장 준비한다.)</li>
  <li>기존 NLP 는 특정 사용 사례에 고도로 최적화 된다.(예시, 특정 물체의 데이터셋으로 학습된 특화 모델)</li>
</ul>

<p>그러나 LLM은</p>

<ul>
  <li>여러 NLP 사용 사례에 단일 모델 사용이 가능하다(범용적이다).</li>
  <li>수 TB 에 달하는 레이블이 없는 데이터에서 학습된 모델이다(기초).</li>
  <li>개방형 사용 - 자연어를 사용하여 모델에 무언가를 ‘프롬프트’ 하도록 한다. 즉 자연스럽게 다양한 질문을 할 수 있고, 모델이 이에 맞춰 콘텐츠를 생성해 낸다.</li>
</ul>

<h4 id="llm-이-하지-못하는-것은">LLM 이 하지 못하는 것은?</h4>
<p>대규모 언어 모델은 강력한 생성형 AI 경험을 제공하고, 이 콘텐츠의 범용성은 지금의 AI 상황의 판도 자체를 뒤집어 엎는 일을 만들어 냈지만, 그 표현, 행위가 다음은 아니라는 사실을 명확히 해야 한다.</p>

<ol>
  <li><strong>언어를 이해한게 아니다</strong> : LLM은 예측 엔진, 예측 함수셋에 가깝기에 이것이 해당 콘텐츠의 문맥이나 의미를 이해한 거라고 말할 수 없다.</li>
  <li><strong>사실을 이해하지 못한다</strong> : <code class="language-plaintext highlighter-rouge">정보 검색</code>, <code class="language-plaintext highlighter-rouge">창의적 글쓰기</code>를 위한 별도의 모드가 있는 건 아니고, 진행중인 시퀀스에서 다음으로 가능성이 높은 토큰을 예측하는 것이기에, 그것이 ‘사실’이냐 ‘주장’이냐와 같은 해석은 LLM 자체에서는 무의미하다.</li>
  <li><strong>매너, 감정, 또는 윤리를 이해하지 못한다</strong> : 인간이 설계하고 설정한 데이터, 프롬프트에 의해 최적의 예측값을 ‘보정한’ 결과이지, 모델이 매너나 감정, 윤리를 이해하고 동작하는 것이 아니다. 결과적으로 LLM 은 통계적 패턴의 예측의 연속이며, 인간처럼 문장의 의미, 맥락을 이해하는 것이 아니다.</li>
</ol>

<h3 id="트랜스포머의-핵심-개념">트랜스포머의 핵심 개념</h3>

<p>트랜스포머는 텍스트를 처음부터 끝까지 순차적으로 읽는 대신, <strong>전체 문장을 한꺼번에 병렬로 처리한다</strong>. 이 과정에서 문장 내 각 단어는 AI가 이해할 수 있는 숫자 벡터로 변환되어 서로의 관계성을 알 수 있게 된다.</p>

<ul>
  <li><strong>토큰(Token)</strong>:
    <ul>
      <li>트랜스포머는 입력된 문장이나 데이터를 <strong>토큰</strong>이라는 작은 조각으로 나누어 처리한다.</li>
      <li>텍스트의 경우, 단어나 단어의 일부, 또는 일반적인 문자 조합이 토큰이 될 수 있다.</li>
      <li>이미지나 음성이 포함될 때는 그 이미지의 작은 조각이나 음성의 작은 부분이 토큰이 될 수 있다.</li>
    </ul>
  </li>
  <li><strong>벡터(Vector) 및 단어 임베딩(Word Embedding)</strong>:
    <ul>
      <li>각 토큰은 해당 부분의 의미를 담도록 설계된 숫자 목록인 <strong>벡터</strong>와 연결된다. 이 벡터들은 고차원 공간의 좌표로 생각할 수 있으며, 의미가 비슷한 단어들은 그 공간에서 가까운 벡터로 배치되는 경향이 있다.</li>
      <li>예를 들어, GPT-2에서는 768차원, DeepSeek R1에서는 7,168차원의 벡터가 단어 하나를 표현하는 데 사용된다.</li>
      <li>훈련 과정에서, 모델은 학습을 통해 공간 속의 방향들이 어느 정도 의미를 가지도록 벡터를 정리한다. 예를 들어, ‘여자’와 ‘남자’ 사이의 벡터 차이가 ‘왕’과 ‘여왕’ 사이의 차이와 유사하게 나타날 수 있다. 이러한 차이 벡터 사이의 차이는 단어들 사이의 관련성이나, 어떤 특성을 나타낼 수 있다. 성의 차이, 복수와 단수의 차이 등 이러한 특성을 수학적 - 수치적으로 이해한 것이다.</li>
    </ul>

    <p><img src="/assets/images/posts/2025-08/2025-08-04-002.png" alt="" /></p>
    <blockquote>
      <p>단어 사이의 관계성이 벡터 사이의 간격으로 이해가 될 수 있다. 출처 : <a href="https://youtu.be/g38aoGttLhI?si=9zdFBTN0cv1ncJ-r">3Blue1Brown 한국어</a></p>
    </blockquote>
  </li>
  <li><strong>어텐션(Attention)</strong>:
    <ul>
      <li>트랜스포머의 핵심 연산으로, 입력된 벡터들이 ‘어텐션 블록’을 통과하며 서로 정보를 주고받고 값을 업데이트하는 과정이다. 이는 문맥을 파악하기 위해 단어들 간의 유사성을 계산하는 방식이다.</li>
      <li><strong>쿼리(Query), 키(Key), 밸류(Value)</strong>: 어텐션은 <strong>‘쿼리(Query)’, ‘키(Key)’, ‘밸류(Value)’</strong>라는 세 가지 개념을 통해 구현된다. 입력된 단어들(벡터 X)은 각각 고유한 학습 가능한 가중치 행렬(WQ, WK, WV)과 곱해져 쿼리 행렬, 키 행렬, 밸류 행렬로 변환된다. 단 이 개념이 별개의 정보라기 보단 결국 벡터 X 에서 나온다는 점은 명확하게 인지해야 한다.
        <ul>
          <li><strong>쿼리(Query)</strong>는 하나의 ‘질문’ 역할을 한다.</li>
          <li><strong>키(Key)</strong>는 그 질문을 해결할 가능성이 있는 ‘열쇠’ 중 하나이다.</li>
          <li><strong>밸류(Value)</strong>는 어텐션 패턴에 따라 이동되거나 결합될 실제 정보의 ‘재료’이다.</li>
        </ul>
      </li>
      <li><strong>내적(Dot Product)</strong>: 쿼리가 키들과의 <strong>유사도</strong>를 계산하는 과정은 수학적으로 두 벡터의 <strong>내적</strong>으로 구현된다. 내적은 기하학적으로 벡터들이 비슷한 방향일 때 양수, 직교할 때 0, 반대 방향일 때 음수가 된다.</li>
      <li><strong>어텐션 패턴(Attention Pattern)</strong>: 모든 쿼리와 키의 유사도를 계산하여 얻는 종합된 정보이다. 이 어텐션 패턴의 크기는 <strong>입력 단어 수의 제곱에 비례하여 늘어난다</strong>. 훈련 과정에서는 다음에 올 단어를 ‘컨닝’하지 못하도록 어텐션 패턴의 오른쪽 윗부분이 가려진다.</li>
      <li><strong>소프트맥스(Softmax)</strong>: 유사도 계산 후, 각 행의 합이 0이 되도록 <code class="language-plaintext highlighter-rouge">정규화</code>하는 함수이다. 이 함수는 어떠한 숫자들의 나열이든 0과 1 사이의 값으로 변환하여 합이 1이 되는 <code class="language-plaintext highlighter-rouge">확률 분포</code>로 만들어준다. 가장 큰 값은 1에 가깝고 작은 값은 0에 가까워진다. 또한 <code class="language-plaintext highlighter-rouge">온도(Temperature)</code>라는 상수를 사용해 예측의 다양성을 조절할 수 있다. (이 온도는 열역학의 개념과 유사한 동작이기에, 그대로 차용했다.)</li>
      <li><strong>어텐션 헤드(Attention Head)</strong>: 어텐션 패턴 하나를 계산하는 단위를 ‘어텐션 헤드’라고 부른다. 여러 헤드가 각기 다른 쿼리, 키, 밸류 세트를 사용하여 독립적으로 패턴을 계산한 뒤, 이 값들을 종합하여 다음 레이어의 입력으로 사용한다.</li>
    </ul>
  </li>
  <li><strong>피드포워드 네트워크(Feedforward Network)</strong>: 트랜스포머 안에 포함된 또 다른 연산으로, 모델이 더 많은 언어 패턴을 저장할 수 있도록 돕는다.</li>
</ul>

<h3 id="트랜스포머의-연산량-문제와-기존-해결책">트랜스포머의 연산량 문제와 기존 해결책</h3>

<p>트랜스포머는 위에서 언급한 어텐션 헤드의 단위로 토큰이 아웃풋이 되고, 그것을 다시 인풋으로 집어넣는 것의 연속이다. 따라서 행렬의 엄청난 연산량을 요구한다는 문제가 있다. 어텐션 패턴의 크기가 입력 단어 수의 제곱에 비례하여 늘어나기 때문에, 몇 문장에서 시작해 책 한권 분량이 들어간다면 기하급수적이라는 것이 무엇인가를 알 수 있게 된다. 이러한 본질적인 구조로 CPU 연산이 아닌 GPU의 사용이 핵심일 수 밖에 없고, 동시에 GPU 의 사용이라 함은 막대한 전기 사용, 발열 등 ‘GPU가 녹는다’ 라는 말에 딱 부합하는 작업인 것이다. (물론 최신 AI 모델들, 특히 구글에선 TPU 를 활용하는 시도라던지, 다양한 시도가 있는 것은 사실이다.)</p>

<p><img src="/assets/images/posts/2025-08/2025-08-04-003.png" alt="" /></p>
<blockquote>
  <p>GPUs Are Melting: … 출처 : <a href="https://www.linkedin.com/pulse/gpus-melting-building-real-time-monitoring-systems-go-snehasish-dutta-cctbe/">SNEHASISH DUTTA</a></p>
</blockquote>

<p>이러한 비효율성을 줄이기 위해 개발된 핵심 기술이 <strong>키-밸류(Key-Value) 캐싱(KV Caching)</strong>이다.</p>
<ul>
  <li><strong>키-밸류 캐싱(KV Caching)</strong>: 이미 모델에 입력된 단어들의 쿼리, 키, 밸류 값은 다시 계산할 필요 없이 저장해두고 재활용하는 방식이다. 이 기술을 사용하면 어텐션 연산량이 단어 수에 선형적으로만 증가하도록 안정화되어 폭발적인 증가를 막는다.</li>
  <li><strong>저장 공간 문제</strong>: 그러나 KV 캐싱은 키-밸류 값을 저장하기 위한 막대한 저장 공간을 요구한다. 단어 하나당 키-밸류를 모두 저장하면 4MB를 차지하며, 10만 개의 단어를 처리할 경우 무려 400GB에 달하는 저장 공간이 필요할 수 있다.</li>
</ul>

<p>위의 내용에서 언급한 저장공간 문제에 대해 이해하기 위하여, 간략화된 캐시 항목의 수를 계산 식은 다음과 같이 표현된다.</p>

<p>$CacheCounter = 2 \cdot n \cdot d_h \cdot n_h \cdot l$</p>

<ul>
  <li>$n$ : 입력 토큰 수</li>
  <li>$d_h$ : 키/ 값 행렬의 차원</li>
  <li>$n_h$ : 레이어 당 어텐션 헤드 수</li>
  <li>$l$ : 레이어 수</li>
</ul>

<p>예를 들어</p>

<p>$let d_h = 128, n_h = 128, l = 61, n = 100000$ 
(DeepSeek R1/V3 아키텍쳐 기준)</p>

<p>$(2)(128)(128)(61)(2) = 3.998 * 10^6 Bytes/token = (approx)4MB/token$</p>

<p>$4MB/Token * 100000 tokens = 400GB$</p>

<p>이러한 저장 공간 문제를 해결하기 위한 이전 시도에는 두 가지 방식이 있었다:</p>
<ul>
  <li><strong>멀티-쿼리 어텐션(Multi-Query Attention)</strong>: 모든 어텐션 헤드가 동일한 키-밸류를 공유하는 전략이다. 이는 저장 용량을 크게 줄일 수 있지만, 각 헤드의 역할이 달라야 하는 점을 방해하여 모델 성능이 저하된다는 단점이 있다.</li>
</ul>

<p><img src="/assets/images/posts/2025-08/2025-08-04-004.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://youtu.be/w5f6mtg0sKQ?si=UMmhUPEorJk_oPAW">웰트랩스</a></p>
</blockquote>

<ul>
  <li><strong>그룹별 쿼리 어텐션(Grouped-Query Attention)</strong>: 멀티-쿼리 어텐션을 개선하여 어텐션 헤드를 여러 그룹으로 묶어 <code class="language-plaintext highlighter-rouge">같은 그룹</code>끼리 키-밸류를 공유하는 방식이다. 메타의 라마 3(Llama 3) 모델이 이 방식을 사용하여 저장 공간을 8배 절약했지만, 여전히 전체 헤드가 키-밸류를 저장하는 방식보다 성능이 못 미쳤다.</li>
</ul>

<p><img src="/assets/images/posts/2025-08/2025-08-04-005.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://youtu.be/w5f6mtg0sKQ?si=UMmhUPEorJk_oPAW">웰트랩스</a></p>
</blockquote>

<h3 id="deepseek의-혁신-multi-head-latent-attention">DeepSeek의 혁신: Multi-Head Latent Attention</h3>

<p><img src="/assets/images/posts/2025-08/2025-08-04-006.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://youtu.be/w5f6mtg0sKQ?si=UMmhUPEorJk_oPAW">웰트랩스</a></p>
</blockquote>

<p>이러한 상황에서 중국의 <strong>딥시크(DeepSeek)</strong>는 기존 AI 개발에 수천억 원이 들어가는 것을 고작 80억 원에 가능하다고 발표하며 세상을 놀라게 했다. 딥시크는 경쟁사의 모델을 모방했다거나 실제 개발 비용보다 축소 발표했다는 구설수가 있었으나, 모든 모델 웨이트와 코드, 그리고 12개에 달하는 디테일한 논문까지 모두 공개하며 그 기술력을 드러냈다.</p>

<p>딥시크의 핵심 기술은 저장 공간과 연산량이라는 두 마리 토끼를 모두 잡은 <strong>멀티-헤드 레이턴트 어텐션(Multi-Head Latent Attention)</strong>이다. 이 기술은 인공지능 압축과 효율의 핵심인 <strong>‘잠재 공간(latent space)’</strong> 개념을 적용했다.</p>

<ul>
  <li><strong>멀티-헤드 레이턴트 어텐션의 원리</strong>: 기존 멀티-헤드 어텐션에서 입력 X를 키-밸류로 만드는 중간에 <strong>압축하는 스테이지를 하나 추가한다</strong>. 모든 어텐션 헤드는 같은 잠재 공간을 공유하는데, 이는 멀티-쿼리 어텐션과 유사하게 저장 공간을 줄이는 데 효과적이다. 그러나 구체적인 값을 저장하는 대신, 각 헤드에서 압축된 잠재 공간으로 보내줄 가중치(Wv와 W)를 학습하는 문제로 바꾸어 <code class="language-plaintext highlighter-rouge">학습 과정</code>에서 실제 단일한 캐싱 전략으로 가서 용량을 줄이는 경우 보다 <code class="language-plaintext highlighter-rouge">더 많은 자유도</code>를 보장한다.</li>
  <li><strong>수학적 효율성</strong>: 기본적인 선형 대수의 원리를 활용하여, 훈련 시 합쳐진 모델 자체로 훈련하기 때문에 추론(inference) 상황에서 추가적인 연산이 필요 없다. 새로운 단어가 입력될 때도 쿼리 레이턴트를 만들고 저장해 둔 레이턴트 키-밸류를 사용하므로 효율적이다.</li>
  <li><strong>성능 개선</strong>: 이 덕분에 딥시크 R1은 키-밸류 캐시를 저장할 때 어텐션 헤드 개수가 아니라 공유된 키-밸류 캐시의 크기에만 영향을 받도록 설계되었다. 이는 <strong>토큰당 70KB만 사용하여 저장 공간을 57배나 줄였으며</strong>, 토큰 생성 속도를 <strong>6배 빠르게</strong> 만들었다. (참고로, 키-밸류 캐시를 모두 저장했다면 토큰당 4MB, 그룹별 쿼리 어텐션은 500KB를 필요로 했을 것이다). 이러한 트랜스포머의 알고리즘 개선은 기존보다 훨씬 빠른 토큰 생성을 가능케 한다는 점에서 주목할 만하다.</li>
</ul>

<h3 id="llm의-잠재력과-그-가치">LLM의 잠재력과 그 가치</h3>

<p>LLM 의 구조를 씹어먹어보고, 수학적 기초는 처음에는 대단히 어렵게 와닿았지만, 결국 단어들 사이의 예측, 입력이 다시 출력이 되고, 그 출력이 다시 입력이 된다는 이 구조에 대한 이해가 있게 되면 Transformer 와 LLM 의 아주 베이직한 표면의 이해에는 어렵지 않다.</p>

<p>하지만 거기에 더 많은 구조적, 효율적 개선, 그리고 LLM 의 보편성을 이용한 다양한 능력, 다시 특화 기능을 위한 모델로 학습하거나 아예 대형 모델을 기반으로 더 튜닝하는 SLM(Small Language Model)의 등장 등, LLM의 잠재력, 그리고 향후에도 지속적인 판도는 이어질 것이다.</p>

<p>이번 내용을 통해 좀더 LLM 을 실증적으로 이해하고, 특히나 DeepSeek 와 같은 개선의 여지가 여전히 있단 점들은, 앞으로 정말 AI를 거쳐 AGI 까지, 초 거대모델들의 성장 폭은 남아 있다는 점을 나름 생각해 볼 수 있는것 같다.</p>

<h3 id="참고-문헌">참고 문헌</h3>
<ul>
  <li><a href="https://www.youtube.com/watch?v=HnvitMTkXro">3BlueL1Brown 한국어 - LLM 설명(요약버전)</a></li>
  <li><a href="https://www.youtube.com/watch?v=g38aoGttLhI">3BlueL1Brown 한국어 - 트랜스포머, ChatGPT가 트랜스포머로 만들어졌죠. -DL5</a></li>
  <li><a href="https://youtu.be/w5f6mtg0sKQ?si=GDTi2tnoFc-SqZVh">웰츠랩스 - 딥시크의 +99 강화 트랜스포머 몽둥이</a></li>
  <li><a href="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/ko/">Microsoft AI Tour - Learn how to interact with OpenAI models</a></li>
</ul>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="생각정리" /><category term="LLM" /><summary type="html"><![CDATA[개요 현재 인공지능(AI) 기술 발전의 핵심에는 트랜스포머(Transformer) 아키텍처가 있으며, 2017년 구글의 ‘Attention Is All You Need’ 논문을 통해 소개된 이후 오늘날 가장 널리 사용되는 AI 모델 구조가 되었다. 챗GPT(ChatGPT)의 ‘GPT’는 ‘Generative Pre-trained Transformer’의 약자로, 방대한 데이터를 통해 사전 학습된 트랜스포머 모델임을 의미한다. 트랜스포머 모델은 텍스트 번역을 넘어 이미지 생성, 음성 변환 등 다양한 AI 분야에 활용되며, 다음 단어나 내용을 예측하는 방식으로 작동한다. 몇 개의 단어를 입력하면 모델이 다음 단어를 예측하고, 그 예측된 단어를 다시 입력으로 사용하여 반복적으로 긴 문장을 생성할 수 있다.]]></summary></entry><entry><title type="html">네이버 부스트캠프 AI Tech 8기 준비해보자</title><link href="http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/04/02-challange-naver-boost-ai-8th.html" rel="alternate" type="text/html" title="네이버 부스트캠프 AI Tech 8기 준비해보자" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/04/02-challange-naver-boost-ai-8th</id><content type="html" xml:base="http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/04/02-challange-naver-boost-ai-8th.html"><![CDATA[<h2 id="들어가면서">들어가면서</h2>
<h3 id="ai-ai-ai">AI, AI, AI…</h3>

<p>AI의 혁신은 누군가에게는 큰 일이 아닐 수 있다.</p>

<p>물론, 온 나라에서, 전 세계가 떠들고 있는 입장에서 관심이 없는 사람이 없겠지만, 그럼에도 현실에선 AI를 아직 제대로 도입하지 않은 이들도 많고, 오히려 개발자들이 여전히 AI 에 대해 등한시 하는 이들도 있단 걸 보면… 새삼 여전히 AI 가 세상을 바꾼다는 생각 보단, 막연한 공포만이 존재하고, 실무에 적용, AI 기반화 된 곳은 많지 않다는 것을 느낀다.</p>

<p>피부에 온전히 <code class="language-plaintext highlighter-rouge">AI 네이티브</code> 라는 키워드가 어울리는 상황까지 도래 하진 않았다.</p>

<p>하지만 AI 의 파급력, 이미 그 수준과 활용 가능성은 훌륭하다. 리소스와 개발자만 충분하다면 AI, LLM 을 기반으로 하여 만들수 있는 것들의 수준, 자동화하기 어려운 것들에 대한 능동적 대응 등은 이미 사람 수준으로 충분히 구현이 가능하다. 국가 차원의 전략 병기 역할을 할 수 있다는 점에서 본다면 내가 다음 시대에서 적응하고 살기 위해 AI에 대한 역량이 없는 것은 결코 용납될 수 없다고 나는 생각한다.</p>

<p>거기다, 이런 거창한 이야기가 아니더라도 생각해보면 AI 덕에 나는 더 빠른 성장, 더 확실한 성장을 할 수 있었다.</p>

<p>내 아이디어나 내 생각을 구현화 하는데도 사람과 리소스가 드는 것을 AI 를 활용하면 10분의 1, 100분의 1로도 절감할 수 있다는 점은, 나의 삶에 새로운 도전, 새로운 기회를 줄 수 있다는 확신을 제공해준다. 그것을 누릴 준비, 써볼 준비를 이제는 해야 하지 않을까?</p>

<p>내가 단순히 백엔드 개발의 즐거움, 그 기술을 가지고 먹고 사는 것을 넘어서서 AI와 결합하여, 기업의 수요, 세상의 방향에서 아직은 내 수준으론 흐름을 쫓는 입장이지만, 언젠가 내가 그 흐름을 만들 수 있지 않을까? AI는 그걸 가능하게 만드는 ‘힘’이란 사실을 나는 한시도 잊고 산 적이 없다.</p>

<p><img src="/assets/images/posts/2025-08/2025-08-04-007.png" alt="" /></p>
<blockquote>
  <p>두둥</p>
</blockquote>

<p>그러는 와중에 퇴사를 하게 되었다. 정말 다양한 일들(…)을 겪었지만, 그 이야기는 나중에 한다 치고,</p>

<p>중요한 포인트는 42서울이라는 부트캠프를 통해 류한솔 버전 2가 될 수 있었고, 백엔드 개발자라는 타이틀을 얻을 수 있었다. 자잘한 성공과 실패를 거쳐 성공적으로 1년 이상을 생활했으며, 메인 서버라는 일을 빠르게 맡게 되어서 정말 백엔드 개발자로 해봐야할 기본적인 일들에 대해서는 A to Z 로 경험하는 것을 해 볼 수 있었다. 믿어주는 리더와 함께 3.0 버전으로 API 서버의 체계화, 업그레이드는 자랑할만한 성과가 아니었나 싶다.</p>

<p>기본 설계부터, API 대응, 서버의 관리나 서버 벤치마킹 및 분석, 요금 절감, 알람 시스템 구축이나 CICD에 무중단 배포까지. 곁다리로 ML 서버의 서빙과 관리, AI 개발까지 보조로 진행했으며, R&amp;D 연구까지 진행한 사실은, 1년 하고도 약 2개월의 시간, 나는 어떻게 성장 할 수 있었던가? 결론은 명확하다.</p>

<p><code class="language-plaintext highlighter-rouge">AI의 파워</code></p>

<p>AI를 통한 효율성의 증대, AI를 통한 개발에서의 문제의 사전의 확인, 백엔드 개발 구조에 대한 AI를 통한 검증이나 초기 조사 기간의 월등한 단축은 러닝커브가 있어야 하는 수 많은 기술들, 처음 경험하기에 생각과 다를 수 있는 영역 들에 보다 빠른 적응을 가능케 한다는 점이서 AI 는 정말 둘도 없는 선생님이자, 가이드 역할이었다고 나는 생각한다.</p>

<h3 id="성장도-방향도-ai">성장도 방향도 AI</h3>
<p>그러는 와중 백엔드 개발자에 대한 수요조사, 특히 내가갈 수 있는 1 ~ 3년차 사이의 주니어 개발자들에 대한 조사 이후 확실하게 얻은 기업이 요구하는 인재에 대한 인사이트는 다음과 같았다.</p>

<blockquote>
  <p>“Back End 도메인 역량을 결코 무시하지 말 것”</p>

  <p>“AI 키워드는 권장 그자체”</p>

  <p>1년 차는 CICD 까지의 흐름 이해 및 유지보수 경험</p>

  <p>3년 차는 CICD 의 구성 및 Kubernates 계열에 대한 배포 경험</p>
</blockquote>

<p>기업들의 AI 수요는 당연히 발생했다. AI라는 키워드를 통해 기존에 불가능하던 서비스의 활성화, 서비스의 고도화를 원하는 것은 당연했지만, 포인트는 거기서 회사들은 ‘어떤 인재’를 찾는가에 대한 내 나름의 특징을 발견했다는 것이다.</p>

<p>예를 들어 AI 전문 인력의 수요는 없지 않다. 분명히 전문가를 원했고, 당연히 석사 수준의 기초 바탕은 핵심이었다. 하지만 그런 자리의 갯수는 많지 않았다. 들려오는 이야기로 봐도, 오히려 소개받아 들어가는 자리에 대한 이야기는 있었지, 공개적으로 모집되는 글은 생각보다 많지 않았다.</p>

<p>곰곰히 생각해본 결과, 이는 ‘응용 서비스’에 가까운 이들에게 필요시 되는 AI 역량이라는 것이 생각보다 괴리감이 있다는 결론을 낼 수 있었다. AI에 전문성을 가진 완전 AI 전문 성향을 가진 수요가 아니라, 기존 도메인을 하면서도 AI 에 대한 준비가되어 있어서, 현실적으로 줄 수 있는 연봉과 AI 역량 사이의 벨런스, 기존 개발자들은 있거나, 그 수요를 하면서도 AI 가치를 가지고 있으면 좀더 고려한다- 라는 지극히 산술적 계산의 수요가 있던 것이다.</p>

<p><img src="/assets/images/posts/2025-08/2025-08-04-008.png" alt="" /></p>
<blockquote>
  <p>핵심은 역량의 ‘밸런스’</p>
</blockquote>

<p>생각해보면 그렇다. AI에 완벽히 특화된 인물들은 AI 베이스의 특화 기업, 투자가 확실하고, AI를 통해 수익을 내려는 기업, 대기업이라면 당연히 얼마를 주더라도 데려올 핵심 인재일 것이다. 하지만 현실의 모든 기업들은 그럴 상황이 아니란 것이다. 원티드를 비롯한 전통적인 구인구직 사이트, 개발자 특화 채용 플랫폼의 구인 탐색 결과 ‘필수’ 라곤 아니지만, ‘권장’이라는 항목에 AI와 관련된 능력이 전형적인 채용 역할들(프론트엔드, 백엔드)에 상당한 비중으로 포함되어 있던 것이다.</p>

<h3 id="결론--그래서-타이밍이-왔다">결론 : 그래서 타이밍이 왔다</h3>

<p>AI  에 대해 투자를 할 때라고 생각했다. 퇴사도 어쩌다보니 손쉽게 가능해졌고, 그렇게 정리를 하고 나오는 찰나 AI 관련한 정부의 정책이나 기업들의 투자 현황을 조사하다 보니 발견한 것이 바로 <code class="language-plaintext highlighter-rouge">네이버 부스트 캠프 8기</code> 의 모집 소식이었다.</p>

<h2 id="네이버-부스트캠프-ai-tech-8기-지원">네이버 부스트캠프 AI Tech 8기 지원</h2>

<h3 id="개요">개요</h3>

<p>해당 모집 사항을 정리하면 다음과 같았다.</p>

<ul>
  <li>지원 접수 : 25.08.14 오전 11시 마감</li>
  <li>온라인 문제 해결력 테스트 : 25.08.20. 오후 7시</li>
  <li>교육 기간 : 25.09.01 시작하여 26.02.11 까지 약 6개월, 전일제 교육</li>
</ul>

<h3 id="지원-자격과-인재상-에-대한-분석">지원 자격과 ‘인재상’ 에 대한 분석</h3>
<ol>
  <li>전일제, 집중, 몰입의 요구: 기본적으로 내용을 통해 확실하게 알 수 있는 것은 ‘쉽지 않을 것이라는’ 각오를 요구하는 내용이라고 판단했다.</li>
  <li>코어 타임의 참여 요청: 이 역시 1번을 다시 강조하는 말이리라</li>
  <li>끝을 보는 ‘덕질’의 성향: 결국 문제는 지속적으로 나타날 것이고, 그 내용을 단순히 스펙 쌓기로 생각하는게 아니라, 분야에대한 집요함을 묻는다는 의미.</li>
  <li>‘협업과 커뮤니케이션에 책임감’: 이 역시 1, 3과 함께 하는 거지만, 특히나 중요한 이유는 결국 AI 라는 영역이 한 사람이 해결할 수 없다는 사실을 여실히 보여주는 것이리라 싶다.</li>
</ol>

<p>결론적으로 정리하면 네이버 재단에서 원하는 인재란, 결국 위에서 언급한 상황, 현실적인 기업의 요구사항과는 다소 차이는 있다고 보인다. 하지만 대기업, 혹은 잠재 가치를 봤을 때 가장 ‘비싼’ 몸값의 인재 양성이 반드시 필요하다고 생각한다는 점을 느낄 수 있었다.</p>

<h3 id="해야-할-일">해야 할 일</h3>
<p>후기를 뒤져보고, 이들을 종합해보니 다음과 같이 해야 것들, 준비해야할 것들이 보였다.</p>

<p><strong>1. 프리코스는 반드시 해라</strong> : 프리코스의 콘텐츠가 온라인 테스트의 핵심 필수 사항이라는 이야기가 있다. 물론 파이썬 기초, AI 기초에 대한 내용이라 이미 숙지한 사람이라면 들을 필요가 있나? 했을 때 약간 갸웃둥 해지긴 하나, 공식 시험 가이드라 생각하고 그래도 보는 것은 괜찮다고 본다. 특히 결정적으로 가산점을 준다는 사실만 봐도, 안하는 건 99% 손해이리라 싶다.</p>

<p><strong>2. 지원서 준비는 미리미리</strong> : 이건 사실 강조할 필요가 있을까? 싶지만, 결국 인재상에 맞는 인재라는 것은 글에서부터 ‘묻어나오는 깊이감’이 있을 것이다. 그리고 그것은 어딜 가나 사람이 인정받는 시작점이며, 거기서 생각이 얕고, 준비가 부족하다면 결국은 ‘시작 조차 하지 못한다’고 보는게 맞을 것이다. 자신의 가치를 경험과 연결하여 구체적으로 작성하고, 도전 과정에서 배운 것들, 어려움과 실패에서 무얼 얻었는지도 중요할 것이며, 무엇보다 진정성과 열정이 느껴지고, 그것을 실재 만드려는 그 내용 전체의 첫 인상이 지원서에서 시작한다는 점은 어떤 후기를 보더라도 필요해보인다.</p>

<p><strong>3. 온라인 문제 해결력 테스트</strong> : 확인해보니 AI와 CS 지식, 코딩역량을 한번에 평가가 기존에 여러 차례 했던 것과는 다르게, 완전히 통합되어 진행된다고 한다. 핵심 주제는 다음 내용 위주로 보인다.</p>

<ul>
  <li>AI 및 CS 지식 테스트 영역 포함 사항들
    <ul>
      <li>선형대수 : 벡터 및 행렬 연산, 고유값(Eigenvalues), 주성분 분석(PCA) 등</li>
      <li>확률 및 통계 : 확률 분포, 조건부 확률, 편향-분산 트레이드 오프 등</li>
      <li>머신러닝 / 딥러닝 기초 : 경사 하강법(Gradient Descent), 활성화 함수(Activation Function), 과적합(Overfitting), 정규화(Regularization), 평가 지표(Evaluation Metrics) 등</li>
      <li>컴퓨터 과학 기초 : OS, 네트워크, 자료구조 등 기초 CS 문제 (단 후기들이 공통적으로 나오는 요소는 아니다)</li>
      <li>난이도 : 단순 암기만으로 풀기 어려운, 개념에 대한 이해를 요구되는 문제 출제 됨. 프리코스를 충실히 학습하고 개념을 완벽히 소화 하는 것이 중요</li>
    </ul>
  </li>
  <li>코딩 테스트
    <ul>
      <li>사용 가능 언어 : C++, Java, Python 3 (당연한 이야기지만 Python3가 가장 낫다)</li>
      <li>난이도나 경향성 : 전체적으로 과거 후기들을 보면, 백준 실버 ~ 백준 골드 ~ 플레티넘, 프로그래머스 1 ~ 3 정도로 고루 나오는 것으로 보는게 맞아 보인다.</li>
      <li>단, 0 또는 1문제를 풀고도 합격 사례 =&gt; 단순히 코딩 성적이 곧 과락을 의미하진 않음으로 보인다.</li>
      <li>주요 문제 유형
        <ul>
          <li>구현 / 시뮬레이션 : 문제의 요구사항을 꼼꼼히 읽고 그대로 코드로 옮기는 능력을 요구하는 문제가 빈번하게 출제된다. 복잡한 알고리즘 지식보다 독해력과 꼼꼼함이 중요</li>
          <li>핵심 알고리즘 : 깊이/너비 우선 탐색(DFS/BFS), 동적 계획법(DP), 그래프 탐색, 스택/큐 등 기본적인 자료구조 및 알고리즘 활용 문제가 꾸준히 언급된다</li>
          <li>CS 지식 융합형 : 일부 기수에서는 CS 지식을 문제 해결 과정에 직접적으로 적용해야 하는 융합형 문제가 출제</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="그래서-왜-네이버냐">그래서 왜 네이버냐?</h2>
<p>당연한 이야기지만 네이버 AI 부스트 캠프의 후기로 취업을 잘했다, 이직을 잘했다 이런 이야기가 아니라는 점은 다수의 후기에서 언급하는 부분이다. 그도 그럴 것이다. 개발자 시장의 과포화, 능력 상향 평준화, AI의 손쉬운 사용으로 신입을 뽑지 않는 환경 등을 고려한다면 그저 부스트캠프를 나왔다고 연봉이 올라간다, 취업이 손쉽게 된다는 것은 당연히 아니다.</p>

<p>뿐만 아니라 AI 가 나에겐 ‘메인’이냐? 라고 하면 그것도 아닐 수 있다. 그러다보니 들어가면 분명히 완벽히 낙제생 포지션이 될 수 밖에 없을 것이고, 가서 아주 잘하면 75점을 받을 수 있을까? 분명 그 이하일 것은 팩트이다 😂</p>

<p>하지만 내가 들어가야 하는 이유이자, 거기서 준비해야 할 것이 무엇인가? 에 대해서는 다음과 같이 정리 할 수 있다.</p>

<p><strong>1) AI 에 대한 제대로된 지식을 기반으로 시작하여 백엔드에 적용하는 AI의 키워드 :</strong></p>

<p>AI 만으로 개발자가 될 수도 없으며, AI 라는 툴이 결국 만나야 하는 것은 기존의 전통적인 영역들의 기술이다. 그 기술을 포함하지 않고 AI 는 비즈니스의 시장에 생명의 불꽃이 되진 못한다. 그러니 나는 AI 를 어떻게 백엔드에 적용하고, 또 반대로 어떤 지점에서 백엔드가 필요한지를 확실하게 파악할 수 있고, 그럴 수요에 부합하는 인재가 될 것이다. 이는 그 내부에서 나의 필요성을 보여줄 수도 있으며, 반대로 내가 AI에게 뭘 요구해야할지 알 수 있을 것이다.</p>

<p><strong>2) 정말 괜찮은 개발자 네트워크와 리소스의 ‘철저한 활용’ :</strong></p>

<p>6개월의 전념. 나같은 이직 준비를 하는 사람이 얼마나 될지는 모르겠다. 하지만 확실한 건 신입이든, 아니든 간에 여기에 들어가기까지 걸린 시간이나 고생한 것을 고려한다면 그들의 마음이나 자세는 분명하게 보인다. 그리고 그런 이들을 아는 것, 그리고 나 역시 그들과 함께 하는 것은 앞으로 나의 꿈, 혹은 그들의 꿈을 구현하는데 더 가까워지는 것이다. 그것은 앞으로의 엄청난 내 자산이 되리라 확신한다.</p>

<p><strong>3) 고급 백엔드 기술의 도입의 기회 마련 :</strong></p>

<p>들어가기만 하면 네이버의 고성능 AI 리소스를 쓸 기회가 생긴다. 뿐만 아니라 설령 리소스를 무제한으로 쓴다고 하더라도 효과적이고 효율적인걸 고려한다고 하면 DevOps 관점, 백엔드 개발자의 관점은 당연히 필요할 것이며, 무엇보다 백엔드의 효과적인 구조, CICD 구현 등 결국 고급 기술들을 적용해야만 AI 기반의 서비스 구현에 어려움이 없을 것이다. 이런 점에서 네이버란 기회는 오히려 더 많은 백엔드 기술 연마와 포트폴리오 준비를 가능케 할 것이라는 건 안봐도 비디오인 상황이다.</p>

<p>완전 AI 지향으로 가는 것에 비하면 나의 목표는 다소 애매(?) 할 수도 있다고 생각한다. 하지만 8월이란 기회는 와버렸고, 스스로 준비하는 것의 한계를 뛰어넘을 기회라는 확신은 있다. 건강도 챙겨야 하다보니 ‘완벽하게’ 라는 수식어를 42서울 처럼 붙이긴 어려울 것 같지만, 그럼에도 여길 발판으로 삼아, 내년에는 정말 AI DevOps Backend 이 키워드 세가지의 전문가로 확실하게 자리 매김을 할 수 있기를 기대해본다.</p>

<p>42서울을 통해 2.0을 만들었었고, 2.x 버전이던 시기를 거쳐 이제는 AI 를 통해 버전 3 라는 매력적인 순간을 차지해보자. 😎</p>]]></content><author><name>Paul2021-R</name></author><category term="생각정리" /><category term="AI" /><category term="LLM" /><category term="생각정리" /><category term="이직" /><category term="학습" /><summary type="html"><![CDATA[들어가면서 AI, AI, AI…]]></summary></entry><entry><title type="html">AI Breakfast Ep 8 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/30/AI-trend-with-google-08.html" rel="alternate" type="text/html" title="AI Breakfast Ep 8 생각정리" /><published>2025-07-30T00:00:00+00:00</published><updated>2025-07-30T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/30/AI-trend-with-google-08</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/30/AI-trend-with-google-08.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=BrR5CQuH7Hs"><img src="https://i.ytimg.com/vi/BrR5CQuH7Hs/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>‘AI Breakfast’의 여덟 번째 에피소드는 ‘개발자의 관점: AI는 좋은 질문을 기다린다, 답이 아니라’라는 주제로 진행된 대담이다. 인공지능 환경을 둘러싼 개발 전반에 대해 이야기했다.</p>

<ul>
  <li><strong>지능과 인공지능의 본질</strong>:
    <ul>
      <li>현재의 인공지능은 인간이 만들어낸 지능이며, 특히 <strong>언어적인 유창함</strong> 때문에 지능으로 오해하는 경향이 크다.</li>
      <li>아직 학습하지 않은 부분에 대해서는 ‘환각(hallucination)’ 현상이 많고 올바른 답을 내지 못하는 한계는 여전하다.</li>
    </ul>
  </li>
  <li><strong>LLM의 안전성과 제어를 위한 노력</strong>:
    <ul>
      <li>LLM(대규모 언어 모델)은 현재 <strong>제어 가능한 범위 내에서 제어 가능한 결과를 얻기 때문에</strong> 창발적인 결과를 얻기 어렵다.</li>
      <li>구글은 <strong>세이프티 필터링</strong>을 통해 도전적인 프롬프팅에 안전하게 대응한다.</li>
      <li>모델 출시 전 사람이 직접 개입하여 질문과 답의 경량성을 평가하고 세이프티 가이던스를 정책으로 적용하는 노력을 기울인다.</li>
      <li>일부 안전성 제어 또한 자동화는 가능하지만, 질문과 답에 대한 평가 결과는 아직 사람이 개입하는 것이 효율적이라고 본다.</li>
    </ul>
  </li>
  <li><strong>AI 모델 출시 전략과 플랫폼 활용</strong>:
    <ul>
      <li>사용자들은 특정 페르소나 부여에 적합한 ‘Anthropic Sonnet’이나 의도된 결과 도출에 적합한 ‘Gemini’ 등 <strong>목적에 맞춰 다양한 AI 모델을 혼용</strong>하여 사용한다.</li>
      <li>‘Vertex AI’와 같은 플랫폼이 다양한 모델을 활용하는 데 큰 도움이 된다.</li>
    </ul>
  </li>
  <li><strong>개발자들의 AI 활용</strong>:
    <ul>
      <li>개발자들 사이에서 가장 인기 있는 AI 서비스는 <strong>LLM과의 채팅</strong>과 <strong>이미지 생성</strong>이다.</li>
      <li>AI 코딩 도구(예: Google의 Code Assist, JetBrains, Cursor, Windsurf)가 개발 생산성을 크게 향상시키고 있으며, Gemini와 Code Assistant를 활용하여 <strong>두 달 만에 Unity로 게임 데모를 개발</strong>한 경험을 공유했다.</li>
      <li>AI가 개발자의 생산성에 미치는 영향은 천차만별이며, 특히 <strong>새롭거나 익숙하지 않은 API 연동과 같은 작업에서 두세 배의 생산성 향상</strong>을 가져올 수 있다.</li>
      <li>그러나 익숙한 로직을 작성하거나 짧은 함수를 만들 때는 AI의 도움이 덜할 수도 있다고 한다.</li>
      <li><strong>자신이 어떤 상황에 처했고 무엇을 해결하려는지 상세하게 넘겨줄수록</strong> 올바른 답을 받을 확률이 높아진다.</li>
      <li>결론적으로 AI는 <strong>숙련가가 본인의 능률을 보다 향상시키는 데 굉장히 좋은 도구</strong>로 기능할 수 있다.</li>
    </ul>
  </li>
  <li><strong>AI 의존과 커리어에 대한 생각</strong>:
    <ul>
      <li>현 시점에서 인공지능에 전적으로 기대어 커리어의 단계를 뛰어넘으려는 것은 바람직하지 않다.</li>
      <li>어떤 도메인이든 잘하는 사람은 AI를 잘 이용하고, 못하는 사람은 잘 이용하지 못한다.</li>
      <li>생성형 AI를 잘 활용하려면 배우고자 하는 열정, 실수해도 일어서는 끈기, 많은 시간 투입 등의 요건이 필요하다.</li>
      <li>LLM이 생성한 코드를 검증 없이 코드 리뷰에 올리는 경우, 리뷰해야 하는 사람들의 감정 소모와 비효율을 초래할 수 있다. 오히려 협업에 독이 되는 경우가 발생하는 것이다.</li>
      <li><strong>AI 도구는 사용자가 통제할 수 있는 영역에서 다뤄야 하며</strong>, 그렇지 않으면 주변 사람들까지 힘들게 할 수 있다.</li>
    </ul>
  </li>
  <li><strong>AI와 1인 개발자 및 콘텐츠 스튜디오</strong>:
    <ul>
      <li>생성형 AI(이미지, 비디오, 문장 생성)는 <strong>1인 개발자가 스튜디오의 역할을 수행할 수 있도록</strong> 돕는다.</li>
      <li>성우나 스토리 작가 없이도 게임 제작이 가능해지며, <strong>여러 AI에 페르소나를 부여하여 서로 대화하게 함으로써 결과물을 얻는 방식</strong>도 상상해 볼 수 있다.</li>
      <li>유튜브 등 콘텐츠 플랫폼에서 얼굴이나 목소리 노출 없이 AI로 영상, 내레이션 등을 만들어 쇼츠를 생산하고 수익화하는 사례가 증가하고 있다.</li>
      <li>AI가 플랫폼의 알고리즘을 학습하여 <strong>최적의 콘텐츠를 만들어낼 수도 있을 것</strong>이라는 전망이 있다.</li>
      <li>Google의 <strong>Veo(영상), Imagen(이미지), 음성 모델, 음악 생성, DJing 도구</strong> 등은 상상력이 닿는 데까지 모든 것을 만들 수 있게 한다.</li>
      <li>사용자들은 음악보다는 영상이나 이미지 생성에 더 큰 관심을 보이며, Veo 등을 활용하여 개인 뮤직비디오를 만드는 것도 충분히 가능하다고 한다.</li>
      <li>AI는 문화재 복원(벽화, 유화, 소실된 영화 필름 복원)과 같이 <strong>인류의 가치 있는 미디어를 복원하는 데도 도움</strong>을 줄 수 있다.</li>
    </ul>
  </li>
  <li><strong>AI 창작물에 대한 구글의 철학 및 대응 방식</strong>:
    <ul>
      <li>Veo를 통해 만들어진 영상에는 눈에 보이지 않는 <strong>워터마크(SynthID)</strong>가 삽입된다.</li>
      <li>SynthID는 오남용을 방지하고, AI가 만든 것임을 쉽게 판독, 나아가선 순수 창작자들을 위해 개발되었다.</li>
      <li>구글은 <strong>순수 창작자를 보호</strong>하기 위해 이 기술을 개발했으며, 원작자의 화풍을 모방하여 콘텐츠를 생성하는 것을 방지하는 데 활용된다.</li>
      <li>구글의 AI 원칙에는 <strong>구글 플랫폼에서 생성된 결과물이 제삼자의 저작권을 침해할 경우 구글이 책임지겠다는 면책 조항</strong>도 포함되어 있다.</li>
      <li>구글은 사용자들의 <strong>생산성 향상과 인류의 근본적인 문제 해결</strong>에 초점을 맞춰 기술을 개발하며, 재미 요소보다는 실용성에 중점을 둔다.</li>
      <li>Gemini는 챗GPT와 달리 ‘건조하고 할 말만 한다’는 특징을 가지며, 이는 <strong>기술의 본질적인 가치에 집중</strong>하는 구글의 방향성을 보여준다.</li>
    </ul>
  </li>
  <li><strong>구글 워크스페이스에서의 생산성 향상</strong>:
    <ul>
      <li>구글 워크스페이스(Docs, Slides)의 AI는 <strong>기존 업무 환경에서 점진적으로 생산성을 향상</strong>시키도록 설계되었다.</li>
      <li>비즈니스 목적에 사용되기 때문에 의도하지 않은 결과가 나오지 않도록 <strong>엄중한 가이드라인</strong>을 지키며, 둔하더라도 신뢰할 수 있는 방향으로 개발된다.</li>
      <li><strong>구글 미트의 회의 요약 기능</strong>은 회의 내용을 시간순으로 배열하고, 누가 누구에게 무엇을 요청했는지 요약하여 업무 누락을 방지하는 데 혁신적인 도움을 준다.</li>
    </ul>
  </li>
  <li><strong>AI 에이전트의 보안</strong>:
    <ul>
      <li>Google의 <strong>Agent2Agent(A2A)</strong>는 기업 환경에서 사용할 수 있도록 <strong>엔터프라이즈 그레이드 보안 및 인증 체계를 갖추는 데 중점</strong>을 두어 개발되었다.</li>
      <li>이를 통해 과거 MCP(Messaging, Content, and Platform)와 같은 우려를 상당 부분 해소할 수 있을 것으로 기대한다.</li>
    </ul>
  </li>
  <li><strong>개발자로서 AI를 통한 미래 기대</strong>:
    <ul>
      <li>AI 도구를 활용하여 개인의 <strong>개발 생산성을 높이고, 나아가 팀과 조직의 생산성을 끌어올려 비즈니스 성공에 기여</strong>할수 있다고 생각한다.</li>
      <li>AI 코드 리뷰는 개발자가 급박하게 돌아가는 개발 과정에서 감정 소모를 줄이고, 사소한 지적을 AI가 대신하여 <strong>효율적인, 객관적인 코드 검토</strong>가 가능하게 한다.</li>
      <li>궁극적으로 AI는 개인의 생산성을 늘리기 위한 도구로 사용될 것이며, 구글의 서비스도 이러한 가치에 부합하는 결과를 목표로 한다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>이번 내용은 AI에 대한 보다 개발자적인 내용들이 위주로 나오면서 좀더 생산적이게 느껴졌다.</p>

<p>특히나 실질적인 사례들이나, 기존에 나도 생각하던 부분, AI에게 얼마나 어떻게 세이프티를 채울 것인가.</p>

<p>그리고 그 세이프티와 함께 AI 를 다루는 사람들은 어떻게 생각하면 좋을까 같은 다소 어려운 주제들이, 상당히 나와 유사한 생각의 형태로 이어졌다.</p>

<p>내가 AI 라는 소재에 매력을 느끼는 건 뭐 때문인가.</p>

<p>생각해보면 그냥 트렌드니까, 돈이 되니까, 그런 영역으로 끝나는 문제는 아니라고 생각한다.</p>

<p>AI 는 날개다.</p>

<p>좋은 질문, 효과적인 상황에서 사용 시 사람의 한계를 뛰어넘는데 발판 역할을 해줄 수 있을 뿐 아니라, 그걸 기준으로 하면 사람이 가지는 감정,</p>

<p>새로운거 배우는게 쉽지 않은 그 감정을 이겨낼 수도 있다는 점에선 AI 는 사람의 다음 그 이상을 만들어줄 거라는 그런 기대를 하게 된다.</p>

<p>실제로 나의 1년의 서버 개발자로의 삶에서도, 결국 AI 가 있었기에 지금 수준의 성과, 지금 수준의 속도, 지금 수준의 자신감을 가질수 있었으니까 말이다.</p>

<p>그나저나 확실한 건 얼른 VertextAI 를 비롯해서 구글의 AI 를 위한 플랫폼에 대한 서비스 이해도가 높아질 필요가 있어 보인다….</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry></feed>