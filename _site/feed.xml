<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" hreflang="ko" /><updated>2025-12-05T07:19:05+00:00</updated><id>http://0.0.0.0:4000/feed.xml</id><title type="html">Paul’s Archives</title><subtitle>성장하는 개발자, 소통하는 개발자, 빠른 적용을 최 우선으로 삼는 개발자. 다음을 항상 생각하며, 개발 속에서 가치를 만들어내는 것을 목표로 합니다.</subtitle><author><name>Paul2021-R</name></author><entry><title type="html">TIL - 11월, K8s 실패 + Docker 환경으로의 전환 정리</title><link href="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/12/05/00-til-change-plan.html" rel="alternate" type="text/html" title="TIL - 11월, K8s 실패 + Docker 환경으로의 전환 정리" /><published>2025-12-05T00:00:00+00:00</published><updated>2025-12-05T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/12/05/00-til-change-plan</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/12/05/00-til-change-plan.html"><![CDATA[<h2 id="k8s-실패--docker-환경으로의-전환-정리">K8s 실패 + Docker 환경으로의 전환 정리</h2>

<p>제목처럼, K8s 로의 완전한 통합환경 구축의 실패와 이후 Docker 기반의 컨테이닝으로 실서비스 배포에 대한 전체 내용을 정리한 글이다.</p>

<h3 id="증명을-할-필요가-있다">증명을 할 필요가 있다</h3>

<p>Protostar 프로젝트를 진행하게 된 것은 어디까지나 1년 차인 내가, 참 많은 일들을 겪었고 증명이 이제는 필요하다는 생각을 했다.</p>

<p>개발자로 살아남기 위해선 정말 어려운 일들을 해낼 수 있을 지식의 풀과 넓이가 있어야 하고, 결국 그걸 증명해내야 한다.</p>

<p>반대로 말하면 물경력이 되는 이유는 당연하지만 ‘회사’는 메이는 곳이고, 회사에서 경험을 쌓는 공간으로 개인 입장에서 맞지만, 한 편으로 그것은 회사의 입장과는 상관 없는 입장이며, 회사의 규모와 수준에 맞춰서 기회가 생기는 것이니, 절대 다수가 1류 기업에 들어갈 수 없다는 점을 생각한다면 대다수가 물경력이 되는 이유는 바로 이 지점에서 생긴다고 생각한다.</p>

<p>그러니 나아가서 증명.
기업이 바라는 인재가 되려면 무언갈 해야하지만,
회사에서 그걸 하긴 쉽지 않다. 그리고 동시에 내 개인의 사정 등등… 결국 고려하고 달려온 결과, 증명의 필요가 있었다.</p>

<h3 id="왜-kubernetesk8s-인가">왜 Kubernetes(k8s) 인가?</h3>

<p>백엔드 개발자로 사실 백엔드 기술 측면에서 본다면 당연히 프레임워크, 그리고 각종 보안에 대한 이해도가 필요하다. 특히 리소스, 대용량 서비스, 특히나 메시지 기술을 활용한 분산처리는 백엔드의 꽃이자 A to Z 라고 배웠다.</p>

<p>그러나 오케스트레이션 도구인 K8s 의 등장은, Container 기술을 기반으로 성장하고 Docker 로 꽃 피운 새로운 시대에, 더욱이 위의 핵심, 맹점을 제대로 다루기를 가능케 했다.</p>

<ol>
  <li>Self healing : Desired State 를 기술함으로서, 자동 재시작이 가능해지고, 노드 관리를 통해 컨테이너들을 자동으로 유지 시켜준다.</li>
  <li>Auto Scaling : 1번과 함께, 트래픽에 대한 하드웨어 모니터링, 리소스 기준을 제시해줌으로써 대용량 설계를 손쉽게 가능하게 한다.</li>
  <li>Rolling Update &amp; Rollback : 여러 CICD 파이프라이닝 도구들을 기반으로 무중단 배포(Zero-down time) 의 구현이 손쉽고, 이는 이용자가 모르는 사이에 업데이트 및 서비스 가용성을 극대화 시킨다. 또한 잘못된 업데이트가 이루어질 때 이에 대한 롤백은 명령어 하나로 즉시 가능하다.</li>
  <li>Bin packing : 각 컨테이너의 필요한 자원의 수준을 결정하고, 이에 따라 노드들을 구성, 서비스를 위한 하드웨어에 그 자원을 딱 맞춰 사용할 수 있도록 구축이 가능하므로, 이를 통한 인프라 비용의 최적화를 이루어낼 수 있다.</li>
  <li>Cloud Agnostinc : AWS, GCP, Azure 등 혹은 자체 데이터 센터까지, 사실 최초의 서비스 플랫폼들은 각각 자체적인 기준과 락인 형태를 구축하기 바빴다. 물론 그렇게 구축되는 것이 매우 편리한 것은 사실이며, 또한 안정성 역시 담보 받을 수 있었다. 하지만 문제는 락인 되었을 때 비용, 동시에 환경들이 별도이다 보니 발생하는 버그 발생 가능성, 그리고 서비스 플랫폼을 여러 곳에서 쓴다고 한다면 설령 Containerize 된 환경이라도 발생 가능한 여러 이슈들의 종합적인 대응. 이를 위하여 완전 표준 기술처럼 동작하고, 이를 기반으로 설정되기에 일부 특화 서비스를 제외하곤 클라우드 제공 업체, 환경을 뛰어넘는 배포를 가능케한다.</li>
</ol>

<h3 id="하지만-이번에는-실패했다--아쉽지만-다른-방법으로">하지만 이번에는 실패했다 &amp; 아쉽지만 다른 방법으로</h3>

<p>그리하여 호기롭게 도전하였다. Dockerize는 너무나 쉬운 일이었고, 이제는 Docker 기반으로 나름대로 뭐든 올릴 수 있겠다는 확신이 있었다. 또한 거기서 내가 뭘 더 할 수 있어야 나에게 도움이 되는가? 라고 한다면 당연히 데이터의 관리 파이프라인 전반에 대한 이해도를 높이는 것이리라 생각했다. 그렇기에 k8s 를 선택. 파고 들어보았다.</p>

<h4 id="순조롭던-microk8s-부터-argocd-까지">순조롭던 MicroK8s 부터 ArgoCD 까지</h4>

<p>서버의 배포는 원래 아주 가벼운 OS 기반으로 할까 생각을 했다. Arch 나 Alpine. 하지만 종합적으로 여러가지를 고려한다면 어차피 세팅이 필요한 호스트 OS 이다보니, 이러한 설정이 다 있는 편리한 OS, Ubuntu 기반으로 생각했다.</p>

<p>그러니 당연히 snap 을 기본으로 쓸 수 있었고, Snap의 장점인 완전히 격리된 환경에서 구동 가능한 앱 환경에서 쓰기 편리한 것, 그것이 바로 MicroK8s 라는 도구였다.</p>

<p>MicroK8s 를 설정한 이유는 위에서 언급한 부분도 있지만, 가볍다고 소개가 되어 있었고, 쉬운 확장성 기능들을 지원해 <code class="language-plaintext highlighter-rouge">microk8s enable dns</code> 이런식으로 명령어 한줄이면 서비스 구축을 위한 애드온들을 기본 내장하고 있었다. 특히나 <code class="language-plaintext highlighter-rouge">CNCF</code> 인증을 받아, 기존에 많이 쓰던 AWS, GCP 등 어떤 곳이든 클라우드 환경과 동일하게 작동을 보장했다.</p>

<p>처음에 살짝 해매긴 했지만(<code class="language-plaintext highlighter-rouge">--classic</code> 옵션 넣고 설치해야함), 나름 순차적으로 진행이 되었으며  GitHub 을 기반으로 <code class="language-plaintext highlighter-rouge">단일진실공급원(Single Source of Truth, SSOT)</code> ArgoCD 를 통해 확실하게 기반을 다져나갔다.</p>

<p>ArgoCD</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 1. 'argocd'라는 네임스페이스(공간) 생성</span>
<span class="nb">sudo </span>microk8s kubectl create namespace argocd

<span class="c"># 2. ArgoCD 공식 설치 YAML 적용</span>
<span class="nb">sudo </span>microk8s kubectl apply <span class="nt">-n</span> argocd <span class="nt">-f</span> https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
</code></pre></div></div>

<p>ArgoCD 접속 가능하도록 임시 설정하기</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># A5 서버의 8080 포트를 ArgoCD 서버(argocd-server)의 443 포트로 연결</span>
<span class="c"># 0.0.0.0 추가로 외부에서 접속 가능하게함</span>
<span class="nb">sudo </span>microk8s kubectl port-forward <span class="nt">--address</span> 0.0.0.0 svc/argocd-server <span class="nt">-n</span> argocd 8080:443
</code></pre></div></div>

<p><img src="/assets/images/posts/2025-12/20251205-002.png" alt="" /></p>

<p>ArgoCD 를 기반으로 하게 된 이유는 간단하다. 우선 핵심 인프라의 설정과정에서 국내에서 다소 표준처럼 쓰이고 있다는 사실을 알 수 있었다. 또한 써보면서 알게된 거지만 당연하게도 GitOps에 최적화된 다양한 설정들이 존재했다.</p>

<p>원래 같으면 1) 개발자가 직접 명령어를 쳐서 구현하던가, 2) Jenkins / Github Action 기반의 배포 스크립트를 구축하는게 방법이겠지만 이하 내용 때문에 ArgoCD 를 써야 한다고 확신했다.</p>

<ol>
  <li>CI 와 CD 의 분리 : Jenkins 로 배포를 만들다보면, CICD 의 의존성, 복잡성이 증가하는 것을 경험할 수 있다.  하지만 ArgoCD 는 CD 부분을 담당하여, 3분마다 동기화를 해주고, 지정된 상태에 따라 기본적인 오케스트레이션을 해주며, 특히 단순하게 특정 어플리케이션만을 위한 형태가 아니라, 각 ‘개별’ 어플리케이션의 상태와 관계 없이 바라보게 해준다. 이러한 점은 (1) Jenkins 가 배포와 관련된 영역에 대한 책임에서 해방되면서, Jenkins 의 관리 영역이 획기적으로 줄어들게 되고, 순수하게 CI에만 집중하면 되게 된다. (2) Jenkins 가 접근을 외부에서 내부로 하게 되다보니 생길 보안의 이슈가 원천적으로 차단되고, ArgoCD 가 직접 Git Repo를 Pull 하는 방식이니, 외부 접속과 관련된 보안 틈을 만들지 않는다. (3) 클러스터로의 통로를 담당하는 키, 환경변수 등 모든 것들이 외부에 있을 필요가 없다. ArgoCD 가 내부에서 쥐고 있다.</li>
  <li>설정 표류 감지 및 자동 복구 : Jenkins 의 배포를 자동화 하는 경우도 있을 것이고, 수동으로 할 때도 있다. 둘다 문제가 있다. 수동으로 하면 적절하게 진행하기가 안되거나, 관리 인원이 여럿이 되는 순간 꼬일 수 있는 일이 발생한다. 또 자동으로 되어 있다면, 누군가 급하게 무언가 수정했다고 칠 때, 그 내용은 Jenkins 는 알 수 없다. 그리고 그 상황에서 배포가 이루어지면 시스템의 마비를 초래할 수도 있으며, 무엇보다 구성원들의 협업에서 맥락의 단절이 발생한다. 하지만 SSOT(단일 진실 공급원)에 충실한 ArgoCD 기반의 배포는 매우 훌륭하게 이 문제를 해결한다. 모든 것, 즉, 롤백도, 코드의 변경 등 모든 변화의 대응은 Git 의 레포지터리가 담당하고, 그 과정에서 어떤 정책으로 할 지만 잘 결정하면 어떠한 이슈 없이도 대응이 가능하다.</li>
</ol>

<p>이러한 점들 때문에 <code class="language-plaintext highlighter-rouge">project-protostar-k8s-config</code>라는 단일 레포를 만들고, 여기에서 메인 서버와 모니터링 서버 별로 자원 배포 및 서버 구동을 위한 infrastructure 들을 구성해보았다. 특히 여기서 적극 도입해본 것이 Helm Chart 의 패키징 방식이었다.</p>

<h4 id="helm-chart의-위험성">Helm Chart의 위험성(?)</h4>

<p>여기서부터가 문제의 시작점.
Helm Chart 는 도커의 이미지에 비하여, 애플리케이션 배포의 실전성을 추가해주는 방식의 도구였다. k8s 에서 애플리케이션을 배포할 때, 특히 실무에서 필요한 여러 설정들이 있고, 특히 failure 를 고려한 이중, 삼중의 시스템 패키징이 되어 있는걸 손쉽게 다운 받을 수 있다- 이 점 때문에 필요하고, 또 실제로 그걸 기반으로 Monitoring 서버 구축, Loki 나 Promtail, Grafana의 설정은 핵심이었기에 룰루랄라 설정을 이어갔다…하지만…</p>

<p>우선 Helm을 운용하는데 문법이 상당히 복잡했다. 뿐만 아니라 가장 핵심은 ‘욕심이 과했다’ 라고 이해하는게 핵심이다. 버전이 어떻게 호환되고, 또 어떤 식으로 써야 할지도 모른체 구축되는 수많은 어플리케이션의 연쇄는 핸들링을 하는 과정에서 제대로 연결이 안되는 온갖 문제들을 야기했다.</p>

<p><img src="/assets/images/posts/2025-12/20251205-007.png" alt="" /></p>

<blockquote>
  <p>현재 단일 서비스를 위해 올라간 모든 컨테이너(물론 지금은 Docker 로만 되어 있고, k8s 를 걷어내긴 했다.)</p>
</blockquote>

<p>그리고 거기서 가장 극심한 것은 역시나 버전 차이 및 호환성 문제.
단순히 어플리케이션 자체만 래핑하는 거였다면 문제가 훨씬 쉬웠을 것이다. 하지만 ArgoCD 기반에, 각종 에러를 대응하기 위해 Helm Chart 패키징한 어플리케이션이란 내가 설정하는 메인 설정이 아니더라도 뒤에서 안전하게 돌아갈 수 있는 설정을을 하게 되어 있고, 그러다보니 유명한 패키지로 열려 있는 것들을 불러오게되면, 이 내부에도 또 버전들이 낮게 설정되어 있거나, 자신들의 테스트한 버전들이 들어 있고, 이걸 래핑한 걸 또 내가 쓰는 입장이니, 호환성 문제는 매우 예민했다.</p>

<p>만났던 여러 문제들을 정리하면 다음과 같은 문제가 있었다.</p>

<ol>
  <li>Zalando PostgreSQL Operator 와 PgVector 구축 시 이미지 레지스트리 : 과거 사용되던 것들을 찾아서 기재했으나, 알고 봤더니 기존과 다른 위치에서 배포되고 있었음. AI 도 이상한 소리함. 찾아보니 새로운 곳에서 지원을 했고, 더욱 문제는 pgVector 설정은 별도로 해줘야 하는 것이었음.</li>
  <li>Vector 데이터베이스 구축 시 사용될 yaml 내부의 문자열 문법에러 : AI 를 기반으로 반 바이브 + 학습 방식으로 진행함. 그런데 여기서 실제 필요한 문법 형식과 다르게 학습된 AI 는 이상한 소리를 했고, 이것이 문제일 것이란 점을 한참 지나서 파악하게됨(…)</li>
  <li>꼬인 리소스 기준으로 좀비 리소스가 된 상태에서의 해결 안됨 : k8s API의 통제권을 ArgoCD 에게 위임하고, finalizer 역시 ArgoCD 로 지정했음. 그러나 여기서 호환성 문제, 특히 Grafana 스택에서 loki 가 있었는데, 문제는 모니터링 서버에 별도로 Grfana를 설치하면서 k8s 의 Grafana 공식 스택과 별도였는데, 이때 Docker 버전 차이, Grafana 버전 차이에 따라 loki의 문법을 제대로 못찾으면서 호환성 이슈가 생김 알게됨. 커넥션 불량이 발생하면 finalizer는 멈추고, 좀비처럼 변해서 ArgoCD 의 통제 명령에 제대로 동작하지 않음. 그 밖에도 MinIO 설정이 필요한 Loki 내부 설정에서의 문제점(최신버전 과 구버전 사이) 등 여러 이슈가 동시 다발로 묶여서 발생함.</li>
  <li>Ingress Nginx 대신 Gateway API 사용 실패 : 지금은 조금더 이해하긴 했지만, 최근 Ingress Nginx 라는 매우 쉽고 편리한 방식에서 API Gateway 를 사용해야 하고 Nginx Fabric 이라는 걸 도입해보려 했으나 에러 발생.</li>
  <li>Snap 기반의 문제: 사용하기 편리하고, 경량이며, 격리된 특성을 가진 snap을 처음 쓸때는 대단히 ‘개발자 친화적’인 도구라고 생각했다. 하지만 여러 문제를 가진 다는 것을 알게 되었을 때는 실제 환경에선 이걸 잘 못쓰면 안된는구나라는 판단이 섰다.
    <ol>
      <li>우선 가장 문제로 <code class="language-plaintext highlighter-rouge">--classic</code> 모드로 설정하지 않으면 설치 되더라도 일반적인 호스트 시스템에 접근이 불가능하다.</li>
      <li>또한 Snap 특성상 자동 업데이트를 강제하는데, 이게 개인용 도구라면야 업데이트를 하는게 큰 문제는 아닐 수 있지만, MicroK8s 를 사용하게 되면 이건 심각한 문제가 될 수 밖에 없다고 느꼈다. (물론 이 문제는 오래된 거라, 요즘은 대안이 있지만 ‘번거롭다’는게 흠.)</li>
      <li>그 밖에도 여러모로 번거로운 부분들이 있었고, 결론적으로 실제 상용으로 쓸 때 MicroK8s 기반이 되는 것 자체는 괜찮았지만, snap 을 쓰는건 절대 하지 말아야겠단 생각이 더욱 명확해질 수 있었다. 개발로 구축한 이후의 서비스에 Snap의 궁합은 대단히 조심스러워야 할 것이었다.</li>
    </ol>
  </li>
</ol>

<p>그리하여 얻은 결론은
확실한 검증, 그리고 동시에 확실한 호환되는 툴들을 버전별로 꿰고 있어야 하며, 더욱이 패키지 방식으로 묶인 걸 먼저 쓰는게 아닌 스스로 설정해보는 것을 써보거나, 아예 해당 패키징 된 것을 쓸 거라면 완전히 그것의 의존성에 기대어 개별적인 환경이나, 내 커스텀한 상황으로 만들면 안된다는 사실(…) 이해할 수 있었다.</p>

<p>현재는 K8S 의 기본적인 골조와 구성부터 다시 학습을 하고 있으며, 프로젝트의 진행 그리고 구현할 것들을 감안했을 때는 멈출 수 없다는 전제 하에, 기존의 Jenkins + Nginx + Docker + GitHub 기반의 무중단 배포 방식으로 설정을 진행하였다.</p>

<h4 id="향후-계획">향후 계획</h4>

<p><img src="/assets/images/posts/2025-12/20251205-003.png" alt="" /></p>

<p><img src="/assets/images/posts/2025-12/20251205-006.png" alt="" /></p>

<p>그리하여 돌고 돌았지만 깨달은 점은</p>

<ol>
  <li>k8s 는 생각 이상으로 별게 맞았다.(?) k8s 자체를 이해하는건 이번 일로 깨달았지만, 문제는 사실 그 안에 채우는 것들이었다.</li>
  <li>기본기를 배울 좋은 기회였고, 대규모 분산처리를 위해 하긴 할건데, 일단 만드려는 것부터 먼저하자(?)</li>
  <li>Docker 는 진짜 직관적인 것이었다.</li>
</ol>

<p>와 같았다. 그러나</p>

<p>목표를 위한 키워드 안에 다른 핵심들도 있었기에, 시간 낭비를 줄이고자 바로 노선을 변경. Docker 기반으로 컨테이너라이징 하는 것으로 수정하였으며, 패키지 방식은 좀더 연구를 통해 구성해보려고 한다. 물론, 가장 문제시 되는 호환성은 각 도구 별로 사용법 그 이상으로 이해도를 높이는 시간을 가지면 아마 무리없었지 않을까 싶긴 하다. 그러나, 어쨌든 당장은 목표를 위해 가야 하니 수정… 지금은 다음과 같은 구조로 설정하였다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Main 서버 
- nginx
- exporter
- cAdvisor 
- promtail
- Front-end Server(Green, Blue)
 -  NextJS 
- Back-end Server(Green, Blue)
 - NestJS
 - FastAPI
- PostgreSQL Vector (DB, RAG)
- Redis (Que, Messaging)

Sub 서버
- nginx 
- exporter
- cAdvisor
- prometheus
- Grafana
- Loki
- MinIO(Obj Storage)
</code></pre></div></div>

<p>또한 이를 위한 관리 구조는 다음 레포지터리로 구성했다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- project-protostar-server-configs : monitoring 핵심 도구레포지터리, Nginx 등의 설정을 관리하는 SSOT로 보장
- project-mini-frontend : NextJS app 및 Jenkins 파일 관리 레포
- project-protostar-nest : NestJS, 서비스 기능 구현 서버
- project-protostar-fastapi : FastAPI 기반 AI 서비스 기능 구현 서버
</code></pre></div></div>

<p>또한 특징적으로 이러한 문제도 있었는데
KT 회선 하나 당 공인 IP 하나가 할당된다. 따라서 정식 서비스를 온프레미스로 진행시 종단간 암호화를 위해선 HTTPS 443 의 적절한 포트를 할당 해야했다.</p>

<p>그러나 여기서 문제는 Nginx 를 통해 443 포트를 점유하는 것까진 괜찮지만, 문제는 이 경우 어드민으로 관리하는 영역을 접속하는 것도 443 으로 암호화 및 외부 접속 가능하게 만들려면 메인 서버의 Nginx 를 경유하던지 해야 하는게 기본적인 해결책이었다. 그러나 이 경우 관리하는 도구들이 있는 서브 서버는 살아 있고, 메인 서버가 죽어버리는 일등이 발생할 때 문제가 심각해진다.</p>

<p>왜냐하면 443으로 메인 서버의 nginx 를 경유한 순간부터, 서버의 문제 발생 시 이에 대한 적절한 대응이 불가능한 것이다.</p>

<p>이에 L4(Transport Layer) 레벨의 프록시 패스, 앞 단에 무료 GCP 서버를 하나 추가한 뒤, 이를 공인 IP의 다른 포트로 전달. 단 이때 암호화된 패킷을 그대로 전달하기 때문에 암호화는 유지되면서도 하나의 공인 IP 기준으로 443 HTTPS 를 두 선으로 만드는 방법을 적용하여, 관리 회선과 서비스 회선의 분리를 만들어냈다. 그림으로 정리하면 이런 구조다</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 서비스 접속</span>
서비스 접속<span class="o">(</span>443<span class="o">)</span> -&gt; HTTPS -&gt; 공인 IP<span class="o">(</span>443<span class="o">)</span> -&gt; 메인 서버 <span class="o">(</span>443<span class="o">)</span> 
<span class="c"># 관리 </span>
관리 도구 접속<span class="o">(</span>443<span class="o">)</span> -&gt; GCP 가상 머신<span class="o">(</span>443<span class="o">)</span> -&gt; L4 proxy pass -&gt; 공인 IP <span class="o">(</span>다른 포트<span class="o">)</span> -&gt; 포트 포워딩 -&gt; 서브 서버<span class="o">(</span>443<span class="o">)</span> 
</code></pre></div></div>

<p>다행이 L4 레이어는 암호화를 해지하지 않는다. 단 외부 IP 를 정확히 인지하지 못하게 되고, GCP 가상 머신의 공개 IP 로 기록이 남는 문제는 있다. 이에 Nginx 에서 이러한 문제를 해결하기 위한 옵션을 켜는 것으로 관리 회선과 서비스 회선의 독립을 만들어냈다.</p>

<h4 id="바이브-ai-k8s-devops-그리고-protostar">바이브, AI, K8s, DevOps 그리고 Protostar</h4>

<p><img src="/assets/images/posts/2025-12/20251205-004.png" alt="" /></p>

<blockquote>
  <p>현재는 데모만 올라가 있다… 계속 개발중</p>
</blockquote>

<p>현재 Protostar 서비스는 계속 작업 중이다. 산넘어 산이라더니 K8s 를 적용하는 과정, MSA 폴리글랏 구조, 그리고 거기에 3년차 정도가 해야 하는 많은 도구들. 처음엔 별거 아니겠지(?) 란 생각, 그리고 AI 라는 강력한 도구로 할 수 있을 것 같았지만 이는 오만한 생각이었고, 화들짝 놀라며 방법을 수정. 지금에 이르렀다(…)</p>

<p>물론, 이젠 생각을 달리 하기로 했다. 서비스와 프로젝트의 구체적인 구성을 채우고, 이미지가 준비만 된다면 Git Ops로 옮기는 건 일도 아니었고, 다행이 시행착오 덕에 ArgoCD 기반으로 배포하는 것은 문제가 아님을 파악했고, 오히려 다른 도구들 S3 호환 MinIO 의 관리나, 기타 다른 도구들에 대한 이해도가 더 끌어올라와야 k8s 로 포팅도 쉽게 가능할 것이란 확신을 얻었다. 그러니 달리고 난 뒤에 다시 적용해보겠다. 달리자(…)</p>

<p><img src="/assets/images/posts/2025-12/20251205-005.png" alt="" /></p>

<blockquote>
  <p>우선 K8s 와 Message 큐 기능은 제외되었다.
향후 추가 예정…</p>
</blockquote>]]></content><author><name>Paul2021-R</name></author><category term="학습" /><category term="학습" /><category term="DevOps" /><category term="Docker" /><category term="MicroK8s" /><category term="Kubernetes" /><category term="AI" /><summary type="html"><![CDATA[K8s 실패 + Docker 환경으로의 전환 정리]]></summary></entry><entry><title type="html">TIL - Antigravity 기반으로 챗봇 데모 구성해보기</title><link href="http://0.0.0.0:4000/%EA%B0%9C%EB%B0%9C/2025/12/05/01-coding-with-antigravity.html" rel="alternate" type="text/html" title="TIL - Antigravity 기반으로 챗봇 데모 구성해보기" /><published>2025-12-05T00:00:00+00:00</published><updated>2025-12-05T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EA%B0%9C%EB%B0%9C/2025/12/05/01-coding-with-antigravity</id><content type="html" xml:base="http://0.0.0.0:4000/%EA%B0%9C%EB%B0%9C/2025/12/05/01-coding-with-antigravity.html"><![CDATA[<h1 id="protostar-chatbot-demo-report">Protostar Chatbot Demo Report</h1>

<p><img src="/assets/images/project-protostar/protostar_icon.png" alt="" /></p>

<h2 id="1-개요-overview">1. 개요 (Overview)</h2>

<p>본 리포트는 블로그 내 ‘Protostar’ 챗봇 위젯의 개발 과정과 기술적 구현 사항을 정리한 것이다. Antigravity 를 기반으로 좀더 빠르게 구성 가능한지? 에 대한 질문과 Google 제시한 Implementation Plan - progress - walkthrough 의 라이프사이클에 따른 개발 방식을 제대로 이해하기 위한 실험적인 미니 프로젝트이다.</p>

<p>이 프로젝트는 단순한 정적 페이지용 위젯을 넘어, 향후 <strong>SSR(Server-Side Rendering) 서버 환경에서 호출될 컴포넌트</strong>임을 고려한 선행 기술 검증(PoC) 및 데모 작성 실험이며, AI 까지 붙일 생각을 했으나, 정적 사이트 및 AI 적용 시 생길 수 있는 이슈들로 인해 단순 채팅 기능의 FE 개발만을 진행해 보았다.</p>

<h2 id="2-기술적-구현-technical-implementation">2. 기술적 구현 (Technical Implementation)</h2>

<p>본 챗봇은 외부 라이브러리 의존성 없이 <strong>Vanilla JavaScript (ES6+)</strong> 만으로 구현되었으며, 이식성과 독립성을 최우선으로 설계되었다. 이러한 설계를 하게된 핵심은 아래를 고려했기 때문이다.</p>

<ol>
  <li>향후 제작할 Agentic AI 기반 챗봇이 어디든 연동되기 위해선 가장 중요한 키워드는 ‘호환성’이다.</li>
  <li>핵심 코어를 제외하곤 외부로 노출되어야 하기 때문에, 이를 고려한 설계가 가능해야하고, 그러기위핸 당장 종속성을 제거한 순수한 기술로 구현 가능한지 검증이 필요하다.</li>
</ol>

<p>그리하여 결론적으로 다음 성과를 달성했다.</p>

<p><img src="/assets/images/posts/2025-12/20251205-012.png" alt="" /></p>

<ul>
  <li><strong>독립적 실행 환경 (<code class="language-plaintext highlighter-rouge">assets/js/protostar.js</code>)</strong>:
    <ul>
      <li>HTML, CSS, Logic이 하나의 JS 파일에 캡슐화함.</li>
      <li><code class="language-plaintext highlighter-rouge">document.createElement</code>와 <code class="language-plaintext highlighter-rouge">appendChild</code>를 통해 DOM을 동적으로 생성함으로써, 어떤 페이지에도 <code class="language-plaintext highlighter-rouge">&lt;script&gt;</code> 태그 한 줄로 이식 가능함.</li>
      <li>CSS는 JS 내부에서 주입되어 스타일 충돌을 방지함.</li>
    </ul>
  </li>
  <li><strong>상태 관리 (State Management)</strong>:
    <ul>
      <li>브라우저의 <code class="language-plaintext highlighter-rouge">localStorage</code>를 미니 데이터베이스처럼 활용하여 세션 지속성을 1차적으로 구현함.</li>
      <li><code class="language-plaintext highlighter-rouge">protostar_sessions</code> 키를 통해 대화 히스토리, 생성 시간, URL 정보를 구조적으로 저장함.</li>
    </ul>
  </li>
</ul>

<h2 id="3-주요-기능-key-features">3. 주요 기능 (Key Features)</h2>

<ol>
  <li><strong>세션 관리 (Session Management)</strong>:
    <ul>
      <li>다중 세션 지원 (단, 현재 계획중인 프로젝트의 유저 사용 제한을 고려하여 일일 3회 생성 제한).</li>
      <li>생성된 지 7일이 지난 데이터 자동 삭제.</li>
      <li>세션 리스트 UI 및 슬라이드 애니메이션 적용.</li>
    </ul>
  </li>
  <li><strong>동적 컨텍스트 (Dynamic Context)</strong>:
    <ul>
      <li>사용자가 보고 있는 페이지의 URL을 기반으로 채팅방 제목이 동적으로 변경된다.</li>
      <li><code class="language-plaintext highlighter-rouge">+</code> 버튼을 통해 현재 페이지의 제목과 내용을 문맥(Context)으로 첨부할 수 있다.(특정 페이지에 대한 요약이나, 준비된 사항이 있다면 AI가 답변해주기 위하여)</li>
    </ul>
  </li>
  <li><strong>사용자 경험 (UX)</strong>:
    <ul>
      <li>커스텀 오버레이를 통한 직관적인 알림 (회원가입 유도 등).</li>
      <li>반응형 아이콘 리사이징 (PC/Tablet/Mobile 최적화).</li>
      <li>라인 아트 스타일의 유저 프로필 아이콘 및 직관적인 인터페이스.</li>
    </ul>
  </li>
</ol>

<h2 id="4-향후-계획-ssr-및-서버-연동-future-integration">4. 향후 계획: SSR 및 서버 연동 (Future Integration)</h2>

<p>현재는 클라이언트 사이드에서 모든 로직이 돌고 있지만, 최종 목표는 <strong>Next.js/React 기반의 SSR 서버</strong>로 이관하고, protostar 페이지에서 관리 될 예정이다. 단 한줄의 스크립트 호출 요청으로 어떤 블로그든 자신만의 기술블로그 및 커리어를 위한 AI 챗봇이 구축될 가능성을 확신하였다.</p>

<p>이번 데모를 통해 클라이언트단에서 필요한 이벤트 처리와 데이터 구조를 확립하였으며, 향후 다음과 같이 발전될 예정이다:</p>

<ul>
  <li><strong>Iframe/Script Injection</strong>: 외부 서버(Protostar 서비스)에서 위젯을 호스팅하고, 블로그는 이를 호출하는 구조.</li>
  <li><strong>실제 DB 연동</strong>: <code class="language-plaintext highlighter-rouge">localStorage</code> 대신 서버 DB(PostgreSQL 등)에 대화 내용을 저장.</li>
  <li><strong>AI 모델 연동</strong>: 현재의 목업(Mock) 응답 대신 실제 LLM API와 통신.</li>
</ul>

<h2 id="5-결론-그리고-antigravity">5. 결론 그리고 Antigravity</h2>

<p><img src="/assets/images/posts/2025-12/20251205-010.png" alt="" /></p>
<blockquote>
  <p>Antigravity 의 Implementation Plan</p>
</blockquote>

<p><img src="/assets/images/posts/2025-12/20251205-011.png" alt="" /></p>
<blockquote>
  <p>Antigravity 의 Walkthrough</p>
</blockquote>

<p>사실 여기서 더 소개를 하진 않겠지만 Antigravity 가 왜 괜찮은가? 라고 생각해볼때, 확실히 ‘UX’가 AI를 어떻게 이용할 것인가 라는 지점에서 완성도가 상당하다고 느껴지기 때문이라고 답할 수 있을 것 같다. 물론 workspace 도 대단하다고 느꼈지만, 순서를 구체화하고 AI 와의 협업, AI를 어떤 식으로 사람이 관리하도록 만들었는가? 차원에서 본다면 대단한 진보가 아닐 수 없었다.</p>

<p>업무의 성격에 따라, 구현의 목표치가 복잡하면 이에 맞춰 구현 플랜을 짜고, 다른 작업을 하고 있는 상황에서 AI의 이해 상황을 확인한다. 그리곤 수정을 할 게 있다면 수정을 진행하고, 그에 맞춰 진행 요청, 그리곤 결과물을 보게되는데, 이때 역시 테스트를 무엇을 얼마나 해야할지를 사람이 판단 가능하게 제시. 여기서 더 나아가면 subagent 기능으로 QA 까지 해보면 될것 같다. 진짜 DevOps 영역은 아직 한계가 명확하지만 웹 개발 영역은… 미친게 분명하단 생각이 든다.</p>

<p>또한 간단하게 순수 바닐라로 DOM 수정까지 포함하고 핵심 기능 전체를 구현하는데 AI 의 도움, 내 확인, 심지어 글 하나 별도로 작성 중이던 시점에서 1천줄의 코드를 작성하는데 약 1시간 반…. 엄청난 생산성 차이라는 건 명백해 보인다. 그러나 한 가지 확실히 알 수 있는 점은</p>

<ol>
  <li>개발 용어에 친숙하고 정확한 지침이 될 수록 기능 완성도는 명확하다.</li>
  <li>우선순위, 원칙을 명확하게 하지 않으면 AI 는 ‘과한 최선’을 다해 다소 꼬일 수 있다.</li>
  <li>반드시 AI 의 구현 작업 목록을 통해 AI의 확률적 판단이 ‘오해’ 인지 아닌지를 검토가 가히 필수이다.</li>
</ol>

<p>라는 점은 더욱 명확해지는 것 같다. 코더는 사라져도 찐 실력자들은 그대로 살아있을거란게 확실히 느껴진다.</p>

<p>더불어, 구현해보고 나니 Protostar 의 프로젝트가 생각 이상 편리할 것이란 생각. 그리고 이를 디테일하게 해주면 최소한 ‘뭘 원하는가’ 라는 차원에서 구직자 구인자 사이의 꽤나 괜찮은 접근이 되지 않을까? 라는 생각은 명료해진 것같다. 물론, 시장의 파워나 크기를 생각해보면 의미 없어 보이긴 하지만…음</p>]]></content><author><name>Paul2021-R</name></author><category term="개발" /><category term="개발" /><category term="VibeCoding" /><category term="Antigravity" /><category term="Frontend" /><summary type="html"><![CDATA[Protostar Chatbot Demo Report]]></summary></entry><entry><title type="html">n8n 개념 정리하기</title><link href="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/01-introduction-n8n.html" rel="alternate" type="text/html" title="n8n 개념 정리하기" /><published>2025-11-09T00:00:00+00:00</published><updated>2025-11-09T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/01-introduction-n8n</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/01-introduction-n8n.html"><![CDATA[<h2 id="n8n-자동화-도구-소개">n8n 자동화 도구 소개</h2>

<p>이 글은 n8n이라는 자동화 도구에 대한 기본적인 개념을 정리한 내용이다. ‘심심풀이’ 프로젝트를 진행하며 n8n을 처음 접하는 개발자들에게 이 도구가 무엇이며, 어떤 핵심 개념을 가지고 있는지 명확히 전달하는 것이 목적이다.</p>

<p>n8n(Nodemation)은 워크플로우 자동화 도구로, Zapier나 Make와 유사한 기능을 제공하지만 몇 가지 차별점을 가진다. 가장 주목할 만한 특징은 <strong>셀프 호스팅(Self-hosting)</strong>이 가능하다는 점이다. 이는 Docker 등을 활용하여 직접 서버에 설치함으로써 비용을 절감하고 데이터 통제권을 확보할 수 있다는 점에서, 특히 개인 프로젝트나 민감한 데이터를 다루는 환경에서 큰 이점을 제공한다.</p>

<p>n8n의 핵심적인 작동 방식은 <strong>노드 기반 시각화(Node-based visualization)</strong>에 있다. 모든 자동화 과정은 ‘노드(Node)’라는 블록으로 표현되며, 이 노드들을 시각적으로 연결하여 전체 자동화 흐름, 즉 <strong>워크플로우(Workflow)</strong>를 구성한다. 워크플로우는 자동화 작업의 전체 단위이며, PRD에서 정의한 콘텐츠 수집부터 기록까지의 선형적인 과정을 하나의 워크플로우로 구현할 수 있다.</p>

<p>n8n은 <strong>개발자 친화적(Developer-friendly)</strong>이라는 점도 강점이다. 기본 제공되는 다양한 노드만으로도 복잡한 자동화를 구현할 수 있지만, 필요에 따라 <code class="language-plaintext highlighter-rouge">Code</code> 노드를 통해 Node.js 기반의 JavaScript로 직접 로직을 작성하거나 외부 라이브러리를 연동하는 것이 가능하다. 이는 기존 도구에서 제공하지 않는 특정 기능을 구현해야 할 때 유용하다.</p>

<p>n8n을 이해하기 위한 네 가지 핵심 구성 요소는 다음과 같다.</p>

<h3 id="1-워크플로우-workflow">1. 워크플로우 (Workflow)</h3>

<p>자동화 작업의 전체적인 단위이자, 노드들이 배치되는 ‘캔버스’ 역할을 한다.</p>

<h3 id="2-노드-node">2. 노드 (Node)</h3>

<p>워크플로우를 구성하는 최소 작업 단위이다.</p>

<ul>
  <li><strong>트리거 노드 (Trigger Nodes):</strong> 워크플로우를 시작시키는 역할을 한다. <code class="language-plaintext highlighter-rouge">Schedule</code> (예약 실행), <code class="language-plaintext highlighter-rouge">Webhook</code> (외부 시스템 호출), <code class="language-plaintext highlighter-rouge">Manual</code> (수동 실행) 등이 대표적이다.</li>
  <li><strong>일반 노드 (Regular Nodes):</strong> 실제 작업을 수행하는 노드들이다. 데이터를 가져오거나, 가공하거나, 전송하는 등의 역할을 담당하며, <code class="language-plaintext highlighter-rouge">HTTP Request</code>, <code class="language-plaintext highlighter-rouge">Google AI</code>, <code class="language-plaintext highlighter-rouge">Discord</code>, <code class="language-plaintext highlighter-rouge">Git</code>, <code class="language-plaintext highlighter-rouge">Code</code> 등이 이에 해당한다.</li>
</ul>

<h3 id="3-데이터-흐름-data-flow--json">3. 데이터 흐름 (Data Flow &amp; JSON)</h3>

<p>n8n의 가장 핵심적인 개념으로, 모든 데이터는 노드 간에 <strong>JSON 배열(Array of JSON objects)</strong> 형태로 전달된다. 앞선 노드의 출력이 다음 노드의 입력이 되는 방식으로, 데이터 구조는 보통 <code class="language-plaintext highlighter-rouge">[ { "data": "value" } ]</code> 형태를 가진다.</p>

<h3 id="4-표현식-expressions">4. 표현식 (Expressions)</h3>

<p>이전 노드의 데이터를 현재 노드에서 참조하는 방식이다. n8n은 <code class="language-plaintext highlighter-rouge">\{\{ ... \}\}</code> 형태의 표현식을 사용하며, <code class="language-plaintext highlighter-rouge">$node["Node Name"].json.data</code> 와 같이 특정 노드의 출력 데이터를 참조하는 것이 일반적이다.</p>

<h3 id="5-자격-증명-credentials">5. 자격 증명 (Credentials)</h3>

<p>Google AI API 키, GitHub PAT, Discord Webhook URL 등 민감한 정보를 n8n에 안전하게 저장하고 관리하는 기능이다. 노드 설정 시 실제 키 값 대신 등록된 자격 증명을 선택하여 보안을 유지한다.</p>

<p>이러한 n8n의 특징과 구성 요소를 이해하는 것은 자동화 프로젝트를 성공적으로 수행하는 데 필수적이다.</p>

<h2 id="왜-쓰는가">왜 쓰는가?</h2>

<p>이제 AI 를 Agent 처럼 구축할 필요가 있다..!
그런데 프레임워크 기반의 서버로 구축하긴 너무 오래 걸리는데, 이때 n8n 은 아주 완벽한 PoC 용 툴이다.</p>]]></content><author><name>Paul2021-R</name></author><category term="학습" /><category term="학습" /><category term="Automation" /><category term="AI" /><category term="Google" /><category term="n8n" /><summary type="html"><![CDATA[n8n 자동화 도구 소개]]></summary></entry><entry><title type="html">TIL - n8n 으로 뉴스 피드 자동화 해서 Discord 레터 받아보기(feat AI)</title><link href="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/02-til-n8n.html" rel="alternate" type="text/html" title="TIL - n8n 으로 뉴스 피드 자동화 해서 Discord 레터 받아보기(feat AI)" /><published>2025-11-09T00:00:00+00:00</published><updated>2025-11-09T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/02-til-n8n</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/02-til-n8n.html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>주말엔 본 목적을 위한 작업을 하는것은 너무 머리 아픈 일이다. 가뜩이나 DevOps 는 하나 하나 하다보면서 알게되는게 너무 많았다. 그래서 평상시에도 꼭 배우리라 생각했던 n8n 기반의 자동화, 비로소 작업해보았다…!</p>

<h2 id="0단계---connection-lost--응-1">0단계 - connection lost … 응? (1)</h2>

<p>n8n 을 다른 서버에서 사용하는 것도 가능은 하다. 하지만 이왕 하는거 셀프 호스팅을 도전해보았다.</p>

<p><img src="/assets/images/posts/2025-11/20251111-013.png" alt="" /></p>
<blockquote>
  <p>Node 를 Create 했는데 우상단에 <code class="language-plaintext highlighter-rouge">Connection lost</code> 가 보임</p>
</blockquote>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Blocked GET /assets/npsSurvey.store-B7_iNEDS.js <span class="k">for</span> <span class="s2">"Mozilla/5.0 (compatible; archive.org_bot; Wayback Machine Live Record; +http://archive.org/details/archive.org_bot)"</span>

Pruning old insights data

Pruning old insights data

Pruning old insights data

ValidationError: The <span class="s1">'X-Forwarded-For'</span> header is <span class="nb">set </span>but the Express <span class="s1">'trust proxy'</span> setting is <span class="nb">false</span> <span class="o">(</span>default<span class="o">)</span><span class="nb">.</span> This could indicate a misconfiguration which would prevent express-rate-limit from accurately identifying users. See https://express-rate-limit.github.io/ERR_ERL_UNEXPECTED_X_FORWARDED_FOR/ <span class="k">for </span>more information.

    at Object.xForwardedForHeader <span class="o">(</span>/usr/local/lib/node_modules/n8n/node_modules/.pnpm/express-rate-limit@7.5.0_express@5.1.0/node_modules/express-rate-limit/dist/index.cjs:187:13<span class="o">)</span>

    at Object.wrappedValidations.&lt;computed&gt; <span class="o">[</span>as xForwardedForHeader] <span class="o">(</span>/usr/local/lib/node_modules/n8n/node_modules/.pnpm/express-rate-limit@7.5.0_express@5.1.0/node_modules/express-rate-limit/dist/index.cjs:398:22<span class="o">)</span>

    at Object.keyGenerator <span class="o">(</span>/usr/local/lib/node_modules/n8n/node_modules/.pnpm/express-rate-limit@7.5.0_express@5.1.0/node_modules/express-rate-limit/dist/index.cjs:671:20<span class="o">)</span>

    at /usr/local/lib/node_modules/n8n/node_modules/.pnpm/express-rate-limit@7.5.0_express@5.1.0/node_modules/express-rate-limit/dist/index.cjs:724:32

    at /usr/local/lib/node_modules/n8n/node_modules/.pnpm/express-rate-limit@7.5.0_express@5.1.0/node_modules/express-rate-limit/dist/index.cjs:704:5 <span class="o">{</span>

  code: <span class="s1">'ERR_ERL_UNEXPECTED_X_FORWARDED_FOR'</span>,

  <span class="nb">help</span>: <span class="s1">'https://express-rate-limit.github.io/ERR_ERL_UNEXPECTED_X_FORWARDED_FOR/'</span>

<span class="o">}</span>

<span class="o">[</span>license SDK] license renewal failed: Connection Error: Unexpected token <span class="s1">'B'</span>, <span class="s2">"Bad Gateway"</span> is not valid JSON

Failed to renew license: Connection Error: Unexpected token <span class="s1">'B'</span>, <span class="s2">"Bad Gateway"</span> is not valid JSON

<span class="o">[</span>license SDK] license successfully renewed
</code></pre></div></div>
<blockquote>
  <p>AI 의 친절한 조언에 따라 docker logs 를 확인하니, 문제가 뭔지 바로 파악 가능했다.</p>
</blockquote>

<p>핵심은 n8n 이 리버스 프록시 뒤에서 실행 중인데, 보안의 문제로 이에 대한 신뢰 설정이 필요하단 점이었다.</p>

<p>해결 방법은 가능하다. 환경 변수에 <code class="language-plaintext highlighter-rouge">N8N_TRUST_PROXY=1</code>를 추가하면 된다. 컨테이너 화든 셀프 호스팅이든 자신의 환경에 맞춰 추가하면 된다. 본인은 Docker container 기반으로 해두었기에 yml 파일에 env 변수를 추가해주었다.</p>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      <span class="c1"># - N8N_SECURE_COOKIE=false # 1. HTTPS가 아니어도 쿠키 사용 허용 # 프록시 있으니 해제</span>
      <span class="pi">-</span> <span class="s">WEBHOOK_URL=https://n8n.paulryu93.ddns.net</span> <span class="c1"># 2. n8n의 공개 주소 설정</span>
      <span class="pi">-</span> <span class="s">N8N_TRUST_PROXY=1</span> <span class="c1"># 리버스 프록시 신뢰 설정 </span>
      <span class="pi">-</span> <span class="s">TZ=Asia/Seoul</span> <span class="c1"># 시간 설정 </span>
      <span class="pi">-</span> <span class="s">NODE_FUNCTION_ALLOW_EXTERNAL=cheerio,axios</span> <span class="c1"># 외부 모듈 설치 요청</span>
      <span class="pi">-</span> <span class="s">EXECUTIONS_DATA_PRUNE=true</span> <span class="c1"># 로깅 데이터 저장 및 자동 삭제 활성화</span>
      <span class="pi">-</span> <span class="s">EXECUTIONS_DATA_MAX_AGE=168</span> <span class="c1"># 로깅 데이터 저장 기간 7일로 지정</span>
</code></pre></div></div>

<p>이제 재시작하면 된다.</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker compose up <span class="nt">-d</span> <span class="nt">--force-recreate</span>
</code></pre></div></div>

<h2 id="0단계---또-다른-connection-lost-2">0단계 - 또 다른 connection lost (2)</h2>
<p>분명히 가이드 문서를 찾아봐도 이걸로 해결 되는 거였다. 근데 안됨. 뭐지? 하고 찾아보니 ‘n8n 에디터’는 웹소켓으로 실시간 통신을 한다고 되어 있고, 해당 기능이 설정되어야 한다고 했다.</p>

<p><img src="/assets/images/posts/2025-11/20251111-014.png" alt="" /></p>
<blockquote>
  <p>Websockets Support 옵션을 켜면</p>
</blockquote>

<p><img src="/assets/images/posts/2025-11/20251111-015.png" alt="" /></p>
<blockquote>
  <p>짠, 해결 완료 되었다.</p>
</blockquote>

<p>결국 n8n의 환경 변수 설정 + Socket 통신 허용을 해줘야만 n8n 에디터를 제대로 셀프 호스팅이 가능하다.</p>

<h2 id="새로운-문제">새로운 문제…</h2>

<p>알고 보니 Connection Lost 에러와</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  code: <span class="s1">'ERR_ERL_UNEXPECTED_X_FORWARDED_FOR'</span>,

  <span class="nb">help</span>: <span class="s1">'https://express-rate-limit.github.io/ERR_ERL_UNEXPECTED_X_FORWARDED_FOR/'</span>
</code></pre></div></div>
<p>이 에러는 실질 다른 문제가 있었다. 
이는 현재 메인 서비스를 위한 HTTPS 할당과 별도로 TLS L4 레이어 기반으로 우회를 하여 공인 IP 를 지나, 서브 서버의 443 포트로 전송 되는 문제로 발생한 이슈였다.</p>

<p>이 에러가 문제시 되는 이유는, 현재 설정이 꼬여 IP 가 하나로 들어오는 것처럼 처리 된다는 점이다.</p>

<p>문제의 핵심은 정리해보니… stream 블록으로 우회하는 데, 이 우회 프로토콜을 NPM Plus 는 제대로 아직 인식이 안된다.</p>

<p>즉, Sub-Server 에 Nginx 를 추가하고 HTTPS 를 다시 인증 받아야한다는점이다(…)</p>
<h2 id="1단계---n8n-워크플로우-생성-및-rss-데이터-가져오기">1단계 - n8n 워크플로우 생성 및 RSS 데이터 가져오기</h2>
<p><img src="/assets/images/posts/2025-11/20251111-016.png" alt="" /></p>
<ul>
  <li>n8n 은 대단히 직관적이었다. 기본적으로 자동화 툴이다보니 기본적으로 <code class="language-plaintext highlighter-rouge">create Workflow</code>를 통해 사용이 가능했고, 만들어진 창의 모습도 직관적이었다.</li>
</ul>

<h2 id="2단계---trigger-설정하기">2단계 - trigger 설정하기</h2>
<p><img src="/assets/images/posts/2025-11/20251111-017.png" alt="" /></p>
<ul>
  <li>설명이랄 것도 없이, 바로 시작하면 각 단위는 ‘노드’ 라고 하는데 최초의 자동화 동작을 뭘로 할 지를 정할 수 있다.</li>
  <li>수동 혹은 app 이벤트, 스케쥴 등 생각할만한 다양한 방법은 존재하며, 심지어 file changes 까지 있는거 보면, 이건 필요한 자동화 마다 골라서 설정하면 된다.</li>
</ul>

<h2 id="3단계---노드-설정">3단계 - 노드 설정</h2>
<p><img src="/assets/images/posts/2025-11/20251111-018.png" alt="" /></p>
<ul>
  <li>이 다음 부터는 사실상 러닝커브다. 각 노드들은 기능들이 있고, 기능들은 수십가지가 있으며, AI 관련해서도 대응이 되어 있다.필요한건 핵심 로직을 어떻게 짤지 해놓고 거기에 필요한 적절한 설정에 따라 데이터를 가공하고, 합치고, 어레이로 정리하거나 하면 된다.</li>
  <li>단 여기서 주의 해야 할 것은 통신 과정에서 json 기반으로 동작하고, Code 노드의 경우 js나 Python 으로 직접 변수 형태로 접근하여 사용이 가능하다. 여기 부분에 바이브 코딩을 같이 얹어주면 직접인 데이터 가공, 저장, 그리고 검색 등을 포함한 serverless 서버까지도 넘겨 볼 수 도있다. (물론 난이도가 올라가지만, 코드를 짜는거에 비하면 양반이긴 하니까…)</li>
</ul>

<h2 id="4단계---ai-활용하기">4단계 - AI 활용하기</h2>
<p><img src="/assets/images/posts/2025-11/20251111-019.png" alt="" /></p>
<ul>
  <li>n8n 을 써봐야 하고 써보면서 알아두려고 했던 영역이 바로 이것. 바로 AI 기능이 내부에 내장되어 있다는 것이다. 원래 API 등에 따라 웹훅, 혹은 다양한 트리깅으로 자동화 자체에만 집중했다면 n8n 은 AI 기능들을 추가함으로써 AI 빌더가 되었다고 보여진다.</li>
  <li>기본적으로 자체적으로 제공해주는 기능도 있기에 <code class="language-plaintext highlighter-rouge">credentials</code>만 설정하면 손쉽게 사용이 가능하다.</li>
  <li>특히 주의 깊게 본 것은 기본 노드 뿐만 아니라 ‘AI Agent’ 노드 였다.  mcp, 메모리용 DB 등 연결이 가능하고, 직접적으로 조절이 되면서 모델을 마음데로 바꿀 수 있었다. 또한 그 외에도 AI 를 위한 파서나, Text classifier, chain 등 배워두면 도움이 아주 될 것이란 생각이 들었다. (그만한 시간을 들여야 겠지만)</li>
</ul>

<hr />

<h2 id="결론">결론</h2>

<p><img src="/assets/images/posts/2025-11/20251111-020.png" alt="" /></p>

<p><img src="/assets/images/posts/2025-11/20251111-021.png" alt="" /></p>

<ul>
  <li>
    <p>현재는 나에게 도움이되는 기사들, DevOps, AI, Backend 관련된 영역에 대한 기사들의 스크래핑 자동화를 만들었고, 여러 조건을 고려한 결과, 일단 현재 가장 최선으로 md 파일 형식으로 정리해주는 것으로 끝을 내었다.</p>
  </li>
  <li>
    <p>n8n 으로 만들어보다 보니 확실히 아이디어가 샘솟는다. 더욱이 Agent 노드는 생각이상으로 구성이 충실하다. 전에 대충 알아본 것에 비하면 확실히 왜 n8n 을 자동화 도구로 쓰는지, 그걸로 뭘 하고 싶어하는지, 실제 수입화의 주요 도구로 쓰는 사람들의 이유는 확실히 있어 보인다. 특히 Obsidian 이나 지식 저장, 블로그 자동화 등 AI 까지 합쳐진 상태에서 얻을 수 있는 건 확실히 많아 보여 앞으로 지속적으로 써보려고 한다.## 요약 내용</p>
  </li>
</ul>]]></content><author><name>Paul2021-R</name></author><category term="학습" /><category term="학습" /><category term="DevOps" /><category term="Docker" /><category term="n8n" /><category term="Automation" /><category term="AI" /><summary type="html"><![CDATA[Introduction 주말엔 본 목적을 위한 작업을 하는것은 너무 머리 아픈 일이다. 가뜩이나 DevOps 는 하나 하나 하다보면서 알게되는게 너무 많았다. 그래서 평상시에도 꼭 배우리라 생각했던 n8n 기반의 자동화, 비로소 작업해보았다…!]]></summary></entry><entry><title type="html">TIL - Opal 로 실전 AI 응용 앱을 만들어보자 - 직무 역량 평가 앱</title><link href="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/03-til-opal.html" rel="alternate" type="text/html" title="TIL - Opal 로 실전 AI 응용 앱을 만들어보자 - 직무 역량 평가 앱" /><published>2025-11-09T00:00:00+00:00</published><updated>2025-11-09T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/03-til-opal</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/03-til-opal.html"><![CDATA[<p><img src="/assets/images/posts/2025-11/20251111-022.png" alt="" /></p>

<h2 id="introduce">Introduce</h2>

<p>이 <a href="https://paul2021-r.github.io/tools/2025/10/09/02-Opal-instroduction.html">글</a>을 작성하면서 Opal 이란 도구의 베타버전을 간단하게 써보았다. 하지만 주말, 토이 프로젝트 느낌으로 진행해보면 좋겠다! 싶어서 n8n 을 만지작 거리다가 AI 특화로 있던 도구, Opal 이 생각이 나서 이번엔 제대로 써보게 되었다.</p>

<p><img src="/assets/images/posts/2025-11/20251111-023.png" alt="" /></p>

<h3 id="기본-개념은">기본 개념은…</h3>

<p>사실 이걸 앱을 만드는 개발 도구라고 보기엔 대단히 아쉬운 점이 많다. 기본적으로 로우코드, 노코드 툴, AI 애플리케이션 빌더- 라고 거창하게 말할 수 있겠지만… share 만 가능하고, 에디터에서 테스트가 되긴 하지만, 세세하게 뭔가 되는 느낌은 아니다. 코드 작업이 되는 것도 아니므로 n8n 에 비하면 커스터마이징이 실질 AI 를 위한 프롬프팅 정도만 가능하다는 단점이 있다. 그럼에도 특징들을 종합하면 <strong>AI 워크플로우 구축에 특화 플랫폼</strong> 이라고 정의 내릴 수 있다.</p>

<p><code class="language-plaintext highlighter-rouge">User Input</code> 항목은 사용자 입력을 받을 수 있으며 옵션에 따라 멀티 모달이 가능하다.</p>

<p><code class="language-plaintext highlighter-rouge">Generate</code> 는 Gemini 의 생성형 AI 모델들을 골라서 수행이 가능하며, 여기엔 텍스트 모델 말고도 Nano Banana나 Veo 와 같은 생성형 AI 모델들을 선택하는 것도 가능하다.</p>

<p><code class="language-plaintext highlighter-rouge">Output</code> 은 결과물에 대해 선을 연결하게 되면, 그것을 어떤 옵션으로 출력을 할지를 결정해준다. Google Docs, Slides, Sheets와 같은 Google Workspace 애플리케이션이나 웹 페이지 등으로 연결하여 출력 형식을 지정할 수 있습니다.</p>

<p><code class="language-plaintext highlighter-rouge">Add Assets</code> 라는 항목은 각종 자료들을 추가할 수 있도록 되어 있다.</p>

<h2 id="생각보다-좋다">생각보다 좋다…?</h2>

<p>이왕 이리 된거 간단한 걸 만들어보고자 생각이 들었고, 뭘 해볼까 고민해보았다.</p>

<p>목표는 다음과 같았다. 이직 준비를 꾸준하게 하고 있고, 가장 궁극적인 목표는 개발자로 내가 할 수 있는 <code class="language-plaintext highlighter-rouge">가속도</code>를 제대로 붙게 만드는게 나에게 필요한 시점이었다. 그리고 그걸 위해 가장 실질적으로 지금 필요한게 뭘까? 라는 생각에 내 결론은 <code class="language-plaintext highlighter-rouge">내가 목표로 삼는 연차 이상의 기술력(경험)을 확보하자</code> 라는 것이었다.</p>

<p>그런데 그럴 거면 무엇이 필요한가?</p>

<p>맞다. 시장에서 요구하는 <code class="language-plaintext highlighter-rouge">연차별 성공적인 케이스 수준의 개발력</code> 스펙으로 알아둬야 하는 기술들, 경험들이 뭔지를 이해도 하는 것이 필요했다. 그렇기에 3년차 수준의 공통된 실무 경험치 기준, 필수, 그리고 권장을 정확히 이해하길 원했다. 그 스펙들에 따라 내 현재 이력서를 확인해보고 얼마나 채웠는가? 를 알아보려고 했다. 그러려면 다음과 같은 로직이 필요하다고 느꼈다.</p>

<ol>
  <li>분석의 기본 데이터 소스를 채용 공고를 활용한다.</li>
  <li>해당 회사에 대한 Deep Research(심층 조사) 기능을 기반으로 회사 자료, 회사의 수준을 신빙성있는 자료를 준비한다. 이 자료는 회사의 배경 조사를 겸하고, 추가적인 데이터 역할을 한다.</li>
  <li>공고, 회사에 대한 배경 지식을 기반으로 필수 역량과 권장 역량을 구분하고 추출해낸다.</li>
  <li>베이스는 준비 되었으니, 개인의 이력서, 경력 자료를 수집하고, 이 데이터 기반으로 종합하여 개인의 이력의 평가를 요청한다.</li>
  <li>분석한 데이터들의 종합으로 회사를 소개하고, 역량치를 정리하고, 정리 아래에 개인 이력에 대한 평가를 수행한다.</li>
</ol>

<p>그리하여… 이렇게 내용을 러프하게 적어 처음에는 ‘Suggest an edit’이란 프롬프트로 알아서 만들어 달라고 해보았다. 하지만 막상 이게 생각보다 애매한감이 있었다. 이유는 막상 작성 된 내용을 기반으로 또 다시 결과물이 나오고 그걸 다시 평가하고 수정하고… 이런 반복은 시간이 아깝다고 생각했다. 구조도 파악했으니, 차라리 간단하게 내가 만들자! 라는 생각을 해서 직접 만들어 보았다.</p>

<p>그리하여 만들고나니 의외로 좋은 점들을 발견할 수 있었다.</p>

<ol>
  <li><strong>병렬 처리(Parallel Processing)가 된다.</strong> 
 전형적인 AI 기본 모델들은 알다시피 모든 일이 ‘요청’ -&gt; ‘수행’ 이라는 선형 구조를 취하고 있다. 하지만 선형이란 건 직관적이고 순서를 보기엔 편하다. 하지만 시간도 오래 걸릴 뿐만 아니라, 중간에 필요한 작업들이나 요청 사항등을 결국 선형으로 기다리면서 작성한다는 건 효율적이지 못하다. 
 하지만 역시 구글, 그럴 일을 줄이기 위해서일까, <code class="language-plaintext highlighter-rouge">User Input</code>은 바로 즉각적으로 순서대로 받게 되어 있었고, 여러 일을 AI 에게 분담을 하면 동일 단계라면 동시에 처리하도록 되었고, 결과적으로 여러 일들이 있었지만, 끝난 시간은 Deep Research 하나 수행한 정도만에 해결이 되었다.</li>
</ol>

<p><img src="/assets/images/posts/2025-11/20251111-037.png" alt="" />
	&gt; 한꺼번에 AI 는 하나의 일을 하도록 시킨다. 그만큼 정확도가 올라가고, 작업 자체에 대한 정밀성을 올릴 수 있으니 아주 좋다.</p>
<ol>
  <li><strong>프롬프트에 직접적으로 어떤 자료를 어디에 쓸 것인지 지정하는 것이 가능하다.</strong> 
이 장점은 기술적인 면 보단 사용자 경험(UX) 의 승리라고 생각이 든다. 웹 챗봇, Cursor 같은 IDE, 그 외에 클라이언트형 AI 도구 등 다양한 AI 도구들은 요즘은 어지간하면 멘션기능을 가진다. 이를 통해 데이터들을 링크 시키고, 파이프라인을 형성한다.
그런데 이때, 아쉬운 점은 <strong>직관성</strong>일 것이다. 워크 플로우를 만들거나, 자동화를 시켜 ‘하기 싫은 일’을 수행 시킬 순 있지만, 결국 핵심은 AI 에게 맡긴 일이 잘 되어가는지? 그리고 안된다면 어딜 고쳐야하지? 에 대한 직관성이 필요한 것이다.
하지만 이런걸 기존 툴들은 일단 <code class="language-plaintext highlighter-rouge">@파일명</code> 이정도로 표현하는 정도에 그친다. 이러다보니 여러 워크플로우를 만들면, 어디서 결과가 이상하게 나오는지 추적하기도 어렵다. 하지만 Opal 은 이에 대한 데이터를 멘션을 하고, 그것이 자연어 사이에 직접적으로 타겟화 시켜서 마치 함수의 인자를 직관적으로 볼 수 있게 했다.
뿐만 아니라 프롬프트를 작성할 때 이 자료가 뭐다- 라는 걸 직접적으로 지칭하고, 자연어 내부에 섞어서 쓸 수 있게 했다. 멘션 기능이 있으면 가능하다고 볼 수 있겠지만 그럼에도 사용 시 가장 편리했던 도구는 단연코 Opal 의 그것이 아니었나 생각이 들었다. 
<img src="/assets/images/posts/2025-11/20251111-024.png" alt="" />
    <blockquote>
      <p>확실히 자료에 대해 구체적이고 직관적인 전달. 내가 의도한 데로 움직이게 만드는데, 심지어전후로 구조적인 이해가 가능하다.</p>
    </blockquote>
  </li>
</ol>

<p>물론 아쉬움이 없나? 그건 아니다.</p>

<ol>
  <li><strong>로우 레벨의 접근 제한</strong> 
처음에 먼저 자동화를 n8n 으로 만들고, 여기에 다가도 AI 를 섞어서 만들었다. 그리고 이는 머리 아픈 과정이긴 했지만, n8n 은 Code 노드가 존재하고, Python 도 지원을 앞두고 있다. Opal은 없다. 이 모든 자잘하고 세세한 설정을 할 수 있는데 못하는게 아니라, 아무리 봐도 의도적으로 막아둔 것으로 보인다. 
이 점은 효율성과 연결이 되는데, 데이터의 아주 로우한 접근, json 화 시켜서 변수화 시킨 다던지, AI 가 필요 없는 작업을 당연히 PC 의 작은 리소스만으로 해결하는데 톡톡한 역할을 해줄 텐데… 여기선 그런 사소한 작업까지도 AI에게 요청해야 했다. 물론 다른 대안으로 모델을 flash-lite 와 같은 걸로 하면, 훨씬 빠르고 간편하게 해준다는 점을 생각해보면..?
Opal 자체는 확실히 GUI 기반에, 뭔가 인스턴트하게 AI 에게 맡기고 싶다! 라는 니즈 자체에 집중한 것이라고 납득이 안되진 않았다. 이를 통해 ‘인스턴트 앱’ 또는 ‘숏앱(Short App)’이라 불리는 신속한 프로토타이핑 환경을 제공하려는 의도가 엿보인다.</li>
  <li><strong>외부 플러그인이 부족하다</strong>
위의 내용과는 반대로 풍부함 역시 부족하다는 생각이 들었다. n8n 은 파일의 저장, 읽기, 쓰기, DB 연결을 비롯해서 광범위한 기능들을 쓸 수 있다. Code node 는 JS 기반이라 관련 라이브러리도 쓸 수 있다. 아직 베타지만 Python 까지 들어간다면? 정말 n8n 자체로 할수 있는 일은 엄청나다고 말 할 수 있다. 정말 깊게 파면, 서버 프레임워크 코드 한줄 없이 서비스용 서버리스 서버도 구현이 가능할 정도다. 
반면 Opal은 Google Drive, Google Workspace, HTML 페이지 등 Google 생태계 내의 서비스 연동에 국한되어 있어, 외부 플러그인 및 서비스 연동성이 부족하다는 점이 아쉽다. (베타 버전임을 감안하더라도 파일명 수정 기능 부재 등은 개선이 필요해 보인다.) 베타라지만 이정돈 해줄수 있을텐데 말이다. 
개인적으론 알림을 보내는 기능, 메일 보내는 기능 정도는 있으면 어떨까 싶었다. 정말 그 정도만 되도 만들어 볼만한 기능들은 엄청날텐데 말이다.</li>
</ol>

<p>완성을 하고 자료가 착착 나오는 걸 보니 꽤나 쉽다는 생각, 역시 AI는 이런 작업은 최고라는 생각을 할 수 있었다. 다행히 프롬프트를 구체적으로 적을 수록 구분이 되고, 프롬프트 내부에서 일종의 조건문 식으로 처리 하는 것도 가능하니 그걸 기반으로 디테일 버전, 간단버전, 혹은 인용한 사이트 정보 취사 선택 여부 등을 추가로 넣어보기도 했다. 방법은 확실히 있다고 느껴진다.</p>

<hr />

<h2 id="일반인들을-위한-ai-자동화-도구-글쎄">일반인들을 위한 AI 자동화 도구… 글쎄</h2>

<p><img src="/assets/images/posts/2025-11/20251111-025.png" alt="" />
<img src="/assets/images/posts/2025-11/20251111-026.png" alt="" /></p>

<p>Google 의 Deep Research 는 이미 전부터 엄청나다고 호평이었다. 그리고 자료, 로직을 추가할 수 있게 되니 정말 만드는데 1시간, 데이터 수집 및 AI에게 일 시켜놓기 30분. 기다리고나니 4개의 업체와 업체의 현재 근황, 재정 상황 분석, 해당 시장 특성, 그리고 나의 역량이 도움이 될지. 부족한 점이 뭔지를 정리해주는 것이 가능했다. 정말 숏 앱이라는 개념에 부합하는 여러 서비스가 있었지만, 가장 안정적이면서도 정확한 서비스는 구글이란 생각을 새삼 안할 수가 없다고 느낀다.</p>

<p>특히나 영악하게도 모든 서비스는 구글의 서비스와 연동이되고, 문서 하나 구글을 벗어나지 않는다는 점은… 처음엔 구글이 AI 의 등장으로 휘청이니 뭐니 했지만, 실상 10년 전부터 준비하던 구글의 엄청난 저력. 그리고 이 모든 것이 2.5 flash 에 프롬프트만으로 충분히 나온다는 지점은….</p>

<p>하지만 쓰면 쓸 수록 한 가지 분명하게 이해되는건 ‘이게 과연 일반인들을 위한 도구가 될 수 있을까?’ 에 대한 생각이다. 물론 자연어를 쓸 수 있고, 시스템적 사고가 가능한 사람들이라면 충분히 도전해볼만 하다. 해볼 사람은 도전해보길 추천한다. 프롬프트를 작성하는 방법에 대해서, AI 의 특성에 대해 간단히 이해만 한다면, 충분히 해봄직 하긴 하다.</p>

<p>하지만 AI를 접하고, 소개하고, 써보길 이야기 할 때 느낄 수 있는 건 생각보다 이러한 접근방법, 생각하는 방법은 배우지 않곤 쓰기 어렵다는 점이다. 엔드 유저에게 AI 가 더 대중화 되지 못하고 있는 이유는 결국 ‘결론’을 지향하는 사고가 기본적으로 효율적이고, 그렇게 사람들이 존재하기 때문에, 막상 로직을 분석하고 로직적으로 논리성을 쌓는 절차를 굳이 해야 하나? 라고 하면 안할 사람들이 많지 않을까?</p>

<p>뿐만 아니라 오히려 격차가 커지겠구나! 하는 생각을 하게 되었다. 특히 자연어를 쓴다고 했지 코딩이랑 실질 다르지 않은 구조이기 때문에, 결국 더욱 개발자나 쓰기 좋고, 만약 지금보다 더 일반인이 쓰길 원한다면 정말 ‘한 마디 문장’을 기반으로 AI 가 자체적으로 판단, 기획, 스텝을 나누고 개발을 해내는 것을 아주 정교하게 만들어야 할텐데. 지금 당장은 아직까진 애매하단 생각이 들었다.</p>

<p>물론 Google의 행보를 보면 명확하다. 아마 5년 안짝이면 그정도는 구현 가능해지리라 생각은 든다. 하지만 정보의 격차, 생각하는 방식의 구체화, 로직화 등등… 어쩌면 인간의 기본 능력치가 앞으로 더 인문학적, 사고적 깊이감이 없다면 이런 모든 상황에서 이겨내고 자기만의 일을 찾을 수 있을까? 란 생각은 든다. 무섭긴 하지만 기대도 되고, 기대가 되니 더 앞으로 가봐야겠다.</p>

<p>만들어본 데모 앱은 써볼 수 있도록 열어 놓겠습니다.</p>

<p><a href="https://opal.google/?flow=drive:/191E1UU8no6s5G_LUaJxwJTKAzZmH6uF_&amp;shared&amp;mode=app">공고글 및 개인 역량 분석기</a></p>

<p><strong>당부사항</strong></p>
<ul>
  <li>해당 앱의 정보는 모두 구글에서 처리 되는 것이며, 저 개인의 서버 등에 저장되지 않습니다.</li>
  <li>또한 리포트는 구글 드라이브 내에 <code class="language-plaintext highlighter-rouge">Opal</code> 폴더가 생성되고 해당 폴더 내에 문서로 저장됩니다.</li>
</ul>]]></content><author><name>Paul2021-R</name></author><category term="학습" /><category term="학습" /><category term="DevOps" /><category term="Docker" /><category term="n8n" /><category term="Automation" /><category term="AI" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">TIL - MVP 구축을 위한 AI 모델 분석</title><link href="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/04-til-AI-for-MVP.html" rel="alternate" type="text/html" title="TIL - MVP 구축을 위한 AI 모델 분석" /><published>2025-11-09T00:00:00+00:00</published><updated>2025-11-09T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/04-til-AI-for-MVP</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/09/04-til-AI-for-MVP.html"><![CDATA[<p><img src="/assets/images/posts/2025-11/20251111-027.png" alt="" /></p>

<h2 id="ai-모델-분석-보고서-ai-기반-심리-테스트-mvp-개발">AI 모델 분석 보고서: ‘AI 기반 심리 테스트’ MVP 개발</h2>

<h3 id="1-프로젝트-개요-및-목표">1. 프로젝트 개요 및 목표</h3>

<p>프로젝트를 진행하기 위한 ‘발사대’가 필요하다!</p>

<p>그게 처음 이 고민의 시작이었다. AI 의 RAG 기반 프로젝트를 진행할 것이지만. 그리고 거기서 DevOps 와 Backend 가 살아 숨쉬는 프로젝트를 해보고 싶지만…! 그걸 바로 목표 지향점으로 가져가기엔 아무래도 어렵다는 생각. 그 생각이 있었기에 그 중간에 뭘 하면 좋을까? 이것이 야심한 11월 10일, 빼빼로 데이 전날 새벽 4시의 고민이었다.</p>

<p>그러다가 번뜩, 데모로 만들만한 것을 찾던 도중 ‘AI 기반 심리 테스트’ MVP(Minimum Viable Product)를 개발해볼까? 하는 생각을 했다. 이유는 간단하다. (1) 진지한 도구나, 거창한 도구는 만들 상황이 안된다. (2) 트래픽을  유도하고, 사람들의 호기심을 끌어야 이용자 수를 볼 수 있고, 만든 서버의 처리 능력을 테스트 해볼 수 있다. (3) 겸사 겸사 모니터링 데이터가 필요하다(?) 그리하여 어그로를 끌어야 하는데… 여기서 중요한건 역시나 AI 로 테스트 결과 리포트를 받는 것이었다.</p>

<p>gemini 2.5 pro 를 기반으로 했을 땐 상당히 흥미 진진하고, 사람들이 관심 가져볼 것 같았다…. 결론적으로 프로젝트를 위한 중간에 계단 역할을 하기엔 최고라는 판단이 섰다. 하지만 알다시피 프로젝트로, 구조적으로, 경험적으로 너무나 괜찮은 경험인 것은 맞지만, 결정적으로 문제가 있다는 사실을 발견했다. 그것은 바로 ‘비용’.</p>

<p>알다시피 AI 는 돈 빨이다. GPU 따위 구할 수도 없는 일개 백수에게 핵심은 결국 어딘가에서 빌려서 AI 를 쓰는 수밖에 없고… 그렇기에 나는 불쑥 생각이 난 플랫폼으로 들어가게 되었다.</p>

<p><img src="/assets/images/posts/2025-11/20251111-028.png" alt="" /></p>

<p>이 플랫폼은, 정말 말 그대로 API 제공 + 다양한 AI 업체들을 연결시켜주는 역할을 하는데, 특히나 좋은 점은 ‘동일한 프롬프트’를 기준으로 여러 모델들을 테스트 해볼 수 있다는 점이며, <strong>‘품질(Quality)’, ‘비용(Cost)’, ‘속도(Speed)’</strong> 세 가지 측면에서 가장 최적화된 대규모 언어 모델(LLM)을 선정해보고자 했다.</p>

<p>본 MVP의 핵심 목표는 다음과 같다.</p>

<ul>
  <li>단순한 객관식(점수제) 테스트를 넘어, 사용자의 <strong>주관식 텍스트 답변</strong>을 AI가 심층 분석하는 고차원적인 경험을 제공하는지 판단해본다.</li>
  <li>분석 결과를 ‘판타지 게임의 설정’ 스타일의 스탯과 서사를 포함한 <strong>‘개인화된 내러티브 리포트’</strong> 로 생성해본다.</li>
  <li>최종적으로 1만 명 규모의 트래픽을 감당하는 <strong>‘DevOps 기술 포트폴리오’</strong> 에 쓸 AI, 즉 머리로 활용해보자.</li>
</ul>

<h3 id="2-분석-및-연구-과정">2. 분석 및 연구 과정</h3>

<p>최적의 모델을 선정하기 위해, OpenRouter 서비스를 활용하여 다양한 모델에 동일한 테스트(판타지 시나리오 질문 및 주관식 답변)를 수행했다. 이때 다음 방식으로 진행했다.</p>

<ol>
  <li>내 의도, 기획을 이해한 gemini 2.5 pro 기반으로 저작권 문제가 없는(…) Big Five 방식의 질문지 데모를 생성했다.</li>
  <li>이에 대한 답변을 객관식(1 ~ 15번) 까지 답변했고, 객관식으로 4 문항에 대해서 주관식으로 한줄 추가했다.</li>
  <li>마지막으로 이 데이터들로 해야할 일이 뭔지를 정리해 보았다.</li>
</ol>

<p>아래의 내용은 실제 동일하게 넣었던 내용이다.</p>

<pre><code class="language-plain">### 🛡️ 모험가 성향 분석 (총 15문항)

당신은 미지의 대륙을 탐험하는 모험가입니다. 아래의 여러 상황을 상상하며, 당신의 생각이나 행동과 가장 가까운 정도를 **1점에서 5점까지**로 답해주세요.

&gt; **[점수 기준]**
&gt; **1점:** 전혀 그렇지 않다
&gt; **2점:** 대체로 그렇지 않다
&gt; **3점:** 보통이다 (그럴 때도 있고 아닐 때도 있다)
&gt; **4점:** 대체로 그렇다
&gt; **5점:** 매우 그렇다

---

**[질문 리스트]**

1.  당신은 숲 속에서 고대에 사라진 문명의 빛나는 유적을 발견했다. 위험할 수도 있지만, 이 미지의 기술을 탐구하고 싶은 강한 호기심을 느낀다.
2.  퀘스트를 마치고 마을의 시끌벅적한 여관에 도착했다. 당신은 모르는 사람들과도 어울려 모험담을 나누고 축배를 드는 것을 즐긴다.
3.  "드래곤의 산"으로 떠나기 전, 당신은 식량, 물약, 장비, 지도를 하나하나 꼼꼼하게 점검하고 목록을 만든다.
4.  당신의 일행이 부상당한 고블린을 생포했다. 당신은 정보를 얻는 것도 중요하지만, 그를 불필요하게 고문하거나 학대하는 것에 반대한다.
5.  어두운 던전에서 복도를 걷던 중, 갑자기 멀리서 함정이 발동하는 소리가 들렸다. 당신은 '다음은 내 차례일지도 모른다'는 생각에 즉시 불안해지고 심장이 뛴다.
6.  마법사 길드는 '불의 주문'을 배우라고 했지만, 당신은 금지된 서고에 있는 '영혼 마법'에 대한 고문서에 더 마음이 끌린다.
7.  파티가 갈림길에서 망설일 때, 당신은 "이쪽 길이 맞는 것 같다! 나를 따르라!"라며 적극적으로 의견을 내고 일행을 이끄는 편이다.
8.  당신은 파티의 재무 담당이다. 퀘스트 보상을 분배할 때, 1골드까지 정확하게 계산해서 공평하게 나누어야 직성이 풀린다.
9.  한 마을 주민이 "우리 아이가 아픈데 약초가 필요해요"라며 애원한다. 비록 당신의 주된 임무는 아니지만, 그를 돕기 위해 기꺼이 시간을 사용한다.
10. 당신의 강력한 마법 공격이 거대 트롤에게 빗나갔다. 당신은 "역시 난 안돼"라며 순간적으로 자신감을 잃고 위축된다.
11. "모든 예언은 정해진 운명이다"라는 말보다, "예언은 해석하기 나름이며, 운명은 개척할 수 있다"는 생각을 더 선호한다.
12. 지루한 야영지에서 불침번을 서는 것보다, 차라리 정찰대를 자원하여 새로운 동료와 함께 미지의 지역을 탐색하는 것이 좋다.
13. 당신의 마법서나 무기고는 항상 완벽하게 정돈되어 있다. 필요한 물건은 언제든 즉시 찾을 수 있어야 한다.
14. 파티원 중 한 명이 실수를 해서 모두가 위험에 빠졌다. 당신은 그를 비난하기보다, "누구나 실수할 수 있다"며 감싸주고 다음 계획을 세우는 데 집중한다.
15. 왕궁에서 중요한 임무를 브리핑받을 때, 당신은 '내가 만약 실패하면 어떡하지?'라는 걱정 때문에 발표 내용에 집중하기 어렵다.

---

### 🔮 분석해 드릴 내용

답변을 주시면, 저는 이 15개의 응답을 Big Five 모델(OCEAN)의 5가지 특성에 대입하여 분석해 드립니다.

1.  **개방성 (Openness): 미지의 탐험가**
    * (질문 1, 6, 11)
    * 새로운 경험, 금지된 마법, 추상적인 예언 등에 대해 얼마나 열려 있는지를 봅니다.
2.  **성실성 (Conscientiousness): 왕국의 기사**
    * (질문 3, 8, 13)
    * 퀘스트 준비, 보상 분배, 장비 관리 등에서 얼마나 체계적이고 책임감이 강한지를 봅니다.
3.  **외향성 (Extraversion): 여관의 음유시인**
    * (질문 2, 7, 12)
    * 파티의 중심에서 에너지를 얻는지, 리더십을 발휘하는지, 사교성을 봅니다.
4.  **우호성 (Agreeableness): 치유의 성직자**
    * (질문 4, 9, 14)
    * 동료나 약자를 대하는 태도, 파티의 조화를 얼마나 중요하게 생각하는지를 봅니다.
5.  **신경성 (Neuroticism) / 정서적 안정성:**
    * (질문 5, 10, 15)
    * 함정, 실수, 실패의 압박감 속에서 얼마나 쉽게 불안을 느끼거나 감정적으로 흔들리는지를 봅니다.

---

여기의 답변 (객관식, 주관식 작성한 내용)
1. 5
2. 3
3. 5
4. 5
5. 3
6. 3
7. 4
8. 4
9. 5
10. 1
11. 3
12. 4
13. 4
14. 5
15. 1
16. 그것이 아주 큰 위험이 아니라, 내가 돈이나, 재료를 통해 충분히 제어 가능하면서 연구 가능하다면 연구를 적극적으로 해보고 싶다!!
17. 파티의 갈림길에서 빠르게 결정하는게 필요한 순간이라면 모를까, 그런게 아니라면 파티원들을 존중하고, 무엇보다 두 길의 리스크와 이점을 이해할 수 있는지를 본다. 그런 게 부족하면 일단 갈거다. 
18. 현실과 상황은 분명 한계를 만들어내기 때문에, 이걸 인정하지 않을수는 없다. 하지만 인정하고 철저하게 더 정확하게 분석적으로 태도를 취하는게 좋고, 그렇게 기회를 잡는게 필요하다고 본다. 그리고 그게 운명의 의미라고 생각한다.
19. 중요 임무를 브리핑 받는다? 이건 기회다! 라고 생각하고, 당연히 걱정이 다소 들겠지만 평소의 나라면 충분히 해결하거나, 부족하면 반드시 날 도울 사람이 옆에 있다고 난 생각함!
---

위의 내용을 가지고 심리 분석하여 판타지 소설의 개요처럼 이 사람을 분석한 리포트를 만들고, 랜덤 기술 2가지를 포함해서 성격 분석 리포트를 만들어줘 볼래? 스텟도 추가해서 민첩 A 이런 식으로 표현해줘. 이건 심리테스트 결과지를 만드는 거야.
</code></pre>

<p><img src="/assets/images/posts/2025-11/20251111-029.png" alt="" /></p>
<blockquote>
  <p>OpenRouter 는 크레딧 충전만 하면 손쉽게 여러모델을 동시에 비교가 가능하다.</p>
</blockquote>

<h4 id="1단계-초기-모델-탐색-및-문제점-식별-a-b-c-d안">1단계: 초기 모델 탐색 및 문제점 식별 (A, B, C, D안)</h4>

<p>12B~20B급의 4가지 주요 모델을 대상으로 초기 벤치마킹을 수행했다. 이 단계에서 ‘품질’과 ‘신뢰성’의 명확한 한계점을 발견했다.</p>

<ul>
  <li><strong>A안 (<code class="language-plaintext highlighter-rouge">gemma 3 12B</code>):</strong>
    <ul>
      <li><strong>평가:</strong> 생성된 리포트(A안)는 안정적이었다. 의도를 이해했고, 나름의 내용이 잘 담겨 있었다. 하지만 창의성이나 깊이 없이 매우 건조하고(dry) 재미가 부족했다. 사용자의 흥미를 유발해야 하는 본 MVP의 목적에 부합하지 않아 초기 스크리닝에서 탈락했다.</li>
    </ul>
  </li>
  <li><strong>B안 (<code class="language-plaintext highlighter-rouge">Llama 4 Maverick 17B</code>):</strong>
    <ul>
      <li><strong>평가 :</strong> 모델이 사용자의 핵심 페르소나를 파악하는 데 <strong>완전히 실패했다.</strong></li>
      <li><strong>근거:</strong> 사용자의 주관식 답변은 ‘통제’, ‘분석’, ‘신뢰’, ‘기회’ 등 <strong>‘전략가적’</strong> 성향을 명확히 드러냈으나, B안(“용기의 탐험가”)은 이를 무시하고 ‘용기’라는, 입력된 의도와 상반되는 <strong>제네릭(Generic)한 템플릿</strong>을 생성했다. 텍스트 분석 기능이 사실상 작동하지 않았다. <del>솔직히 가장 실망한 모델이다</del></li>
    </ul>
  </li>
  <li><strong>C안 (<code class="language-plaintext highlighter-rouge">Qwen3 14B</code>):</strong>
 	* <strong>평가</strong>: 가장 요구한 내용들에 대한 구조적인 이해도가 뛰어났다. 내용의 재미나 창의성도 괜찮았다. 그러나 가장 치명적인 <strong>‘신뢰도’와 ‘논리적 오류’</strong> 문제를 노출했다.
    <ul>
      <li><strong>근거 1 (지시 불이행):</strong> “스킬 2개로 제한”이라는 명확한 지시를 “섹션당 2개”로 오해하여 총 10개의 스킬을 생성하는 등, <strong>지시사항 준수(Instruction Following)에 실패</strong>했다.</li>
      <li><strong>근거 2 (맥락 오류):</strong> 한 섹션의 주관식 답변(Q15)을 전혀 상관없는 다른 섹션(Q7)에 복사-붙여넣기하는 <strong>심각한 맥락 파괴(Context Error)</strong> 를 일으켰다. 이는 복잡한 프롬프트의 안정적인 실행이 불가능함을 의미했다.</li>
    </ul>
  </li>
  <li><strong>D안 (<code class="language-plaintext highlighter-rouge">gpt-oss-20b</code>):</strong>
    <ul>
      <li><strong>평가(비판):</strong> 의도에 대한 이해도는 높았고, 컨텐츠로 작성한 내용도 꽤나 준수하긴 했다. 하지만 문제는 이상할 정도로 기본 상태에선 설명이 건조하고, 축약 되어 토큰이 아껴지는 것을 볼 수 있었다. 결론적으로 정리 자체가 아쉬운 건 아니었다.</li>
    </ul>
  </li>
</ul>

<h4 id="2단계-마스터-프롬프트의-발견-c안">2단계: ‘마스터 프롬프트’의 발견 (C+안)</h4>

<p>초기 1단계의 실패(특히 C안의 오류)를 나오고 보니 아쉬움이 생겼다. 분명 기재할만한 내용은 적었지만, 여전히 부족하다는 생각. 특히 모델의 성능에만 의존할 수 없음을 깨달았다. 구조에서 누락하고 읽는 거라던가, 인용이 빠진다거나 하는 지점들을 보완하는게 필요하겠단 생각을 하게 되었다. 일종의 추론 스텝을 임의적으로 추가하는 것이다. 이에 가성비가 괜찮은걸로 알고 있던 <code class="language-plaintext highlighter-rouge">Gemini 2.5 Flash-lite</code> 모델의 구조를 기준으로, AI의 역할을 정의하고 리포트의 구조, 논리, 근거 제시 방식을 꼼꼼하게 설계한 <strong>‘로직 가이드라인 프롬프트’</strong> 를 개발했다. 사실 개발이라고 해도 별거 아니다 ㅋ</p>

<p><code class="language-plaintext highlighter-rouge">이 모든 프롬프트를 위한 의도를 파악하고, 이 프롬프트를 더 정확하게 표현하기 위한 로직 프롬프트를 짜줘</code></p>

<p>라고 추가하여, 기존 프롬프트를 함께 넣어 준 것이었다.</p>

<p><img src="/assets/images/posts/2025-11/20251111-030.png" alt="" /></p>
<blockquote>
  <p>그 결과 다음과 같이 개선 및 AI 가 맥락을 이해할 수 있도록 대폭 강화하는 프롬프트를 생성해냈다.</p>
</blockquote>

<p>일단 1차적으로 flash-lite 가 생각 이상으로 훌륭하구나! 라는 걸 느꼈다.</p>

<p>이 가이드라인을 각 모델 별로 넣어 보았고, 특히 핵심 일부가 누락된 가장 아쉬운 모델 <code class="language-plaintext highlighter-rouge">Qwen 14B</code> 모델에 재적용한 결과(C+안), 이전의 오류가 사라지고 ‘질서의 현자’라는 99점 수준의 재미도 있고, 흥미진진하며, 보는 맛이 있는 리포트를 생성했다. 😂 이는 <strong>모델의 성능 만큼 가이드 ‘프롬프트의 꼼꼼함’이 이 프로젝트의 핵심 기술(IP)</strong> 임을 증명하는 첫 번째 순간이었다.</p>

<h4 id="3단계-최종-후보군-압축-및-s-tier-품질-검증">3단계: 최종 후보군 압축 및 S-Tier 품질 검증</h4>

<p>하지만 그렇게 나온 결론으로 정리를 한 상태에서 ‘가격’ 에 대한 점검을 수행했다.  이유는 간단하다. 트래픽을 위해선 서버를 이용해야 하고, 다행이 서버 까지는 온프레미스로 구축할 수 있었다. 그러나 AI 는 별도다. 현재 예상하는 심리테스트 계열은 좀 알아보니 조회수 기준 1만회에서 10만회 사이로 유행이 될 것이고, 내가 잠시 막아둔다고 해도 필요하다면 다소 지속적으로 열어 둬야 하지 않겠는가? 그러므로 AI 로 간단하게 서비스 1회 요청 시 얼마의 토큰이 달것이고, 그러면 100명, 1천명, 1만명 요청시 과연 얼마나 드느가? 에 대한 예상이 필요했다.</p>

<p>처음 비교는 Google 에서의 모델들 끼리 비교 였다.</p>

<table>
  <thead>
    <tr>
      <th>**비교 항목**</th>
      <th>**Gemini 2.5 Flash-Lite**</th>
      <th>**Gemini 2.5 Flash**</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**입력 비용** (1백만 토큰당)</td>
      <td>$0.10</td>
      <td>$0.30</td>
    </tr>
    <tr>
      <td>**출력 비용** (1백만 토큰당)</td>
      <td>$0.40</td>
      <td>$2.50</td>
    </tr>
    <tr>
      <td>**1인당 예상 비용 (USD)**</td>
      <td>**$0.0018**</td>
      <td>**$0.008**</td>
    </tr>
    <tr>
      <td>(1인당 원화 환산)</td>
      <td>(약 2.5원)</td>
      <td>(약 10.8원)</td>
    </tr>
    <tr>
      <td>**1만 명 총 예상 비용 (USD)**</td>
      <td>**$18.00**</td>
      <td>**$80.00**</td>
    </tr>
    <tr>
      <td>**1만 명 총 예상 비용 (KRW)**</td>
      <td>**약 24,300원**</td>
      <td>**약 108,000원**</td>
    </tr>
  </tbody>
</table>

<p>10, 10만원…ㄷㄷ 2.5 flash 는 프롬프트만 잘 먹이면 2.5 pro 수준은 된다는 걸 알고 있었고, pro 는 의도 파악, 추론에서 아주 괜찮지만 비용이 너무 비싸므로 lite 와 비교했다. flash-lite 성능 분석 표까지 검색해보고 얻은 결론은 ‘flash-lite 가 좋겠네’ 였다.</p>

<p><img src="/assets/images/posts/2025-11/20251111-031.png" alt="" /></p>
<blockquote>
  <p>출처 : Artificial Analysis</p>
</blockquote>

<p>그런데 응? 성능도 그렇고 가격도 아주 착한 녀석이 하나 더 보였다. 그것이 바로 <code class="language-plaintext highlighter-rouge">gpt-oss-120b</code> 모델이었다.</p>

<p><img src="/assets/images/posts/2025-11/20251111-032.png" alt="" /></p>
<blockquote>
  <p>출처 : OpenRouter</p>
</blockquote>

<p>gpt-oss 모델은 오픈소스, MoE 구조로 꽤나 괜찮은 모델임은 알았고, 20B 모델은 실제로 양자화 시킨 걸로 내 컴퓨터에서 구동을 했었다. 그런데 알고보니 120b 모델이 존재하며, 이걸 라우팅 해주는 업체들이 있는 걸 알게 된 것이다. 그리하여 넣어서 비교해본 결과… 정리하면 아래와 같았다.</p>

<p>‘마스터 프롬프트’를 기반으로 가장 유력한 두 후보 모델을 심층 비교 결과, 두 모델 모두 <strong>‘마스터 프롬프트’</strong> 를 완벽하게 수행하며 ‘S-Tier’ 품질의 리포트(최종 A안, B안)를 생성하는 데 성공했다.</p>

<ul>
  <li><strong>후보 1: <code class="language-plaintext highlighter-rouge">Google: Gemini 2.5 Flash-lite</code></strong></li>
  <li><strong>후보 2: <code class="language-plaintext highlighter-rouge">OpenAI: gpt-oss-120b</code></strong></li>
</ul>

<p><img src="/assets/images/posts/2025-11/20251111-033.png" alt="" /></p>
<blockquote>
  <p>후보 1 - flash-lite 프롬프트 가이드 + flash-lite 프롬프트</p>
</blockquote>

<p><img src="/assets/images/posts/2025-11/20251111-034.png" alt="" /></p>
<blockquote>
  <p>후보 2 -  flash-lite 프롬프트 가이드 + gpt-oss-120b</p>
</blockquote>

<h3 id="4-최종-후보군-상세-평가">4. 최종 후보군 상세 평가</h3>

<p>두 S-Tier 모델은 품질은 동등했으나, ‘스타일’과 ‘비용 구조’에서 명확한 차이를 보였다.</p>

<h4 id="41-후보-1-google-gemini-25-flash-lite-a안">4.1. 후보 1: <code class="language-plaintext highlighter-rouge">Google: Gemini 2.5 Flash-lite</code> (A안)</h4>

<ul>
  <li><strong>품질 (S-Tier): “융합적 분석가”</strong>
    <ul>
      <li>A안(“균형 잡힌 지혜의 맹세자”)은 모델의 <strong>고급 추론 및 합성(Synthesis)</strong> 능력을 증명했다.</li>
      <li><strong>핵심 강점:</strong> 단순히 답변을 나열하는 것을 넘어, ‘행동 예시 재구성’ 섹션에서 <code class="language-plaintext highlighter-rouge">(Q3, Q1, 주관식 W1)</code>처럼 <strong>여러 질문(체계성+탐구심+통제 가능성)을 융합</strong>하여 “유적 탐사 시 이렇게 행동할 것이다”라는 <strong>하나의 새로운 시나리오로 ‘재창조’</strong> 했다. AI가 ‘똑똑한 분석가’처럼 행동했다.</li>
    </ul>
  </li>
  <li><strong>속도 (압도적 우위): <code class="language-plaintext highlighter-rouge">217.8 t/s</code></strong>
    <ul>
      <li>1만 명 트래픽 대응 시, 사용자 경험(UX) 측면에서 가장 큰 강점이 있다고 예상했다. 사용자가 거의 기다림 없이 리포트를 받을 수 있음을 의미한다.</li>
    </ul>
  </li>
  <li><strong>비용 (치명적 약점): <code class="language-plaintext highlighter-rouge">입력 $0.10 / M 토큰</code></strong>
    <ul>
      <li>본 MVP는 ‘마스터 프롬프트’가 길고 정교하기 때문에 ‘입력 비용’에 매우 민감하다. Flash-lite의 입력 비용은 <code class="language-plaintext highlighter-rouge">gpt-oss-120b</code> 대비 2.5배 비싸, DevOps의 ‘비용 통제’ 목표에 불리하게 작용한다.</li>
    </ul>
  </li>
</ul>

<h4 id="42-후보-2-openai-gpt-oss-120b-b안">4.2. 후보 2: <code class="language-plaintext highlighter-rouge">OpenAI: gpt-oss-120b</code> (B안)</h4>

<ul>
  <li><strong>품질 (S-Tier): “투명한 가이드”</strong>
    <ul>
      <li>B안(“지식-조화의 수호자”)은 <strong>‘분석의 투명성’</strong> 을 극대화했다.</li>
      <li><strong>핵심 강점:</strong> ‘행동 예시’ 섹션에서 <strong>15개 문항 전체</strong>를 하나도 빠짐없이 “이렇게 해석했다”라고 전부 리스트업했다. 사용자는 자신의 어떤 답변도 무시되지 않았음을 즉각적으로 알 수 있다. 이는 벤치마크 61점(Flash-lite 30점)이라는 <strong>더 높은 지적 능력</strong>이 ‘마스터 프롬프트’를 오류 없이 꼼꼼하게 수행했기 때문으로 분석된다.</li>
    </ul>
  </li>
  <li><strong>속도 (경쟁력 확보): <code class="language-plaintext highlighter-rouge">176.2 t/s</code></strong>
    <ul>
      <li>Flash-lite보다는 느리지만, 1만 명의 동시 요청이 아닌 이상, 사용자가 체감하기에 ‘충분히 빠른’ 경쟁력 있는 속도였다. 심지어 제공해주는 프로바이더에 따라 차이가 났는데, 최대 170.2tps 수준인 경우도 보였고, 이정도면 gemini 2.5 flash-lite 와 비등한 속도까지도 나와주었다.</li>
    </ul>
  </li>
  <li><strong>비용 (결정적 우위): <code class="language-plaintext highlighter-rouge">입력 $0.04 / M 토큰</code></strong>
    <ul>
      <li><strong>이것이 승리의 결정타이다.</strong> 본 MVP의 아키텍처(긴 프롬프트)에 완벽하게 부합한다. Flash-lite 대비 2.5배 저렴한 입력 비용은, 1만 명 트래픽 시나리오에서 <strong>총비용을 30% 이상 절감</strong>시킬 수 있는 핵심 요소이다.</li>
    </ul>
  </li>
</ul>

<h4 id="43-비용-비교표-1만-명-트래픽-시뮬레이션">4.3. 비용 비교표 (1만 명 트래픽 시뮬레이션)</h4>

<p>DevOps 포트폴리오의 핵심인 ‘비용 통제’ 목표를 검증하기 위해, 보수적인 ‘최대 시나리오’(1인당 입력 10k, 출력 2k 토큰 가정)를 기준으로 1만 명의 트래픽을 시뮬레이션했다. (환율 1,350원 기준)</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">비교 항목</th>
      <th style="text-align: left"><code class="language-plaintext highlighter-rouge">Gemini 2.5 Flash-lite</code></th>
      <th style="text-align: left"><code class="language-plaintext highlighter-rouge">gpt-oss-120b</code></th>
      <th style="text-align: left">절감 효과</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">**입력 비용** (10k * 10,000)</td>
      <td style="text-align: left">$1.0 (약 1,350원)</td>
      <td style="text-align: left">**$0.4 (약 540원)**</td>
      <td style="text-align: left">**60% 절감**</td>
    </tr>
    <tr>
      <td style="text-align: left">**출력 비용** (2k * 10,000)</td>
      <td style="text-align: left">$0.8 (약 1,080원)</td>
      <td style="text-align: left">$0.8 (약 1,080원)</td>
      <td style="text-align: left">동일</td>
    </tr>
    <tr>
      <td style="text-align: left">**1인당 평균 비용**</td>
      <td style="text-align: left">약 2.5원</td>
      <td style="text-align: left">**약 1.7원**</td>
      <td style="text-align: left">**32% 절감**</td>
    </tr>
    <tr>
      <td style="text-align: left">**1만 명 총 예상 비용**</td>
      <td style="text-align: left">약 25,000원</td>
      <td style="text-align: left">**약 17,000원**</td>
      <td style="text-align: left">**약 8,000원 절감**</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/images/posts/2025-11/20251111-035.png" alt="" /></p>
<blockquote>
  <p>출처 : OpenRouter</p>
</blockquote>

<p><img src="/assets/images/posts/2025-11/20251111-036.png" alt="" /></p>
<blockquote>
  <p>출처 : OpenRouter</p>
</blockquote>

<p>MVP 로 작게 만들어보려고 하는 이번 프로젝트는 이미지 생성이나 다른 부가 기능이 필요하지 않았다. 하물며 프롬프트를 입력시 가이드를 세세하게 주는 걸 제외하곤 기본 텍스트 모델이면 충분했다. 특히나 Provider 에 따라 차이가 있었지만, 토큰 숫자도 오히려 더 많이 나오는데 1/10… 지적능력의 포텐셜을 생각하면 결론은 명백해 보였다.</p>

<hr />

<h3 id="5-최종-결론-gpt-oss-120b-채택">5. 최종 결론: <code class="language-plaintext highlighter-rouge">gpt-oss-120b</code> 채택</h3>

<p>본 MVP의 최종 모델로 <strong><code class="language-plaintext highlighter-rouge">OpenAI: gpt-oss-120b</code></strong> 를 선정했다.</p>

<p>‘gemini 2.5 flash-lite’가 압도적인 속도를 보여주긴 했다. 거기다 곰곰히 생각해보면 안정성 측면을 고려시 google 의 서버, vertex 기반으로 안정적으로 돌아갈 걸 생각한다면? 사실 gemini 가 정답일지도 모르겠다. 하지만 <code class="language-plaintext highlighter-rouge">gpt-oss-120b</code>는 <strong>더 높은 지적 능력(61점)</strong> 을 바탕으로 S-Tier 품질(투명성)을 달성하면서도, 본 프로젝트의 핵심 비용인 <strong>‘입력 비용’이 2.5배 더 저렴하다.</strong> 이 경쟁력은 지금과 같이 안정성 + 서비스의 목표 구현을 양 쪽으로 고려시 최선의 선택이 되리라 느꼈다.</p>

<p>1만 명 트래픽 시뮬레이션 결과, 총비용을 <strong>30% 이상 절감</strong>할 수 있고, ‘1만 명 트래픽’을 목표로 하는 DevOps 포트폴리오에서, 176 t/s는 ‘충분히 빠른’ 속도이며, 이 속도를 유지하면서 비용 절감까지 증명해낸 <code class="language-plaintext highlighter-rouge">gpt-oss-120b</code>가 가장 합리적이고 전략적인 선택이다. 또한 이 과정에서 가이드, 맥락 파악을 위한 프롬프트를 또 작성해 주는 것이 오히려 모델들의 잠재력을 끌어올릴 수 있다는 인사이트는 대단히 인상적이었다.</p>

<p>본 프로젝트의 성공은 <strong>‘AI 모델’</strong> 자체에 달린 것이 아니라, <strong>‘꼼꼼한 프롬프트’</strong> 로 <strong>‘저렴하고 똑똑한 AI(gpt-oss-120b)’</strong> 를 통제하는 개발자의 역량에 달려 있다는… 그런 내용이 아니었나 싶다.</p>]]></content><author><name>Paul2021-R</name></author><category term="학습" /><category term="학습" /><category term="DevOps" /><category term="Docker" /><category term="n8n" /><category term="Automation" /><category term="AI" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">TIL - monitoring server 구축기 (2)</title><link href="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/05/til-monitoring-server-2.html" rel="alternate" type="text/html" title="TIL - monitoring server 구축기 (2)" /><published>2025-11-05T00:00:00+00:00</published><updated>2025-11-05T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/05/til-monitoring-server-2</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/05/til-monitoring-server-2.html"><![CDATA[<h2 id="2025-11-05--monitoring-서버-구축하기">2025-11-05 : Monitoring 서버 구축하기</h2>

<p>드디어 모든 문제를 해결하였다.
HTTPS 를 통한 종단암호화를 마쳤으며
네트워크를 선행 구축하여 통로로 연결될 수 있도록 설정하였다. 
이제 남은 단 하나… 모니터링…!!</p>

<hr />

<h2 id="서버-아키텍쳐-구조도">서버 아키텍쳐 구조도</h2>

<p><img src="/assets/images/assets/project-monitoring-diagram.png" alt="" /></p>

<h2 id="핵심-설정-과정-및-트러블슈팅-qa">핵심 설정 과정 및 트러블슈팅 (Q&amp;A)</h2>

<p>구축 과정에서 몇 가지 중요한 개념과 문제를 마주했으며, 이를 해결하는 과정이 이번 TIL의 핵심이다.</p>

<h3 id="핵심-네트워크구조">핵심 네트워크구조</h3>

<p>네트워크의 설정이 난해했지만, 결국 핵심은 ‘외부’와 ‘내부’에 대한 명료함이다.</p>

<ol>
  <li><strong>내부 통신 (Docker Network):</strong> 모니터링 서버 <em>내부</em> 의 컨테이너들(e.g., <code class="language-plaintext highlighter-rouge">centre-prometheus</code>, <code class="language-plaintext highlighter-rouge">centre-grafana</code>, <code class="language-plaintext highlighter-rouge">NPM</code>)은 docker의 가상 네트워크를 통해 컨테이너 이름으로 통신한다. 이 통신은 Docker가 내부 DNS를 통해 처리하므로 외부 포트가 필요 없다.
    <ul>
      <li><strong>예시:</strong> NPM 프록시 설정 시 Grafana의 주소는 <code class="language-plaintext highlighter-rouge">http://centre-grafana:3000</code>이 된다.</li>
    </ul>
  </li>
  <li><strong>외부 통신 (Physical LAN):</strong> 모니터링 서버가 <em>다른</em> 물리적 서버에 접근할 때는 이 가상 네트워크를 쓸 수 없다. 반드시 외부 서버의 물리적 IP 주소와 <code class="language-plaintext highlighter-rouge">service-exporters</code>에서 <code class="language-plaintext highlighter-rouge">ports</code>로 외부에 노출시킨 포트(<code class="language-plaintext highlighter-rouge">9100</code>, <code class="language-plaintext highlighter-rouge">8081</code>)를 사용해야 한다.</li>
</ol>

<h3 id="restart-정책으로-always-대신-unless-stopped를-써야-한다"><code class="language-plaintext highlighter-rouge">restart</code> 정책으로 <code class="language-plaintext highlighter-rouge">always</code> 대신 <code class="language-plaintext highlighter-rouge">unless-stopped</code>를 써야 한다</h3>

<p>사실 항상 restart 의 정책이 어떻게 되는지 정확하게 알고 있지 못했기에 이번 기회에 알아보았다. 두 정책 모두 시스템 재부팅 시 컨테이너를 자동 재시작해준다. 하지만 결정적인 차이가 있다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">restart: always</code>: 관리자가 유지보수를 위해 <code class="language-plaintext highlighter-rouge">docker stop</code> 명령으로 컨테이너를 <em>수동 정지</em> 해도, Docker 데몬이 재시작되거나 시스템이 재부팅되면 컨테이너를 다시 켜버린다.</li>
  <li><code class="language-plaintext highlighter-rouge">restart: unless-stopped</code>: 관리자의 수동 정지 명령을 “존중”한다. 즉, 수동으로 정지된 컨테이너는 관리자가 명시적으로 다시 시작(<code class="language-plaintext highlighter-rouge">docker start</code>)하기 전까지는 꺼진 상태를 유지한다.</li>
</ul>

<p>이러한 결정적인 차이 때문에 유지보수 및 예측 가능성 측면에서 <code class="language-plaintext highlighter-rouge">unless-stopped</code>가 훨씬 안전한 정책이기에 향후엔 <code class="language-plaintext highlighter-rouge">unless-stopped</code>를 쓰려고 한다.</p>

<h3 id="prometheus_data-grafana_data를-gitignore에-추가해야-하는가"><code class="language-plaintext highlighter-rouge">prometheus_data</code>, <code class="language-plaintext highlighter-rouge">grafana_data</code>를 <code class="language-plaintext highlighter-rouge">.gitignore</code>에 추가해야 하는가?</h3>

<p>설정을 찾아보다 보니, 볼륨의 연결이 필요했다. 이에 진행하면서, 해당 볼륨의 특성을 보았다. 처음엔 생성되는 것들이 git 으로 버전 관리되는걸로 하면 권한 문제가 생길 수 있다고 판단했었다. 하지만… <code class="language-plaintext highlighter-rouge">docker-compose.yml</code>에서 <strong>Named Volume</strong> (<code class="language-plaintext highlighter-rouge">grafana_data:/var/lib/grafana</code>)을 사용하기에 그럴 필요가 없다는 것을 배웠다.</p>

<ul>
  <li><strong>Named Volume:</strong> Docker가 관리하는 별도의 시스템 경로( <code class="language-plaintext highlighter-rouge">/var/lib/docker/volumes/...</code>)에 데이터를 저장한다. Git 리포지토리 폴더 내에 파일이 생성되지 않으므로 <code class="language-plaintext highlighter-rouge">.gitignore</code>가 필요 없다.</li>
  <li><strong>Bind Mount:</strong> 만약 프로젝트 폴더에 직접 데이터를 저장하는 방식 (<code class="language-plaintext highlighter-rouge">./grafana_data:/var/lib/grafana</code>)을 사용했다면, 이 폴더는 Git이 추적하게 되므로 <code class="language-plaintext highlighter-rouge">.gitignore</code>에 반드시 추가해야 했을 것이다.</li>
</ul>

<h3 id="prometheus와-grafana의-cpu메모리-제한은">Prometheus와 Grafana의 CPU/메모리 제한은?</h3>

<p>제한된 온프레미스 서버. 최적화된 설정을 위해 Docker 의 리소스 관리 기능을 활용하려고 생각하고, AI 와 이야기하며 현실적인 수준을 파악해보았다. 현재 설정된 리소스(Prometheus 0.5 CPU/512M, Grafana 0.3 CPU/256M)는 2대의 서버(호스트 2개 + 컨테이너 수십 개)를 모니터링하기에 충분히 넉넉하다는 판단 하에 설정하였다.</p>

<p>다만, 처음엔 이정도가 맞는가? 라는 의문은 가지고 있었다. 아무리 생각해도 이정도는 하고, 윈도우 95 시절인줄 알았지만…. AI가 제시한 의도를 보고 파악할 수 있었다. 이 리소스 제한의 주 목적은 성능 자체가 아니라, 만약의 버그나 매우 복잡한 쿼리로 인해 모니터링 컨테이너 하나가 서버의 전체 리소스를 고갈시켜, 모니터링 시스템은 물론 서버 전체를 다운시키는 것을 방지하는 ‘안전벽(safety wall)’ 역할을 하고, 그렇게 볼때 다소의 보수적인 설정은 충분히 설득력이 있었다.</p>

<h2 id="최종-설정-파일">최종 설정 파일</h2>

<p>위의 모든 과정을 거쳐 완성된 최종 설정 파일들이다.</p>

<h3 id="1-메인-서비스-서버-a5-server">1. 메인 서비스 서버 (A5 Server)</h3>

<p><code class="language-plaintext highlighter-rouge">service-exporters/docker-compose.yml</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># main server watcher for monitoring structure 

services:
  #########################################################
  #  NodeExporter_Svc: 호스트 지표 (CPU, RAM, Disk)
  #########################################################
  node-exporter:
    image: prom/node-exporter:latest
    container_name: a5-node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
    pid: host
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: '64M'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  #########################################################
  #  cAdvisor_Svc: 컨테이너 지표 (Docker)
  #########################################################
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: a5-cadvisor
    restart: unless-stopped
    ports:
      - "8081:8080" 
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    devices:
      - /dev/kmsg
    deploy:
      resources:
        limits:
          cpus: '0.15'
          memory: '128M'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
</code></pre></div></div>

<h3 id="2-모니터링-서버-centre-server">2. 모니터링 서버 (Centre Server)</h3>

<p><code class="language-plaintext highlighter-rouge">monitoring-stack/docker-compose.yml</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># monitoring structure + sub server watcher

services:
  #########################################################
  #  Prometheus: The core data collection service
  #########################################################
  prometheus:
    image: prom/prometheus:latest
    container_name: centre-prometheus
    restart: unless-stopped
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    networks:
      - my-central-proxy-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: '512M'

  #########################################################
  #  Grafana: The data visualization dashboard
  #########################################################
  grafana:
    image: grafana/grafana:latest
    container_name: centre-grafana
    restart: unless-stopped
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - my-central-proxy-network
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: '256M'

  #########################################################
  #  NodeExporter_Mon: Host metrics for THIS server
  #########################################################
  node-exporter-mon:
    image: prom/node-exporter:latest
    container_name: centre-node-exporter
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
    pid: host
    networks:
      - my-central-proxy-network
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: '64M'

  #########################################################
  #  cAdvisor_Mon: Container metrics for THIS server
  #########################################################
  cadvisor-mon:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: centre-cadvisor
    restart: unless-stopped
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    devices:
      - /dev/kmsg
    networks:
      - my-central-proxy-network
    deploy:
      resources:
        limits:
          cpus: '0.15'
          memory: '128M'

#########################################################
#  Shared Volumes and Networks
#########################################################
volumes:
  prometheus_data:
  grafana_data:

networks:
  my-central-proxy-network:
    external: true
    name: my-central-proxy-network 
</code></pre></div></div>

<h3 id="3-모니터링-두뇌-prometheus-config">3. 모니터링 “두뇌” (Prometheus Config)</h3>

<p><code class="language-plaintext highlighter-rouge">monitoring-stack/prometheus/prometheus.yml</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>global:
  scrape_interval: 15s # How often to scrape targets

scrape_configs:
  # 1. Monitor Prometheus itself (Internal)
  - job_name: 'prometheus'
    static_configs:
      - targets: ['centre-prometheus:9090']

  # 2. Monitor the monitoring server's HOST (Internal)
  - job_name: 'monitoring_host'
    static_configs:
      - targets: ['centre-node-exporter:9100']

  # 3. Monitor the monitoring server's CONTAINERS (Internal)
  - job_name: 'monitoring_containers'
    static_configs:
      # cAdvisor's default port inside the container is 8080
      - targets: ['centre-cadvisor:8080']

  # 4. Monitor the REMOTE main service server's HOST (External)
  - job_name: 'service_host'
    static_configs:
      # A5 Server's physical IP and exposed port
      - targets: ['192.168.0.37:9100']

  # 5. Monitor the REMOTE main service server's CONTAINERS (External)
  - job_name: 'service_containers'
    static_configs:
      # A5 Server's physical IP and exposed port
      - targets: ['192.168.0.37:8081']
</code></pre></div></div>

<h3 id="4-gitignore">4. <code class="language-plaintext highlighter-rouge">.gitignore</code></h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.DS_Store
Thumbs.db
.env
*.env.local
docker-compose.override.yml
</code></pre></div></div>

<h2 id="결과">결과</h2>

<p>모든 설정이 완료되고, Grafana에서 <code class="language-plaintext highlighter-rouge">https://grafana.paulryu93.ddns.net</code>에서 모든걸 볼 수 있었다.</p>

<p><img src="/assets/images/posts/2025-11/20251105-008.png" alt="" /></p>

<p><strong>Node Exporter (monitoring_host) 대시보드:</strong>
<img src="/assets/images/posts/2025-11/20251105-009.png" alt="" />
<img src="/assets/images/posts/2025-11/20251105-010.png" alt="" /></p>

<p><strong>cAdvisor (monitoring_containers) 대시보드:</strong>
<img src="/assets/images/posts/2025-11/20251105-011.png" alt="" />
<img src="/assets/images/posts/2025-11/20251105-012.png" alt="" /></p>

<p>이제 두 서버의 모든 호스트 및 컨테이너 지표를 중앙에서 실시간으로 모니터링할 수 있게 되었다!</p>

<hr />

<p>아직 알람 기능이라거나, 디테일한 접근은 되지 않았다. 
그러나</p>
<ul>
  <li>G/B 방식의 무중단 배포와 이를 위한 CI/CD Jenkins 파이프라인 구축</li>
  <li>Next.js 기반의 SPA 어플리케이션 서버</li>
  <li>MSA 방식의 NestJS 와 AI를 위한 FastAPI 서버</li>
  <li>이 모든것을 감시하는 Monitoring의 Grafana + Prometheus 설정
은 앞으로 더욱 흥미 진진한 제대로 된 스케일러블 서비스 구축의 ingnition 이 될 것같다…ㅎ</li>
</ul>]]></content><author><name>Paul2021-R</name></author><category term="학습" /><category term="학습" /><category term="NextJS" /><category term="DevOps" /><category term="Jenkins" /><category term="Docker" /><category term="Monitoring" /><category term="Grafana" /><category term="Prometheus" /><summary type="html"><![CDATA[2025-11-05 : Monitoring 서버 구축하기]]></summary></entry><entry><title type="html">TIL - monitoring server 구축기 &amp;amp; 지옥같은 네트워크 문제 해결기..</title><link href="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/04/til-monitoring-server.html" rel="alternate" type="text/html" title="TIL - monitoring server 구축기 &amp;amp; 지옥같은 네트워크 문제 해결기.." /><published>2025-11-04T00:00:00+00:00</published><updated>2025-11-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/04/til-monitoring-server</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/04/til-monitoring-server.html"><![CDATA[<h2 id="2025-10-31--2025-11-03--monitoring-서버-구축하기--네트워크-문제-해결하기">2025-10-31 ~ 2025-11-03 : Monitoring 서버 구축하기 &amp; 네트워크 문제 해결하기</h2>

<p>구축하고 있는 NextJS 와, MSA 백엔드 서비스, AI 에이전트를 위한 모니터링 시스템을 구축하고 이를 기반으로 지속적으로 서비스의 상태를 확인하며 프로젝트를 진행해 나가려고 한다.</p>

<hr />

<h2 id="서버-아키텍쳐-구조도">서버 아키텍쳐 구조도</h2>

<p><img src="/assets/images/assets/project-monitoring-diagram.png" alt="" /></p>

<h3 id="아키텍처-구성-요소-및-역할">아키텍처 구성 요소 및 역할</h3>

<h4 id="1-사용자-users">1. 사용자 (Users)</h4>
<ul>
  <li><strong>Admin (관리자):</strong> ‘모니터링 서버’의 <code class="language-plaintext highlighter-rouge">Nginx_Mon</code>을 통해 Grafana 대시보드에 접속하여 전체 서버 인프라의 상태를 확인한다.</li>
  <li><strong>Public User (일반 사용자):</strong> ‘메인 서비스 서버’의 <code class="language-plaintext highlighter-rouge">Frontend</code> 애플리케이션에 접속하여 실제 모니터링 되고 있는 내용 중 일부를 볼 수 있다.</li>
</ul>

<hr />

<h4 id="2-모니터링-서버-ryzen-3400g">2. 모니터링 서버 (Ryzen 3400G)</h4>
<ul>
  <li><strong>Nginx_Mon (HTTPS 프록시):</strong> Admin의 Grafana 접속 요청을 받아 HTTPS 암호화 통신을 처리하고, 내부의 Grafana 컨테이너로 요청을 전달(리버스 프록시)하는 게이트웨이이다.</li>
  <li><strong>Grafana (데이터 시각화):</strong> Prometheus에 저장된 모든 지표(메트릭) 데이터를 가져와 관리자가 한눈에 볼 수 있도록 다양한 대시보드를 시각화한다.</li>
  <li><strong>Prometheus (데이터 수집/저장):</strong> 모니터링의 핵심이다. 두 서버의 모든 Exporter로부터 주기적으로 지표를 수집(Scrape)하고 시계열 데이터베이스(TSDB)에 저장한다.</li>
  <li><strong>NodeExporter_Mon (호스트 지표):</strong> 모니터링 서버 자체의 CPU, 메모리, 디스크, 네트워크 사용량 등 하드웨어 자원 지표를 Prometheus에 제공한다.</li>
  <li><strong>cAdvisor_Mon (컨테이너 지표):</strong> 모니터링 서버에서 실행 중인 Docker 컨테이너(Prometheus, Grafana 등)들의 개별 리소스 사용량 지표를 Prometheus에 제공한다.</li>
</ul>

<hr />

<h4 id="3-메인-서비스-서버-모니터링-대상">3. 메인 서비스 서버 (모니터링 대상)</h4>

<ul>
  <li><strong>App_1 (Frontend):</strong> Public User에게 보여지는 웹 애플리케이션(Project Mini Frontend)이다.</li>
  <li><strong>App_2 (Backend):</strong> 서비스의 비즈니스 로직을 처리하는 NestJS 및 FastAPI 기반의 MSA 백엔드 API 서버이다.</li>
  <li><strong>NodeExporter_Svc (호스트 지표):</strong> 메인 서비스 서버 자체의 하드웨어 자원 지표(CPU, RAM 등)를 Prometheus에 제공한다.</li>
  <li><strong>cAdvisor_Svc (컨테이너 지표):</strong> 메인 서비스 서버에서 실행 중인 모든 서비스 컨테이너(App_1, App_2 등)의 리소스 사용량 지표를 Prometheus에 제공한다.</li>
</ul>

<h2 id="프로세스">프로세스</h2>

<ol>
  <li>
    <p><strong>1단계: GitHub 리포지토리 구조 설계 및 초기화</strong></p>

    <ul>
      <li>단일 리포지토리 내에 <strong>모니터링 스택</strong>(Prometheus, Grafana)과 <strong>Exporter 스택</strong>(Node Exporter, cAdvisor)의 구성을 분리할 디렉터리 구조를 설계합니다.</li>
      <li><em>예시 구조:</em>
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  /monitoring-infra
  ├── monitoring-stack/          # [모니터링 서버(Ryzen 3400G)용]
  │   ├── docker-compose.yml
  │   └── prometheus/
  │       └── prometheus.yml     # Prometheus 설정 파일
  └── service-exporters/         # [메인 서비스 서버용]
      └── docker-compose.yml
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>2단계: ‘service-exporters’ 구성 파일 작성</strong>
    <ul>
      <li>모니터링 대상 서버(메인 서비스 서버)에서 실행될 <code class="language-plaintext highlighter-rouge">service-exporters/docker-compose.yml</code> 파일을 작성합니다.</li>
      <li>이 파일은 <strong>Node Exporter</strong>와 <strong>cAdvisor</strong> 컨테이너를 실행하는 내용을 포함합니다.</li>
    </ul>
  </li>
  <li><strong>3단계: ‘monitoring-stack’ 구성 파일 작성</strong>
    <ul>
      <li>모니터링 서버(Ryzen 3400G)에서 실행될 <code class="language-plaintext highlighter-rouge">monitoring-stack/docker-compose.yml</code> 파일을 작성합니다.</li>
      <li>이 파일은 <strong>Prometheus</strong>와 <strong>Grafana</strong> 컨테이너를 실행하는 내용을 포함합니다.</li>
      <li>동시에 <code class="language-plaintext highlighter-rouge">monitoring-stack/prometheus/prometheus.yml</code> 설정 파일을 작성합니다. 이 파일에는 2단계에서 실행될 Exporter들(메인 서비스 서버의 IP)을 수집 대상으로 지정합니다.</li>
    </ul>
  </li>
  <li><strong>4단계: 각 서버에 배포 실행</strong>
    <ul>
      <li><strong>[메인 서비스 서버에서]</strong>
        <ol>
          <li>프로젝트 리포지토리를 <code class="language-plaintext highlighter-rouge">git pull</code> 합니다.</li>
          <li><code class="language-plaintext highlighter-rouge">service-exporters</code> 디렉터리로 이동합니다.</li>
          <li><code class="language-plaintext highlighter-rouge">docker-compose up -d</code>를 실행하여 Exporter들을 활성화합니다.</li>
        </ol>
      </li>
      <li><strong>[모니터링 서버(Ryzen 3400G)에서]</strong>
        <ol>
          <li>프로젝트 리포지토리를 <code class="language-plaintext highlighter-rouge">git pull</code> 합니다.</li>
          <li><code class="language-plaintext highlighter-rouge">monitoring-stack</code> 디렉터리로 이동합니다.</li>
          <li><code class="language-plaintext highlighter-rouge">docker-compose up -d</code>를 실행하여 Prometheus와 Grafana를 활성화합니다.</li>
        </ol>
      </li>
    </ul>
  </li>
  <li><strong>5단계: Grafana 대시보드 구성</strong>
    <ul>
      <li>웹 브라우저로 Grafana에 접속합니다.</li>
      <li>Prometheus를 데이터 소스로 추가합니다.</li>
      <li>Node Exporter 및 cAdvisor 용 대시보드를 Import하여 모니터링을 시작합니다.</li>
    </ul>
  </li>
</ol>

<h2 id="문제-해결-및-개선-절차">문제 해결 및 개선 절차</h2>

<h3 id="1-초기-스택-배포">1. 초기 스택 배포</h3>
<ul>
  <li>Docker Compose를 활용하여 모니터링 스택(Prometheus, Grafana) 및 Exporter(Node Exporter, cAdvisor) 컨테이너의 기본 배포를 성공적으로 완료하였다.</li>
  <li>Jenkins 서버 이전을 대비한 Nginx 리버스 프록시 기본 구성을 완료하였다.</li>
</ul>

<h3 id="2-온프레미스-네트워크-다중화-구성">2. 온프레미스 네트워크 다중화 구성</h3>
<p>신규 모니터링 서버(Ryzen 3400G) 도입에 따라 발생한 네트워크 문제를 해결하는 과정이다.</p>
<h4 id="21-443-포트-점유-및-ddns-라우팅-이슈">2.1. 443 포트 점유 및 DDNS 라우팅 이슈</h4>
<ul>
  <li><strong>문제:</strong> 단일 공유기 환경에서는 443 포트(HTTPS)를 메인 서버와 모니터링 서버로 동시에 포트 포워딩할 수 없는 문제가 발생하였다.</li>
  <li><strong>분석:</strong> DDNS 서비스는 도메인을 공인 IP에 매핑할 뿐, 포트 레벨의 라우팅을 지원하지 않는다. 포트 분배는 라우터(NAT)의 역할이다.</li>
  <li><strong>1차 해결:</strong> 물리적 네트워크 분리를 위해 2번째 공유기와 USB 이더넷 어댑터를 도입하였다. 각 공유기에 별도의 공인 IP를 할당받아 443 포트 점유 문제를 해결하고자 시도하였다.</li>
</ul>

<h4 id="22-게이트웨이-및-서브넷-충돌">2.2. 게이트웨이 및 서브넷 충돌</h4>
<ul>
  <li><strong>문제:</strong> 두 공유기가 동일한 기본 서브넷(예: <code class="language-plaintext highlighter-rouge">192.168.0.x</code>)을 사용함에 따라 게이트웨이 충돌이 발생하였고, 이로 인해 서브 공유기의 관리 페이지 접근이 불가한 현상이 나타났다.</li>
  <li><strong>2차 해결:</strong> 서브 공유기의 LAN 및 DHCP 설정을 <code class="language-plaintext highlighter-rouge">192.168.10.x</code>와 같이 고유한 서브넷 대역으로 변경하여 네트워크를 논리적으로 분리하였다.</li>
</ul>

<h3 id="3-isp-제약-및-아키텍처-변경">3. ISP 제약 및 아키텍처 변경</h3>
<p>1, 2차 해결책이 ISP단의 제약으로 인해 새로운 문제에 직면하였다.</p>
<h4 id="31-공인-ip-다중-할당-제한">3.1. 공인 IP 다중 할당 제한</h4>
<ul>
  <li><strong>문제:</strong> ISP(KT) 모뎀에서 두 개의 공인 IP 할당 요청을 비정상적인 트래픽으로 간주, 특정 MAC 주소의 연결을 차단하는 문제가 발생하였다. 2.1에서 시도한 물리적 네트워크 분리(공유기 2대 사용)가 무효화되었다.</li>
  <li><strong>3차 해결 (아키텍처 변경):</strong>
    <ol>
      <li><strong>클라우드 프록시 도입:</strong> 단일 진입점(Single Entry Point)으로 GCP 가상 인스턴스(VM)를 배치하였다.</li>
      <li><strong>L4 프록시 전환:</strong> GCP의 Nginx를 L7(HTTP) 프록시가 아닌 L4(TCP) 프록시 모드로 설정하여 트래픽을 단순 전달(forwarding)하도록 하였다.</li>
      <li><strong>SSL Passthrough 적용:</strong> 클라우드 프록시는 SSL/TLS 암호화를 복호화하지 않고, 암호화된 트래픽(TCP)을 그대로 온프레미스 서버로 전달한다.</li>
      <li><strong>종단간 암호화 유지:</strong> SSL Termination (암호화 복호화)은 최종 목적지인 온프레미스 Nginx 서버에서 직접 처리하도록 구성하여 종단간 암호화를 유지한다.</li>
      <li><strong>Client IP 보존:</strong> <strong>Proxy Protocol</strong>을 활성화하여 L4 프록시 환경에서 유실될 수 있는 원본 클라이언트 IP를 백엔드 서버로 전달하였다.</li>
    </ol>
  </li>
  <li><strong>결과:</strong> GCP 인스턴스를 경유하여 온프레미스 서버의 특정 포트(8888, 8889 등)로 트래픽을 성공적으로 포워딩하는 것을 확인하였다.</li>
</ul>

<h3 id="4-현재-블로킹-이슈-물리적-인프라-장애국내-dhcp-환경의-특징---가정용만인듯">4. 현재 블로킹 이슈: 물리적 인프라 장애(국내 DHCP 환경의 특징 - 가정용만인듯?)</h3>
<ul>
  <li><strong>문제:</strong> ISP 모뎀 자체의 노후화 또는 물리적 결함으로 추정되는 인터넷 신호의 간헐적 끊김 현상이 발생하였다.</li>
  <li><strong>영향:</strong> 온프레미스 환경의 모든 서버(메인 서비스, 모니터링)가 외부에서 접근 불가능한 상태(unreachable)가 되었다.</li>
  <li><strong>현황:</strong> 모뎀 하드웨어 문제 해결 전까지 모든 서버 배포 및 설정 작업이 중단(Blocked)되었다. 현재는 문제 해결 과정을 문서화하며 대기 중이다. (후… KT)</li>
  <li><strong>분석 및 결론:</strong> 핵심 문제는 DHCP 관련된 문제였다고 발견되었다. 모뎀을 교체하여 신상으로 했는데도 동일 증상(붙었다 끊어졌다)가 반복 되었다. 
거기다 주기적으로 붙었다 떨어지는것, 공유기는 이상이 없는 것을 발견하였다.</li>
  <li>결국 설정을 뒤지다가 문제의 핵심이 ‘고정IP’ 라는 결론에 다다르게 된다. 
<img src="/assets/images/posts/2025-11/20251104-001.png" alt="" />
<img src="/assets/images/posts/2025-11/20251104-002.png" alt="" /></li>
  <li><strong>고정할당 문제:</strong> ISP 는 공인 IP 주소 풀을 독접 관리하고, 사용자에게 필요시 해당 IP 를 제공하는 방식을 사용한다. 그런데 여기서 기본적으로 임대를 해주는 개념이고 결과적으로 L2 레이어에서 요청-응답-승인-갱신 절차를 거친다. 문제는 거기서 내가 뭣도 모르고, 공유기를 ‘고정IP 방식’으로 했다. 내 의도는 내 공인 IP 를 그대로 유지해달라! 는 요청이었는데, 이건 제공하는 쪽과 수신하는 쪽, 사이에서 고정 할당을 해주고, 그 뒤에 고정 할당을 했을 때 문제가 없는 것이다..!</li>
  <li><strong>DHCP 규약:</strong> 일방적으로 설정해두면, 공유기는 더이상 승인요청을 하지 않고, 갱신 요청을 보내지 않게 된다….ㅠㅠ 결과적으로 최초에 설정하거나, 연결이 끊어진 직후에 인터넷 시그널을 보내면 처음 성공한 상태에서 사용 가능한 시점까지만 제공 =&gt; 갱신없음 =&gt; 공유기에서 인터넷 패킷이 들어오지 않음 의 연속이었던 것이다(….)</li>
  <li>고정 IP 로 변경이 DHCP 규약을 안따르겠다(갱신 안함)라는 의도를 포함한 설정이란 걸 몰랐기에 생긴 문제였다.</li>
  <li>KT 의 경우 ISP 에서 기본적으로 Sticky IP 정책을 쓰기 때문에 DHCP 프로토콜 규약은 지키지만, 어지간하면 IP 가 안바뀌고, 개인 프로젝트라면 문제가 없는 것으로 판단하고 유동IP 방식으로 변경하였다.</li>
</ul>

<h3 id="5-https-인증서-발급-certbot과-nginx-사이에-400-bad-request-오류-발생">5. HTTPS 인증서 발급 Certbot과 Nginx 사이에 <code class="language-plaintext highlighter-rouge">400 Bad Request</code> 오류 발생</h3>

<p>GCP(Google Cloud Platform) VM에 Nginx를 설치하여 프록시 서버로 구성했다. 목적은 443 포트(TLS)와 80 포트(HTTP)로 들어오는 트래픽을 내부망에 있는 ‘Centre 서버’로 전달(proxy pass)하는 것이다.</p>

<p>이후 HTTPS 인증서를 발급받기 위해 Centre 서버에서 Certbot을 실행했으나, <code class="language-plaintext highlighter-rouge">400 Bad Request</code> 오류가 발생하며 인증이 계속 실패했다.</p>

<p>브라우저 개발자 도구로 확인 결과, 이 <code class="language-plaintext highlighter-rouge">400</code> 오류는 최종 목적인 Centre 서버가 아닌, 요청의 맨 앞단인 <strong>GCP 프록시 서버(<code class="language-plaintext highlighter-rouge">35.197.5.162</code>)</strong>가 직접 반환하는 것을 확인했다.</p>

<p>이번 문제의 핵심은 서로 다른 원인을 가진 두 개의 <code class="language-plaintext highlighter-rouge">400</code> 오류가 겹쳐 있었던 것이다.</p>

<h4 id="1-gcp-서버-stream과-http-모듈-충돌-핵심-원인">1. GCP 서버: <code class="language-plaintext highlighter-rouge">stream</code>과 <code class="language-plaintext highlighter-rouge">http</code> 모듈 충돌 (핵심 원인)</h4>

<ul>
  <li>
    <p><strong>원인:</strong> GCP 서버의 Nginx 설정(<code class="language-plaintext highlighter-rouge">nginx_target.conf</code>)이 443 포트와 80 포트 모두를 <code class="language-plaintext highlighter-rouge">stream</code> (TCP) 모듈로 처리하도록 되어 있었다.</p>
  </li>
  <li>
    <p><strong>충돌:</strong> Certbot과 브라우저는 80 포트에 <code class="language-plaintext highlighter-rouge">http</code> (<code class="language-plaintext highlighter-rouge">GET /...</code>) 요청을 보냈다. Nginx의 <code class="language-plaintext highlighter-rouge">stream</code> 모듈은 <code class="language-plaintext highlighter-rouge">http</code> 문법을 이해하지 못하므로, 이를 ‘형식에 맞지 않는 요청’으로 간주하여 <code class="language-plaintext highlighter-rouge">400</code> 오류를 반환했다.</p>
  </li>
  <li>
    <p><strong>해결:</strong> GCP 서버 Nginx 설정을 ‘하이브리드’ 모드로 수정했다. 443 포트는 <code class="language-plaintext highlighter-rouge">stream</code> 블록(TCP 프록시)으로 유지하되, 80 포트는 <code class="language-plaintext highlighter-rouge">http</code> 블록으로 분리하여 <code class="language-plaintext highlighter-rouge">proxy_pass</code> (HTTP 프록시)로 Centre 서버에 정상 전달되도록 조치했다.</p>
  </li>
</ul>

<h4 id="2-centre-서버-server_name-해시-버킷-제한">2. Centre 서버: <code class="language-plaintext highlighter-rouge">server_name</code> 해시 버킷 제한</h4>

<ul>
  <li>
    <p><strong>원인:</strong> Centre 서버의 Nginx 설정(<code class="language-plaintext highlighter-rouge">nginx_init.conf</code>)은 4개의 긴 도메인 이름을 하나의 <code class="language-plaintext highlighter-rouge">server_name</code> 지시어에 모두 나열했다. 이는 Nginx의 기본 <code class="language-plaintext highlighter-rouge">server_names_hash_bucket_size</code> (이름 처리 메모리) 제한을 초과하여 <code class="language-plaintext highlighter-rouge">400</code> 오류를 유발할 수 있는 잠재적 문제였다.</p>
  </li>
  <li>
    <p><strong>해결:</strong> <code class="language-plaintext highlighter-rouge">http</code> 블록 자체의 메모리(<code class="language-plaintext highlighter-rouge">server_names_hash_bucket_size 64;</code>)를 늘리는 대신, <code class="language-plaintext highlighter-rouge">server</code> 블록을 4개로 분리하여 각 블록이 1개의 <code class="language-plaintext highlighter-rouge">server_name</code>만 처리하도록 구조를 변경함으로써 문제를 우회하고 해결했다.</p>
  </li>
</ul>

<hr />

<h4 id="현상황-duckdns-네임서버-응답-대기">현상황: DuckDNS 네임서버 응답 대기</h4>

<p>GCP 서버와 Centre 서버의 Nginx 설정이 모두 완료되었다.</p>

<ul>
  <li>
    <p><strong>검증:</strong> 브라우저로 80 포트 접속 시, 의도했던 대로 GCP 프록시를 거쳐 Centre 서버의 Nginx가 <code class="language-plaintext highlighter-rouge">404 Not Found</code>를 정상적으로 반환한다.</p>
  </li>
  <li>
    <p><strong>로그:</strong> Centre 서버의 Nginx 로그에도 Certbot의 <code class="language-plaintext highlighter-rouge">.well-known</code> 경로 접근이 <code class="language-plaintext highlighter-rouge">200 OK</code>로 성공 처리된 것이 확인되었다.</p>
  </li>
  <li>
    <p><strong>현재 문제:</strong> Nginx 설정은 완벽하지만, Certbot은 <code class="language-plaintext highlighter-rouge">DNS problem: SERVFAIL</code> 오류를 반환하며 여전히 실패한다.</p>
  </li>
  <li>
    <p><strong>원인:</strong> <code class="language-plaintext highlighter-rouge">SERVFAIL</code>은 로컬 Nginx 설정 문제가 아니다. Let’s Encrypt 인증 서버가 <strong>DuckDNS 네임서버</strong>에 DNS 조회를 시도했으나, DuckDNS 서버가 불안정하여 “서버 실패(Server Failure)” 응답을 반환한 것이다.</p>
  </li>
  <li>
    <p><strong>상태:</strong> 모든 로컬 및 프록시 설정은 완료되었으며, DuckDNS 네임서버가 안정화되고 Let’s Encrypt의 ‘실패 캐시’가 만료되기를 <strong>대기 중</strong>이다.</p>
  </li>
</ul>

<h3 id="6-nginx-jenkins-n8n-서버-구축">6. Nginx, Jenkins, n8n 서버 구축</h3>
<p>우선 안된 HTTPS 를 연결할 수 없으니 일단 HTTP 상태에서 세팅을 해보았다.</p>
<h4 id="1-nginx">1. Nginx</h4>
<ul>
  <li><strong>설정 파일 수정</strong> :
    <div class="language-conf highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">server</span> {
      <span class="n">listen</span> <span class="m">80</span>;
      <span class="n">server_name</span> {도메인};

      <span class="c"># Certbot 인증 경로
</span>      <span class="c"># 흑흑 얼른 되라고...
</span>      <span class="n">location</span> /.<span class="n">well</span>-<span class="n">known</span>/<span class="n">acme</span>-<span class="n">challenge</span>/ {
          <span class="n">root</span> /<span class="n">var</span>/<span class="n">www</span>/<span class="n">certbot</span>;
      }

      <span class="n">location</span> / {
          <span class="c"># Docker 이미지의 기본 Host 가 정해진다. 
</span>          <span class="c"># n8n 의 경우 http://n8n-server:5678 이다
</span>          <span class="n">proxy_pass</span> <span class="n">http</span>://<span class="n">jenkins</span>-<span class="n">server</span>:<span class="m">8080</span>; 
          <span class="n">proxy_set_header</span> <span class="n">Host</span> $<span class="n">host</span>;
          <span class="n">proxy_set_header</span> <span class="n">X</span>-<span class="n">Real</span>-<span class="n">IP</span> $<span class="n">remote_addr</span>;
          <span class="n">proxy_set_header</span> <span class="n">X</span>-<span class="n">Forwarded</span>-<span class="n">For</span> $<span class="n">proxy_add_x_forwarded_for</span>;
          <span class="n">proxy_set_header</span> <span class="n">X</span>-<span class="n">Forwarded</span>-<span class="n">Proto</span> $<span class="n">scheme</span>;
      }
  }
</code></pre></div>    </div>
  </li>
  <li><strong>네트워크 공유:</strong>
    <ul>
      <li>도커 네트워크를 연결해야 한다. 하지만 개별 프로젝트로 관리되고 있는 상황에서 이걸 일일히 다시 하나의 Docker-compose 파일로 모으는 건 비효율적이라고 생각. 각자 사용하게 만들기 위해선 다음과 같이 하면된다.
        <ol>
          <li><code class="language-plaintext highlighter-rouge">docker network create {명칭}</code>: 해당 명령어로 네트워크를 미리 사전에 설정해둔다.</li>
          <li>각각의 컴포즈 파일에 <code class="language-plaintext highlighter-rouge">network</code> 항목에 해당 네트워크 명칭을 작성, <code class="language-plaintext highlighter-rouge">networks</code> 항목에 해당 항목을 기재하고 <code class="language-plaintext highlighter-rouge">external: true</code> 라고 넣으면 된다.
            <div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="s">... 전략</span>
			
     <span class="na">networks</span><span class="pi">:</span>
       <span class="pi">-</span> <span class="s">my-central-proxy-network</span>

 <span class="na">networks</span><span class="pi">:</span>
   <span class="na">my-central-proxy-network</span><span class="pi">:</span>
     <span class="na">external</span><span class="pi">:</span> <span class="kc">true</span>
</code></pre></div>            </div>
          </li>
          <li>제대로 proxy 전달에 대해서만 가리키고 있다면, 이것으로 HTTP 접속은 구현된다.
            <h4 id="2-jenkins-서버-백업-및-복구">2. Jenkins 서버 백업 및 복구</h4>
          </li>
        </ol>
      </li>
    </ul>
  </li>
  <li><strong>백업하기:</strong>
    <ul>
      <li>기본적으로 Jenkins 는 jenkins_home 이라는 폴더 내부 데이터를 통째로 옮기면 백업과 복원이 용이한 구조다. 이를 위해 볼륨도 호스트와 공유하도록 설정했다면, 손쉽게 통째로 백업 및 복원하면 된다.</li>
      <li><code class="language-plaintext highlighter-rouge">tar -pczvf [압축파일명] [압축 대상 폴더]</code>: p 가 중요한데, 단순히 진행하게 되면 소유권 문제가 발생할 수 있다(시스템의 유저명칭 등이 같더라도 UID, GID 등의 불일치 문제가 발생할 수 있으므로) 이때 해당 옵션을 추가시 해당 기록까지 그대로 가져가준다.</li>
    </ul>
  </li>
  <li><strong>복원하기:</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">tar -xzvf [대상 압축파일명]</code>: jenkins_home 동일하게 진행해주면 되고, 젠킨스 컨테이너를 재시작하면 완벽하게 복원된다.</li>
    </ul>
  </li>
  <li><strong>문제상황:</strong> DooD 권한실패…!
    <ul>
      <li>DooD 구조를 하다보니 GID 가 같지 않으면 안되는데, 이게 아무래도 확실히 다를 수 밖에 없었다. 기존 메인 서버의 임시 Jenkins 서버는 1001 번이었지만, 이번 서버는 998번(…)</li>
      <li>자동으로 스크립트로 따오게 만들기도 가능하겠지만, 시간관계상 일단 하드코딩으로 Dockerfile에서 이를 설정해주는 작업을 해주었다.
        <div class="language-dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  ARG DOCKER_GID=984
  RUN groupadd -g ${DOCKER_GID} docker
  RUN usermod -aG docker jenkins
</code></pre></div>        </div>
      </li>
      <li>DooD 랑 호스트의 도커 시스템을 마운트하여도커 컨테이너 내부에서 호스트를 이용해 빌드를 하는 방식이다. 이를 통해 호스트 자원을 그대로 가져다 쓰고, 제어만 커테이너가 하게 된다. 단, 권한 문제를 비롯 제어시 민감한 부분들을 설정을 잘 해줄 필요가 있다.
        <h4 id="3-n8n-서버-http-상에서-열어주기">3. n8n 서버 HTTP 상에서 열어주기</h4>
      </li>
    </ul>
  </li>
  <li><strong>환경변수 설정:</strong> HTTP 환경에선 쓰지 못하게 하는 것이 기본이다. 당연히 종단간 암호화가 안된 상태에서 이걸 진행하게 되면 누군가가 볼 가능성이 당연히 너무 크고, 따라서 중간 탈취를 막아야 하기 때문이다. 그러나 부득불 공개를 해야 한다 or 해도 된다면(내부망 사용 등) 환경 변수를 설정하면된다.
    <pre><code class="language-docker-compose.yml">      environment:
        - GENERIC_TIMEZONE=${GENERIC_TIMEZONE}
        - N8N_SECURE_COOKIE=false # 1. HTTPS가 아니어도 쿠키 사용 허용
        - WEBHOOK_URL=${WEBHOOK_URL} # 2. n8n의 공개 주소 설정
</code></pre>
  </li>
</ul>]]></content><author><name>Paul2021-R</name></author><category term="학습" /><category term="학습" /><category term="NextJS" /><category term="DevOps" /><category term="Jenkins" /><category term="Docker" /><category term="Monitoring" /><summary type="html"><![CDATA[2025-10-31 ~ 2025-11-03 : Monitoring 서버 구축하기 &amp; 네트워크 문제 해결하기]]></summary></entry><entry><title type="html">TIL - HTTPS 인증 받기, 그리고 NPM 도입</title><link href="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/04/til-npm-plus-server.html" rel="alternate" type="text/html" title="TIL - HTTPS 인증 받기, 그리고 NPM 도입" /><published>2025-11-04T00:00:00+00:00</published><updated>2025-11-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/04/til-npm-plus-server</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/11/04/til-npm-plus-server.html"><![CDATA[<h2 id="2025-11-04--https-인증-받기-그리고-npm-도입">2025-11-04 : HTTPS 인증 받기, 그리고 NPM 도입</h2>

<p>다시 HTTPS 인증을 받으려고 해보았다. 이젠 서버에 등록도 되었겠지. Fail 캐싱도 해결되서 문제 없겠지 라는 생각으로 해보았다.</p>

<p><img src="/assets/images/posts/2025-11/20251104-003.png" alt="" /></p>
<blockquote>
  <p>으아ㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㄱㄱㄱㄱㄱㄱㄱㄱㄱㄱ</p>
</blockquote>

<p>내 시간을 도대체 얼마나 잡아 먹을 생각인가 DuckDNS!!! 라는 생각을 하고 검색으로 문제 해결 방법을 조사해보았다.</p>

<p>그러다 알게된 유사한 경험의 <a href="https://www.reddit.com/r/selfhosted/comments/1j2nkmv/dns_challenge_with_duckdnsorg_timeouts_and/">Reddit 글</a>. 답변을 확인해보니 다음과 같았다.</p>

<ol>
  <li>DNSSE 쿼리 처리가 걍 영구적으로 문제 있음</li>
  <li>HTTPS 인증 요청하면 아마 답 자체를 안하게 됨.</li>
  <li>그러면 님 무조건 timeout 발생함</li>
</ol>

<p>(….)</p>

<p>DuckDNS 의 영구적 문제가 있다는 걸 발견하자 오히려 마음이 편해졌다. 그리하여 NoIP 의 서비스를 구매. 어차피 쓸꺼 하고 화끈하게 2년치 구매를 해버렸다…내 십만원..흑흑 앞으로도 서비스를 만들수도 있으니..</p>

<p>어쨌든 그렇게 하고 보니 NPM 서비스라는 것을 발견하여 해당 방식을 적용 후기이다. <del>가즈아</del></p>

<hr />

<h2 id="nginx-proxy-manager-npm란-무엇인가">Nginx Proxy Manager (NPM)란 무엇인가?</h2>

<p>Nginx Proxy Manager(NPM)는 오픈소스 프로젝트 중 하나로, 강력한 웹 서버인 <strong>Nginx</strong>를 기반으로 한다.
Nginx의 핵심 기능 중 하나인 ‘리버스 프록시’를 누구나 쉽게 사용할 수 있도록 <strong>웹 기반의 그래픽 사용자 인터페이스(GUI)</strong> 를 제공하는 데 목적이 있다.
터미널에 접속하여 복잡한 <code class="language-plaintext highlighter-rouge">.conf</code> 설정 파일을 직접 작성하는 대신, 사용자는 웹 브라우저로 NPM 관리자 페이지(예: <code class="language-plaintext highlighter-rouge">http://서버IP:81</code>)에 접속하여 마우스 클릭과 폼 입력만으로 모든 설정을 완료할 수 있다.</p>

<h2 id="npm의-핵심-기능">NPM의 핵심 기능</h2>

<p>NPM이 제공하는 주요 기능은 크게 세 가지로 나눌 수 있다.</p>

<h3 id="1-리버스-프록시-reverse-proxy-관리">1. 리버스 프록시 (Reverse Proxy) 관리</h3>

<ul>
  <li><strong>호스트 기반 라우팅:</strong> 단일 공인 IP 주소와 80/443 포트를 사용하더라도, <code class="language-plaintext highlighter-rouge">jenkins.yourdomain.com</code>, <code class="language-plaintext highlighter-rouge">n8n.yourdomain.com</code> 등 서로 다른 도메인/서브도메인 요청을 받아, 내부의 각기 다른 서비스(예: <code class="language-plaintext highlighter-rouge">localhost:8080</code>, <code class="language-plaintext highlighter-rouge">localhost:5678</code>)로 정확하게 연결(전달)해준다.</li>
  <li><strong>간편한 설정:</strong> GUI의 ‘Proxy Hosts’ 메뉴에서 도메인 이름, 내부 IP 주소, 내부 포트만 입력하면 즉시 리버스 프록시 설정이 완료된다.</li>
</ul>

<h3 id="2-ssl-인증서-자동화-lets-encrypt">2. SSL 인증서 자동화 (Let’s Encrypt)</h3>

<ul>
  <li><strong>원클릭 SSL:</strong> Let’s Encrypt와 완벽하게 연동되어, GUI에서 스위치 하나만 켜면 자동으로 SSL 인증서를 발급받고 Nginx에 적용한다.</li>
  <li><strong>인증서 자동 갱신:</strong> 발급받은 인증서가 만료되기 전에 자동으로 갱신(Renew)하여 HTTPS가 중단되지 않게 한다.</li>
  <li><strong>DNS-01 챌린지 지원:</strong> (한솔의 현재 상황에 핵심) NoIP, Cloudflare 등 주요 DNS 서비스의 API를 지원한다. GUI에 API 키(또는 계정 정보)를 입력하면, <strong>와일드카드 인증서(<code class="language-plaintext highlighter-rouge">*.yourdomain.com</code>)</strong>를 복잡한 과정 없이 자동으로 발급받을 수 있다.</li>
</ul>

<h3 id="3-기타-편의-기능">3. 기타 편의 기능</h3>

<ul>
  <li><strong>접근 제어 (Access Lists):</strong> 특정 도메인에 대해 IP 기반 접근 제한 또는 사용자 로그인(HTTP Basic Auth)을 쉽게 설정할 수 있다.</li>
  <li><strong>리디렉션 (Redirection):</strong> 특정 주소로 들어온 요청을 다른 주소로 강제 이동(예: HTTP를 HTTPS로)시키는 규칙을 쉽게 생성한다.</li>
</ul>

<h2 id="왜-nginx-대신-npm을-사용하는가">왜 Nginx 대신 NPM을 사용하는가?</h2>

<ul>
  <li><strong>압도적인 편의성:</strong> Nginx 원본(Raw Nginx)은 모든 설정을 텍스트 파일(<code class="language-plaintext highlighter-rouge">nginx.conf</code>)로 관리한다. 문법이 복잡하고, 서비스 하나를 추가할 때마다 SSH 접속, 파일 수정, 문법 검사(<code class="language-plaintext highlighter-rouge">nginx -t</code>), 서비스 재시작(<code class="language-plaintext highlighter-rouge">reload</code>) 과정을 거쳐야 한다. NPM은 이 모든 것을 웹 GUI의 ‘저장’ 버튼 하나로 끝낸다.</li>
  <li><strong>SSL 설정의 간소화:</strong> 원본 Nginx에서 Let’s Encrypt를 쓰려면 ‘Certbot’이라는 별도 도구를 설치하고, Nginx와 연동하는 복잡한 명령어를 실행하며, 갱신을 위한 <code class="language-plaintext highlighter-rouge">cron</code> 작업을 수동으로 등록해야 한다. NPM은 이 모든 과정을 내부적으로 자동화했다.</li>
  <li><strong>낮은 진입 장벽:</strong> Nginx에 대한 깊은 지식이 없어도, NPM의 직관적인 GUI를 통해 누구나 강력한 리버스 프록시 환경을 구축할 수 있다.
<img src="/assets/images/posts/2025-11/20251104-004.png" alt="" /></li>
</ul>

<hr />
<h2 id="문제-해결-과정">문제 해결 과정</h2>
<h3 id="wildcard-ddns-실패">wildcard DDNS 실패</h3>
<ul>
  <li>NoIP 기준 wildcard 방식으로 url 을 설정하는 것이 가능하다.</li>
  <li>이렇게 설정하면 다행이(?) DNS 자리를 줄일 수 있었다. 
<img src="/assets/images/posts/2025-11/20251104-005.png" alt="" /></li>
</ul>

<blockquote>

  <ul>
    <li>그런데 이경우 HTTPS 설정을 해야 하는데, 이때는 방식 두 가지 중 하나로 가능하다.
      <ul>
        <li><strong>HTTP-01 방식:</strong> 개별 URL에 대해서 처리하는 방식</li>
        <li><strong>DNS-01 챌린지 방식:</strong> 특정 사이트 URL 이 소유주가 있음을 인정하여 직접 제어하고, 해당 도메인을 아예 인정해버리는 것. =&gt; 이걸 활용해야 원래는 wildcard 방식의 도메인 접근가능</li>
      </ul>
    </li>
    <li>하필이면… NoIP 는 DNS 프로바이더로  없었다. DNS-01 방식은 공용 포트도 불필요, 와일드카드를 위한 인증서용인데 어쩔수 없이 기본적인 HTTP-01 방식으로 마무리 했다. 
<img src="/assets/images/posts/2025-11/20251104-006.png" alt="" /></li>
    <li>HTTP-01 방식은 전통적인 nginx 의 설정을 그대로 옮긴다고 보면 되었다. 
<img src="/assets/images/posts/2025-11/20251104-007.png" alt="" /></li>
  </ul>
</blockquote>

<hr />

<p>하.. DNS-01 방식으로 삽질을 했다. 그런데 안된다는 걸 깨닫고 빠르게 하니 거의 10분? 이 안걸렸다.</p>

<p>다음부턴 NPM + 쉽게 연결하기로 해결해야지 ㅠ..</p>]]></content><author><name>Paul2021-R</name></author><category term="학습" /><category term="학습" /><category term="NextJS" /><category term="DevOps" /><category term="Jenkins" /><category term="Docker" /><category term="Monitoring" /><summary type="html"><![CDATA[2025-11-04 : HTTPS 인증 받기, 그리고 NPM 도입]]></summary></entry><entry><title type="html">TIL - NextJS 데모 페이지 구축 (001)</title><link href="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/10/29/til-nextjs.html" rel="alternate" type="text/html" title="TIL - NextJS 데모 페이지 구축 (001)" /><published>2025-10-29T00:00:00+00:00</published><updated>2025-10-29T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/10/29/til-nextjs</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/10/29/til-nextjs.html"><![CDATA[<h2 id="2025-10-29--nextjs-프론트엔드-핵심-개념들">2025-10-29 : Next.js 프론트엔드 핵심 개념들</h2>

<p>오늘은 Next.js와 React를 사용한 프론트엔드 개발을 진행하고 몇 가지 핵심 개념을 살펴보았다. 백엔드 개발자에게 생소할 수 있는 개념들을 위주로 더 자세히 정리하고 코드 예시를 포함했다.</p>

<hr />

<h2 id="-백엔드-개발자가-알아두면-좋은-프론트엔드-개념">💡 백엔드 개발자가 알아두면 좋은 프론트엔드 개념</h2>

<h3 id="1-컴포넌트-렌더링-서버-컴포넌트-vs-클라이언트-컴포넌트-️-vs-">1. 컴포넌트 렌더링: 서버 컴포넌트 vs 클라이언트 컴포넌트 🖥️ vs 💻</h3>

<p>Next.js는 컴포넌트를 <strong>서버</strong>에서 그릴지(HTML 완성) <strong>클라이언트(브라우저)</strong> 에서 그릴지(JavaScript 사용) 결정할수 있다. 이는 백엔드의 서버 사이드 렌더링(SSR) vs 프론트엔드의 클라이언트 사이드 렌더링(CSR) 개념과 유사합니다.</p>
<ul>
  <li><strong>컴포넌트</strong> :
    <ul>
      <li><strong>개념</strong> : 사용자 인터페이스에서 재사용, 독립적인 조각으로 나누어 개발하는 방식으로 생성되는 대상.
        <ul>
          <li>Next.js 는 React를 기반으로 하여, React의 컴포넌트 개념을 그대로 따라간다.</li>
        </ul>
      </li>
      <li><strong>종류</strong> :
        <ul>
          <li><strong>함수 컴포넌트</strong> :
            <ul>
              <li>일반적인 형태</li>
              <li><code class="language-plaintext highlighter-rouge">useState</code>, <code class="language-plaintext highlighter-rouge">useEffect</code>와 같은 React 훅을 사용하여 상태와 생명주기 기능을 활용 가능</li>
            </ul>
          </li>
          <li><strong>클래스 컴포넌트</strong>
            <ul>
              <li>ES6클래스로 작성됨.</li>
              <li>최신 React 개발에선 함수형을 권장함 .</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>Next.js에서 컴포넌트를 사용하는 이유</strong>
        <ul>
          <li>코드 구조화 및 관리 용이성</li>
          <li>개발 생산성 향상</li>
          <li>성능 최적화</li>
          <li>모듈화</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>서버 컴포넌트 (Server Component, RSC - 기본값):</strong>
    <ul>
      <li><strong>개념:</strong> 컴포넌트 코드가 서버에서 실행되어 최종 HTML로 변환된 후 브라우저로 전송된다. NestJS에서 <code class="language-plaintext highlighter-rouge">EJS</code>나 <code class="language-plaintext highlighter-rouge">Handlebars</code> 같은 템플릿 엔진을 사용해 HTML을 완성해서 보내는 것과 비슷하다.</li>
      <li><strong>장점:</strong>
        <ul>
          <li><strong>초기 로딩 속도:</strong> 브라우저는 완성된 HTML을 바로 보여줄 수 있어 초기 로딩이 빠르다.</li>
          <li><strong>SEO:</strong> 검색 엔진 봇이 완성된 HTML 컨텐츠를 쉽게 수집할 수 있다.</li>
          <li><strong>서버 자원 접근:</strong> DB 조회, 파일 시스템 접근 등 서버에서만 가능한 작업을 직접 수행할 수 있다.</li>
          <li><strong>번들 크기 감소:</strong> 서버에서만 실행되므로 브라우저로 보내는 JavaScript 양이 줄어든다.</li>
        </ul>
      </li>
      <li><strong>제한:</strong> 사용자와의 상호작용(클릭, 입력 등)이나 브라우저 상태(예: <code class="language-plaintext highlighter-rouge">window</code> 객체)에 구조적으로 접근할 수 없다. 즉, <code class="language-plaintext highlighter-rouge">useState</code>, <code class="language-plaintext highlighter-rouge">useEffect</code>, <code class="language-plaintext highlighter-rouge">onClick</code> 등을 사용할 수 없다.</li>
    </ul>
  </li>
  <li><strong>클라이언트 컴포넌트 (Client Component):</strong>
    <ul>
      <li><strong>개념:</strong> 파일 맨 위에 <code class="language-plaintext highlighter-rouge">"use client";</code> 지시어를 추가하여 명시하면 사용이 가능해짐. 이 컴포넌트의 JavaScript 코드는 브라우저로 다운로드되고 실행된다. 우리가 흔히 아는 React 컴포넌트.</li>
      <li><strong>장점:</strong>
        <ul>
          <li><strong>상호작용:</strong> <code class="language-plaintext highlighter-rouge">useState</code> (상태 관리), <code class="language-plaintext highlighter-rouge">useEffect</code> (라이프사이클 관리), <code class="language-plaintext highlighter-rouge">onClick</code> (이벤트 핸들링) 등을 사용하여 동적인 사용자 인터페이스를 만들 수 있다.</li>
          <li><strong>브라우저 API 접근:</strong> <code class="language-plaintext highlighter-rouge">localStorage</code>, <code class="language-plaintext highlighter-rouge">window</code> 객체 등 브라우저 환경에서만 사용 가능한 API를 활용할 수 있다.</li>
        </ul>
      </li>
      <li><strong>단점:</strong>
        <ul>
          <li><strong>초기 로딩:</strong> 브라우저가 JavaScript 파일을 다운로드하고 실행해야 컴포넌트가 그려지므로, 서버 컴포넌트보다 초기 로딩이 느릴 수 있다(Hydration 과정 필요).</li>
          <li><strong>번들 크기 증가:</strong> 브라우저로 보내는 JavaScript 양이 늘어나고 이는 트래픽이다.</li>
        </ul>
      </li>
    </ul>

    <pre><code class="language-TypeScript">  // page.tsx 맨 위에 추가하여 클라이언트 컴포넌트임을 명시
  "use client";
    
  import { useState } from 'react';
    
  export default function MyInteractiveComponent() {
    const [count, setCount] = useState(0);
    
    return (
      &lt;button onClick={() =&gt; setCount(count + 1)}&gt; // 버튼 이벤트 
                Count: {count}
      &lt;/button&gt;
    );
  }
</code></pre>
  </li>
</ul>

<h3 id="2-상태state-관리와-리렌더링-usestate-훅-">2. 상태(State) 관리와 리렌더링: <code class="language-plaintext highlighter-rouge">useState</code> 훅 🔄</h3>

<p>React 컴포넌트는 UI에 영향을 미치는 <strong>상태(State)</strong> 를 가질 수 있다. <code class="language-plaintext highlighter-rouge">useState</code>는 함수 컴포넌트에서 상태를 추가하고 관리하기 위한 <strong>훅(Hook)</strong> 이다.</p>
<ul>
  <li><strong>훅(Hook):</strong> 함수 컴포넌트에서 React의 기능(상태 관리, 라이프사이클 등)을 “연결(hook into)”할 수 있게 해주는 특별한 함수들이다. <code class="language-plaintext highlighter-rouge">useState</code>, <code class="language-plaintext highlighter-rouge">useEffect</code>, <code class="language-plaintext highlighter-rouge">useContext</code> 등이 있다.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">useState</code> 사용법:</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">const [stateVariable, setStateFunction] = useState(initialState);</code></li>
      <li><code class="language-plaintext highlighter-rouge">stateVariable</code>: 현재 상태 값을 저장하는 변수 (읽기 전용).</li>
      <li><code class="language-plaintext highlighter-rouge">setStateFunction</code>: 이 상태 값을 <strong>업데이트하는 함수</strong>. 이 함수를 호출해야만 React가 컴포넌트를 <strong>리렌더링(Re-render)</strong> 하여 변경된 상태를 화면에 반영한다.</li>
      <li><code class="language-plaintext highlighter-rouge">initialState</code>: 상태의 초기값. 컴포넌트가 처음 렌더링될 때 사용하다.</li>
    </ul>
  </li>
  <li><strong>백엔드와의 비교:</strong>
    <ul>
      <li>상태는 DB에 저장되는 영구 데이터와는 다르게 컴포넌트 인스턴스가 살아있는 동안만 유지되는 <strong>메모리상의 임시 데이터</strong>이다 (NestJS 서비스의 멤버 변수와 유사)</li>
      <li>가장 큰 차이점은 React는 <code class="language-plaintext highlighter-rouge">setStateFunction</code> 호출을 통해 상태 변경을 감지하고, <strong>선언적으로(declaratively)</strong> UI를 업데이트한다는 점이다 . 개발자는 “상태를 이렇게 바꿔줘”라고만 명령하면, React가 알아서 DOM을 효율적으로 조작하여 화면을 변경한다.</li>
    </ul>

    <pre><code class="language-TypeScript">  // page.tsx
  "use client";
    
  import { useState } from 'react';
    
  // ... (projects 배열 정의)
    
  export default function Home() {
    // isProjectsOpen: 현재 프로젝트 목록이 열려있는지 여부 (true/false)
    // setIsProjectsOpen: isProjectsOpen 값을 변경하는 함수
    // useState(false): 초기값은 false (닫힌 상태)
    const [isProjectsOpen, setIsProjectsOpen] = useState(false);
    
    // 버튼 클릭 시 호출될 함수
    const toggleProjects = () =&gt; {
      // 현재 isProjectsOpen 값의 반대값으로 상태를 업데이트 (일종의 업데이트 )
      setIsProjectsOpen(!isProjectsOpen);
    };
    
    return (
      // ... (생략)
      &lt;button
        onClick={toggleProjects} // 버튼 클릭 시 toggleProjects 함수 실행
        aria-expanded={isProjectsOpen}
      &gt;
        {/* ... SVG 아이콘 ... */}
      &lt;/button&gt;
      // ...
      {isProjectsOpen &amp;&amp; ( // isProjectsOpen이 true일 때만 하위 목록 렌더링
        &lt;ul&gt;
          {/* ... 프로젝트 링크 목록 ... */}
        &lt;/ul&gt;
      )}
      // ...
    );
  }
    
</code></pre>
  </li>
</ul>

<h3 id="3-스타일링-tailwind-css-유틸리티-우선-접근법-">3. 스타일링: Tailwind CSS 유틸리티 우선 접근법 🎨</h3>

<p>Tailwind CSS는 미리 정의된 수많은 <strong>유틸리티 클래스</strong>를 제공한다. 개발자는 이러한 클래스들을 HTML 요소의 <code class="language-plaintext highlighter-rouge">className</code> 속성에 직접 조합하여 스타일을 적용 할 수 있다.</p>

<ul>
  <li><strong>유틸리티 우선(Utility-First):</strong> <code class="language-plaintext highlighter-rouge">button-primary</code> 같은 <strong>의미론적(semantic)</strong> 클래스 대신, <code class="language-plaintext highlighter-rouge">bg-blue-600</code>, <code class="language-plaintext highlighter-rouge">py-3</code>, <code class="language-plaintext highlighter-rouge">font-semibold</code> 같이 <strong>시각적 기능</strong>에 집중된 작은 클래스들을 조합한다.</li>
  <li><strong>작동 방식:</strong>
    <ol>
      <li>개발자가 <code class="language-plaintext highlighter-rouge">className="text-center font-bold"</code>라고 작성한다</li>
      <li>빌드 시 Tailwind CSS가 프로젝트 내의 모든 <code class="language-plaintext highlighter-rouge">className</code>을 스캔한다.</li>
      <li>사용된 유틸리티(<code class="language-plaintext highlighter-rouge">text-center</code>, <code class="language-plaintext highlighter-rouge">font-bold</code>)에 해당하는 CSS 규칙(<code class="language-plaintext highlighter-rouge">.text-center { text-align: center; }</code>, <code class="language-plaintext highlighter-rouge">.font-bold { font-weight: 700; }</code>)을 생성해준다.</li>
      <li>이 생성된 CSS를 <code class="language-plaintext highlighter-rouge">globals.css</code> 파일에 주입한다.</li>
      <li>브라우저는 HTML의 <code class="language-plaintext highlighter-rouge">class</code> 속성과 CSS 파일의 규칙을 매칭하여 스타일을 적용한다.</li>
    </ol>
  </li>
  <li><strong><code class="language-plaintext highlighter-rouge">tailwind.config.ts</code>:</strong> 테마(색상, 글꼴 크기 등) 커스터마이징, 플러그인 추가, <code class="language-plaintext highlighter-rouge">darkMode</code> 전략 설정 등을 위한 설정 파일이다.</li>
  <li>
    <p><strong><code class="language-plaintext highlighter-rouge">globals.css</code>:</strong> Tailwind의 기본 스타일(<code class="language-plaintext highlighter-rouge">@tailwind base;</code>), 컴포넌트 스타일(<code class="language-plaintext highlighter-rouge">@tailwind components;</code>), 유틸리티 스타일(<code class="language-plaintext highlighter-rouge">@tailwind utilities;</code>)을 주입하는 역할과, 직접 작성한 커스텀 CSS 클래스를 추가하는 역할을 한다.</p>

    <pre><code class="language-TypeScript">  // login/page.tsx 예시
  &lt;div className="flex min-h-screen items-center justify-center bg-gray-100"&gt;
    {/* flex: display: flex;
      min-h-screen: min-height: 100vh;
      items-center: align-items: center;
      justify-center: justify-content: center;
      bg-gray-100: 배경색 지정
    */}
    &lt;div className="w-full max-w-md rounded-lg bg-white p-8 shadow-md"&gt;
      {/*
        w-full: width: 100%;
        max-w-md: max-width: 28rem;
        rounded-lg: border-radius: 0.5rem;
        bg-white: background-color: white;
        p-8: padding: 2rem;
        shadow-md: box-shadow 적용
      */}
      &lt;h1 className="mb-6 text-center text-3xl font-bold text-gray-800"&gt;
        로그인
        {/*
          mb-6: margin-bottom: 1.5rem;
          text-center: text-align: center;
          text-3xl: font-size: 1.875rem; line-height: 2.25rem;
          font-bold: font-weight: 700;
          text-gray-800: 글자색 지정
        */}
      &lt;/h1&gt;
      {/* ... */}
    &lt;/div&gt;
  &lt;/div&gt;
</code></pre>
  </li>
</ul>

<h3 id="4-nextjs-특화-컴포넌트-link와-image-">4. Next.js 특화 컴포넌트: <code class="language-plaintext highlighter-rouge">&lt;Link&gt;</code>와 <code class="language-plaintext highlighter-rouge">&lt;Image&gt;</code> ✨</h3>

<p>성능 향상을 위해 Next.js는 표준 HTML 태그의 기능을 확장한 자체 컴포넌트를 제공한다. 따라서 표준 HTML 태그가 아닌 태그들을 써야 하는 경우가 있다.</p>
<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">&lt;Link&gt;</code> 컴포넌트:</strong>
    <ul>
      <li><strong>역할:</strong> 페이지 간 이동을 처리한다. 내부적으로 <code class="language-plaintext highlighter-rouge">&lt;a&gt;</code> 태그를 렌더링하지만, 동작 방식이 다르다.</li>
      <li><strong>핵심 기능 (클라이언트 사이드 라우팅):</strong>
        <ul>
          <li>클릭 시 브라우저가 페이지 전체를 새로고침하지 않는다.</li>
          <li>대신, JavaScript를 사용하여 URL을 변경하고 필요한 페이지만 동적으로 로드하여 교체한다 (SPA처럼 동작).(레이아웃 기반으로 최초 접근 위치에서 자식만 교체 한다던가…)</li>
          <li>결과로서 매우 빠르고 부드러운 페이지 전환 경험을 제공한다.</li>
        </ul>
      </li>
      <li><strong>프리페칭(Prefetching):</strong> 기본적으로 <code class="language-plaintext highlighter-rouge">&lt;Link&gt;</code>가 화면에 보이면, 해당 링크가 가리키는 페이지의 코드를 백그라운드에서 미리 다운로드한다. 사용자가 클릭했을 때 거의 즉시 페이지가 로드된다.</li>
      <li><strong>사용법:</strong> <code class="language-plaintext highlighter-rouge">href</code> 속성으로 이동할 경로를 지정한다.</li>
    </ul>

    <pre><code class="language-TypeScript">  // page.tsx 예시
  import Link from 'next/link';
    
  &lt;Link href="/login" className="text-blue-600 hover:underline"&gt;
    Login Page
  &lt;/Link&gt;
</code></pre>
  </li>
  <li><strong><code class="language-plaintext highlighter-rouge">&lt;Image&gt;</code> 컴포넌트:</strong>
    <ul>
      <li><strong>역할:</strong> 이미지를 표시합니다. 내부적으로 <code class="language-plaintext highlighter-rouge">&lt;img&gt;</code> 태그를 렌더링하지만, 강력한 최적화 기능을 추가한다.</li>
      <li><strong>핵심 기능 (자동 이미지 최적화):</strong>
        <ul>
          <li><strong>사이즈 최적화:</strong> 다양한 화면 크기(데스크탑, 모바일 등)에 맞는 이미지 크기를 자동으로 생성하고 제공한다.</li>
          <li><strong>포맷 최적화:</strong> 브라우저가 지원하는 경우, 이미지를 WebP나 AVIF 같은 최신 포맷으로 자동 변환하여 용량을 최적화 시킨다.</li>
          <li><strong>지연 로딩 (Lazy Loading):</strong> 기본적으로 이미지가 사용자의 뷰포트(화면 영역)에 들어올 때까지 로딩을 지연시켜 초기 페이지 로딩 속도를 향상시킵니다. (<code class="language-plaintext highlighter-rouge">priority</code> 속성으로 비활성화 가능, 필요한 경우 즉시 로딩을 요청할 수 있다.)</li>
          <li><strong>CLS(Cumulative Layout Shift) 방지:</strong> <code class="language-plaintext highlighter-rouge">width</code>와 <code class="language-plaintext highlighter-rouge">height</code> 속성을 필수로 요구하여, 이미지가 로드되기 전에 해당 공간을 미리 확보함으로써 레이아웃이 갑자기 변경되는 현상을 방지한다.</li>
        </ul>
      </li>
      <li><strong>사용법:</strong> <code class="language-plaintext highlighter-rouge">src</code>, <code class="language-plaintext highlighter-rouge">width</code>, <code class="language-plaintext highlighter-rouge">height</code>, <code class="language-plaintext highlighter-rouge">alt</code> 속성이 필수(이걸 몰라서 왜 에러가 뜨지? 하고 한참 해맸다.). <code class="language-plaintext highlighter-rouge">src</code>는 <code class="language-plaintext highlighter-rouge">public</code> 폴더 기준의 절대 경로 또는 외부 URL을 사용한다.</li>
    </ul>

    <pre><code class="language-TypeScript">  // page.tsx 예시
  import Image from 'next/image';
    
  &lt;Image
    src="/main.png" // public 폴더의 main.png
    alt="메인 비주얼"
    width={800}    // 이미지 원본 너비
    height={800}   // 이미지 원본 높이
    priority       // 이 이미지는 중요하므로 먼저 로드
  /&gt;
</code></pre>
  </li>
</ul>

<hr />

<h2 id="-질문-목록-qa">❓ 질문 목록 (Q&amp;A)</h2>

<h3 id="q1-맨-위에-use-client의-역할은">Q1: 맨 위에 <code class="language-plaintext highlighter-rouge">"use client"</code>의 역할은?</h3>

<p><strong>A:</strong> 해당 파일(모듈)이 <strong>클라이언트 컴포넌트</strong>임을 명시하는 지시어다. <code class="language-plaintext highlighter-rouge">"use client"</code>가 선언된 파일과 그 파일에서 import하는 모든 모듈은 클라이언트 번들에 포함되어 브라우저에서 실행된다. 이는 <code class="language-plaintext highlighter-rouge">useState</code>, <code class="language-plaintext highlighter-rouge">useEffect</code> 같은 React 훅이나 <code class="language-plaintext highlighter-rouge">onClick</code> 같은 브라우저 이벤트를 사용하기 위해 필수적이다. 반대로, 이 지시어가 없으면 기본적으로 <strong>서버 컴포넌트</strong>로 간주되므로 클라이언트 사이드의 이벤트에 대해서 인식이 불가능하다.</p>

<h3 id="q2-usestatefalse는-기본값을-선정하는-건가-isprojectsopen과-setisprojectsopen-두-가지의-역할과-차이는">Q2: <code class="language-plaintext highlighter-rouge">useState(false)</code>는 기본값을 선정하는 건가? <code class="language-plaintext highlighter-rouge">isProjectsOpen</code>과 <code class="language-plaintext highlighter-rouge">setIsProjectsOpen</code> 두 가지의 역할과 차이는?</h3>

<p><strong>A:</strong></p>
<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">useState()</code>의 인자로 전달된 값(<code class="language-plaintext highlighter-rouge">false</code> 등)은 해당 상태 변수의 <strong>초기값(initial state)</strong>. 컴포넌트가 처음 마운트될 때 이 값으로 상태가 초기화된다.(해당 코드에선 접혀있는 상태로 시작해야 하므로 false를 넣고, 대신 statetFunction에서 not 처리를 해준다.)</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">isProjectsOpen</code>: <strong>현재 상태 값</strong>을 담고 있는 변수. JSX 내에서 이 값을 읽어 UI를 조건부로 렌더링하거나 표시할 수 있다. 이 변수는 직접 수정할 수 없다 (예: <code class="language-plaintext highlighter-rouge">isProjectsOpen = true;</code> 불가).</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">setIsProjectsOpen</code>: <code class="language-plaintext highlighter-rouge">isProjectsOpen</code> 상태를 <strong>업데이트하는 함수</strong>다. 이 함수에 새로운 상태 값을 전달하여 호출하면 (<code class="language-plaintext highlighter-rouge">setIsProjectsOpen(true);</code> 또는 <code class="language-plaintext highlighter-rouge">setIsProjectsOpen(prev =&gt; !prev);</code>), React는 상태 변경을 감지하고 컴포넌트를 리렌더링하여 UI를 갱신한다. 이것이 전형적인 React에서 상태를 변경하는 방법이다.</p>
  </li>
</ul>

<h3 id="q3-const-toggle로-화살표-함수는-usestate에-사용하기-위해-설정해주는-일종의-변수형-메서드인-건가">Q3: <code class="language-plaintext highlighter-rouge">const toggle~</code>로 화살표 함수는 <code class="language-plaintext highlighter-rouge">useState</code>에 사용하기 위해 설정해주는 일종의 변수형 메서드인 건가?</h3>

<p><strong>A:</strong> “일종의 변수형 메서드” 또는 더 정확히는 <strong>이벤트 핸들러 함수</strong>라고 볼 수 있다. <code class="language-plaintext highlighter-rouge">useState</code> 자체에 필요한 것은 아니다. 단, 상태를 변경하는 로직(예: <code class="language-plaintext highlighter-rouge">setIsProjectsOpen(!isProjectsOpen)</code>)을 <code class="language-plaintext highlighter-rouge">&lt;button&gt;</code>의 <code class="language-plaintext highlighter-rouge">onClick</code> 속성에 직접 넣는 대신, 별도의 함수(<code class="language-plaintext highlighter-rouge">toggleProjects</code>)로 분리하여 정의한 것이다. 이렇게 하면 코드가 더 깔끔해지고, 로직이 복잡해질 경우 관리하기 용이하며, 필요하다면 다른 곳에서 재사용할 수도 있다.</p>

<pre><code class="language-TypeScript">// 이벤트 핸들러 함수 정의
const toggleProjects = () =&gt; {
  setIsProjectsOpen(prevState =&gt; !prevState); // 이전 상태를 기반으로 토글
};

// JSX에서 이벤트 핸들러로 함수 연결
&lt;button onClick={toggleProjects}&gt;...&lt;/button&gt;
</code></pre>

<h3 id="q4-nextjs에서-주로-사용한다는-html이-아닌-자체-태그들link라던가이-있는데-왜-이걸-써야-하고-안-쓰면-안-되는-이유가-있는지">Q4: Next.js에서 주로 사용한다는 HTML이 아닌 자체 태그들(<code class="language-plaintext highlighter-rouge">Link</code>라던가)이 있는데, 왜 이걸 써야 하고, 안 쓰면 안 되는 이유가 있는지?</h3>

<p><strong>A:</strong> <strong>성능 최적화와 향상된 사용자 경험</strong>을 위해서 Next.js의 자체 컴포넌트 사용이 강력히 권장한다. 안 쓴다고 해서 앱이 작동하지 않는 것은 아니지만, Next.js를 사용하는 핵심 이점들을 놓치게 된다.</p>

<ul>
  <li>
    <p><strong><code class="language-plaintext highlighter-rouge">&lt;Link&gt;</code> vs <code class="language-plaintext highlighter-rouge">&lt;a&gt;</code>:</strong> <code class="language-plaintext highlighter-rouge">&lt;Link&gt;</code>는 <strong>클라이언트 사이드 라우팅</strong>을 구현하여 페이지 전환 시 전체 새로고침 없이 변경된 부분만 업데이트한다. 이는 훨씬 빠르고 부드러운 사용자 경험(SPA와 유사)을 제공합니다. 또한, <strong>프리페칭</strong> 기능으로 미리 다음 페이지를 로드하여 전환 속도를 더욱 높인다. 일반 <code class="language-plaintext highlighter-rouge">&lt;a&gt;</code> 태그는 전통적인 서버 방식의 페이지 이동(전체 새로고침)을 만들고, 당연히 동작은 하나 전체를 새로 그려야 한다.</p>
  </li>
  <li>
    <p><strong><code class="language-plaintext highlighter-rouge">&lt;Image&gt;</code> vs <code class="language-plaintext highlighter-rouge">&lt;img&gt;</code>:</strong> <code class="language-plaintext highlighter-rouge">&lt;Image&gt;</code>는 <strong>자동으로 이미지를 최적화</strong>한다(사이즈 조절, WebP 변환, 지연 로딩 등). 이는 페이지 로딩 속도를 크게 개선하고 대역폭 사용량을 줄여준다. 또한 <code class="language-plaintext highlighter-rouge">width</code>, <code class="language-plaintext highlighter-rouge">height</code>를 강제하여 레이아웃 쉬프트(CLS) 문제를 예방한다. 일반 <code class="language-plaintext highlighter-rouge">&lt;img&gt;</code> 태그는 이러한 최적화 기능을 제공하지 않고 직접 처리해야 한다.</p>
  </li>
</ul>

<h3 id="q5-button-컴포넌트의-svg-태그에서--안에-넣으면-일종의-함수로-동작하는-건지-그리고-fill-stroke와-같은-classname에-안-들어간-별도의-요소들은-그냥-svg-태그의-요소들인-건지">Q5: <code class="language-plaintext highlighter-rouge">button</code> 컴포넌트의 <code class="language-plaintext highlighter-rouge">svg</code> 태그에서 <code class="language-plaintext highlighter-rouge">${}</code> 안에 넣으면 일종의 함수로 동작하는 건지? 그리고 <code class="language-plaintext highlighter-rouge">fill</code>, <code class="language-plaintext highlighter-rouge">stroke</code>와 같은 <code class="language-plaintext highlighter-rouge">className</code>에 안 들어간 별도의 요소들은 그냥 <code class="language-plaintext highlighter-rouge">svg</code> 태그의 요소들인 건지?</h3>

<p><strong>A:</strong></p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">${...}</code>: 이것은 함수 호출이 아니라, JavaScript의 <strong>템플릿 리터럴(Template Literal)</strong> 내에서 <strong>표현식 삽입(Expression Interpolation)</strong> 을 사용하는 문법이다. 백틱(<code class="language-plaintext highlighter-rouge">`</code>)으로 감싸진 문자열 안에서 <code class="language-plaintext highlighter-rouge">${}</code>를 사용하면, 중괄호 안의 JavaScript 코드가 평가되고 그 결과값이 문자열의 해당 위치에 삽입한다. 예시 코드에서는 <code class="language-plaintext highlighter-rouge">isProjectsOpen</code> 상태에 따라 <code class="language-plaintext highlighter-rouge">rotate-180</code> 클래스를 조건부로 추가하여 아이콘의 회전 상태를 제어한다.</p>

    <pre><code class="language-JavaScript">  // className 속성에 템플릿 리터럴 사용
  &lt;svg
    className={`h-5 w-5 transition-transform ${ // 백틱(`)으로 시작
      isProjectsOpen ? 'rotate-180' : '' // ${} 안에 삼항 연산자 표현식
    }`} // 백틱(`)으로 끝
    // ... (SVG 속성들)
  &gt;
    {/* ... */}
  &lt;/svg&gt;
</code></pre>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">fill</code>, <code class="language-plaintext highlighter-rouge">stroke</code>, <code class="language-plaintext highlighter-rouge">viewBox</code>, <code class="language-plaintext highlighter-rouge">xmlns</code>, <code class="language-plaintext highlighter-rouge">d</code>, <code class="language-plaintext highlighter-rouge">strokeLinecap</code>, <code class="language-plaintext highlighter-rouge">strokeLinejoin</code>, <code class="language-plaintext highlighter-rouge">strokeWidth</code>:  이 속성들은 <code class="language-plaintext highlighter-rouge">className</code>과는 별개로 <strong>SVG(Scalable Vector Graphics) 표준 명세에 정의된 고유한 속성(attributes)</strong> 이다. 벡터 그래픽의 모양, 색상, 선 스타일 등을 정의하는 데 사용됩니다. Tailwind CSS 클래스와는 직접적인 관련이 없다.</p>
  </li>
</ul>]]></content><author><name>Paul2021-R</name></author><category term="학습" /><category term="학습" /><category term="NextJS" /><category term="DevOps" /><category term="Jenkins" /><category term="Docker" /><summary type="html"><![CDATA[2025-10-29 : Next.js 프론트엔드 핵심 개념들]]></summary></entry></feed>