<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" hreflang="ko" /><updated>2025-08-05T06:14:25+00:00</updated><id>http://0.0.0.0:4000/feed.xml</id><title type="html">Paul’s Archives</title><subtitle>성장하는 개발자, 소통하는 개발자, 빠른 적용을 최 우선으로 삼는 개발자. 다음을 항상 생각하며, 개발 속에서 가치를 만들어내는 것을 목표로 합니다.</subtitle><author><name>Paul2021-R</name></author><entry><title type="html">AI Breakfast Ep 11 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/08/05/00-AI-trend-with-google-11.html" rel="alternate" type="text/html" title="AI Breakfast Ep 11 생각정리" /><published>2025-08-05T00:00:00+00:00</published><updated>2025-08-05T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/05/00-AI-trend-with-google-11</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/05/00-AI-trend-with-google-11.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=P7TzvAJ6n_w"><img src="https://i.ytimg.com/vi/P7TzvAJ6n_w/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>이번 내용은 AI와 대규모 언어 모델(LLM)이 코딩 및 개발자 역할에 미치는 영향, 그리고 현재의 한계와 미래 전망에 대한 논의이다.</p>

<ul>
  <li><strong>대규모 언어 모델(LLM)과 코딩의 미래</strong>:
    <ul>
      <li>LLM은 기존 자연어 처리(NLP) 솔루션과 달리 <strong>단일 모델로 다양한 NLP 작업을 수행할 수 있으며</strong>, 수 테라바이트의 레이블 없는 데이터로 학습된 <strong>기초 모델</strong>이다.</li>
      <li>현재의 구조화된 프로그래밍 언어는 LLM에 비적합하며, 미래에는 <strong>자동 회귀(auto-regressive) 방식으로 한 줄씩 진화하는 새로운 프로그래밍 언어가 등장할 수 있다</strong>고 예상된다. 이는 토큰 사용량을 대폭 줄일 것이다. =&gt; 이 인사이트는 염두해 둬야 하는, 어쩌면 개선해야할 AI 영역일 것임.</li>
      <li>LLM은 언어를 ‘이해’하는 것이 아니라 학습된 패턴을 기반으로 <strong>다음에 올 가장 확률 높은 토큰을 예측하는 정교한 수학적 함수</strong>이며, 트랜스포머 아키텍처와 어텐션 메커니즘을 사용한다.</li>
    </ul>
  </li>
  <li><strong>개발자의 역할 변화와 비즈니스 영향</strong>:
    <ul>
      <li>먼 미래에는 개발자 직업이 사라질 수 있다는 예측에 동의하며, 5년 이내에도 개발 인력이 크게 줄어들 수 있다고 보았다.</li>
      <li>LLM은 개발자의 <strong>생산성을 10배 이상 향상</strong>시켜, 개발자가 기획보다 빠르게 결과물을 내놓는 시대로 전환시키고 있다.</li>
      <li>코딩은 상품화를 위한 중간 과정이며, <strong>AI를 통해 대체 가능한 부분</strong>으로 여겨진다.</li>
      <li>앞으로는 큰 도메인 지식을 갖춘 <strong>‘빅픽처 전문가’ 또는 ‘프로덕트 엔지니어’가 중요</strong>해질 것이며, AI에게 명확한 요구사항을 전달하는 능력이 핵심이다.</li>
      <li>비개발자들도 코딩에 참여하는 <strong>개발의 ‘민주화’ 현상</strong>이 나타나고 있다.</li>
      <li><strong>인간과 기술은 공존해야 하며</strong>, AI를 받아들이고 경험하는 정도가 개인의 대체 여부를 결정하는 중요한 요소이다.</li>
    </ul>
  </li>
  <li><strong>바이브 코딩의 실제 적용과 한계</strong>:
    <ul>
      <li>바이브 코딩은 <strong>빠르게 데모를 만들고 결과물을 검증하는 데 효과적</strong>이다.</li>
      <li>그러나 <strong>보안이 매우 취약할 수 있어</strong> 금융 등 중요한 분야에서는 도입에 거부감이 크다.</li>
      <li>큰 범위의 프로젝트에는 아직 적용하기 어렵다.</li>
      <li>AI가 생성한 코드는 방대하여 인간이 리뷰하기 어렵고, <strong>AI 생성 코드에 대한 신뢰도가 아직 높지 않다</strong>.</li>
      <li>LLM의 한계로 인해 복잡한 문제 해결 시에는 <strong>인간이 직접 고치는 것이 더 빠르다</strong>.</li>
      <li>LLM은 학습된 지식 내에서만 작동하며 <strong>메타인지 능력이 부족하여 새로운 지식에 대한 업데이트나 함수 생성에 어려움</strong>이 있다.</li>
      <li>정확한 결과물을 얻기 위해서는 <strong>요구사항을 아주 세분화하여 명확하게 설계하고, 테스트를 잘 작성하는 능력</strong>이 중요해졌다.</li>
      <li>생성된 코드를 다시 설계 문서 등으로 <strong>‘리버스 엔지니어링’하여 저장하고 관리하는 방식</strong>이 활용될 수 있다.</li>
      <li>사용자는 <strong>‘프롬프트 문해력’을 길러야</strong> 하며, 생성된 결과를 올바르게 이해하고 검증해야 한다. =&gt; 결국 프롬프트 문해력이란것이 무엇인가? 프롬프트를 잘 작성한다는 게 무엇인가? 를 이해해야 한다.</li>
    </ul>
  </li>
  <li><strong>결론 및 시사점</strong>:
    <ul>
      <li>LLM 시대에는 <strong>인간의 도메인 지식과 노하우, 그리고 비판적 사고가 더욱 중요</strong>해지며, LLM의 명확한 한계를 인지하고 이를 보완하는 것이 필요하다.</li>
      <li>개개인은 <strong>‘언어의 경계가 곧 세계의 경계’라는 철학자의 말처럼</strong>, 어떤 언어(프롬프트)를 구사하느냐에 따라 자신의 가능성이 달라지므로, <strong>무한히 도전해 볼 것</strong>이 권장된다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>Gemini 의 성능을 약간 보여주는 화 같아서(물론 그래도 잘 만들긴 하더라 ㅋㅋ), 핵심적인 내용들, 개발자로 가져야 하는 태도에 대해 다시 한번 생각해본 시간이었다.</p>

<p>여전히 한계로 지적되는 부분, 즉 구조적으로 현 AI 는 코딩을 하기에 효율적인 도구가 아니고, ‘효율적인 척’ 하면서 GPU 를 녹이고 있다는 사실을 다시 한 번 강조했다.</p>

<p>생각해보면 그정도로 자기 회귀적으로 진행되는 구조로 가는 건 어쩌면 모든 점에서 더 나을 건데, 과연 그런 형태의 예측이나, 알고리즘 개선이 되는지는 잘 모르겠다는 생각이 든다. (수알못이라…)</p>

<p>어쨌든 모델의 개선도 지속적으로 이루어지고 있으니, 어쩌면 그러한 부분까지 언젠가는 개선이 되지 않을까 하는 생각은 해본다. 메타가 거의 백억단위 연봉을 주며 개발자를 데려가고 AGI 그 이상의 초 인공지능을 만들겠다고 하니, 결국 AI 는 양과 질의 향상이 계속 될 것은 맞고, 그런걸 실현 가능한 사람이 되는게 1티어 급 인사가 되는 길이 아닐까?</p>

<p>어쨌든, 일단 현 개발자라는 차원에서 본다면 사용 방법에 대해, 내 방법이 틀린게 아니었구나 ~ 하는 생각이 들었다.</p>

<p>무조건 맡기는 식으론 매우 위험하고, MVP 그 이상으로 빠르게 구현이 되지만 보안의 문제는 확실하게 존재한다. 더불어 회사가 그걸 용인해주는 곳인가? 여러 면에서 편리함, 효용성에 +로 고려할 것을 미리미리 고려하는 것은 매우 중요한 부분이라고 생각된다.</p>

<p>어쩌면 나만의 검증 절차를 AI 로 체계화 하는 것, 그리고 그걸 내 작업 루틴에 넣는 것이 포함되면 좋지 않을까? 하는 생각을 하게 된다. 그리고 그걸 종합해서 적절하게 코드 리포트 형태로 만든다거나 하는 것도 괜찮지 않을까?</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI는 집에서 만들지 말고 사서 쓰세요 | 스케일링 법칙</title><link href="http://0.0.0.0:4000/ai/2025/08/05/01-do-not-make-ai.html" rel="alternate" type="text/html" title="AI는 집에서 만들지 말고 사서 쓰세요 | 스케일링 법칙" /><published>2025-08-05T00:00:00+00:00</published><updated>2025-08-05T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/05/01-do-not-make-ai</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/05/01-do-not-make-ai.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=QkPeMzr3Qz4"><img src="/assets/images/posts/2025-08/2025-08-05-001.png" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>인공지능(AI) 발전의 핵심 원동력 중 하나는 <strong>‘스케일링 법칙(Scaling Laws)’</strong>이며, 이 법칙은 AI 모델의 성능이 <strong>연산량(Compute), 모델 크기(Model Size), 데이터 크기(Data Size)</strong>의 세 가지 핵심 요소에 따라 일정한 패턴으로 예측 가능하게 변화하는 원리이다.</p>

<h3 id="1-스케일링-법칙의-발견과-핵심-개념">1. 스케일링 법칙의 발견과 핵심 개념</h3>

<ul>
  <li><strong>성능의 한계와 최적의 경계선(Compute Optimal Frontier)</strong>: AI 모델을 훈련할 때 처음에는 오류(Loss)가 급격히 줄지만, 어느 순간부터는 더 이상 줄지 않는다. 모델 크기를 키우면 오류는 더 줄지만 그만큼 더 많은 연산이 필요하다. 로그 스케일로 보면 모델 크기를 늘려도 넘어설 수 없는 명확한 선이 보이는데, 이것을 <strong>‘최적의 경계선’</strong>이라고 부른다. 스케일링 법칙은 AI 성능이 연산량, 모델 크기, 데이터 크기에 따라 일정하게 줄어드는 것을 보여준다.</li>
  <li><strong>OpenAI의 발견 (2020년)</strong>: OpenAI는 2020년 논문을 통해 언어 모델 성능에 일정한 패턴이 있음을 발견했으며, 성능이 컴퓨팅 파워, 데이터 크기, 모델 크기에 따라 일정하게 감소함을 확인했다. 이 패턴은 아주 큰 스케일에서도 동일하게 적용된다는 것을 깨달았다. 가장 큰 테스트 모델은 15억 개의 파라미터를 가졌고 약 10 페타플롭/일의 계산 능력이 필요했다.</li>
  <li><strong>오류 측정: 크로스 엔트로피(Cross-Entropy)</strong>:
    <ul>
      <li>GPT-3와 같은 언어 모델은 이전 단어들을 받아 다음 단어나 단어의 조각을 예측하는 방식으로 학습된다. 다음에 올 단어들의 확률을 예측하는데, 이 값들은 ‘소프트맥스’ 과정을 거쳐 모든 확률의 합이 1이 되도록 조정된다. 참고로 GPT-3는 사용할 어휘를 총 52,571개 단어로 미리 구성했다.</li>
      <li>훈련 과정에서 모델의 예측이 실제 정답과 얼마나 일치하는지 <strong>‘로스(Loss)’</strong> 값을 계산하는데, 이 로스 값을 줄이는 것이 비싼 GPU들이 하는 핵심 작업이다.</li>
      <li>일반적으로 L1 로스보다 <strong>‘크로스 엔트로피’</strong>라는 로스 함수를 더 자주 사용한다. 크로스 엔트로피는 모델이 예측한 확률값에 로그를 씌우고 음수로 바꿔 계산하는데, 모델의 예측이 정답과 다를수록 로스값이 훨씬 빠르게 증가하여 더 많은 페널티를 부여한다.</li>
      <li>우리가 보는 성능 그래프는 대부분 테스트셋에서 측정한 평균 크로스 엔트로피 값으로, 모델이 다음 단어를 더 높은 확률로 맞출수록 평균 크로스 엔트로피는 0에 가까워지며 이는 모델이 더 똑똑해진다는 것을 의미한다.</li>
    </ul>
  </li>
  <li><strong>자연어의 엔트로피와 성능의 한계</strong>: 모델이 똑똑해져도 로스(오류)가 0이 되지 않는 이유는 주어진 문장에서 다음에 올 단어가 실제로 여러 개 있을 수 있기 때문이고, 그것 모두 정답이 될 수 있다. 이러한 특성을 <strong>‘자연어에서의 엔트로피’</strong>라고 부른다.
    <ul>
      <li>OpenAI 내부적으로 이러한 내용에 대해 언급이 이루어지고, Google 딥마인드 팀이 언어에서의 성능 한계를 예측할 수 있는 단서를 내놓았고, 이를 통해 언어에서도 모델과 데이터 크기에 따라 성능을 예측할 수 있는 스케일링 법칙을 크로스 엔트로피 상수항 <strong>1.69</strong>를 포함해 완성할 수 있었다. 이는 아무리 모델을 키우고 데이터를 늘려 훈련해도 크로스 엔트로피 로스를 결국 1.69 이상 낮출 수 없다는 것을 발견하게 된 것이었다.</li>
    </ul>
  </li>
</ul>

<h3 id="2-llm-개발과-투자의-지형-변화">2. LLM 개발과 투자의 지형 변화</h3>

<ul>
  <li><strong>막대한 투자와 예측의 중요성</strong>: OpenAI는 GPT-3 훈련에 1,750억 개의 파라미터와 3,640 페타플롭/일의 연산이 필요했으며, 훈련용 GPU 가격만 한화 약 1,400억 원 가량이 필요했다. GPT-4는 그보다 5배가 넘는 20만 페타플롭/일의 연산을 사용했고, A100 GPU 25,000개를 석 달 동안 사용하며 GPU 가격만 6,000억 원이 넘게 들었다고 알려졌다.</li>
  <li><strong>투자의 정당성 확보</strong>: 스케일링 법칙은 이처럼 막대한 자본 지출(CapEx)을 하기 전에 모델의 성능 향상 정도를 <strong>정확히 예측</strong>할 수 있게 해주었다. 2020년 초 10^-8 페타플롭/일 규모에서 GPT-4의 20만 페타플롭/일까지 약 13자리가 넘는 차이에서도 정교하게 작동하는 스케일링 법칙이 이러한 투자를 가능하게 했다. OpenAI는 GPT-4 훈련을 위해 약 1,400억 원 이상을 투자하기 전 조그만 실험들을 돌려 그만큼 투자했을 때 얼마나 성능을 뽑을 수 있는지 먼저 확인했다.</li>
</ul>

<h3 id="3-스케일링-법칙의-이론적-배경-매니폴드-가설">3. 스케일링 법칙의 이론적 배경: 매니폴드 가설</h3>

<ul>
  <li><strong>고차원 데이터와 매니폴드</strong>: 머신러닝에서는 모델이 학습하는 데이터들이 어떤 ‘곡면’, <strong>‘매니폴드(Manifold)’</strong> 위에 놓인다고 가정한다. 이미지나 텍스트와 같은 주변의 모든 데이터는 이 고차원 공간의 한 점들로 생각할 수 있다. 예를 들어, 28x28 크기의 손글씨 이미지들도 각 위치를 축으로 하는 784차원 공간의 점으로 생각할 수 있다. 하지만 이 거대한 고차원 공간의 대부분은 <code class="language-plaintext highlighter-rouge">손글씨 숫자와 전혀 무관</code>하며, <code class="language-plaintext highlighter-rouge">무작위로 공간의 점을 선택하면 의미 없는 노이즈</code>일 뿐이다.</li>
  <li><strong>차원 축소와 매니폴드의 중요성</strong>: AI 모델의 학습은 고차원의 데이터를 알기 쉽고 의미 있는 저차원의 공간으로 이동시키는 과정이다. 매니폴드는 단순히 데이터의 차원을 줄이는 것 이상의 의미를 가지는데, 바로 이 매니폴드의 기하 구조 자체가 데이터를 설명하는 중요한 정보를 담고 있기 때문이다. 비슷한 이미지나 개념을 가진 단어가 매니폴드 위에서 서로 가까워지는 것을 확인할 수 있다.</li>
  <li><strong>데이터 밀도와 오류 예측</strong>: 매니폴드 가설에 따르면 모델은 고차원 공간의 훈련 데이터를 매니폴드 위에 점으로 옮기는 학습을 한다. 훈련 데이터가 매니폴드 위에 얼마나 촘촘하게 분포하는지는 데이터의 양과 매니폴드의 차원에 따라 달라지며, 차원이 높을수록 같은 데이터 개수에도 포인트 간 거리가 멀어져 ‘듬성듬성’해진다.</li>
  <li><strong>해상도 제한 스케일링</strong>: 테스트할 점에서 생길 오류는 해당 점으로부터 가장 가까운 훈련 점의 거리보다 커질 수 없다. 모델이 훈련 데이터를 완벽하게 학습했다고 가정하면, 훈련된 데이터 지점에서만큼은 오차 없이 실제 데이터의 매니폴드를 정확하게 맞출 것이다. AI 모델은 훈련 포인트들을 선형적으로 보간하여 <code class="language-plaintext highlighter-rouge">보지 않은 지점도 예측한다고</code> 볼 수 있다. 매니폴드가 충분히 매끄럽다고 가정하면 오류는 가장 가까운 훈련 포인트와 테스트 포인트 간의 거리의 제곱에 비례하며, 최종적으로 오류는 데이터셋 크기(D)의 마이너스 (매니폴드 차원 d / 4) 제곱에 비례한다. 이것을 <strong>‘해상도 제한 스케일링’</strong>이라고 부르는데, 데이터가 많을수록 데이터 매니폴드를 더 선명하게 볼 수 있음을 뜻한다.</li>
  <li><strong>이론과 실제의 일치</strong>: 흥미로운 점은 데이터 차원뿐만 아니라 모델 크기로 수식을 만들어도 똑같이 거듭제곱에 4가 들어간다는 것이다. OpenAI는 2020년 논문에서 크로스 엔트로피 로스가 데이터셋 크기의 -0.095제곱에 비례한다고 발표했는데, 이론대로라면 이 값은 데이터 차원의 최소 네 배 이상이어야 한다. 자연어의 고유 차원은 약 42 정도로 계산되지만, 실제 언어 모델이 학습한 매니폴드의 고유 차원은 약 100 정도로 훨씬 높게 나왔다. 이는 이론적으로는 문제없는 범위에 놓이지만, 자연어에서는 합성 및 작은 데이터셋에서만큼 정확히 맞추지 못했다고 볼 수도 있다. 따라서 지금까지 설명한 이론은 잘 작동하지만, 아직 AI를 완벽히 통합할 만한 이론이라고 보기엔 이르다는 평가다.</li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>LLM의 배경지식을 위하여 AI 에 대한 좋은 영상들을 계속해서 보고, 학습하고 있다. 아직 실질적인 학습까진 아니긴하지만, 어쨌든 기존에 겉핧기로 이해하던 영역을 좀더 구체화하여 이해하고, 이 복잡하고 큰 AI 라는 영역에 대해 어떻게 투자하고, 어떻게 가이드를 잡는지에 대해 저렇게 수학적, 수치적으로 나타내는 것. 그리고 거기까지 앞서가는 이들이 있다는 생각을 하게 되니, 정말 세상이 미친듯이 빠르게 돌아가고 있구나를 새삼 느꼈다.</p>

<p>또한 동시에, 결국 수학적 방식을 통해 저러한 수치적 한계점이 나온다는 것이, 단순한 한계점이 아니라, 오히려 투자를 왜 그렇게 해야만 하는가를 나타내는 시각은 매우 신선한 영역이었다고 생각한다.</p>

<p>동시에, 왜 죽기살기로 거대한 규모를 만들어야 하고, 소버린 AI 라는 차원으로 뭔가 해보려고 하는 국내 업체들에 대한 요최근의 뉴스를 보면 시사하는 지점이 많다는 생각을 하게도 된다.</p>

<p>여담이지만 해당 유튭 내용은 정말 하나하나 엄청나게 주옥같은 내용이라, 엄청나게 도움이 된다고 느낀다…</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="LLM" /><category term="학습" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">난 글로벌 인재일까?</title><link href="http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/05/02-what-is-global-power-to-man.html" rel="alternate" type="text/html" title="난 글로벌 인재일까?" /><published>2025-08-05T00:00:00+00:00</published><updated>2025-08-05T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/05/02-what-is-global-power-to-man</id><content type="html" xml:base="http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/05/02-what-is-global-power-to-man.html"><![CDATA[<h2 id="요약">요약</h2>
<p>본 내용은 황성현 교수님의 경험, 생각을 ‘지식 인사이드’ 라는 유튜브 채널에 나와서 공유한 내용에 대해 요약한 것이다.</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=bn9nhe7w9xc">영상 보러가기 - 직급을 없앤다며 영어 이름 쓰는 회사들의 공통점 지식인초대석 EP.49 (황성현 교수 1부)</a></li>
  <li><a href="https://www.youtube.com/watch?v=-TYSiaWpIB4">영상 보러가기 - 전 구글 인사담당자가 면접에서 반드시 물어보는 질문 지식인초대석 EP.50 (황성현 교수 2부)</a></li>
</ul>

<h3 id="1-구글의-채용-기준-및-인재상">1. 구글의 채용 기준 및 인재상</h3>
<ul>
  <li>구글은 채용 시 <strong>네 가지 명확한 기준</strong>을 가지고 있다.
    <ul>
      <li><strong>GCA (General Cognitive Ability)</strong>: 문제 해결 역량으로, 방대한 정보 속에서 문제의 핵심을 찾아내고 해결하는 능력이다. 과거에는 좋은 학교 출신이 이를 잘할 것이라는 가설이 있었으나, 5년 후에는 그렇지 않다는 것을 깨달았다.</li>
      <li><strong>RRK (Role-Related Knowledge and Experience)</strong>: 업무 관련 지식과 경험, 즉 해당 분야의 전문가인지를 본다.</li>
      <li><strong>리더십</strong>: 일반적인 회사에서 임원급에게 요구하는 리더십과 달리, 모든 직원이 사원이라도 자신이 하는 일을 주도적으로 문제 해결해야 한다는 의미이다.</li>
      <li><strong>Cultural Fit (구글리니스 Googliness)</strong>: 회사의 문화와 잘 맞는지를 의미한다. 구글리니스는 수트를 입지 않고도 진지할 수 있으며, 문제가 생기면 팔 걷어붙이고 인류를 위해 헌신할 수 있는 기운을 가진 사람을 뜻한다. 구글은 문화적으로 맞지 않으면 절대 채용하지 않으며, 심지어 18년 동안 적합한 인재를 찾지 못해 채용하지 않은 경우도 있다. 구글의 모든 직원은 ‘구글리니스’의 의미를 이해하고 있으며, 이는 입사뿐만 아니라 진급이나 평가의 잣대가 된다.</li>
    </ul>
  </li>
</ul>

<h3 id="2-구직-전략-및-경력-관리">2. 구직 전략 및 경력 관리</h3>
<ul>
  <li><strong>링크드인(LinkedIn) 활용의 중요성</strong>: 구글과 같은 글로벌 기업에 취업하려면 링크드인을 적극적으로 활용해야 한다. 채용 담당자들은 링크드인에서 지원자의 경력, 네트워크, 성과를 모두 확인하며, 최근 학습한 내용까지 기록하여 지속적으로 발전하는 모습을 보여주는 것이 중요하다.</li>
  <li><strong>패시브 캔디데이트 선호</strong>: 구글은 적극적으로 직장을 구하는 ‘액티브 캔디데이트’보다 숨어있는 ‘패시브 캔디데이트’를 선호한다. 이력서를 보낸다고 해서 구글에 채용될 확률은 0.0 몇 %에 불과하다. 준비가 완전히 되어 있다면 회사 내부 알고리즘에 의해 발견될 수 있으므로, 지원서를 보내기보다는 구글의 눈에 띄도록 스스로를 준비하는 것이 더 효과적이다. 구글 코리아도 본사와 동일한 채용 기준을 적용한다.</li>
  <li><strong>신입 및 저연차 전략</strong>: 신입사원이나 저연차는 자신을 드러낼 경력이 적어 불리할 수 있다. 한국의 이력서는 미국 대학 입학 시 요구되는 활동들이 부족하여 글로벌 시각에서 무엇을 할 수 있는지 검증이 어렵다. 따라서, 전략적으로 국내 유수 IT 기업(네카라쿠배당토: 네이버, 카카오, 라인, 쿠팡, 배달의민족, 당근, 토스)에 먼저 들어가 경력을 쌓은 후 구글로 이직하는 것도 좋은 방법이다. 인턴십을 통해 인정을 받아 신입사원으로 전환되는 경우도 있다.</li>
  <li><strong>3년 후 이력서 작성</strong>: 3년 후의 자신의 이력서를 미리 작성하고, 현재 자신의 역량과 목표하는 역량 사이의 갭(Gap)을 파악하여 이를 채워나가는 노력을 해야 한다. 막연하게 ‘가고 싶다’는 생각보다는 ‘나는 3년 후에 그곳에 가 있다’는 최면을 걸어야 한다. 이는 구글뿐만 아니라 모든 인생에 적용되는 원리이다.</li>
</ul>

<h3 id="3-기업-문화-및-인재상-차이">3. 기업 문화 및 인재상 차이</h3>
<ul>
  <li><strong>구글과 애플의 철학 차이</strong>: 구글은 개방형 철학을 가진 반면, 애플은 폐쇄형 철학을 가진 회사이다. 이러한 철학적 차이는 인재 채용에도 영향을 미친다.
    <ul>
      <li><strong>구글 인재상</strong>: 미지의 세상에 기여하고, 없던 것을 만들어내며, 본인의 창의성을 극단적으로 끌어내고 싶은 사람에게 더 적합하다. 모든 조직이 방사형으로 연결되어 있어 정보 공유가 활발하며, 모든 사람이 서로에게 피드백을 주는 문화가 있다.</li>
      <li><strong>애플 인재상</strong>: 탁월성을 끝까지 추구하고 디테일을 중요시하며, 남들에게 보여주지 않더라도 혼자서 뭔가를 만들어 내기를 잘하는 사람에게 더 맞을 수 있다. 애플은 중앙 집권적인 조직 구조를 가지며, 정보가 상위 관리자를 통해서만 전달되는 경향이 있다.</li>
    </ul>
  </li>
  <li><strong>협업 능력의 중요성</strong>: 아무리 인지적 능력과 업무 전문성이 뛰어나도 구글 문화와 맞지 않는다면(예: 협업 불가) 오래 다니기 어렵다. 구글은 천재이면서도 겸손하고 타인과 협업이 잘 되는 인재를 선호한다.</li>
  <li><strong>IT 기업의 공통 인재상</strong>: IT 기업들은 ‘무엇을 공부했는가’보다는 <strong>일하는 태도</strong>를 중요하게 본다. 역량은 지식(Knowledge), 기술(Skill), 태도(Attitude)의 세 가지 요소(KSA)로 구성되는데, 특히 일을 대하는 태도가 중요하다. 문제를 적극적으로 해결하려는 사람들이 선호된다. 일반적인 수능 공부만 한 고등학생처럼 과거에 머물러 있지 않고 봉사활동, 코딩, 소규모 창업 등 다양한 경험을 통해 능동성을 보여주어야 한다.</li>
</ul>

<h3 id="4-면접-및-이직-관련-조언">4. 면접 및 이직 관련 조언</h3>
<ul>
  <li><strong>연봉 협상</strong>: 글로벌 기업들은 경쟁자보다 적게 주지 않는다는 원칙이 있다. 이전 직장에서 적게 받았더라도 적게 주지 않으며, 연봉 질문 시에는 현재 받는 연봉의 10~20% 내외를 더 요구하는 것이 일반적이다.</li>
  <li><strong>경력 부풀리기의 위험성</strong>: 면접에서 경력을 부풀리는 것은 가장 좋지 않다. 면접관이 특정 프로젝트에서의 역할과 해결한 문제를 5번 정도 깊게 질문하면 대부분 탄로 난다. 자신이 관리만 했던 외주 프로젝트를 자신이 직접 한 것처럼 부풀리는 경우가 많지만, 이는 3번 정도 질문하면 드러난다. 하나라도 거짓이 드러나면 합격하기 어렵다.</li>
  <li><strong>면접관의 태도 변화 감지</strong>: 면접관이 지원자를 공격하듯 질문하다가 어느 순간 회사 자랑을 하기 시작하면 이는 지원자를 놓치지 않으려는 긍정적인 신호이다. 이때부터 지원자는 줄다리기를 시작해야 한다. 반대로 끝까지 회사 자랑을 하지 않고 공격적인 태도를 유지한다면 긍정적인 신호는 아니다.</li>
  <li><strong>회사 선택 전 철저한 조사</strong>: 지원하기 전에 해당 회사의 문화나 내부 진실을 알려주는 사이트들을 통해 충분히 숙지하고 공부한 후 지원해야 한다. 지원서를 무작위로 복사-붙여넣기 하는 것보다는, 회사에 대한 이해를 바탕으로 진정성 있게 작성하는 것이 중요하다.</li>
  <li><strong>이직 판단 기준</strong>: 황성현 교수는 이직을 고려하는 개인적인 세 가지 기준을 제시한다.
    <ul>
      <li><strong>자신의 성장 여부</strong>: 성장이 멈추면 연봉이 아무리 높아도 의미가 없다.</li>
      <li><strong>회사의 성장 가능성</strong>: 회사가 성장하지 못하면 개인의 성장도 한계에 부딪힌다.</li>
      <li><strong>회사에 대한 기여도</strong>: 자신이 회사에 기여하고 있는지 여부도 중요하다.
셋 중 하나라도 빨간불이 들어오면 이직을 고려해야 한다.</li>
    </ul>
  </li>
  <li><strong>평생 직업 시대</strong>: 과거의 평생 직장 개념은 사라지고 있으며, 이제는 ‘평생 직업’ 또는 그마저도 없어질 수 있는 시대이다. 50대 이상은 기존의 기득권과 직장 내 타이틀, 과거의 지식을 내려놓고 새로운 것을 받아들일 준비를 해야 한다.</li>
</ul>

<h3 id="5-조직-문화-혁신과-글로벌-리더십">5. 조직 문화 혁신과 글로벌 리더십</h3>
<ul>
  <li><strong>한국과 서구 기업 문화의 차이</strong>: 한국 조직은 보통 인사팀이 인사를 관리하는 책임을 지지만, 서구권에서는 조직의 헤드(현업 매니저)가 채용부터 퇴직까지 모든 인사를 책임진다.
    <ul>
      <li>한국의 인사팀은 채용을 한직으로 여기고 전략 없이 진행하여, 채용 이후의 온보딩 및 관리 단계에서 어려움을 겪는 경우가 많다. 이는 회사의 성장을 저해하는 요소가 된다.</li>
      <li>구글 같은 회사는 채용에 90%의 노력을 투자하여 각 분야의 천재들을 데려오기 때문에, 채용 이후의 관리가 훨씬 쉬워진다.</li>
    </ul>
  </li>
  <li><strong>한국인의 글로벌 기업 임원 승진 난관 (‘뱀부 실링’ Bamboo Ceiling)</strong>: 한국인들이 글로벌 기업에 취업하는 확률은 높아졌지만, 임원까지 올라가는 비율은 1% 미만으로 매우 낮다. 이는 하드웨어/반도체 분야와 달리 IT/딥테크 섹터에서 두드러진다.
    <ul>
      <li><strong>‘뱀부 실링’의 세 가지 원인</strong>: 구글 본사의 연구 결과, 동북아시아 사람들이 고위직으로 승진하기 어려운 세 가지 이유가 밝혀졌다.
        <ol>
          <li><strong>권위에 대한 복종 (Deference to Authority)</strong>: ‘나는 자랑스러운 아들이 되고 싶었다’와 같이 자신의 주체적인 욕구보다는 타인의 인정을 중시한다. 이로 인해 윗사람의 지시에 익숙해져 새로운 것을 만들어내는 힘이 부족하다.</li>
          <li><strong>관계 형성의 어려움 (Relationship Building)</strong>: 아시아인들은 서구인들에게 ‘능력은 뛰어나지만 차갑다’고 인식된다. 우리는 동료들 간에 ‘정’을 중시하지만, 서구권에서는 감정이나 친밀감을 명시적으로 표현해야 관계가 형성된다고 생각한다. 업무 외적인 대화(스포츠, 연예인 등)에 잘 끼지 못하고 진정한 친구가 되기 어려워, 서구인들에게는 아시아인이 ‘위협적’으로 보일 수 있다.</li>
          <li><strong>취약성 노출의 어려움 (Vulnerability)</strong>: 자신의 약점을 드러내는 것을 두려워하고 숨기려 한다. 이는 ‘큰일 난다’는 트라우마와 체면 문화와 직결되며, 자신을 감추기 위해 ‘센 척, 아는 척’을 하며 갑옷을 입는 것과 같다. 이러한 태도는 진정한 관계 형성을 방해한다.</li>
        </ol>
      </li>
    </ul>
  </li>
  <li><strong>직급 체계와 수평 문화</strong>: 직급을 없애는 시도는 좋지만, ‘직위가 없으면 수평적이 될 것’이라는 착각은 문제이다. 구글은 13단계의 세분화된 직급 체계를 가지고 있음에도 불구하고 수평적인 소통이 가능하다. 수평 조직의 목적은 사람들의 머리를 열어 아이디어가 샘솟게 하는 것이며, 직급이 없다고 해서 사수 문화가 사라지고 경쟁 관계만 남는 것은 바람직하지 않다.</li>
  <li><strong>회의 문화의 혁신</strong>: 혁신적인 기업들은 회의를 최고위급 리더가 직접 주도하며, 어젠다를 설정하고 진행한다. 이는 리더십을 보여주고 시간을 효율적으로 활용하는 기회이다. 반면, 전통적인 회사들은 회의가 단순히 지시 사항 전달의 장이 되는 경우가 많다.
    <ul>
      <li><strong>구글 슬라이드의 의도적 불편함</strong>: 구글은 MS 오피스에서 벗어나기 위한 ‘아웃 오브 오피스(Out of Office)’ 프로젝트를 통해 구글 슬라이드 사용을 강제했다. 구글 슬라이드는 의도적으로 현란한 기교를 부리지 못하게 만들어, 보고의 핵심은 아이디어에 집중하도록 유도한다.</li>
      <li><strong>아마존의 ‘6-페이저’</strong>: 아마존은 ‘6-페이저(6-pager)’라는 보고서 방식을 사용한다. 이는 6장 이내의 워드 문서로, 도표나 다이어그램 없이 처음부터 글로 쓰는 보고서이다. 회의 전에 미리 공유하여 참가자들이 내용을 숙지하고 오며, 회의 시간에는 5분간 다시 읽고 질문만 하는 방식으로 진행되어 매우 효율적이다.</li>
    </ul>
  </li>
  <li><strong>무능한 자의 승진</strong>: 과거 선형적 성장 시대에는 범용 인재를 찾았고, 능력이 있든 없든 큰 차이가 없다고 여겨져 일 시키기 편한 사람을 승진시키는 경향이 있었다. 그러나 현재는 세상이 급변하여 능력이 없는 사람을 승진시키면 회사가 큰일 나기 때문에 이러한 현상이 줄어들고 있다.</li>
</ul>

<h3 id="6-경영자-및-개인의-삶에-대한-통찰">6. 경영자 및 개인의 삶에 대한 통찰</h3>
<ul>
  <li><strong>경영자의 역할 변화</strong>: 현재 경영자들은 과거의 성공 경험에 대한 확신 편향을 내려놓고, 세상 변화에 맞춰 일하는 방식을 배워야 한다. 넷플릭스나 애플, 구글 등 다른 회사의 방식을 무조건적으로 복사하기보다는, ‘우리는 어떤 일을 하려 하고, 어떤 철학을 가지며, 우리 사람들이 가장 신나게 일할 수 있는 환경은 무엇인가’에 대한 깊은 고민이 필요하다.</li>
  <li><strong>워라밸과 시간 관리</strong>: 황성현 교수 개인은 40대에 미국에서 자신의 삶을 돌아보고 정비하는 방법을 배웠다. 건강, 취미, 가족과의 시간을 달력에 미리 ‘Do not Schedule (DNS)’ 구역으로 설정하여 확보하는 것이 중요하다. 조급해하지 않고 긴 시각으로 미래를 준비하는 자세가 필요하다. 궁극적으로 AI는 반복적인 업무를 자동화하여 인간이 더욱 중요하고 전략적인 의사 결정에 집중할 수 있도록 시간을 아껴주는 도구가 될 것이라고 본다.</li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>나는 뭘 원하는가? 
나는 내가 일하는 일이 신이 났으면 한다. 
나는 내가 하는 일의 전문성을 갖길 원한다.</p>

<p>그리고 나는 내가 하는 일을 통해 세상에 뭔가 변화의 가치에 한 숟가락이라도 더 얹을 수 있는 사람이 되고 싶다고 생각한다.</p>

<p>솔직히 아직 부족하고, 나이도 좀 먹었고, 어쩌면 완전히 요즘 시대에 대세, 성공자, 천재까진 아닐 거라고 생각은 든다. 
하지만 생각보다 난 잘하고 있고, 가능성이 있으며, 무엇보다 스스로의 성장에 확신과 결과를 만들어왔다.</p>

<p>문제는 세상을 이해하는 것이리라 본다.</p>

<p>마라톤을 최적으로 돌아낼 힘, 최적으로 신뢰받을 힘, 스스로를 지속적으로 성장시키는데, 설령 90살이 되더라도 멈추지 않을 수 있는 내 안의 에너지를 계속 만들어내고 싶다 생각한다.</p>

<p>왜그럴까?</p>

<p>언제부터 그런 생각을 더 깊이 하게 된건지는 사실 슬 가물가물 하긴 하다 ㅋㅋ.. 🤣</p>

<p>하지만 명확한건, 내 개인의 문제부터 사회, 조직, 나라에 이르기까지 좀더 좋은, 좀더 괜찮은, 좀더 편리한 세상은 오지 않을까?</p>

<p>그때 신나게, 행복하게 살고 싶은게 내 꿈이다.</p>

<p>일단 더욱 전문가 스러워지자. 😎</p>]]></content><author><name>Paul2021-R</name></author><category term="생각정리" /><category term="이직" /><category term="생각정리" /><category term="etc" /><summary type="html"><![CDATA[요약 본 내용은 황성현 교수님의 경험, 생각을 ‘지식 인사이드’ 라는 유튜브 채널에 나와서 공유한 내용에 대해 요약한 것이다.]]></summary></entry><entry><title type="html">AI Breakfast Ep 10 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/08/04/00-AI-trend-with-google-10.html" rel="alternate" type="text/html" title="AI Breakfast Ep 10 생각정리" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/04/00-AI-trend-with-google-10</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/04/00-AI-trend-with-google-10.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=AuviDcSne9g"><img src="https://i.ytimg.com/vi/AuviDcSne9g/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>

<p>9화는 AI 와 관련된 특정 주제에 대한 내용이었기에 생략하고 10화 내용을 기반으로 요약해본다.</p>

<ul>
  <li><strong>AI 발전과 바이브 코딩의 등장</strong>: AI 기술은 하루가 다르게 빠르게 발전하며, 이 가운데 ‘바이브 코딩(vibe coding)’이 가장 뜨거운 아이템으로 주목받고 있다.</li>
  <li><strong>바이브 코딩의 의미와 확산</strong>: 바이브 코딩은 AI가 내놓은 답을 <strong>즉흥적으로 수용하여 원하는 결과물을 만들어내는 방식</strong>이다. 한국에서는 ‘입코딩’이나 ‘손코딩’이라고도 부른다. 2023년 초 인도 개발자가 AI로 가벼운 비행기 게임을 만들어 월 5만 달러 수익을 올린 사례가 바이럴되며 시작되었고, Andrej Karpathy가 X(트위터)에서 이 용어를 사용하며 확산되었다. 이 단어는 2025년 3월 Merriam-Webster 사전에 ‘유행하는 속어’로 등재될 예정이기도 하다. 박찬성 연구원의 바이브 코딩 관련 게시물이 데미스 허사비스(DeepMind CEO)와 제프 딘(Google AI Research 수장)의 리트윗과 좋아요를 받으며 <strong>AI 거장들의 인정</strong>을 받았다.</li>
  <li><strong>아이디어의 중요성 증대</strong>: 생성형 AI의 발전으로 초기 PoC(개념 증명) 수준의 아이디어 구현 비용이 크게 낮아졌다. 이는 <strong>특정 도메인 전문가의 전문 지식을 바탕으로 한 아이디어 자체의 중요성과 가치</strong>를 더욱 높이는 결과를 가져왔다. 박찬성 연구원이 자신의 네트워크 전문 지식을 녹여낸 바이브 코딩 결과물이 바이럴된 것이 좋은 예시이다.</li>
  <li><strong>바이브 코딩에 필요한 역량</strong>:
    <ul>
      <li><strong>반복(Iteration)</strong>: 프롬프트 엔지니어링에서 반복은 매우 중요한 요소이다. 확률에 의거하여 나오는 결과 도출이라는 기반을 가지기 때문에, 요구 사항에 대해 여러번의 반복은 그만큼 높은 확률로 좋은 결과물을 만들어낼 가능성이 생긴다.</li>
      <li><strong>시행착오와 집요함</strong>: 원하는 결과물이 나올 때까지 AI에 끊임없이 시도하고 개선하는 ‘시행착오(trial and error)’와 집요함이 중요하다.</li>
      <li><strong>전문 지식</strong>: 기존 개발 지식이나 특정 분야의 전문적인 키워드를 아는 것이 AI에게 정확한 요구사항을 전달하고 생산성을 높이는 데 매우 유용하다.</li>
      <li><strong>호기심과 흥미</strong>: AI 코딩에 대한 호기심과 즐거움을 느끼는 것이 시작의 중요한 단계이며, 자신이 무엇을 좋아하고 잘하는지를 알아가는 과정이 필요하다.</li>
    </ul>
  </li>
  <li><strong>개인 맞춤형 도구 개발 시대</strong>: 이제는 개인이 자신에게 최적화된 도구를 직접 개발하여 사용하는 시대가 도래하고 있다. 강수진 박사는 시중에 있는 도구들이 자신의 작업 환경에 맞지 않아 <strong>프롬프트 엔지니어링 실험을 위한 플레이그라운드를 직접 만들어 사용</strong>하고 있다고 언급했다.</li>
  <li><strong>프롬프트와 프로그래밍 역량의 미래</strong>:
    <ul>
      <li>자연어 엔지니어 관점에서는 ‘의미론적 응축(Sementic Condensation)’이나 ‘단어 대체(Word Substitution)’를 통해 핵심 의미를 압축하고 제어하는 기술이 활용될 수 있다.</li>
      <li>현재 AI는 개발자들이 사용하던 용어, 일반인들이 기존에 사용하던 언어 기반인 만큼, 바이브 코딩을 수행함에 있어 개발적 지식이 필요하거나, 단어가 필요시 될 수 있다. 하지만 이것 조차도 학습을 통해 개선될 수 있다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>바이브 코딩. 이제는 너무 익숙해진 단어이다. 하지만 동시에 여전히 중요하고, 이제는 개발의 중심에 침입하였고, MCP, A2A 를 만나면서 그저 간단하게 질문에 답을 한다 에서 실제 수행을 한다 라는 차원의 영역으로 발전하고 있다.</p>

<p>오늘의 내용은 어쩌면 보편적인 바이브코딩이라는 행위를 평가하는 간단한 내용이기는 했다.</p>

<p>그러나 동시에 전문가들의 이야기에서 그럼에도 인사이트로 얻을 수 있는 영역은 있었다.</p>

<p>예를 들어 한 개발자 분이 네트워크에 대한 시뮬레이터를 만들었다던지 하는 것들은, 상당히 인상 깊었고, 프롬프트 엔지니어링 전문가로 나온 패널은 자신이 직접 만든 프롬프터 테스터를 보여주었다.</p>

<p>그리고 한 마디 더 걸치니, ‘개발 지식이 있는 사람과 일반인의 개발의 차이’를 언급한 부분이다.</p>

<p>바이브코딩을 할 때 개발 지식은 보다 정확한 지시가 가능하다. 하지만 개발 지식의 부재는 어쩔 수 없이 동작 방식을 묘사해야하고, 그 묘사는 결국 확률적으로 어떤 구현 대상에 대해 100% 지목하는게 아니라 ‘가능성’으로 표현할 뿐인거고, 거기서 잘못된 지식이 있다면 이는 비효율적 개발이 이루어질 수 있다.</p>

<p>하지만 기술을 이해하고, 단어를 정확하게 아는 경우, 그 지식은 좀더 명확한 전달, 명확한 결과를 만들 수 있다.</p>

<p>AI 에 대해 명령을 내릴 때 언어적 방법에 대해 체계화가 잘 된 경우 명령을 잘 내리지만, 동시에 빼놓지 말고 기억해야 하는 부분이 있다면 역시나 도메인.</p>

<p>물론 개발자도 언급하길 바이브 코딩을 하는 과정을 통해 또 다시 AI 가 학습할 것들이 생성되고, AI 가 그걸 이해하고 다시 학습된 데이터를 기반이 된다면 더 찰떡같이 알아먹게 되겠지만</p>

<p>현재 가장 필요한 영역이자, 바이브 코딩을 제대로 내 무기화 하려면 필요한 것은 결국 ‘내 분야’ 혹은 ‘전문 지식’의 체계적인 내재화라는 생각은 이번 편을 통해 보다 선명하게 기억하게 되었다.</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">트랜스포머, AI 를 이해해보자</title><link href="http://0.0.0.0:4000/ai/2025/08/04/01-transformer-gpt-deepSeek-introduction.html" rel="alternate" type="text/html" title="트랜스포머, AI 를 이해해보자" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/04/01-transformer-gpt-deepSeek-introduction</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/04/01-transformer-gpt-deepSeek-introduction.html"><![CDATA[<h2 id="개요">개요</h2>
<p>현재 인공지능(AI) 기술 발전의 핵심에는 <strong>트랜스포머(Transformer)</strong> 아키텍처가 있으며, 2017년 구글의 ‘Attention Is All You Need’ 논문을 통해 소개된 이후 오늘날 가장 널리 사용되는 AI 모델 구조가 되었다. <strong>챗GPT(ChatGPT)</strong>의 ‘GPT’는 ‘Generative Pre-trained Transformer’의 약자로, 방대한 데이터를 통해 사전 학습된 트랜스포머 모델임을 의미한다. 트랜스포머 모델은 텍스트 번역을 넘어 이미지 생성, 음성 변환 등 다양한 AI 분야에 활용되며, 다음 단어나 내용을 예측하는 방식으로 작동한다. 몇 개의 단어를 입력하면 모델이 다음 단어를 예측하고, 그 예측된 단어를 다시 입력으로 사용하여 반복적으로 긴 문장을 생성할 수 있다.</p>

<p>AI 기술의 발전 속도는 전례가 없는데, AI 사용자 및 사용량 증가는 인터넷보다 훨씬 빠르게 나타나고 있으며, 관련 자본 지출(CapEx) 또한 급증하고 있다. ChatGPT는 불과 5일 만에 100만 사용자를 확보하며 역사상 가장 빠른 사용자 채택을 기록했다.</p>

<p>오늘은 이러한 내용들을 정리해보면서, GPT에서 시작해 DeepSeek 까지의 발전 과정을 조금(?) 훑어 보려고 한다. 문돌이 입장에서 AI 의 힘을 여실히 빌려서 만든 내용이긴 하지만 AI 를 좀더 깊게 이해하고 싶은 모든이들에게 도움이 되길 기원한다.</p>

<h3 id="llmlarge-language-model의-개요">LLM(Large Language Model)의 개요</h3>

<p><img src="/assets/images/posts/2025-08/2025-08-04-001.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/ko/llms/">Microsoft AI Tour</a></p>
</blockquote>

<p><strong>대규모 언어 모델(Large Language Model, LLM)</strong>은 주어진 텍스트가 있을 때 다음에 올 단어를 예측하는 매우 정교한 수학적 함수이다. 더 정확하게는, 딱 하나의 단어를 확정적으로 예측하는 대신 다음에 올 단어들에 대한 확률을 계속해서 구하는 함수이다.</p>

<ul>
  <li><strong>작동 방식</strong>: LLM은 몇 개의 단어를 입력으로 받아 다음 단어를 예측하고, 그 예측된 단어를 다시 입력으로 사용하여 반복적으로 긴 문장을 생성한다. 이는 챗GPT와 같은 모델과의 대화가 한 단어씩 생성되는 방식으로 이루어지는 이유이다.</li>
  <li><strong>학습 데이터</strong>: LLM은 인터넷에서 수집한 엄청난 양의 텍스트 데이터로 학습된다. 예를 들어, GPT-3가 학습한 텍스트 양은 사람이 24시간 쉬지 않고 읽었을 때 2,600년 이상이 걸릴 것이며, 요즘 모델들은 훨씬 더 많은 데이터로 훈련된다.</li>
  <li><strong>파라미터(매개변수) 및 훈련</strong>: 모델 속의 수많은 다이얼(파라미터 또는 가중치)을 조정해가며 학습이 이루어진다. LLM은 수백억 개에서 수천억 개까지 이르는 파라미터를 가지고 있으며, 처음엔 랜덤하게 설정된 이 값들이 훈련을 반복하며 점차 그럴듯한 예측을 할 수 있도록 조정된다.
    <ul>
      <li><strong>역전파(Backpropagation)</strong>: 훈련 시 마지막 단어를 제외한 나머지를 모델 입력으로 넣고, 모델이 마지막 단어를 어떻게 예측하는지 확인한 후, 그 예측이 정답에 가까워지도록 파라미터를 조정하는 알고리즘이다.</li>
      <li><strong>강화 학습(RLHF)</strong>: 사전 훈련된 모델은 사람이 모델의 잘못된 응답을 직접 수정하거나 더 나은 응답을 골라주는 RLHF(Reinforcement Learning from Human Feedback)와 같은 강화 학습을 통해 추가 학습된다.</li>
    </ul>
  </li>
</ul>

<h3 id="llm의-속성을-이해하자">LLM의 속성을 이해하자</h3>

<h4 id="llm-vs-nlp">LLM vs NLP</h4>
<p>기존 자연어 처리의 기술과 LLM 이 다른 점은 다음과 같이 설명할 수 있다.</p>

<ul>
  <li>기존 NLP 는 기능 당 하나의 모델이 필요하다.</li>
  <li>기존 NLP 는 한정된 레이블 데이터 셋에서 학습을 시킨다. (예시, 특정 물체 인식 AI 를 위해 특정 물체의 사진을 수십만장 준비한다.)</li>
  <li>기존 NLP 는 특정 사용 사례에 고도로 최적화 된다.(예시, 특정 물체의 데이터셋으로 학습된 특화 모델)</li>
</ul>

<p>그러나 LLM은</p>

<ul>
  <li>여러 NLP 사용 사례에 단일 모델 사용이 가능하다(범용적이다).</li>
  <li>수 TB 에 달하는 레이블이 없는 데이터에서 학습된 모델이다(기초).</li>
  <li>개방형 사용 - 자연어를 사용하여 모델에 무언가를 ‘프롬프트’ 하도록 한다. 즉 자연스럽게 다양한 질문을 할 수 있고, 모델이 이에 맞춰 콘텐츠를 생성해 낸다.</li>
</ul>

<h4 id="llm-이-하지-못하는-것은">LLM 이 하지 못하는 것은?</h4>
<p>대규모 언어 모델은 강력한 생성형 AI 경험을 제공하고, 이 콘텐츠의 범용성은 지금의 AI 상황의 판도 자체를 뒤집어 엎는 일을 만들어 냈지만, 그 표현, 행위가 다음은 아니라는 사실을 명확히 해야 한다.</p>

<ol>
  <li><strong>언어를 이해한게 아니다</strong> : LLM은 예측 엔진, 예측 함수셋에 가깝기에 이것이 해당 콘텐츠의 문맥이나 의미를 이해한 거라고 말할 수 없다.</li>
  <li><strong>사실을 이해하지 못한다</strong> : <code class="language-plaintext highlighter-rouge">정보 검색</code>, <code class="language-plaintext highlighter-rouge">창의적 글쓰기</code>를 위한 별도의 모드가 있는 건 아니고, 진행중인 시퀀스에서 다음으로 가능성이 높은 토큰을 예측하는 것이기에, 그것이 ‘사실’이냐 ‘주장’이냐와 같은 해석은 LLM 자체에서는 무의미하다.</li>
  <li><strong>매너, 감정, 또는 윤리를 이해하지 못한다</strong> : 인간이 설계하고 설정한 데이터, 프롬프트에 의해 최적의 예측값을 ‘보정한’ 결과이지, 모델이 매너나 감정, 윤리를 이해하고 동작하는 것이 아니다. 결과적으로 LLM 은 통계적 패턴의 예측의 연속이며, 인간처럼 문장의 의미, 맥락을 이해하는 것이 아니다.</li>
</ol>

<h3 id="트랜스포머의-핵심-개념">트랜스포머의 핵심 개념</h3>

<p>트랜스포머는 텍스트를 처음부터 끝까지 순차적으로 읽는 대신, <strong>전체 문장을 한꺼번에 병렬로 처리한다</strong>. 이 과정에서 문장 내 각 단어는 AI가 이해할 수 있는 숫자 벡터로 변환되어 서로의 관계성을 알 수 있게 된다.</p>

<ul>
  <li><strong>토큰(Token)</strong>:
    <ul>
      <li>트랜스포머는 입력된 문장이나 데이터를 <strong>토큰</strong>이라는 작은 조각으로 나누어 처리한다.</li>
      <li>텍스트의 경우, 단어나 단어의 일부, 또는 일반적인 문자 조합이 토큰이 될 수 있다.</li>
      <li>이미지나 음성이 포함될 때는 그 이미지의 작은 조각이나 음성의 작은 부분이 토큰이 될 수 있다.</li>
    </ul>
  </li>
  <li><strong>벡터(Vector) 및 단어 임베딩(Word Embedding)</strong>:
    <ul>
      <li>각 토큰은 해당 부분의 의미를 담도록 설계된 숫자 목록인 <strong>벡터</strong>와 연결된다. 이 벡터들은 고차원 공간의 좌표로 생각할 수 있으며, 의미가 비슷한 단어들은 그 공간에서 가까운 벡터로 배치되는 경향이 있다.</li>
      <li>예를 들어, GPT-2에서는 768차원, DeepSeek R1에서는 7,168차원의 벡터가 단어 하나를 표현하는 데 사용된다.</li>
      <li>훈련 과정에서, 모델은 학습을 통해 공간 속의 방향들이 어느 정도 의미를 가지도록 벡터를 정리한다. 예를 들어, ‘여자’와 ‘남자’ 사이의 벡터 차이가 ‘왕’과 ‘여왕’ 사이의 차이와 유사하게 나타날 수 있다. 이러한 차이 벡터 사이의 차이는 단어들 사이의 관련성이나, 어떤 특성을 나타낼 수 있다. 성의 차이, 복수와 단수의 차이 등 이러한 특성을 수학적 - 수치적으로 이해한 것이다.</li>
    </ul>

    <p><img src="/assets/images/posts/2025-08/2025-08-04-002.png" alt="" /></p>
    <blockquote>
      <p>단어 사이의 관계성이 벡터 사이의 간격으로 이해가 될 수 있다. 출처 : <a href="https://youtu.be/g38aoGttLhI?si=9zdFBTN0cv1ncJ-r">3Blue1Brown 한국어</a></p>
    </blockquote>
  </li>
  <li><strong>어텐션(Attention)</strong>:
    <ul>
      <li>트랜스포머의 핵심 연산으로, 입력된 벡터들이 ‘어텐션 블록’을 통과하며 서로 정보를 주고받고 값을 업데이트하는 과정이다. 이는 문맥을 파악하기 위해 단어들 간의 유사성을 계산하는 방식이다.</li>
      <li><strong>쿼리(Query), 키(Key), 밸류(Value)</strong>: 어텐션은 <strong>‘쿼리(Query)’, ‘키(Key)’, ‘밸류(Value)’</strong>라는 세 가지 개념을 통해 구현된다. 입력된 단어들(벡터 X)은 각각 고유한 학습 가능한 가중치 행렬(WQ, WK, WV)과 곱해져 쿼리 행렬, 키 행렬, 밸류 행렬로 변환된다. 단 이 개념이 별개의 정보라기 보단 결국 벡터 X 에서 나온다는 점은 명확하게 인지해야 한다.
        <ul>
          <li><strong>쿼리(Query)</strong>는 하나의 ‘질문’ 역할을 한다.</li>
          <li><strong>키(Key)</strong>는 그 질문을 해결할 가능성이 있는 ‘열쇠’ 중 하나이다.</li>
          <li><strong>밸류(Value)</strong>는 어텐션 패턴에 따라 이동되거나 결합될 실제 정보의 ‘재료’이다.</li>
        </ul>
      </li>
      <li><strong>내적(Dot Product)</strong>: 쿼리가 키들과의 <strong>유사도</strong>를 계산하는 과정은 수학적으로 두 벡터의 <strong>내적</strong>으로 구현된다. 내적은 기하학적으로 벡터들이 비슷한 방향일 때 양수, 직교할 때 0, 반대 방향일 때 음수가 된다.</li>
      <li><strong>어텐션 패턴(Attention Pattern)</strong>: 모든 쿼리와 키의 유사도를 계산하여 얻는 종합된 정보이다. 이 어텐션 패턴의 크기는 <strong>입력 단어 수의 제곱에 비례하여 늘어난다</strong>. 훈련 과정에서는 다음에 올 단어를 ‘컨닝’하지 못하도록 어텐션 패턴의 오른쪽 윗부분이 가려진다.</li>
      <li><strong>소프트맥스(Softmax)</strong>: 유사도 계산 후, 각 행의 합이 0이 되도록 <code class="language-plaintext highlighter-rouge">정규화</code>하는 함수이다. 이 함수는 어떠한 숫자들의 나열이든 0과 1 사이의 값으로 변환하여 합이 1이 되는 <code class="language-plaintext highlighter-rouge">확률 분포</code>로 만들어준다. 가장 큰 값은 1에 가깝고 작은 값은 0에 가까워진다. 또한 <code class="language-plaintext highlighter-rouge">온도(Temperature)</code>라는 상수를 사용해 예측의 다양성을 조절할 수 있다. (이 온도는 열역학의 개념과 유사한 동작이기에, 그대로 차용했다.)</li>
      <li><strong>어텐션 헤드(Attention Head)</strong>: 어텐션 패턴 하나를 계산하는 단위를 ‘어텐션 헤드’라고 부른다. 여러 헤드가 각기 다른 쿼리, 키, 밸류 세트를 사용하여 독립적으로 패턴을 계산한 뒤, 이 값들을 종합하여 다음 레이어의 입력으로 사용한다.</li>
    </ul>
  </li>
  <li><strong>피드포워드 네트워크(Feedforward Network)</strong>: 트랜스포머 안에 포함된 또 다른 연산으로, 모델이 더 많은 언어 패턴을 저장할 수 있도록 돕는다.</li>
</ul>

<h3 id="트랜스포머의-연산량-문제와-기존-해결책">트랜스포머의 연산량 문제와 기존 해결책</h3>

<p>트랜스포머는 위에서 언급한 어텐션 헤드의 단위로 토큰이 아웃풋이 되고, 그것을 다시 인풋으로 집어넣는 것의 연속이다. 따라서 행렬의 엄청난 연산량을 요구한다는 문제가 있다. 어텐션 패턴의 크기가 입력 단어 수의 제곱에 비례하여 늘어나기 때문에, 몇 문장에서 시작해 책 한권 분량이 들어간다면 기하급수적이라는 것이 무엇인가를 알 수 있게 된다. 이러한 본질적인 구조로 CPU 연산이 아닌 GPU의 사용이 핵심일 수 밖에 없고, 동시에 GPU 의 사용이라 함은 막대한 전기 사용, 발열 등 ‘GPU가 녹는다’ 라는 말에 딱 부합하는 작업인 것이다. (물론 최신 AI 모델들, 특히 구글에선 TPU 를 활용하는 시도라던지, 다양한 시도가 있는 것은 사실이다.)</p>

<p><img src="/assets/images/posts/2025-08/2025-08-04-003.png" alt="" /></p>
<blockquote>
  <p>GPUs Are Melting: … 출처 : <a href="https://www.linkedin.com/pulse/gpus-melting-building-real-time-monitoring-systems-go-snehasish-dutta-cctbe/">SNEHASISH DUTTA</a></p>
</blockquote>

<p>이러한 비효율성을 줄이기 위해 개발된 핵심 기술이 <strong>키-밸류(Key-Value) 캐싱(KV Caching)</strong>이다.</p>
<ul>
  <li><strong>키-밸류 캐싱(KV Caching)</strong>: 이미 모델에 입력된 단어들의 쿼리, 키, 밸류 값은 다시 계산할 필요 없이 저장해두고 재활용하는 방식이다. 이 기술을 사용하면 어텐션 연산량이 단어 수에 선형적으로만 증가하도록 안정화되어 폭발적인 증가를 막는다.</li>
  <li><strong>저장 공간 문제</strong>: 그러나 KV 캐싱은 키-밸류 값을 저장하기 위한 막대한 저장 공간을 요구한다. 단어 하나당 키-밸류를 모두 저장하면 4MB를 차지하며, 10만 개의 단어를 처리할 경우 무려 400GB에 달하는 저장 공간이 필요할 수 있다.</li>
</ul>

<p>위의 내용에서 언급한 저장공간 문제에 대해 이해하기 위하여, 간략화된 캐시 항목의 수를 계산 식은 다음과 같이 표현된다.</p>

<p>$CacheCounter = 2 \cdot n \cdot d_h \cdot n_h \cdot l$</p>

<ul>
  <li>$n$ : 입력 토큰 수</li>
  <li>$d_h$ : 키/ 값 행렬의 차원</li>
  <li>$n_h$ : 레이어 당 어텐션 헤드 수</li>
  <li>$l$ : 레이어 수</li>
</ul>

<p>예를 들어</p>

<p>$let d_h = 128, n_h = 128, l = 61, n = 100000$ 
(DeepSeek R1/V3 아키텍쳐 기준)</p>

<p>$(2)(128)(128)(61)(2) = 3.998 * 10^6 Bytes/token = (approx)4MB/token$</p>

<p>$4MB/Token * 100000 tokens = 400GB$</p>

<p>이러한 저장 공간 문제를 해결하기 위한 이전 시도에는 두 가지 방식이 있었다:</p>
<ul>
  <li><strong>멀티-쿼리 어텐션(Multi-Query Attention)</strong>: 모든 어텐션 헤드가 동일한 키-밸류를 공유하는 전략이다. 이는 저장 용량을 크게 줄일 수 있지만, 각 헤드의 역할이 달라야 하는 점을 방해하여 모델 성능이 저하된다는 단점이 있다.</li>
</ul>

<p><img src="/assets/images/posts/2025-08/2025-08-04-004.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://youtu.be/w5f6mtg0sKQ?si=UMmhUPEorJk_oPAW">웰트랩스</a></p>
</blockquote>

<ul>
  <li><strong>그룹별 쿼리 어텐션(Grouped-Query Attention)</strong>: 멀티-쿼리 어텐션을 개선하여 어텐션 헤드를 여러 그룹으로 묶어 <code class="language-plaintext highlighter-rouge">같은 그룹</code>끼리 키-밸류를 공유하는 방식이다. 메타의 라마 3(Llama 3) 모델이 이 방식을 사용하여 저장 공간을 8배 절약했지만, 여전히 전체 헤드가 키-밸류를 저장하는 방식보다 성능이 못 미쳤다.</li>
</ul>

<p><img src="/assets/images/posts/2025-08/2025-08-04-005.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://youtu.be/w5f6mtg0sKQ?si=UMmhUPEorJk_oPAW">웰트랩스</a></p>
</blockquote>

<h3 id="deepseek의-혁신-multi-head-latent-attention">DeepSeek의 혁신: Multi-Head Latent Attention</h3>

<p><img src="/assets/images/posts/2025-08/2025-08-04-006.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://youtu.be/w5f6mtg0sKQ?si=UMmhUPEorJk_oPAW">웰트랩스</a></p>
</blockquote>

<p>이러한 상황에서 중국의 <strong>딥시크(DeepSeek)</strong>는 기존 AI 개발에 수천억 원이 들어가는 것을 고작 80억 원에 가능하다고 발표하며 세상을 놀라게 했다. 딥시크는 경쟁사의 모델을 모방했다거나 실제 개발 비용보다 축소 발표했다는 구설수가 있었으나, 모든 모델 웨이트와 코드, 그리고 12개에 달하는 디테일한 논문까지 모두 공개하며 그 기술력을 드러냈다.</p>

<p>딥시크의 핵심 기술은 저장 공간과 연산량이라는 두 마리 토끼를 모두 잡은 <strong>멀티-헤드 레이턴트 어텐션(Multi-Head Latent Attention)</strong>이다. 이 기술은 인공지능 압축과 효율의 핵심인 <strong>‘잠재 공간(latent space)’</strong> 개념을 적용했다.</p>

<ul>
  <li><strong>멀티-헤드 레이턴트 어텐션의 원리</strong>: 기존 멀티-헤드 어텐션에서 입력 X를 키-밸류로 만드는 중간에 <strong>압축하는 스테이지를 하나 추가한다</strong>. 모든 어텐션 헤드는 같은 잠재 공간을 공유하는데, 이는 멀티-쿼리 어텐션과 유사하게 저장 공간을 줄이는 데 효과적이다. 그러나 구체적인 값을 저장하는 대신, 각 헤드에서 압축된 잠재 공간으로 보내줄 가중치(Wv와 W)를 학습하는 문제로 바꾸어 <code class="language-plaintext highlighter-rouge">학습 과정</code>에서 실제 단일한 캐싱 전략으로 가서 용량을 줄이는 경우 보다 <code class="language-plaintext highlighter-rouge">더 많은 자유도</code>를 보장한다.</li>
  <li><strong>수학적 효율성</strong>: 기본적인 선형 대수의 원리를 활용하여, 훈련 시 합쳐진 모델 자체로 훈련하기 때문에 추론(inference) 상황에서 추가적인 연산이 필요 없다. 새로운 단어가 입력될 때도 쿼리 레이턴트를 만들고 저장해 둔 레이턴트 키-밸류를 사용하므로 효율적이다.</li>
  <li><strong>성능 개선</strong>: 이 덕분에 딥시크 R1은 키-밸류 캐시를 저장할 때 어텐션 헤드 개수가 아니라 공유된 키-밸류 캐시의 크기에만 영향을 받도록 설계되었다. 이는 <strong>토큰당 70KB만 사용하여 저장 공간을 57배나 줄였으며</strong>, 토큰 생성 속도를 <strong>6배 빠르게</strong> 만들었다. (참고로, 키-밸류 캐시를 모두 저장했다면 토큰당 4MB, 그룹별 쿼리 어텐션은 500KB를 필요로 했을 것이다). 이러한 트랜스포머의 알고리즘 개선은 기존보다 훨씬 빠른 토큰 생성을 가능케 한다는 점에서 주목할 만하다.</li>
</ul>

<h3 id="llm의-잠재력과-그-가치">LLM의 잠재력과 그 가치</h3>

<p>LLM 의 구조를 씹어먹어보고, 수학적 기초는 처음에는 대단히 어렵게 와닿았지만, 결국 단어들 사이의 예측, 입력이 다시 출력이 되고, 그 출력이 다시 입력이 된다는 이 구조에 대한 이해가 있게 되면 Transformer 와 LLM 의 아주 베이직한 표면의 이해에는 어렵지 않다.</p>

<p>하지만 거기에 더 많은 구조적, 효율적 개선, 그리고 LLM 의 보편성을 이용한 다양한 능력, 다시 특화 기능을 위한 모델로 학습하거나 아예 대형 모델을 기반으로 더 튜닝하는 SLM(Small Language Model)의 등장 등, LLM의 잠재력, 그리고 향후에도 지속적인 판도는 이어질 것이다.</p>

<p>이번 내용을 통해 좀더 LLM 을 실증적으로 이해하고, 특히나 DeepSeek 와 같은 개선의 여지가 여전히 있단 점들은, 앞으로 정말 AI를 거쳐 AGI 까지, 초 거대모델들의 성장 폭은 남아 있다는 점을 나름 생각해 볼 수 있는것 같다.</p>

<h3 id="참고-문헌">참고 문헌</h3>
<ul>
  <li><a href="https://www.youtube.com/watch?v=HnvitMTkXro">3BlueL1Brown 한국어 - LLM 설명(요약버전)</a></li>
  <li><a href="https://www.youtube.com/watch?v=g38aoGttLhI">3BlueL1Brown 한국어 - 트랜스포머, ChatGPT가 트랜스포머로 만들어졌죠. -DL5</a></li>
  <li><a href="https://youtu.be/w5f6mtg0sKQ?si=GDTi2tnoFc-SqZVh">웰츠랩스 - 딥시크의 +99 강화 트랜스포머 몽둥이</a></li>
  <li><a href="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/ko/">Microsoft AI Tour - Learn how to interact with OpenAI models</a></li>
</ul>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="생각정리" /><category term="LLM" /><summary type="html"><![CDATA[개요 현재 인공지능(AI) 기술 발전의 핵심에는 트랜스포머(Transformer) 아키텍처가 있으며, 2017년 구글의 ‘Attention Is All You Need’ 논문을 통해 소개된 이후 오늘날 가장 널리 사용되는 AI 모델 구조가 되었다. 챗GPT(ChatGPT)의 ‘GPT’는 ‘Generative Pre-trained Transformer’의 약자로, 방대한 데이터를 통해 사전 학습된 트랜스포머 모델임을 의미한다. 트랜스포머 모델은 텍스트 번역을 넘어 이미지 생성, 음성 변환 등 다양한 AI 분야에 활용되며, 다음 단어나 내용을 예측하는 방식으로 작동한다. 몇 개의 단어를 입력하면 모델이 다음 단어를 예측하고, 그 예측된 단어를 다시 입력으로 사용하여 반복적으로 긴 문장을 생성할 수 있다.]]></summary></entry><entry><title type="html">네이버 부스트캠프 AI Tech 8기 준비해보자</title><link href="http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/04/02-challange-naver-boost-ai-8th.html" rel="alternate" type="text/html" title="네이버 부스트캠프 AI Tech 8기 준비해보자" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/04/02-challange-naver-boost-ai-8th</id><content type="html" xml:base="http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/04/02-challange-naver-boost-ai-8th.html"><![CDATA[<h2 id="들어가면서">들어가면서</h2>
<h3 id="ai-ai-ai">AI, AI, AI…</h3>

<p>AI의 혁신은 누군가에게는 큰 일이 아닐 수 있다.</p>

<p>물론, 온 나라에서, 전 세계가 떠들고 있는 입장에서 관심이 없는 사람이 없겠지만, 그럼에도 현실에선 AI를 아직 제대로 도입하지 않은 이들도 많고, 오히려 개발자들이 여전히 AI 에 대해 등한시 하는 이들도 있단 걸 보면… 새삼 여전히 AI 가 세상을 바꾼다는 생각 보단, 막연한 공포만이 존재하고, 실무에 적용, AI 기반화 된 곳은 많지 않다는 것을 느낀다.</p>

<p>피부에 온전히 <code class="language-plaintext highlighter-rouge">AI 네이티브</code> 라는 키워드가 어울리는 상황까지 도래 하진 않았다.</p>

<p>하지만 AI 의 파급력, 이미 그 수준과 활용 가능성은 훌륭하다. 리소스와 개발자만 충분하다면 AI, LLM 을 기반으로 하여 만들수 있는 것들의 수준, 자동화하기 어려운 것들에 대한 능동적 대응 등은 이미 사람 수준으로 충분히 구현이 가능하다. 국가 차원의 전략 병기 역할을 할 수 있다는 점에서 본다면 내가 다음 시대에서 적응하고 살기 위해 AI에 대한 역량이 없는 것은 결코 용납될 수 없다고 나는 생각한다.</p>

<p>거기다, 이런 거창한 이야기가 아니더라도 생각해보면 AI 덕에 나는 더 빠른 성장, 더 확실한 성장을 할 수 있었다.</p>

<p>내 아이디어나 내 생각을 구현화 하는데도 사람과 리소스가 드는 것을 AI 를 활용하면 10분의 1, 100분의 1로도 절감할 수 있다는 점은, 나의 삶에 새로운 도전, 새로운 기회를 줄 수 있다는 확신을 제공해준다. 그것을 누릴 준비, 써볼 준비를 이제는 해야 하지 않을까?</p>

<p>내가 단순히 백엔드 개발의 즐거움, 그 기술을 가지고 먹고 사는 것을 넘어서서 AI와 결합하여, 기업의 수요, 세상의 방향에서 아직은 내 수준으론 흐름을 쫓는 입장이지만, 언젠가 내가 그 흐름을 만들 수 있지 않을까? AI는 그걸 가능하게 만드는 ‘힘’이란 사실을 나는 한시도 잊고 산 적이 없다.</p>

<p><img src="/assets/images/posts/2025-08/2025-08-04-007.png" alt="" /></p>
<blockquote>
  <p>두둥</p>
</blockquote>

<p>그러는 와중에 퇴사를 하게 되었다. 정말 다양한 일들(…)을 겪었지만, 그 이야기는 나중에 한다 치고,</p>

<p>중요한 포인트는 42서울이라는 부트캠프를 통해 류한솔 버전 2가 될 수 있었고, 백엔드 개발자라는 타이틀을 얻을 수 있었다. 자잘한 성공과 실패를 거쳐 성공적으로 1년 이상을 생활했으며, 메인 서버라는 일을 빠르게 맡게 되어서 정말 백엔드 개발자로 해봐야할 기본적인 일들에 대해서는 A to Z 로 경험하는 것을 해 볼 수 있었다. 믿어주는 리더와 함께 3.0 버전으로 API 서버의 체계화, 업그레이드는 자랑할만한 성과가 아니었나 싶다.</p>

<p>기본 설계부터, API 대응, 서버의 관리나 서버 벤치마킹 및 분석, 요금 절감, 알람 시스템 구축이나 CICD에 무중단 배포까지. 곁다리로 ML 서버의 서빙과 관리, AI 개발까지 보조로 진행했으며, R&amp;D 연구까지 진행한 사실은, 1년 하고도 약 2개월의 시간, 나는 어떻게 성장 할 수 있었던가? 결론은 명확하다.</p>

<p><code class="language-plaintext highlighter-rouge">AI의 파워</code></p>

<p>AI를 통한 효율성의 증대, AI를 통한 개발에서의 문제의 사전의 확인, 백엔드 개발 구조에 대한 AI를 통한 검증이나 초기 조사 기간의 월등한 단축은 러닝커브가 있어야 하는 수 많은 기술들, 처음 경험하기에 생각과 다를 수 있는 영역 들에 보다 빠른 적응을 가능케 한다는 점이서 AI 는 정말 둘도 없는 선생님이자, 가이드 역할이었다고 나는 생각한다.</p>

<h3 id="성장도-방향도-ai">성장도 방향도 AI</h3>
<p>그러는 와중 백엔드 개발자에 대한 수요조사, 특히 내가갈 수 있는 1 ~ 3년차 사이의 주니어 개발자들에 대한 조사 이후 확실하게 얻은 기업이 요구하는 인재에 대한 인사이트는 다음과 같았다.</p>

<blockquote>
  <p>“Back End 도메인 역량을 결코 무시하지 말 것”</p>

  <p>“AI 키워드는 권장 그자체”</p>

  <p>1년 차는 CICD 까지의 흐름 이해 및 유지보수 경험</p>

  <p>3년 차는 CICD 의 구성 및 Kubernates 계열에 대한 배포 경험</p>
</blockquote>

<p>기업들의 AI 수요는 당연히 발생했다. AI라는 키워드를 통해 기존에 불가능하던 서비스의 활성화, 서비스의 고도화를 원하는 것은 당연했지만, 포인트는 거기서 회사들은 ‘어떤 인재’를 찾는가에 대한 내 나름의 특징을 발견했다는 것이다.</p>

<p>예를 들어 AI 전문 인력의 수요는 없지 않다. 분명히 전문가를 원했고, 당연히 석사 수준의 기초 바탕은 핵심이었다. 하지만 그런 자리의 갯수는 많지 않았다. 들려오는 이야기로 봐도, 오히려 소개받아 들어가는 자리에 대한 이야기는 있었지, 공개적으로 모집되는 글은 생각보다 많지 않았다.</p>

<p>곰곰히 생각해본 결과, 이는 ‘응용 서비스’에 가까운 이들에게 필요시 되는 AI 역량이라는 것이 생각보다 괴리감이 있다는 결론을 낼 수 있었다. AI에 전문성을 가진 완전 AI 전문 성향을 가진 수요가 아니라, 기존 도메인을 하면서도 AI 에 대한 준비가되어 있어서, 현실적으로 줄 수 있는 연봉과 AI 역량 사이의 벨런스, 기존 개발자들은 있거나, 그 수요를 하면서도 AI 가치를 가지고 있으면 좀더 고려한다- 라는 지극히 산술적 계산의 수요가 있던 것이다.</p>

<p><img src="/assets/images/posts/2025-08/2025-08-04-008.png" alt="" /></p>
<blockquote>
  <p>핵심은 역량의 ‘밸런스’</p>
</blockquote>

<p>생각해보면 그렇다. AI에 완벽히 특화된 인물들은 AI 베이스의 특화 기업, 투자가 확실하고, AI를 통해 수익을 내려는 기업, 대기업이라면 당연히 얼마를 주더라도 데려올 핵심 인재일 것이다. 하지만 현실의 모든 기업들은 그럴 상황이 아니란 것이다. 원티드를 비롯한 전통적인 구인구직 사이트, 개발자 특화 채용 플랫폼의 구인 탐색 결과 ‘필수’ 라곤 아니지만, ‘권장’이라는 항목에 AI와 관련된 능력이 전형적인 채용 역할들(프론트엔드, 백엔드)에 상당한 비중으로 포함되어 있던 것이다.</p>

<h3 id="결론--그래서-타이밍이-왔다">결론 : 그래서 타이밍이 왔다</h3>

<p>AI  에 대해 투자를 할 때라고 생각했다. 퇴사도 어쩌다보니 손쉽게 가능해졌고, 그렇게 정리를 하고 나오는 찰나 AI 관련한 정부의 정책이나 기업들의 투자 현황을 조사하다 보니 발견한 것이 바로 <code class="language-plaintext highlighter-rouge">네이버 부스트 캠프 8기</code> 의 모집 소식이었다.</p>

<h2 id="네이버-부스트캠프-ai-tech-8기-지원">네이버 부스트캠프 AI Tech 8기 지원</h2>

<h3 id="개요">개요</h3>

<p>해당 모집 사항을 정리하면 다음과 같았다.</p>

<ul>
  <li>지원 접수 : 25.08.14 오전 11시 마감</li>
  <li>온라인 문제 해결력 테스트 : 25.08.20. 오후 7시</li>
  <li>교육 기간 : 25.09.01 시작하여 26.02.11 까지 약 6개월, 전일제 교육</li>
</ul>

<h3 id="지원-자격과-인재상-에-대한-분석">지원 자격과 ‘인재상’ 에 대한 분석</h3>
<ol>
  <li>전일제, 집중, 몰입의 요구: 기본적으로 내용을 통해 확실하게 알 수 있는 것은 ‘쉽지 않을 것이라는’ 각오를 요구하는 내용이라고 판단했다.</li>
  <li>코어 타임의 참여 요청: 이 역시 1번을 다시 강조하는 말이리라</li>
  <li>끝을 보는 ‘덕질’의 성향: 결국 문제는 지속적으로 나타날 것이고, 그 내용을 단순히 스펙 쌓기로 생각하는게 아니라, 분야에대한 집요함을 묻는다는 의미.</li>
  <li>‘협업과 커뮤니케이션에 책임감’: 이 역시 1, 3과 함께 하는 거지만, 특히나 중요한 이유는 결국 AI 라는 영역이 한 사람이 해결할 수 없다는 사실을 여실히 보여주는 것이리라 싶다.</li>
</ol>

<p>결론적으로 정리하면 네이버 재단에서 원하는 인재란, 결국 위에서 언급한 상황, 현실적인 기업의 요구사항과는 다소 차이는 있다고 보인다. 하지만 대기업, 혹은 잠재 가치를 봤을 때 가장 ‘비싼’ 몸값의 인재 양성이 반드시 필요하다고 생각한다는 점을 느낄 수 있었다.</p>

<h3 id="해야-할-일">해야 할 일</h3>
<p>후기를 뒤져보고, 이들을 종합해보니 다음과 같이 해야 것들, 준비해야할 것들이 보였다.</p>

<p><strong>1. 프리코스는 반드시 해라</strong> : 프리코스의 콘텐츠가 온라인 테스트의 핵심 필수 사항이라는 이야기가 있다. 물론 파이썬 기초, AI 기초에 대한 내용이라 이미 숙지한 사람이라면 들을 필요가 있나? 했을 때 약간 갸웃둥 해지긴 하나, 공식 시험 가이드라 생각하고 그래도 보는 것은 괜찮다고 본다. 특히 결정적으로 가산점을 준다는 사실만 봐도, 안하는 건 99% 손해이리라 싶다.</p>

<p><strong>2. 지원서 준비는 미리미리</strong> : 이건 사실 강조할 필요가 있을까? 싶지만, 결국 인재상에 맞는 인재라는 것은 글에서부터 ‘묻어나오는 깊이감’이 있을 것이다. 그리고 그것은 어딜 가나 사람이 인정받는 시작점이며, 거기서 생각이 얕고, 준비가 부족하다면 결국은 ‘시작 조차 하지 못한다’고 보는게 맞을 것이다. 자신의 가치를 경험과 연결하여 구체적으로 작성하고, 도전 과정에서 배운 것들, 어려움과 실패에서 무얼 얻었는지도 중요할 것이며, 무엇보다 진정성과 열정이 느껴지고, 그것을 실재 만드려는 그 내용 전체의 첫 인상이 지원서에서 시작한다는 점은 어떤 후기를 보더라도 필요해보인다.</p>

<p><strong>3. 온라인 문제 해결력 테스트</strong> : 확인해보니 AI와 CS 지식, 코딩역량을 한번에 평가가 기존에 여러 차례 했던 것과는 다르게, 완전히 통합되어 진행된다고 한다. 핵심 주제는 다음 내용 위주로 보인다.</p>

<ul>
  <li>AI 및 CS 지식 테스트 영역 포함 사항들
    <ul>
      <li>선형대수 : 벡터 및 행렬 연산, 고유값(Eigenvalues), 주성분 분석(PCA) 등</li>
      <li>확률 및 통계 : 확률 분포, 조건부 확률, 편향-분산 트레이드 오프 등</li>
      <li>머신러닝 / 딥러닝 기초 : 경사 하강법(Gradient Descent), 활성화 함수(Activation Function), 과적합(Overfitting), 정규화(Regularization), 평가 지표(Evaluation Metrics) 등</li>
      <li>컴퓨터 과학 기초 : OS, 네트워크, 자료구조 등 기초 CS 문제 (단 후기들이 공통적으로 나오는 요소는 아니다)</li>
      <li>난이도 : 단순 암기만으로 풀기 어려운, 개념에 대한 이해를 요구되는 문제 출제 됨. 프리코스를 충실히 학습하고 개념을 완벽히 소화 하는 것이 중요</li>
    </ul>
  </li>
  <li>코딩 테스트
    <ul>
      <li>사용 가능 언어 : C++, Java, Python 3 (당연한 이야기지만 Python3가 가장 낫다)</li>
      <li>난이도나 경향성 : 전체적으로 과거 후기들을 보면, 백준 실버 ~ 백준 골드 ~ 플레티넘, 프로그래머스 1 ~ 3 정도로 고루 나오는 것으로 보는게 맞아 보인다.</li>
      <li>단, 0 또는 1문제를 풀고도 합격 사례 =&gt; 단순히 코딩 성적이 곧 과락을 의미하진 않음으로 보인다.</li>
      <li>주요 문제 유형
        <ul>
          <li>구현 / 시뮬레이션 : 문제의 요구사항을 꼼꼼히 읽고 그대로 코드로 옮기는 능력을 요구하는 문제가 빈번하게 출제된다. 복잡한 알고리즘 지식보다 독해력과 꼼꼼함이 중요</li>
          <li>핵심 알고리즘 : 깊이/너비 우선 탐색(DFS/BFS), 동적 계획법(DP), 그래프 탐색, 스택/큐 등 기본적인 자료구조 및 알고리즘 활용 문제가 꾸준히 언급된다</li>
          <li>CS 지식 융합형 : 일부 기수에서는 CS 지식을 문제 해결 과정에 직접적으로 적용해야 하는 융합형 문제가 출제</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="그래서-왜-네이버냐">그래서 왜 네이버냐?</h2>
<p>당연한 이야기지만 네이버 AI 부스트 캠프의 후기로 취업을 잘했다, 이직을 잘했다 이런 이야기가 아니라는 점은 다수의 후기에서 언급하는 부분이다. 그도 그럴 것이다. 개발자 시장의 과포화, 능력 상향 평준화, AI의 손쉬운 사용으로 신입을 뽑지 않는 환경 등을 고려한다면 그저 부스트캠프를 나왔다고 연봉이 올라간다, 취업이 손쉽게 된다는 것은 당연히 아니다.</p>

<p>뿐만 아니라 AI 가 나에겐 ‘메인’이냐? 라고 하면 그것도 아닐 수 있다. 그러다보니 들어가면 분명히 완벽히 낙제생 포지션이 될 수 밖에 없을 것이고, 가서 아주 잘하면 75점을 받을 수 있을까? 분명 그 이하일 것은 팩트이다 😂</p>

<p>하지만 내가 들어가야 하는 이유이자, 거기서 준비해야 할 것이 무엇인가? 에 대해서는 다음과 같이 정리 할 수 있다.</p>

<p><strong>1) AI 에 대한 제대로된 지식을 기반으로 시작하여 백엔드에 적용하는 AI의 키워드 :</strong></p>

<p>AI 만으로 개발자가 될 수도 없으며, AI 라는 툴이 결국 만나야 하는 것은 기존의 전통적인 영역들의 기술이다. 그 기술을 포함하지 않고 AI 는 비즈니스의 시장에 생명의 불꽃이 되진 못한다. 그러니 나는 AI 를 어떻게 백엔드에 적용하고, 또 반대로 어떤 지점에서 백엔드가 필요한지를 확실하게 파악할 수 있고, 그럴 수요에 부합하는 인재가 될 것이다. 이는 그 내부에서 나의 필요성을 보여줄 수도 있으며, 반대로 내가 AI에게 뭘 요구해야할지 알 수 있을 것이다.</p>

<p><strong>2) 정말 괜찮은 개발자 네트워크와 리소스의 ‘철저한 활용’ :</strong></p>

<p>6개월의 전념. 나같은 이직 준비를 하는 사람이 얼마나 될지는 모르겠다. 하지만 확실한 건 신입이든, 아니든 간에 여기에 들어가기까지 걸린 시간이나 고생한 것을 고려한다면 그들의 마음이나 자세는 분명하게 보인다. 그리고 그런 이들을 아는 것, 그리고 나 역시 그들과 함께 하는 것은 앞으로 나의 꿈, 혹은 그들의 꿈을 구현하는데 더 가까워지는 것이다. 그것은 앞으로의 엄청난 내 자산이 되리라 확신한다.</p>

<p><strong>3) 고급 백엔드 기술의 도입의 기회 마련 :</strong></p>

<p>들어가기만 하면 네이버의 고성능 AI 리소스를 쓸 기회가 생긴다. 뿐만 아니라 설령 리소스를 무제한으로 쓴다고 하더라도 효과적이고 효율적인걸 고려한다고 하면 DevOps 관점, 백엔드 개발자의 관점은 당연히 필요할 것이며, 무엇보다 백엔드의 효과적인 구조, CICD 구현 등 결국 고급 기술들을 적용해야만 AI 기반의 서비스 구현에 어려움이 없을 것이다. 이런 점에서 네이버란 기회는 오히려 더 많은 백엔드 기술 연마와 포트폴리오 준비를 가능케 할 것이라는 건 안봐도 비디오인 상황이다.</p>

<p>완전 AI 지향으로 가는 것에 비하면 나의 목표는 다소 애매(?) 할 수도 있다고 생각한다. 하지만 8월이란 기회는 와버렸고, 스스로 준비하는 것의 한계를 뛰어넘을 기회라는 확신은 있다. 건강도 챙겨야 하다보니 ‘완벽하게’ 라는 수식어를 42서울 처럼 붙이긴 어려울 것 같지만, 그럼에도 여길 발판으로 삼아, 내년에는 정말 AI DevOps Backend 이 키워드 세가지의 전문가로 확실하게 자리 매김을 할 수 있기를 기대해본다.</p>

<p>42서울을 통해 2.0을 만들었었고, 2.x 버전이던 시기를 거쳐 이제는 AI 를 통해 버전 3 라는 매력적인 순간을 차지해보자. 😎</p>]]></content><author><name>Paul2021-R</name></author><category term="생각정리" /><category term="AI" /><category term="LLM" /><category term="생각정리" /><category term="이직" /><category term="학습" /><summary type="html"><![CDATA[들어가면서 AI, AI, AI…]]></summary></entry><entry><title type="html">AI Breakfast Ep 8 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/30/AI-trend-with-google-08.html" rel="alternate" type="text/html" title="AI Breakfast Ep 8 생각정리" /><published>2025-07-30T00:00:00+00:00</published><updated>2025-07-30T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/30/AI-trend-with-google-08</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/30/AI-trend-with-google-08.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=BrR5CQuH7Hs"><img src="https://i.ytimg.com/vi/BrR5CQuH7Hs/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>‘AI Breakfast’의 여덟 번째 에피소드는 ‘개발자의 관점: AI는 좋은 질문을 기다린다, 답이 아니라’라는 주제로 진행된 대담이다. 인공지능 환경을 둘러싼 개발 전반에 대해 이야기했다.</p>

<ul>
  <li><strong>지능과 인공지능의 본질</strong>:
    <ul>
      <li>현재의 인공지능은 인간이 만들어낸 지능이며, 특히 <strong>언어적인 유창함</strong> 때문에 지능으로 오해하는 경향이 크다.</li>
      <li>아직 학습하지 않은 부분에 대해서는 ‘환각(hallucination)’ 현상이 많고 올바른 답을 내지 못하는 한계는 여전하다.</li>
    </ul>
  </li>
  <li><strong>LLM의 안전성과 제어를 위한 노력</strong>:
    <ul>
      <li>LLM(대규모 언어 모델)은 현재 <strong>제어 가능한 범위 내에서 제어 가능한 결과를 얻기 때문에</strong> 창발적인 결과를 얻기 어렵다.</li>
      <li>구글은 <strong>세이프티 필터링</strong>을 통해 도전적인 프롬프팅에 안전하게 대응한다.</li>
      <li>모델 출시 전 사람이 직접 개입하여 질문과 답의 경량성을 평가하고 세이프티 가이던스를 정책으로 적용하는 노력을 기울인다.</li>
      <li>일부 안전성 제어 또한 자동화는 가능하지만, 질문과 답에 대한 평가 결과는 아직 사람이 개입하는 것이 효율적이라고 본다.</li>
    </ul>
  </li>
  <li><strong>AI 모델 출시 전략과 플랫폼 활용</strong>:
    <ul>
      <li>사용자들은 특정 페르소나 부여에 적합한 ‘Anthropic Sonnet’이나 의도된 결과 도출에 적합한 ‘Gemini’ 등 <strong>목적에 맞춰 다양한 AI 모델을 혼용</strong>하여 사용한다.</li>
      <li>‘Vertex AI’와 같은 플랫폼이 다양한 모델을 활용하는 데 큰 도움이 된다.</li>
    </ul>
  </li>
  <li><strong>개발자들의 AI 활용</strong>:
    <ul>
      <li>개발자들 사이에서 가장 인기 있는 AI 서비스는 <strong>LLM과의 채팅</strong>과 <strong>이미지 생성</strong>이다.</li>
      <li>AI 코딩 도구(예: Google의 Code Assist, JetBrains, Cursor, Windsurf)가 개발 생산성을 크게 향상시키고 있으며, Gemini와 Code Assistant를 활용하여 <strong>두 달 만에 Unity로 게임 데모를 개발</strong>한 경험을 공유했다.</li>
      <li>AI가 개발자의 생산성에 미치는 영향은 천차만별이며, 특히 <strong>새롭거나 익숙하지 않은 API 연동과 같은 작업에서 두세 배의 생산성 향상</strong>을 가져올 수 있다.</li>
      <li>그러나 익숙한 로직을 작성하거나 짧은 함수를 만들 때는 AI의 도움이 덜할 수도 있다고 한다.</li>
      <li><strong>자신이 어떤 상황에 처했고 무엇을 해결하려는지 상세하게 넘겨줄수록</strong> 올바른 답을 받을 확률이 높아진다.</li>
      <li>결론적으로 AI는 <strong>숙련가가 본인의 능률을 보다 향상시키는 데 굉장히 좋은 도구</strong>로 기능할 수 있다.</li>
    </ul>
  </li>
  <li><strong>AI 의존과 커리어에 대한 생각</strong>:
    <ul>
      <li>현 시점에서 인공지능에 전적으로 기대어 커리어의 단계를 뛰어넘으려는 것은 바람직하지 않다.</li>
      <li>어떤 도메인이든 잘하는 사람은 AI를 잘 이용하고, 못하는 사람은 잘 이용하지 못한다.</li>
      <li>생성형 AI를 잘 활용하려면 배우고자 하는 열정, 실수해도 일어서는 끈기, 많은 시간 투입 등의 요건이 필요하다.</li>
      <li>LLM이 생성한 코드를 검증 없이 코드 리뷰에 올리는 경우, 리뷰해야 하는 사람들의 감정 소모와 비효율을 초래할 수 있다. 오히려 협업에 독이 되는 경우가 발생하는 것이다.</li>
      <li><strong>AI 도구는 사용자가 통제할 수 있는 영역에서 다뤄야 하며</strong>, 그렇지 않으면 주변 사람들까지 힘들게 할 수 있다.</li>
    </ul>
  </li>
  <li><strong>AI와 1인 개발자 및 콘텐츠 스튜디오</strong>:
    <ul>
      <li>생성형 AI(이미지, 비디오, 문장 생성)는 <strong>1인 개발자가 스튜디오의 역할을 수행할 수 있도록</strong> 돕는다.</li>
      <li>성우나 스토리 작가 없이도 게임 제작이 가능해지며, <strong>여러 AI에 페르소나를 부여하여 서로 대화하게 함으로써 결과물을 얻는 방식</strong>도 상상해 볼 수 있다.</li>
      <li>유튜브 등 콘텐츠 플랫폼에서 얼굴이나 목소리 노출 없이 AI로 영상, 내레이션 등을 만들어 쇼츠를 생산하고 수익화하는 사례가 증가하고 있다.</li>
      <li>AI가 플랫폼의 알고리즘을 학습하여 <strong>최적의 콘텐츠를 만들어낼 수도 있을 것</strong>이라는 전망이 있다.</li>
      <li>Google의 <strong>Veo(영상), Imagen(이미지), 음성 모델, 음악 생성, DJing 도구</strong> 등은 상상력이 닿는 데까지 모든 것을 만들 수 있게 한다.</li>
      <li>사용자들은 음악보다는 영상이나 이미지 생성에 더 큰 관심을 보이며, Veo 등을 활용하여 개인 뮤직비디오를 만드는 것도 충분히 가능하다고 한다.</li>
      <li>AI는 문화재 복원(벽화, 유화, 소실된 영화 필름 복원)과 같이 <strong>인류의 가치 있는 미디어를 복원하는 데도 도움</strong>을 줄 수 있다.</li>
    </ul>
  </li>
  <li><strong>AI 창작물에 대한 구글의 철학 및 대응 방식</strong>:
    <ul>
      <li>Veo를 통해 만들어진 영상에는 눈에 보이지 않는 <strong>워터마크(SynthID)</strong>가 삽입된다.</li>
      <li>SynthID는 오남용을 방지하고, AI가 만든 것임을 쉽게 판독, 나아가선 순수 창작자들을 위해 개발되었다.</li>
      <li>구글은 <strong>순수 창작자를 보호</strong>하기 위해 이 기술을 개발했으며, 원작자의 화풍을 모방하여 콘텐츠를 생성하는 것을 방지하는 데 활용된다.</li>
      <li>구글의 AI 원칙에는 <strong>구글 플랫폼에서 생성된 결과물이 제삼자의 저작권을 침해할 경우 구글이 책임지겠다는 면책 조항</strong>도 포함되어 있다.</li>
      <li>구글은 사용자들의 <strong>생산성 향상과 인류의 근본적인 문제 해결</strong>에 초점을 맞춰 기술을 개발하며, 재미 요소보다는 실용성에 중점을 둔다.</li>
      <li>Gemini는 챗GPT와 달리 ‘건조하고 할 말만 한다’는 특징을 가지며, 이는 <strong>기술의 본질적인 가치에 집중</strong>하는 구글의 방향성을 보여준다.</li>
    </ul>
  </li>
  <li><strong>구글 워크스페이스에서의 생산성 향상</strong>:
    <ul>
      <li>구글 워크스페이스(Docs, Slides)의 AI는 <strong>기존 업무 환경에서 점진적으로 생산성을 향상</strong>시키도록 설계되었다.</li>
      <li>비즈니스 목적에 사용되기 때문에 의도하지 않은 결과가 나오지 않도록 <strong>엄중한 가이드라인</strong>을 지키며, 둔하더라도 신뢰할 수 있는 방향으로 개발된다.</li>
      <li><strong>구글 미트의 회의 요약 기능</strong>은 회의 내용을 시간순으로 배열하고, 누가 누구에게 무엇을 요청했는지 요약하여 업무 누락을 방지하는 데 혁신적인 도움을 준다.</li>
    </ul>
  </li>
  <li><strong>AI 에이전트의 보안</strong>:
    <ul>
      <li>Google의 <strong>Agent2Agent(A2A)</strong>는 기업 환경에서 사용할 수 있도록 <strong>엔터프라이즈 그레이드 보안 및 인증 체계를 갖추는 데 중점</strong>을 두어 개발되었다.</li>
      <li>이를 통해 과거 MCP(Messaging, Content, and Platform)와 같은 우려를 상당 부분 해소할 수 있을 것으로 기대한다.</li>
    </ul>
  </li>
  <li><strong>개발자로서 AI를 통한 미래 기대</strong>:
    <ul>
      <li>AI 도구를 활용하여 개인의 <strong>개발 생산성을 높이고, 나아가 팀과 조직의 생산성을 끌어올려 비즈니스 성공에 기여</strong>할수 있다고 생각한다.</li>
      <li>AI 코드 리뷰는 개발자가 급박하게 돌아가는 개발 과정에서 감정 소모를 줄이고, 사소한 지적을 AI가 대신하여 <strong>효율적인, 객관적인 코드 검토</strong>가 가능하게 한다.</li>
      <li>궁극적으로 AI는 개인의 생산성을 늘리기 위한 도구로 사용될 것이며, 구글의 서비스도 이러한 가치에 부합하는 결과를 목표로 한다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>이번 내용은 AI에 대한 보다 개발자적인 내용들이 위주로 나오면서 좀더 생산적이게 느껴졌다.</p>

<p>특히나 실질적인 사례들이나, 기존에 나도 생각하던 부분, AI에게 얼마나 어떻게 세이프티를 채울 것인가.</p>

<p>그리고 그 세이프티와 함께 AI 를 다루는 사람들은 어떻게 생각하면 좋을까 같은 다소 어려운 주제들이, 상당히 나와 유사한 생각의 형태로 이어졌다.</p>

<p>내가 AI 라는 소재에 매력을 느끼는 건 뭐 때문인가.</p>

<p>생각해보면 그냥 트렌드니까, 돈이 되니까, 그런 영역으로 끝나는 문제는 아니라고 생각한다.</p>

<p>AI 는 날개다.</p>

<p>좋은 질문, 효과적인 상황에서 사용 시 사람의 한계를 뛰어넘는데 발판 역할을 해줄 수 있을 뿐 아니라, 그걸 기준으로 하면 사람이 가지는 감정,</p>

<p>새로운거 배우는게 쉽지 않은 그 감정을 이겨낼 수도 있다는 점에선 AI 는 사람의 다음 그 이상을 만들어줄 거라는 그런 기대를 하게 된다.</p>

<p>실제로 나의 1년의 서버 개발자로의 삶에서도, 결국 AI 가 있었기에 지금 수준의 성과, 지금 수준의 속도, 지금 수준의 자신감을 가질수 있었으니까 말이다.</p>

<p>그나저나 확실한 건 얼른 VertextAI 를 비롯해서 구글의 AI 를 위한 플랫폼에 대한 서비스 이해도가 높아질 필요가 있어 보인다….</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI Breakfast Ep 7 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/29/AI-trend-with-google-07.html" rel="alternate" type="text/html" title="AI Breakfast Ep 7 생각정리" /><published>2025-07-29T00:00:00+00:00</published><updated>2025-07-29T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/29/AI-trend-with-google-07</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/29/AI-trend-with-google-07.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=113tJcX0io8"><img src="https://i.ytimg.com/vi/113tJcX0io8/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>이번 최신화는 AI 시대의 업무와 삶의 혁신에 대한 논의를 다루고 있다.</p>

<ul>
  <li>
    <p><strong>Vertex AI 스튜디오</strong>: 구글 클라우드 내에 있는 서비스로, 기업 고객과 개발자들이 <strong>직접 AI 서비스를 만들 수 있는 도구</strong>이다. 이는 단순히 코드를 입력하는 개발 도구가 아니라, 노트북LM이나 제미나이 같은 다양한 AI 서비스를 접목하여 챗봇, 기업 맞춤형 제미나이, 비디오 및 음악 생성 등 새로운 서비스를 창의적으로 만들 수 있도록 돕는다. 또한, 고객이 직접 <strong>레고 조립하듯이 본인의 서비스를 만들 수 있는 도구</strong>로 비유되며, 이는 밀키트 판매보다는 음식 프랜차이즈를 기획하고 만드는 과정에 필요한 도구와 같다고 설명된다.</p>
  </li>
  <li><strong>구글 클라우드</strong>의 강점:
    <ul>
      <li><strong>확장성</strong>과 <strong>연결성</strong>이 매우 중요하며, 구글 클라우드는 AI 서비스의 가장 아래 단계인 모델(제미나이, 클라우드 소넷 등)부터 코드를 만들고 서비스를 제공하는 환경까지 <strong>전 포트폴리오</strong>를 제공하는 업계 유일의 서비스 제공자이다.</li>
      <li>구글 워크스페이스 같은 생산성 도구와 <strong>유기적인 데이터 교환 및 연동</strong>이 가능하여, 워크스페이스의 데이터를 Vertex AI 학습에 활용하거나 Vertex AI에서 생성된 데이터를 워크스페이스에서 참조할 수 있다. 이는 구글의 가장 큰 강점으로 꼽힌다.</li>
    </ul>
  </li>
  <li><strong>AI 도입 진입 장벽</strong>을 낮추기 위한 전략:
    <ul>
      <li>사용자가 AI를 <strong>자연스럽게 받아들이도록 유도</strong>하는 방향을 지향한다. 예를 들어, 구글링이나 이메일, 문서 작업 중 자연스럽게 AI 검색 결과나 제미나이 같은 기능이 등장하여 익숙해지도록 하는 방식이다.</li>
      <li>구글은 <strong>변화 관리 방법론</strong>을 가지고 있는데, 이는 사용자들이 A에서 B로 변화할 때 겪는 어려움을 최소화하고 마치 게임의 점진적인 업데이트처럼 사용자들이 눈치채지 못할 정도로 부드럽게 변화를 경험하도록 돕는다.</li>
      <li>이 방법론은 기업이 새로운 기술을 도입할 때 발생하는 <strong>기술 부채를 탕감</strong>해주는 역할을 한다. 기업의 현재 상황을 진단하고, 기존의 좋은 문화를 유지하면서 유연한 도구를 통해 개선할 수 있는 부분을 제안하며, <strong>작은 성공부터 맛보며 변화</strong>할 수 있도록 돕는다. 이는 “긁어 부스럼 만들지 말자”는 기업의 인식을 “변화를 눈치채지 못할 것”이라는 접근 방식으로 설득하는 데 사용된다.</li>
    </ul>
  </li>
  <li><strong>AI의 미래 발전 방향과 역할</strong>:
    <ul>
      <li>구글은 AI가 <strong>생산성 증강</strong>과 인간의 능력을 증강시켜 주는 방향으로 개발되고 있다고 밝힌다.</li>
      <li><strong>멀티모달리티</strong>를 추구하는 <strong>프로젝트 아스트라</strong>를 통해 렌즈, 음성, 소리를 통해 제미나이와 자연스러운 상호작용이 가능하며, 이는 시각 장애인 지원이나 학습 도구로 활용될 수 있다.</li>
      <li>AI가 발전할수록 우리 생활 속에 스며들어 마치 스마트폰처럼 <strong>본질은 같지만 접근 방식이 달라지는 도구</strong>가 될 것이며, 혁신적인 삶을 살아도 사용자들은 이를 당연하게 여기고 예전과 비슷하게 느낄 것이다.</li>
      <li>단기적으로는 <strong>개인 맞춤화</strong>된 AI가 발전할 것이며, 사용자의 업무 패턴이나 선호도를 기반으로 맞춤형 결과물을 제공할 것이다.</li>
      <li>더 나아가 <strong>자연스러운 인터랙션</strong>을 넘어, AI가 사용자의 모든 것을 지켜보다가 필요할 때 알아서 해주는 <strong>‘시키지도 않는 AI’</strong> 단계에 도달할 것이라는 예측도 있다. 이는 자동화와 자율 기능 부여 사이의 딜레마를 내포하고 있으며, 구글은 <strong>책임감 있는 AI</strong>를 만드는 것을 가장 중요한 가치로 삼고 있다.</li>
    </ul>
  </li>
  <li>
    <p><strong>AI의 핵심 가치</strong>는 <strong>시간 절약</strong>이다. AI는 개인이 업무에 소요되는 시간을 단축시켜 삶의 질을 높이는 데 기여한다.</p>
  </li>
  <li><strong>교육 현장</strong>에서의 AI:
    <ul>
      <li>AI는 학생들에게 양질의 정보를 쉽게 접하고 궁금증을 해결할 수 있는 새로운 채널을 제공한다.</li>
      <li>선생님들의 행정 업무 부담을 줄여주고, 아이들의 눈높이에 맞는 학습 자료나 과제 아이디어를 얻는 데 도움을 준다.</li>
      <li>AI는 <strong>숙제 개념 변화</strong>를 가져올 수 있으며, 미래 사회는 AI를 쓰는 능력이 필수가 될 것이기에 <strong>AI 숙련</strong>이 중요해진다.</li>
      <li>구글의 <strong>노트북LM</strong>은 학교 현장에서 <strong>할루시네이션</strong>(환각) 우려를 줄이고 <strong>데이터 소스 검증</strong> 능력을 키워주는 등 학생 학습과 교사 콘텐츠 준비에 높은 활용도를 제공한다.</li>
    </ul>
  </li>
  <li>학생들의 <strong>안전한 AI 사용</strong>:
    <ul>
      <li>어린 학생들의 경우, 판단 기준이 아직 확립되지 않았으므로 AI 도입은 <strong>점진적</strong>이어야 하며, 긍정적/부정적 변화를 평가할 시간이 필요하다. 정책적인 고려가 이루어지고 있다.</li>
      <li>AI가 아이들에게 칭찬을 많이 해줌으로써 학습 동기를 부여하는 등 긍정적인 학습 방법으로도 활용될 수 있다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>이제 슬슬 구글의 서비스들에 생각 이상으로 이해가 되는, 자체 구글 홍보(?) 같은 일을 내가 하고 있는가 싶다.</p>

<p>구글의 전략, 구글에 대한 이해도가 높아지고 있지만 그러는 한 편으로 AI 관련해서 구글의 전략에 대해서만 이해도가 높아져선 공평하지 않으니(?) 향후에 AWS, MS 등 웹프로바이져들을 중심으로 그 전략을, 그리고 특히나 Naver나 kakao, KT Cloud에 SKT까지는 알아봐야 하지 않을까 생각이 든다.</p>

<p>내용의 핵심인 요는 결국 ‘변화’의 바람에 떠밀듯이 회사도, 조직도, 학교도 적용될 것이지만, 문제는 그것을 어떻게 얼마나 플랫폼으로써 확장 될 수 있을까? 그리고 그 기반, 즉 공기나 물과 같은 위치를 구글의 서비스나 모델들이 확장될 수 있는가를 구글은 고민하고 있다는게 느껴진다.</p>

<p>변화는 좋은 것이지만, 그 결과가 명확하지 않을 때, 도전적인 이들도 있지만, 사실 생각해보면 대부분의 케이스 기존의 것들이 좋다는 관념적인 움직임이이 태반일 것이며 실제로도 그런 이들이 ‘어 바꿨나?’ 싶을 정도로 자연스럽게 녹아들고, 그 서비스에 락인(lock-in)될 때 그것이 진짜 플랫폼이 되는게 아닐까?</p>

<p>플랫폼 사업의 노하우, 그리고 그 앞을 바라보는 시선을 보면 왜 구글이 인터넷 춘추전국시대를 지나, 그 왕자를 분명 뺏을 만한 강자들이 있었음에도 그 강자들 사이에서 압도적일 수 있었는가에 대한 비전, 안목, 그리고 깊이감이 느껴지는 대담이 어제와 오늘자 내용이었다고 생각이 든다.</p>

<p>특히나 노트북LM, 이런 서비스에 대한 지속적인 노출이나, 교육 서비스, 워크 스페이스와의 연동 등은 어쩌면 그런 ‘가랑비에 옷 젖는’ 그리고 동시 ‘숨쉬듯’ 사용하기 위한 서비스이자, 특히나 ‘어떤 결과가 초래될지 모른다’라는 AI의 대중들의 거부감보다는 신뢰감, 효과성을 어필하려는 구글의 노력이 무엇인가를 새삼 느끼게 만드는 것 같다.</p>

<p>결국 내가 AI 와 관련되어 전문성을 얻어야 하는 지점은 어디일까?</p>

<p>어쩌면 일상의 생활에 얼마나 AI를 통해 자연스럽게 녹아들게 만들것인가. 그리고 그 과정을 단순히 백엔드의 절차적 사고를 통해서만 구현해내는 것이 아니라, 얼마나 통합된 구조를 만들 것인가?</p>

<p>궤도님의 발언처럼, 향후를 고려하여 미리 예측하여 결과를 만들어두는 것과 같이 전통적이지만 좀더 효율성이 있는 서비스로의 성장(물론, 지금 AI 산업의 구조나 하드웨어적 상황으론 거의 불가능할 것 같다만)에 도움이 되는 로직, 구조, 그리고 코드로 살려낼 수 있어야 한다는 생각, 그러려면 그런 서비스의 본질을 이해해야 한다는 생각이다.</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI Breakfast Ep 6 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/28/AI-trend-with-google-06.html" rel="alternate" type="text/html" title="AI Breakfast Ep 6 생각정리" /><published>2025-07-28T00:00:00+00:00</published><updated>2025-07-28T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/28/AI-trend-with-google-06</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/28/AI-trend-with-google-06.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://youtu.be/t3OuoheRiTU?si=KMR8Xvpq0Nma9XI7"><img src="https://i.ytimg.com/vi/t3OuoheRiTU/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>dd</p>

<h2 id="내-생각-정리">내 생각 정리</h2>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI Breakfast Ep 5 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/25/AI-trend-with-google-05.html" rel="alternate" type="text/html" title="AI Breakfast Ep 5 생각정리" /><published>2025-07-25T00:00:00+00:00</published><updated>2025-07-25T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/25/AI-trend-with-google-05</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/25/AI-trend-with-google-05.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=Osk6h0ionM0"><img src="https://i.ytimg.com/vi/Osk6h0ionM0/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>이번 최신화는 에이전트 기술이 기업에 도입되는 현황과 미래에 대한 내용을 다루었다.</p>

<ul>
  <li><strong>기업들의 에이전트 도입 현황</strong>: 기업들은 이미 자체 서비스나 제품에 에이전트 개념을 많이 도입하였다. 예를 들어, LG유플러스의 콜 에이전트 서비스인 익시오나 카카오헬스케어의 혈당 관리 앱 파스타 등이 이에 해당한다. 그러나 자체 직원들을 위한 에이전트 도입은 아직 초기 단계에 있으며, 소수의 선구자들이 스스로 사용하고 만들어보는 단계이다.</li>
  <li><strong>업무 패러다임의 변화</strong>: 코로나19로 인한 재택근무와 온라인 협업의 시대에서 이제는 에이전트를 통해 개개인의 업무 생산성을 극대화하는 자동화의 시대로 전환되고 있다.</li>
  <li><strong>에이전트 스페이스</strong>: 구글은 이러한 변화에 대응하기 위해 ‘에이전트 스페이스’라는 제품을 출시 준비 중이다. 구글 직원들은 이미 6개월 전부터 에이전트 스페이스를 내부적으로 사용하여, 제품 출시 전 실제 사용 환경에서 문제점을 발견하고 피드백을 제공하는 ‘독푸딩(dogfooding)’ 개념으로 검증하고 있다. 구글 직원들은 에이전트 스페이스 없이는 일할 수 없을 정도의 높은 생산성을 경험하고 있다고 한다.</li>
  <li><strong>생산성 향상 경험</strong>: 과거에는 비효율적으로 일했지만 그 당시에는 인지하지 못했던 부분들이 에이전트를 사용하면서 명확해졌다. 한 번 에이전트를 사용하면 예전 방식으로 돌아가기 매우 어렵다는 점이 강조되었다. 예를 들어, ‘노트북LM’과 같은 에이전트 기술을 통해 방대한 데이터를 기반으로 자연어 대화 및 질의응답이 가능해지면서 자료를 찾아보는 시간을 대폭 절약할 수 있다.</li>
  <li><strong>에이전트가 그릴 미래</strong>: 에이전트가 많은 시간을 절약하고 업무를 대신하면서, 인간의 역할은 관리 감독, 결과 판단, 의사 결정 등으로 변화할 것이다. 인간은 에이전트의 역량을 자신의 역량으로 받아들여 더 많은 일을 할 수 있는 ‘강화형 인간’이 될 수 있다. 미래에는 단순 작업을 수행하는 에이전트를 넘어 에이전트를 관리하거나 다른 에이전트들의 상호 작용을 조율하고 학습하여 개선하는 ‘메타 에이전트’로 발전할 가능성이 있다. 궁극적으로 기업의 업무 생산성은 상상할 수 없는 수준으로 올라가 핵심 의사 결정이나 중요한 태스크에 시간을 집중할 수 있게 될 것이 예상된다.</li>
  <li><strong>에이전트 스페이스의 딥 리서치 기능</strong>: 에이전트 스페이스는 기업형 제품으로, 사용자가 가진 데이터 소스를 기반으로 딥 리서치를 수행한다. 예를 들어, 최근 AI 동향 조사를 요청하면 1분에서 10분 이내에 보고서를 생성할 수 있는데, 이는 사람이 며칠 또는 몇 주가 걸릴 일을 단축하는 것이다. 이를 통해 업무량은 늘어나더라도 더 어렵고 복잡한 일을 맡아 유능한 직원이 될 수 있다.</li>
  <li><strong>기업의 에이전트 도입 판단 기준</strong>: 에이전트 도입은 이미 많은 기업에서 생산성 도구로서 논의가 시작된 단계이며, ‘시기상조’인 기업은 거의 없다. 특히 인사, 재무, 백 오피스 지원 프로세스 등 명확한 ‘페인 포인트(Pain Point)’를 가진 기업은 에이전트 스페이스를 빠르게 테스트해보고 업무 효율성을 경험할 수 있다.</li>
  <li><strong>에이전트와 조직 변화</strong>: 에이전트 도입은 업무 프로세스를 자동화하여 위임하는 과정을 통해 이루어지며, 사람의 역할은 관리 감독과 판단 및 의사 결정으로 변화한다. 조직 관점에서는 중간 관리자의 취합 및 보고 업무가 자동화되어, 사람들은 관리보다는 실제 일하는 인력으로서 수평적인 역할을 하게 될 가능성이 있다. 또한, 마케팅, 영업, 크리에이팅 등을 혼자서도 할 수 있게 되어 1인 기업과 같은 새로운 기업 유형이 많이 생겨날 것으로 예상된다.</li>
  <li><strong>변화 관리의 중요성</strong>: 새로운 도구와 기술 도입에 있어 ‘변화 관리’가 가장 중요하다. 기업의 임원부터 실무자까지 모든 직무와 레벨에서 지원이 필요하며, 이를 위해 각 부서의 ‘챔피언’을 양성하여 에이전트의 성공 경험을 만들고 내부적으로 전파해야 한다.</li>
  <li><strong>에이전트 활용 분야</strong>: 에이전트는 반복적이고 정형화된 업무 프로세스를 가진 직무나 분야에 가장 먼저 도입될 수 있다. 일반적인 사무직 업무, 예를 들어 이메일 교환을 통한 가격 취합 및 계약서 작성 지원 등이 해당된다. 반면, 영업과 같이 다양한 감정 교류, 비언어적 의사소통, 눈치 싸움이 필요한 분야나 한 번의 잘못된 의사 결정이 큰 영향을 미치는 업무(예: 국가 지도자의 역할)에서는 에이전트가 완전히 대체하기 어렵다. 이러한 영역에서는 에이전트가 도움은 줄 수 있으나, 최종 의사 결정은 사람이 해야 한다.</li>
  <li><strong>에이전트 보안 및 신뢰성 확보</strong>: 구글은 에이전트 시스템의 보안을 다각도로 접근하고 있다. 인프라 측면에서는 모든 네트워크 통신과 데이터 사용이 암호화된 보안 채널을 통해 이루어진다. 또한, ‘IAM(Identity Access Management)’을 통해 누가 어떤 정보에 접근할 수 있는지를 세분화하여 관리하며, 에이전트 스페이스는 개개인의 접근 권한을 물고 들어와 각 직무나 팀에 따라 안전하게 정보를 검색하고 업무를 수행할 수 있는 엔터프라이즈 환경을 제공한다. 구글은 이러한 보안 측면에서 큰 사고가 발생한 적이 없다는 점을 강조한다.</li>
  <li><strong>에이전트 생태계의 미래</strong>: 에이전트가 할 수 있는 일은 지능과 툴 통합을 통해 계속 늘어날 것이다. 미래에는 사람들이 에이전트를 사용하는지조차 의식하지 못하고 공기처럼 자연스럽게 생활의 기반 기술처럼 사용하게 될 가능성이 크다. 직업 생태계는 에이전트와의 협업을 통해 변화하며, 에이전트가 마치 다른 부서처럼 여겨질 수도 있다. 멀티모달리티의 대세화로 AI와의 상호작용이 증가할 것이며, 스마트폰의 앱 생태계처럼 특정 태스크를 해결하는 다양한 에이전트들이 등장하는 ‘에이전트 생태계’가 열릴 것이다. 이 생태계에서는 책임감 있고 안정적인 에이전트 배포가 중요한 쟁점이 될 것으로 예상된다. 이러한 변화는 매우 빠르게 다가오고 있다고 예측된다.</li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>오늘 후반부의 내용은 정신이 번쩍 뜨이는 대목이었다.</p>

<p>첨단 기업의 ‘첨단’ 이란 말이 어떤 건지 새삼 깨달았다.</p>

<p>언론에서는 다양한 AI 관련된 소식을 빠르게 전한다고 하지만, 생각해보면 그러한 기술은 결국 엔드 유저의 관심을 사기 위한 것들이지, 실제 기업의 위치를 가르쳐주지는 않는 다는 내 나름의 오랜 깨달음을 알고 있었음에도 다시 한 번 뒤통수를 맞은 느낌이었다.</p>

<p>에이전트 플랫폼의 활성화, B2B 시장에만 열려 있는 Agent Space, 그리고 이를 준비하기 위한 ADK 와 노코드 툴.</p>

<p>세상의 AI의 등장과 흐름은 이미 시작된지 오래였고, 구글의 준비는 사실 언론이나, 커뮤니티의 정도를 이미 뛰어 넘었구나- 라는 생각을 했다.</p>

<p>백엔드 개발자이자, AI 개발자로 성장을 꿈꿔오고 있지만, 그런 것에 비하면 실제 비즈니스 시장과 구글과 같은 기업들이 어디까지 계획과 상황을 고려하고 있는지를 보면, 정말 침착하게, 대신 치열하게 준비해야 하는 것인지, 새삼 느낄 수 있었다.</p>

<p>이런 상황의 대처, 준비, 기업이 꿈꾸는 형태를 모르는데 어떻게 전문가가 될 수 있겠는가? 그리고 거기서도 핵심 기술로 보이는 ADK 와 같은 것들, 파이썬과 자바를 제대로 다시 공부하는게 필요하고, 그렇게 해서 ADK 적 방법론을 제대로 배워야 할 것이라 생각한다.</p>

<p>Human-in-the-loop 키워드를 비롯해서, adk, 플랫폼이 되는 언어 python 에 대한 키워드 등… 대응해야할 키워드가 보다 선명해지는 것이 느껴진다.</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry></feed>