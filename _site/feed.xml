<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/" rel="alternate" type="text/html" hreflang="ko" /><updated>2025-08-05T03:30:04+00:00</updated><id>http://0.0.0.0:4000/feed.xml</id><title type="html">Paul’s Archives</title><subtitle>성장하는 개발자, 소통하는 개발자, 빠른 적용을 최 우선으로 삼는 개발자. 다음을 항상 생각하며, 개발 속에서 가치를 만들어내는 것을 목표로 합니다.</subtitle><author><name>Paul2021-R</name></author><entry><title type="html">AI Breakfast Ep 11 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/08/05/AI-trend-with-google-11.html" rel="alternate" type="text/html" title="AI Breakfast Ep 11 생각정리" /><published>2025-08-05T00:00:00+00:00</published><updated>2025-08-05T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/05/AI-trend-with-google-11</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/05/AI-trend-with-google-11.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=P7TzvAJ6n_w"><img src="https://i.ytimg.com/vi/P7TzvAJ6n_w/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>이번 내용은 AI와 대규모 언어 모델(LLM)이 코딩 및 개발자 역할에 미치는 영향, 그리고 현재의 한계와 미래 전망에 대한 논의이다.</p>

<ul>
  <li><strong>대규모 언어 모델(LLM)과 코딩의 미래</strong>:
    <ul>
      <li>LLM은 기존 자연어 처리(NLP) 솔루션과 달리 <strong>단일 모델로 다양한 NLP 작업을 수행할 수 있으며</strong>, 수 테라바이트의 레이블 없는 데이터로 학습된 <strong>기초 모델</strong>이다.</li>
      <li>현재의 구조화된 프로그래밍 언어는 LLM에 비적합하며, 미래에는 <strong>자동 회귀(auto-regressive) 방식으로 한 줄씩 진화하는 새로운 프로그래밍 언어가 등장할 수 있다</strong>고 예상된다. 이는 토큰 사용량을 대폭 줄일 것이다. =&gt; 이 인사이트는 염두해 둬야 하는, 어쩌면 개선해야할 AI 영역일 것임.</li>
      <li>LLM은 언어를 ‘이해’하는 것이 아니라 학습된 패턴을 기반으로 <strong>다음에 올 가장 확률 높은 토큰을 예측하는 정교한 수학적 함수</strong>이며, 트랜스포머 아키텍처와 어텐션 메커니즘을 사용한다.</li>
    </ul>
  </li>
  <li><strong>개발자의 역할 변화와 비즈니스 영향</strong>:
    <ul>
      <li>먼 미래에는 개발자 직업이 사라질 수 있다는 예측에 동의하며, 5년 이내에도 개발 인력이 크게 줄어들 수 있다고 보았다.</li>
      <li>LLM은 개발자의 <strong>생산성을 10배 이상 향상</strong>시켜, 개발자가 기획보다 빠르게 결과물을 내놓는 시대로 전환시키고 있다.</li>
      <li>코딩은 상품화를 위한 중간 과정이며, <strong>AI를 통해 대체 가능한 부분</strong>으로 여겨진다.</li>
      <li>앞으로는 큰 도메인 지식을 갖춘 <strong>‘빅픽처 전문가’ 또는 ‘프로덕트 엔지니어’가 중요</strong>해질 것이며, AI에게 명확한 요구사항을 전달하는 능력이 핵심이다.</li>
      <li>비개발자들도 코딩에 참여하는 <strong>개발의 ‘민주화’ 현상</strong>이 나타나고 있다.</li>
      <li><strong>인간과 기술은 공존해야 하며</strong>, AI를 받아들이고 경험하는 정도가 개인의 대체 여부를 결정하는 중요한 요소이다.</li>
    </ul>
  </li>
  <li><strong>바이브 코딩의 실제 적용과 한계</strong>:
    <ul>
      <li>바이브 코딩은 <strong>빠르게 데모를 만들고 결과물을 검증하는 데 효과적</strong>이다.</li>
      <li>그러나 <strong>보안이 매우 취약할 수 있어</strong> 금융 등 중요한 분야에서는 도입에 거부감이 크다.</li>
      <li>큰 범위의 프로젝트에는 아직 적용하기 어렵다.</li>
      <li>AI가 생성한 코드는 방대하여 인간이 리뷰하기 어렵고, <strong>AI 생성 코드에 대한 신뢰도가 아직 높지 않다</strong>.</li>
      <li>LLM의 한계로 인해 복잡한 문제 해결 시에는 <strong>인간이 직접 고치는 것이 더 빠르다</strong>.</li>
      <li>LLM은 학습된 지식 내에서만 작동하며 <strong>메타인지 능력이 부족하여 새로운 지식에 대한 업데이트나 함수 생성에 어려움</strong>이 있다.</li>
      <li>정확한 결과물을 얻기 위해서는 <strong>요구사항을 아주 세분화하여 명확하게 설계하고, 테스트를 잘 작성하는 능력</strong>이 중요해졌다.</li>
      <li>생성된 코드를 다시 설계 문서 등으로 <strong>‘리버스 엔지니어링’하여 저장하고 관리하는 방식</strong>이 활용될 수 있다.</li>
      <li>사용자는 <strong>‘프롬프트 문해력’을 길러야</strong> 하며, 생성된 결과를 올바르게 이해하고 검증해야 한다. =&gt; 결국 프롬프트 문해력이란것이 무엇인가? 프롬프트를 잘 작성한다는 게 무엇인가? 를 이해해야 한다.</li>
    </ul>
  </li>
  <li><strong>결론 및 시사점</strong>:
    <ul>
      <li>LLM 시대에는 <strong>인간의 도메인 지식과 노하우, 그리고 비판적 사고가 더욱 중요</strong>해지며, LLM의 명확한 한계를 인지하고 이를 보완하는 것이 필요하다.</li>
      <li>개개인은 <strong>‘언어의 경계가 곧 세계의 경계’라는 철학자의 말처럼</strong>, 어떤 언어(프롬프트)를 구사하느냐에 따라 자신의 가능성이 달라지므로, <strong>무한히 도전해 볼 것</strong>이 권장된다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>Gemini 의 성능을 약간 보여주는 화 같아서(물론 그래도 잘 만들긴 하더라 ㅋㅋ), 핵심적인 내용들, 개발자로 가져야 하는 태도에 대해 다시 한번 생각해본 시간이었다.</p>

<p>여전히 한계로 지적되는 부분, 즉 구조적으로 현 AI 는 코딩을 하기에 효율적인 도구가 아니고, ‘효율적인 척’ 하면서 GPU 를 녹이고 있다는 사실을 다시 한 번 강조했다.</p>

<p>생각해보면 그정도로 자기 회귀적으로 진행되는 구조로 가는 건 어쩌면 모든 점에서 더 나을 건데, 과연 그런 형태의 예측이나, 알고리즘 개선이 되는지는 잘 모르겠다는 생각이 든다. (수알못이라…)</p>

<p>어쨌든 모델의 개선도 지속적으로 이루어지고 있으니, 어쩌면 그러한 부분까지 언젠가는 개선이 되지 않을까 하는 생각은 해본다. 메타가 거의 백억단위 연봉을 주며 개발자를 데려가고 AGI 그 이상의 초 인공지능을 만들겠다고 하니, 결국 AI 는 양과 질의 향상이 계속 될 것은 맞고, 그런걸 실현 가능한 사람이 되는게 1티어 급 인사가 되는 길이 아닐까?</p>

<p>어쨌든, 일단 현 개발자라는 차원에서 본다면 사용 방법에 대해, 내 방법이 틀린게 아니었구나 ~ 하는 생각이 들었다.</p>

<p>무조건 맡기는 식으론 매우 위험하고, MVP 그 이상으로 빠르게 구현이 되지만 보안의 문제는 확실하게 존재한다. 더불어 회사가 그걸 용인해주는 곳인가? 여러 면에서 편리함, 효용성에 +로 고려할 것을 미리미리 고려하는 것은 매우 중요한 부분이라고 생각된다.</p>

<p>어쩌면 나만의 검증 절차를 AI 로 체계화 하는 것, 그리고 그걸 내 작업 루틴에 넣는 것이 포함되면 좋지 않을까? 하는 생각을 하게 된다. 그리고 그걸 종합해서 적절하게 코드 리포트 형태로 만든다거나 하는 것도 괜찮지 않을까?</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI Breakfast Ep 10 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/08/04/00-AI-trend-with-google-10.html" rel="alternate" type="text/html" title="AI Breakfast Ep 10 생각정리" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/04/00-AI-trend-with-google-10</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/04/00-AI-trend-with-google-10.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=AuviDcSne9g"><img src="https://i.ytimg.com/vi/AuviDcSne9g/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>

<p>9화는 AI 와 관련된 특정 주제에 대한 내용이었기에 생략하고 10화 내용을 기반으로 요약해본다.</p>

<ul>
  <li><strong>AI 발전과 바이브 코딩의 등장</strong>: AI 기술은 하루가 다르게 빠르게 발전하며, 이 가운데 ‘바이브 코딩(vibe coding)’이 가장 뜨거운 아이템으로 주목받고 있다.</li>
  <li><strong>바이브 코딩의 의미와 확산</strong>: 바이브 코딩은 AI가 내놓은 답을 <strong>즉흥적으로 수용하여 원하는 결과물을 만들어내는 방식</strong>이다. 한국에서는 ‘입코딩’이나 ‘손코딩’이라고도 부른다. 2023년 초 인도 개발자가 AI로 가벼운 비행기 게임을 만들어 월 5만 달러 수익을 올린 사례가 바이럴되며 시작되었고, Andrej Karpathy가 X(트위터)에서 이 용어를 사용하며 확산되었다. 이 단어는 2025년 3월 Merriam-Webster 사전에 ‘유행하는 속어’로 등재될 예정이기도 하다. 박찬성 연구원의 바이브 코딩 관련 게시물이 데미스 허사비스(DeepMind CEO)와 제프 딘(Google AI Research 수장)의 리트윗과 좋아요를 받으며 <strong>AI 거장들의 인정</strong>을 받았다.</li>
  <li><strong>아이디어의 중요성 증대</strong>: 생성형 AI의 발전으로 초기 PoC(개념 증명) 수준의 아이디어 구현 비용이 크게 낮아졌다. 이는 <strong>특정 도메인 전문가의 전문 지식을 바탕으로 한 아이디어 자체의 중요성과 가치</strong>를 더욱 높이는 결과를 가져왔다. 박찬성 연구원이 자신의 네트워크 전문 지식을 녹여낸 바이브 코딩 결과물이 바이럴된 것이 좋은 예시이다.</li>
  <li><strong>바이브 코딩에 필요한 역량</strong>:
    <ul>
      <li><strong>반복(Iteration)</strong>: 프롬프트 엔지니어링에서 반복은 매우 중요한 요소이다. 확률에 의거하여 나오는 결과 도출이라는 기반을 가지기 때문에, 요구 사항에 대해 여러번의 반복은 그만큼 높은 확률로 좋은 결과물을 만들어낼 가능성이 생긴다.</li>
      <li><strong>시행착오와 집요함</strong>: 원하는 결과물이 나올 때까지 AI에 끊임없이 시도하고 개선하는 ‘시행착오(trial and error)’와 집요함이 중요하다.</li>
      <li><strong>전문 지식</strong>: 기존 개발 지식이나 특정 분야의 전문적인 키워드를 아는 것이 AI에게 정확한 요구사항을 전달하고 생산성을 높이는 데 매우 유용하다.</li>
      <li><strong>호기심과 흥미</strong>: AI 코딩에 대한 호기심과 즐거움을 느끼는 것이 시작의 중요한 단계이며, 자신이 무엇을 좋아하고 잘하는지를 알아가는 과정이 필요하다.</li>
    </ul>
  </li>
  <li><strong>개인 맞춤형 도구 개발 시대</strong>: 이제는 개인이 자신에게 최적화된 도구를 직접 개발하여 사용하는 시대가 도래하고 있다. 강수진 박사는 시중에 있는 도구들이 자신의 작업 환경에 맞지 않아 <strong>프롬프트 엔지니어링 실험을 위한 플레이그라운드를 직접 만들어 사용</strong>하고 있다고 언급했다.</li>
  <li><strong>프롬프트와 프로그래밍 역량의 미래</strong>:
    <ul>
      <li>자연어 엔지니어 관점에서는 ‘의미론적 응축(Sementic Condensation)’이나 ‘단어 대체(Word Substitution)’를 통해 핵심 의미를 압축하고 제어하는 기술이 활용될 수 있다.</li>
      <li>현재 AI는 개발자들이 사용하던 용어, 일반인들이 기존에 사용하던 언어 기반인 만큼, 바이브 코딩을 수행함에 있어 개발적 지식이 필요하거나, 단어가 필요시 될 수 있다. 하지만 이것 조차도 학습을 통해 개선될 수 있다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>바이브 코딩. 이제는 너무 익숙해진 단어이다. 하지만 동시에 여전히 중요하고, 이제는 개발의 중심에 침입하였고, MCP, A2A 를 만나면서 그저 간단하게 질문에 답을 한다 에서 실제 수행을 한다 라는 차원의 영역으로 발전하고 있다.</p>

<p>오늘의 내용은 어쩌면 보편적인 바이브코딩이라는 행위를 평가하는 간단한 내용이기는 했다.</p>

<p>그러나 동시에 전문가들의 이야기에서 그럼에도 인사이트로 얻을 수 있는 영역은 있었다.</p>

<p>예를 들어 한 개발자 분이 네트워크에 대한 시뮬레이터를 만들었다던지 하는 것들은, 상당히 인상 깊었고, 프롬프트 엔지니어링 전문가로 나온 패널은 자신이 직접 만든 프롬프터 테스터를 보여주었다.</p>

<p>그리고 한 마디 더 걸치니, ‘개발 지식이 있는 사람과 일반인의 개발의 차이’를 언급한 부분이다.</p>

<p>바이브코딩을 할 때 개발 지식은 보다 정확한 지시가 가능하다. 하지만 개발 지식의 부재는 어쩔 수 없이 동작 방식을 묘사해야하고, 그 묘사는 결국 확률적으로 어떤 구현 대상에 대해 100% 지목하는게 아니라 ‘가능성’으로 표현할 뿐인거고, 거기서 잘못된 지식이 있다면 이는 비효율적 개발이 이루어질 수 있다.</p>

<p>하지만 기술을 이해하고, 단어를 정확하게 아는 경우, 그 지식은 좀더 명확한 전달, 명확한 결과를 만들 수 있다.</p>

<p>AI 에 대해 명령을 내릴 때 언어적 방법에 대해 체계화가 잘 된 경우 명령을 잘 내리지만, 동시에 빼놓지 말고 기억해야 하는 부분이 있다면 역시나 도메인.</p>

<p>물론 개발자도 언급하길 바이브 코딩을 하는 과정을 통해 또 다시 AI 가 학습할 것들이 생성되고, AI 가 그걸 이해하고 다시 학습된 데이터를 기반이 된다면 더 찰떡같이 알아먹게 되겠지만</p>

<p>현재 가장 필요한 영역이자, 바이브 코딩을 제대로 내 무기화 하려면 필요한 것은 결국 ‘내 분야’ 혹은 ‘전문 지식’의 체계적인 내재화라는 생각은 이번 편을 통해 보다 선명하게 기억하게 되었다.</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">트랜스포머, AI 를 이해해보자</title><link href="http://0.0.0.0:4000/ai/2025/08/04/01-transformer-gpt-deepSeek-introduction.html" rel="alternate" type="text/html" title="트랜스포머, AI 를 이해해보자" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/08/04/01-transformer-gpt-deepSeek-introduction</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/08/04/01-transformer-gpt-deepSeek-introduction.html"><![CDATA[<h2 id="개요">개요</h2>
<p>현재 인공지능(AI) 기술 발전의 핵심에는 <strong>트랜스포머(Transformer)</strong> 아키텍처가 있으며, 2017년 구글의 ‘Attention Is All You Need’ 논문을 통해 소개된 이후 오늘날 가장 널리 사용되는 AI 모델 구조가 되었다. <strong>챗GPT(ChatGPT)</strong>의 ‘GPT’는 ‘Generative Pre-trained Transformer’의 약자로, 방대한 데이터를 통해 사전 학습된 트랜스포머 모델임을 의미한다. 트랜스포머 모델은 텍스트 번역을 넘어 이미지 생성, 음성 변환 등 다양한 AI 분야에 활용되며, 다음 단어나 내용을 예측하는 방식으로 작동한다. 몇 개의 단어를 입력하면 모델이 다음 단어를 예측하고, 그 예측된 단어를 다시 입력으로 사용하여 반복적으로 긴 문장을 생성할 수 있다.</p>

<p>AI 기술의 발전 속도는 전례가 없는데, AI 사용자 및 사용량 증가는 인터넷보다 훨씬 빠르게 나타나고 있으며, 관련 자본 지출(CapEx) 또한 급증하고 있다. ChatGPT는 불과 5일 만에 100만 사용자를 확보하며 역사상 가장 빠른 사용자 채택을 기록했다.</p>

<p>오늘은 이러한 내용들을 정리해보면서, GPT에서 시작해 DeepSeek 까지의 발전 과정을 조금(?) 훑어 보려고 한다. 문돌이 입장에서 AI 의 힘을 여실히 빌려서 만든 내용이긴 하지만 AI 를 좀더 깊게 이해하고 싶은 모든이들에게 도움이 되길 기원한다.</p>

<h3 id="llmlarge-language-model의-개요">LLM(Large Language Model)의 개요</h3>

<p><img src="/assets/images/posts/2025-08/2025-08-04-001.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/ko/llms/">Microsoft AI Tour</a></p>
</blockquote>

<p><strong>대규모 언어 모델(Large Language Model, LLM)</strong>은 주어진 텍스트가 있을 때 다음에 올 단어를 예측하는 매우 정교한 수학적 함수이다. 더 정확하게는, 딱 하나의 단어를 확정적으로 예측하는 대신 다음에 올 단어들에 대한 확률을 계속해서 구하는 함수이다.</p>

<ul>
  <li><strong>작동 방식</strong>: LLM은 몇 개의 단어를 입력으로 받아 다음 단어를 예측하고, 그 예측된 단어를 다시 입력으로 사용하여 반복적으로 긴 문장을 생성한다. 이는 챗GPT와 같은 모델과의 대화가 한 단어씩 생성되는 방식으로 이루어지는 이유이다.</li>
  <li><strong>학습 데이터</strong>: LLM은 인터넷에서 수집한 엄청난 양의 텍스트 데이터로 학습된다. 예를 들어, GPT-3가 학습한 텍스트 양은 사람이 24시간 쉬지 않고 읽었을 때 2,600년 이상이 걸릴 것이며, 요즘 모델들은 훨씬 더 많은 데이터로 훈련된다.</li>
  <li><strong>파라미터(매개변수) 및 훈련</strong>: 모델 속의 수많은 다이얼(파라미터 또는 가중치)을 조정해가며 학습이 이루어진다. LLM은 수백억 개에서 수천억 개까지 이르는 파라미터를 가지고 있으며, 처음엔 랜덤하게 설정된 이 값들이 훈련을 반복하며 점차 그럴듯한 예측을 할 수 있도록 조정된다.
    <ul>
      <li><strong>역전파(Backpropagation)</strong>: 훈련 시 마지막 단어를 제외한 나머지를 모델 입력으로 넣고, 모델이 마지막 단어를 어떻게 예측하는지 확인한 후, 그 예측이 정답에 가까워지도록 파라미터를 조정하는 알고리즘이다.</li>
      <li><strong>강화 학습(RLHF)</strong>: 사전 훈련된 모델은 사람이 모델의 잘못된 응답을 직접 수정하거나 더 나은 응답을 골라주는 RLHF(Reinforcement Learning from Human Feedback)와 같은 강화 학습을 통해 추가 학습된다.</li>
    </ul>
  </li>
</ul>

<h3 id="llm의-속성을-이해하자">LLM의 속성을 이해하자</h3>

<h4 id="llm-vs-nlp">LLM vs NLP</h4>
<p>기존 자연어 처리의 기술과 LLM 이 다른 점은 다음과 같이 설명할 수 있다.</p>

<ul>
  <li>기존 NLP 는 기능 당 하나의 모델이 필요하다.</li>
  <li>기존 NLP 는 한정된 레이블 데이터 셋에서 학습을 시킨다. (예시, 특정 물체 인식 AI 를 위해 특정 물체의 사진을 수십만장 준비한다.)</li>
  <li>기존 NLP 는 특정 사용 사례에 고도로 최적화 된다.(예시, 특정 물체의 데이터셋으로 학습된 특화 모델)</li>
</ul>

<p>그러나 LLM은</p>

<ul>
  <li>여러 NLP 사용 사례에 단일 모델 사용이 가능하다(범용적이다).</li>
  <li>수 TB 에 달하는 레이블이 없는 데이터에서 학습된 모델이다(기초).</li>
  <li>개방형 사용 - 자연어를 사용하여 모델에 무언가를 ‘프롬프트’ 하도록 한다. 즉 자연스럽게 다양한 질문을 할 수 있고, 모델이 이에 맞춰 콘텐츠를 생성해 낸다.</li>
</ul>

<h4 id="llm-이-하지-못하는-것은">LLM 이 하지 못하는 것은?</h4>
<p>대규모 언어 모델은 강력한 생성형 AI 경험을 제공하고, 이 콘텐츠의 범용성은 지금의 AI 상황의 판도 자체를 뒤집어 엎는 일을 만들어 냈지만, 그 표현, 행위가 다음은 아니라는 사실을 명확히 해야 한다.</p>

<ol>
  <li><strong>언어를 이해한게 아니다</strong> : LLM은 예측 엔진, 예측 함수셋에 가깝기에 이것이 해당 콘텐츠의 문맥이나 의미를 이해한 거라고 말할 수 없다.</li>
  <li><strong>사실을 이해하지 못한다</strong> : <code class="language-plaintext highlighter-rouge">정보 검색</code>, <code class="language-plaintext highlighter-rouge">창의적 글쓰기</code>를 위한 별도의 모드가 있는 건 아니고, 진행중인 시퀀스에서 다음으로 가능성이 높은 토큰을 예측하는 것이기에, 그것이 ‘사실’이냐 ‘주장’이냐와 같은 해석은 LLM 자체에서는 무의미하다.</li>
  <li><strong>매너, 감정, 또는 윤리를 이해하지 못한다</strong> : 인간이 설계하고 설정한 데이터, 프롬프트에 의해 최적의 예측값을 ‘보정한’ 결과이지, 모델이 매너나 감정, 윤리를 이해하고 동작하는 것이 아니다. 결과적으로 LLM 은 통계적 패턴의 예측의 연속이며, 인간처럼 문장의 의미, 맥락을 이해하는 것이 아니다.</li>
</ol>

<h3 id="트랜스포머의-핵심-개념">트랜스포머의 핵심 개념</h3>

<p>트랜스포머는 텍스트를 처음부터 끝까지 순차적으로 읽는 대신, <strong>전체 문장을 한꺼번에 병렬로 처리한다</strong>. 이 과정에서 문장 내 각 단어는 AI가 이해할 수 있는 숫자 벡터로 변환되어 서로의 관계성을 알 수 있게 된다.</p>

<ul>
  <li><strong>토큰(Token)</strong>:
    <ul>
      <li>트랜스포머는 입력된 문장이나 데이터를 <strong>토큰</strong>이라는 작은 조각으로 나누어 처리한다.</li>
      <li>텍스트의 경우, 단어나 단어의 일부, 또는 일반적인 문자 조합이 토큰이 될 수 있다.</li>
      <li>이미지나 음성이 포함될 때는 그 이미지의 작은 조각이나 음성의 작은 부분이 토큰이 될 수 있다.</li>
    </ul>
  </li>
  <li><strong>벡터(Vector) 및 단어 임베딩(Word Embedding)</strong>:
    <ul>
      <li>각 토큰은 해당 부분의 의미를 담도록 설계된 숫자 목록인 <strong>벡터</strong>와 연결된다. 이 벡터들은 고차원 공간의 좌표로 생각할 수 있으며, 의미가 비슷한 단어들은 그 공간에서 가까운 벡터로 배치되는 경향이 있다.</li>
      <li>예를 들어, GPT-2에서는 768차원, DeepSeek R1에서는 7,168차원의 벡터가 단어 하나를 표현하는 데 사용된다.</li>
      <li>훈련 과정에서, 모델은 학습을 통해 공간 속의 방향들이 어느 정도 의미를 가지도록 벡터를 정리한다. 예를 들어, ‘여자’와 ‘남자’ 사이의 벡터 차이가 ‘왕’과 ‘여왕’ 사이의 차이와 유사하게 나타날 수 있다. 이러한 차이 벡터 사이의 차이는 단어들 사이의 관련성이나, 어떤 특성을 나타낼 수 있다. 성의 차이, 복수와 단수의 차이 등 이러한 특성을 수학적 - 수치적으로 이해한 것이다.</li>
    </ul>

    <p><img src="/assets/images/posts/2025-08/2025-08-04-002.png" alt="" /></p>
    <blockquote>
      <p>단어 사이의 관계성이 벡터 사이의 간격으로 이해가 될 수 있다. 출처 : <a href="https://youtu.be/g38aoGttLhI?si=9zdFBTN0cv1ncJ-r">3Blue1Brown 한국어</a></p>
    </blockquote>
  </li>
  <li><strong>어텐션(Attention)</strong>:
    <ul>
      <li>트랜스포머의 핵심 연산으로, 입력된 벡터들이 ‘어텐션 블록’을 통과하며 서로 정보를 주고받고 값을 업데이트하는 과정이다. 이는 문맥을 파악하기 위해 단어들 간의 유사성을 계산하는 방식이다.</li>
      <li><strong>쿼리(Query), 키(Key), 밸류(Value)</strong>: 어텐션은 <strong>‘쿼리(Query)’, ‘키(Key)’, ‘밸류(Value)’</strong>라는 세 가지 개념을 통해 구현된다. 입력된 단어들(벡터 X)은 각각 고유한 학습 가능한 가중치 행렬(WQ, WK, WV)과 곱해져 쿼리 행렬, 키 행렬, 밸류 행렬로 변환된다. 단 이 개념이 별개의 정보라기 보단 결국 벡터 X 에서 나온다는 점은 명확하게 인지해야 한다.
        <ul>
          <li><strong>쿼리(Query)</strong>는 하나의 ‘질문’ 역할을 한다.</li>
          <li><strong>키(Key)</strong>는 그 질문을 해결할 가능성이 있는 ‘열쇠’ 중 하나이다.</li>
          <li><strong>밸류(Value)</strong>는 어텐션 패턴에 따라 이동되거나 결합될 실제 정보의 ‘재료’이다.</li>
        </ul>
      </li>
      <li><strong>내적(Dot Product)</strong>: 쿼리가 키들과의 <strong>유사도</strong>를 계산하는 과정은 수학적으로 두 벡터의 <strong>내적</strong>으로 구현된다. 내적은 기하학적으로 벡터들이 비슷한 방향일 때 양수, 직교할 때 0, 반대 방향일 때 음수가 된다.</li>
      <li><strong>어텐션 패턴(Attention Pattern)</strong>: 모든 쿼리와 키의 유사도를 계산하여 얻는 종합된 정보이다. 이 어텐션 패턴의 크기는 <strong>입력 단어 수의 제곱에 비례하여 늘어난다</strong>. 훈련 과정에서는 다음에 올 단어를 ‘컨닝’하지 못하도록 어텐션 패턴의 오른쪽 윗부분이 가려진다.</li>
      <li><strong>소프트맥스(Softmax)</strong>: 유사도 계산 후, 각 행의 합이 0이 되도록 <code class="language-plaintext highlighter-rouge">정규화</code>하는 함수이다. 이 함수는 어떠한 숫자들의 나열이든 0과 1 사이의 값으로 변환하여 합이 1이 되는 <code class="language-plaintext highlighter-rouge">확률 분포</code>로 만들어준다. 가장 큰 값은 1에 가깝고 작은 값은 0에 가까워진다. 또한 <code class="language-plaintext highlighter-rouge">온도(Temperature)</code>라는 상수를 사용해 예측의 다양성을 조절할 수 있다. (이 온도는 열역학의 개념과 유사한 동작이기에, 그대로 차용했다.)</li>
      <li><strong>어텐션 헤드(Attention Head)</strong>: 어텐션 패턴 하나를 계산하는 단위를 ‘어텐션 헤드’라고 부른다. 여러 헤드가 각기 다른 쿼리, 키, 밸류 세트를 사용하여 독립적으로 패턴을 계산한 뒤, 이 값들을 종합하여 다음 레이어의 입력으로 사용한다.</li>
    </ul>
  </li>
  <li><strong>피드포워드 네트워크(Feedforward Network)</strong>: 트랜스포머 안에 포함된 또 다른 연산으로, 모델이 더 많은 언어 패턴을 저장할 수 있도록 돕는다.</li>
</ul>

<h3 id="트랜스포머의-연산량-문제와-기존-해결책">트랜스포머의 연산량 문제와 기존 해결책</h3>

<p>트랜스포머는 위에서 언급한 어텐션 헤드의 단위로 토큰이 아웃풋이 되고, 그것을 다시 인풋으로 집어넣는 것의 연속이다. 따라서 행렬의 엄청난 연산량을 요구한다는 문제가 있다. 어텐션 패턴의 크기가 입력 단어 수의 제곱에 비례하여 늘어나기 때문에, 몇 문장에서 시작해 책 한권 분량이 들어간다면 기하급수적이라는 것이 무엇인가를 알 수 있게 된다. 이러한 본질적인 구조로 CPU 연산이 아닌 GPU의 사용이 핵심일 수 밖에 없고, 동시에 GPU 의 사용이라 함은 막대한 전기 사용, 발열 등 ‘GPU가 녹는다’ 라는 말에 딱 부합하는 작업인 것이다. (물론 최신 AI 모델들, 특히 구글에선 TPU 를 활용하는 시도라던지, 다양한 시도가 있는 것은 사실이다.)</p>

<p><img src="/assets/images/posts/2025-08/2025-08-04-003.png" alt="" /></p>
<blockquote>
  <p>GPUs Are Melting: … 출처 : <a href="https://www.linkedin.com/pulse/gpus-melting-building-real-time-monitoring-systems-go-snehasish-dutta-cctbe/">SNEHASISH DUTTA</a></p>
</blockquote>

<p>이러한 비효율성을 줄이기 위해 개발된 핵심 기술이 <strong>키-밸류(Key-Value) 캐싱(KV Caching)</strong>이다.</p>
<ul>
  <li><strong>키-밸류 캐싱(KV Caching)</strong>: 이미 모델에 입력된 단어들의 쿼리, 키, 밸류 값은 다시 계산할 필요 없이 저장해두고 재활용하는 방식이다. 이 기술을 사용하면 어텐션 연산량이 단어 수에 선형적으로만 증가하도록 안정화되어 폭발적인 증가를 막는다.</li>
  <li><strong>저장 공간 문제</strong>: 그러나 KV 캐싱은 키-밸류 값을 저장하기 위한 막대한 저장 공간을 요구한다. 단어 하나당 키-밸류를 모두 저장하면 4MB를 차지하며, 10만 개의 단어를 처리할 경우 무려 400GB에 달하는 저장 공간이 필요할 수 있다.</li>
</ul>

<p>위의 내용에서 언급한 저장공간 문제에 대해 이해하기 위하여, 간략화된 캐시 항목의 수를 계산 식은 다음과 같이 표현된다.</p>

<p>$CacheCounter = 2 \cdot n \cdot d_h \cdot n_h \cdot l$</p>

<ul>
  <li>$n$ : 입력 토큰 수</li>
  <li>$d_h$ : 키/ 값 행렬의 차원</li>
  <li>$n_h$ : 레이어 당 어텐션 헤드 수</li>
  <li>$l$ : 레이어 수</li>
</ul>

<p>예를 들어</p>

<p>$let d_h = 128, n_h = 128, l = 61, n = 100000$ 
(DeepSeek R1/V3 아키텍쳐 기준)</p>

<p>$(2)(128)(128)(61)(2) = 3.998 * 10^6 Bytes/token = (approx)4MB/token$</p>

<p>$4MB/Token * 100000 tokens = 400GB$</p>

<p>이러한 저장 공간 문제를 해결하기 위한 이전 시도에는 두 가지 방식이 있었다:</p>
<ul>
  <li><strong>멀티-쿼리 어텐션(Multi-Query Attention)</strong>: 모든 어텐션 헤드가 동일한 키-밸류를 공유하는 전략이다. 이는 저장 용량을 크게 줄일 수 있지만, 각 헤드의 역할이 달라야 하는 점을 방해하여 모델 성능이 저하된다는 단점이 있다.</li>
</ul>

<p><img src="/assets/images/posts/2025-08/2025-08-04-004.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://youtu.be/w5f6mtg0sKQ?si=UMmhUPEorJk_oPAW">웰트랩스</a></p>
</blockquote>

<ul>
  <li><strong>그룹별 쿼리 어텐션(Grouped-Query Attention)</strong>: 멀티-쿼리 어텐션을 개선하여 어텐션 헤드를 여러 그룹으로 묶어 <code class="language-plaintext highlighter-rouge">같은 그룹</code>끼리 키-밸류를 공유하는 방식이다. 메타의 라마 3(Llama 3) 모델이 이 방식을 사용하여 저장 공간을 8배 절약했지만, 여전히 전체 헤드가 키-밸류를 저장하는 방식보다 성능이 못 미쳤다.</li>
</ul>

<p><img src="/assets/images/posts/2025-08/2025-08-04-005.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://youtu.be/w5f6mtg0sKQ?si=UMmhUPEorJk_oPAW">웰트랩스</a></p>
</blockquote>

<h3 id="deepseek의-혁신-multi-head-latent-attention">DeepSeek의 혁신: Multi-Head Latent Attention</h3>

<p><img src="/assets/images/posts/2025-08/2025-08-04-006.png" alt="" /></p>
<blockquote>
  <p>출처 : <a href="https://youtu.be/w5f6mtg0sKQ?si=UMmhUPEorJk_oPAW">웰트랩스</a></p>
</blockquote>

<p>이러한 상황에서 중국의 <strong>딥시크(DeepSeek)</strong>는 기존 AI 개발에 수천억 원이 들어가는 것을 고작 80억 원에 가능하다고 발표하며 세상을 놀라게 했다. 딥시크는 경쟁사의 모델을 모방했다거나 실제 개발 비용보다 축소 발표했다는 구설수가 있었으나, 모든 모델 웨이트와 코드, 그리고 12개에 달하는 디테일한 논문까지 모두 공개하며 그 기술력을 드러냈다.</p>

<p>딥시크의 핵심 기술은 저장 공간과 연산량이라는 두 마리 토끼를 모두 잡은 <strong>멀티-헤드 레이턴트 어텐션(Multi-Head Latent Attention)</strong>이다. 이 기술은 인공지능 압축과 효율의 핵심인 <strong>‘잠재 공간(latent space)’</strong> 개념을 적용했다.</p>

<ul>
  <li><strong>멀티-헤드 레이턴트 어텐션의 원리</strong>: 기존 멀티-헤드 어텐션에서 입력 X를 키-밸류로 만드는 중간에 <strong>압축하는 스테이지를 하나 추가한다</strong>. 모든 어텐션 헤드는 같은 잠재 공간을 공유하는데, 이는 멀티-쿼리 어텐션과 유사하게 저장 공간을 줄이는 데 효과적이다. 그러나 구체적인 값을 저장하는 대신, 각 헤드에서 압축된 잠재 공간으로 보내줄 가중치(Wv와 W)를 학습하는 문제로 바꾸어 <code class="language-plaintext highlighter-rouge">학습 과정</code>에서 실제 단일한 캐싱 전략으로 가서 용량을 줄이는 경우 보다 <code class="language-plaintext highlighter-rouge">더 많은 자유도</code>를 보장한다.</li>
  <li><strong>수학적 효율성</strong>: 기본적인 선형 대수의 원리를 활용하여, 훈련 시 합쳐진 모델 자체로 훈련하기 때문에 추론(inference) 상황에서 추가적인 연산이 필요 없다. 새로운 단어가 입력될 때도 쿼리 레이턴트를 만들고 저장해 둔 레이턴트 키-밸류를 사용하므로 효율적이다.</li>
  <li><strong>성능 개선</strong>: 이 덕분에 딥시크 R1은 키-밸류 캐시를 저장할 때 어텐션 헤드 개수가 아니라 공유된 키-밸류 캐시의 크기에만 영향을 받도록 설계되었다. 이는 <strong>토큰당 70KB만 사용하여 저장 공간을 57배나 줄였으며</strong>, 토큰 생성 속도를 <strong>6배 빠르게</strong> 만들었다. (참고로, 키-밸류 캐시를 모두 저장했다면 토큰당 4MB, 그룹별 쿼리 어텐션은 500KB를 필요로 했을 것이다). 이러한 트랜스포머의 알고리즘 개선은 기존보다 훨씬 빠른 토큰 생성을 가능케 한다는 점에서 주목할 만하다.</li>
</ul>

<h3 id="llm의-잠재력과-그-가치">LLM의 잠재력과 그 가치</h3>

<p>LLM 의 구조를 씹어먹어보고, 수학적 기초는 처음에는 대단히 어렵게 와닿았지만, 결국 단어들 사이의 예측, 입력이 다시 출력이 되고, 그 출력이 다시 입력이 된다는 이 구조에 대한 이해가 있게 되면 Transformer 와 LLM 의 아주 베이직한 표면의 이해에는 어렵지 않다.</p>

<p>하지만 거기에 더 많은 구조적, 효율적 개선, 그리고 LLM 의 보편성을 이용한 다양한 능력, 다시 특화 기능을 위한 모델로 학습하거나 아예 대형 모델을 기반으로 더 튜닝하는 SLM(Small Language Model)의 등장 등, LLM의 잠재력, 그리고 향후에도 지속적인 판도는 이어질 것이다.</p>

<p>이번 내용을 통해 좀더 LLM 을 실증적으로 이해하고, 특히나 DeepSeek 와 같은 개선의 여지가 여전히 있단 점들은, 앞으로 정말 AI를 거쳐 AGI 까지, 초 거대모델들의 성장 폭은 남아 있다는 점을 나름 생각해 볼 수 있는것 같다.</p>

<h3 id="참고-문헌">참고 문헌</h3>
<ul>
  <li><a href="https://www.youtube.com/watch?v=HnvitMTkXro">3BlueL1Brown 한국어 - LLM 설명(요약버전)</a></li>
  <li><a href="https://www.youtube.com/watch?v=g38aoGttLhI">3BlueL1Brown 한국어 - 트랜스포머, ChatGPT가 트랜스포머로 만들어졌죠. -DL5</a></li>
  <li><a href="https://youtu.be/w5f6mtg0sKQ?si=GDTi2tnoFc-SqZVh">웰츠랩스 - 딥시크의 +99 강화 트랜스포머 몽둥이</a></li>
  <li><a href="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/ko/">Microsoft AI Tour - Learn how to interact with OpenAI models</a></li>
</ul>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="생각정리" /><category term="LLM" /><summary type="html"><![CDATA[개요 현재 인공지능(AI) 기술 발전의 핵심에는 트랜스포머(Transformer) 아키텍처가 있으며, 2017년 구글의 ‘Attention Is All You Need’ 논문을 통해 소개된 이후 오늘날 가장 널리 사용되는 AI 모델 구조가 되었다. 챗GPT(ChatGPT)의 ‘GPT’는 ‘Generative Pre-trained Transformer’의 약자로, 방대한 데이터를 통해 사전 학습된 트랜스포머 모델임을 의미한다. 트랜스포머 모델은 텍스트 번역을 넘어 이미지 생성, 음성 변환 등 다양한 AI 분야에 활용되며, 다음 단어나 내용을 예측하는 방식으로 작동한다. 몇 개의 단어를 입력하면 모델이 다음 단어를 예측하고, 그 예측된 단어를 다시 입력으로 사용하여 반복적으로 긴 문장을 생성할 수 있다.]]></summary></entry><entry><title type="html">네이버 부스트캠프 AI Tech 8기 준비해보자</title><link href="http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/04/02-challange-naver-boost-ai-8th.html" rel="alternate" type="text/html" title="네이버 부스트캠프 AI Tech 8기 준비해보자" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/04/02-challange-naver-boost-ai-8th</id><content type="html" xml:base="http://0.0.0.0:4000/%EC%83%9D%EA%B0%81%EC%A0%95%EB%A6%AC/2025/08/04/02-challange-naver-boost-ai-8th.html"><![CDATA[<h2 id="들어가면서">들어가면서</h2>
<h3 id="ai-ai-ai">AI, AI, AI…</h3>

<p>AI의 혁신은 누군가에게는 큰 일이 아닐 수 있다.</p>

<p>물론, 온 나라에서, 전 세계가 떠들고 있는 입장에서 관심이 없는 사람이 없겠지만, 그럼에도 현실에선 AI를 아직 제대로 도입하지 않은 이들도 많고, 오히려 개발자들이 여전히 AI 에 대해 등한시 하는 이들도 있단 걸 보면… 새삼 여전히 AI 가 세상을 바꾼다는 생각 보단, 막연한 공포만이 존재하고, 실무에 적용, AI 기반화 된 곳은 많지 않다는 것을 느낀다.</p>

<p>피부에 온전히 <code class="language-plaintext highlighter-rouge">AI 네이티브</code> 라는 키워드가 어울리는 상황까지 도래 하진 않았다.</p>

<p>하지만 AI 의 파급력, 이미 그 수준과 활용 가능성은 훌륭하다. 리소스와 개발자만 충분하다면 AI, LLM 을 기반으로 하여 만들수 있는 것들의 수준, 자동화하기 어려운 것들에 대한 능동적 대응 등은 이미 사람 수준으로 충분히 구현이 가능하다. 국가 차원의 전략 병기 역할을 할 수 있다는 점에서 본다면 내가 다음 시대에서 적응하고 살기 위해 AI에 대한 역량이 없는 것은 결코 용납될 수 없다고 나는 생각한다.</p>

<p>거기다, 이런 거창한 이야기가 아니더라도 생각해보면 AI 덕에 나는 더 빠른 성장, 더 확실한 성장을 할 수 있었다.</p>

<p>내 아이디어나 내 생각을 구현화 하는데도 사람과 리소스가 드는 것을 AI 를 활용하면 10분의 1, 100분의 1로도 절감할 수 있다는 점은, 나의 삶에 새로운 도전, 새로운 기회를 줄 수 있다는 확신을 제공해준다. 그것을 누릴 준비, 써볼 준비를 이제는 해야 하지 않을까?</p>

<p>내가 단순히 백엔드 개발의 즐거움, 그 기술을 가지고 먹고 사는 것을 넘어서서 AI와 결합하여, 기업의 수요, 세상의 방향에서 아직은 내 수준으론 흐름을 쫓는 입장이지만, 언젠가 내가 그 흐름을 만들 수 있지 않을까? AI는 그걸 가능하게 만드는 ‘힘’이란 사실을 나는 한시도 잊고 산 적이 없다.</p>

<p><img src="/assets/images/posts/2025-08/2025-08-04-007.png" alt="" /></p>
<blockquote>
  <p>두둥</p>
</blockquote>

<p>그러는 와중에 퇴사를 하게 되었다. 정말 다양한 일들(…)을 겪었지만, 그 이야기는 나중에 한다 치고,</p>

<p>중요한 포인트는 42서울이라는 부트캠프를 통해 류한솔 버전 2가 될 수 있었고, 백엔드 개발자라는 타이틀을 얻을 수 있었다. 자잘한 성공과 실패를 거쳐 성공적으로 1년 이상을 생활했으며, 메인 서버라는 일을 빠르게 맡게 되어서 정말 백엔드 개발자로 해봐야할 기본적인 일들에 대해서는 A to Z 로 경험하는 것을 해 볼 수 있었다. 믿어주는 리더와 함께 3.0 버전으로 API 서버의 체계화, 업그레이드는 자랑할만한 성과가 아니었나 싶다.</p>

<p>기본 설계부터, API 대응, 서버의 관리나 서버 벤치마킹 및 분석, 요금 절감, 알람 시스템 구축이나 CICD에 무중단 배포까지. 곁다리로 ML 서버의 서빙과 관리, AI 개발까지 보조로 진행했으며, R&amp;D 연구까지 진행한 사실은, 1년 하고도 약 2개월의 시간, 나는 어떻게 성장 할 수 있었던가? 결론은 명확하다.</p>

<p><code class="language-plaintext highlighter-rouge">AI의 파워</code></p>

<p>AI를 통한 효율성의 증대, AI를 통한 개발에서의 문제의 사전의 확인, 백엔드 개발 구조에 대한 AI를 통한 검증이나 초기 조사 기간의 월등한 단축은 러닝커브가 있어야 하는 수 많은 기술들, 처음 경험하기에 생각과 다를 수 있는 영역 들에 보다 빠른 적응을 가능케 한다는 점이서 AI 는 정말 둘도 없는 선생님이자, 가이드 역할이었다고 나는 생각한다.</p>

<h3 id="성장도-방향도-ai">성장도 방향도 AI</h3>
<p>그러는 와중 백엔드 개발자에 대한 수요조사, 특히 내가갈 수 있는 1 ~ 3년차 사이의 주니어 개발자들에 대한 조사 이후 확실하게 얻은 기업이 요구하는 인재에 대한 인사이트는 다음과 같았다.</p>

<blockquote>
  <p>“Back End 도메인 역량을 결코 무시하지 말 것”</p>

  <p>“AI 키워드는 권장 그자체”</p>

  <p>1년 차는 CICD 까지의 흐름 이해 및 유지보수 경험</p>

  <p>3년 차는 CICD 의 구성 및 Kubernates 계열에 대한 배포 경험</p>
</blockquote>

<p>기업들의 AI 수요는 당연히 발생했다. AI라는 키워드를 통해 기존에 불가능하던 서비스의 활성화, 서비스의 고도화를 원하는 것은 당연했지만, 포인트는 거기서 회사들은 ‘어떤 인재’를 찾는가에 대한 내 나름의 특징을 발견했다는 것이다.</p>

<p>예를 들어 AI 전문 인력의 수요는 없지 않다. 분명히 전문가를 원했고, 당연히 석사 수준의 기초 바탕은 핵심이었다. 하지만 그런 자리의 갯수는 많지 않았다. 들려오는 이야기로 봐도, 오히려 소개받아 들어가는 자리에 대한 이야기는 있었지, 공개적으로 모집되는 글은 생각보다 많지 않았다.</p>

<p>곰곰히 생각해본 결과, 이는 ‘응용 서비스’에 가까운 이들에게 필요시 되는 AI 역량이라는 것이 생각보다 괴리감이 있다는 결론을 낼 수 있었다. AI에 전문성을 가진 완전 AI 전문 성향을 가진 수요가 아니라, 기존 도메인을 하면서도 AI 에 대한 준비가되어 있어서, 현실적으로 줄 수 있는 연봉과 AI 역량 사이의 벨런스, 기존 개발자들은 있거나, 그 수요를 하면서도 AI 가치를 가지고 있으면 좀더 고려한다- 라는 지극히 산술적 계산의 수요가 있던 것이다.</p>

<p><img src="/assets/images/posts/2025-08/2025-08-04-008.png" alt="" /></p>
<blockquote>
  <p>핵심은 역량의 ‘밸런스’</p>
</blockquote>

<p>생각해보면 그렇다. AI에 완벽히 특화된 인물들은 AI 베이스의 특화 기업, 투자가 확실하고, AI를 통해 수익을 내려는 기업, 대기업이라면 당연히 얼마를 주더라도 데려올 핵심 인재일 것이다. 하지만 현실의 모든 기업들은 그럴 상황이 아니란 것이다. 원티드를 비롯한 전통적인 구인구직 사이트, 개발자 특화 채용 플랫폼의 구인 탐색 결과 ‘필수’ 라곤 아니지만, ‘권장’이라는 항목에 AI와 관련된 능력이 전형적인 채용 역할들(프론트엔드, 백엔드)에 상당한 비중으로 포함되어 있던 것이다.</p>

<h3 id="결론--그래서-타이밍이-왔다">결론 : 그래서 타이밍이 왔다</h3>

<p>AI  에 대해 투자를 할 때라고 생각했다. 퇴사도 어쩌다보니 손쉽게 가능해졌고, 그렇게 정리를 하고 나오는 찰나 AI 관련한 정부의 정책이나 기업들의 투자 현황을 조사하다 보니 발견한 것이 바로 <code class="language-plaintext highlighter-rouge">네이버 부스트 캠프 8기</code> 의 모집 소식이었다.</p>

<h2 id="네이버-부스트캠프-ai-tech-8기-지원">네이버 부스트캠프 AI Tech 8기 지원</h2>

<h3 id="개요">개요</h3>

<p>해당 모집 사항을 정리하면 다음과 같았다.</p>

<ul>
  <li>지원 접수 : 25.08.14 오전 11시 마감</li>
  <li>온라인 문제 해결력 테스트 : 25.08.20. 오후 7시</li>
  <li>교육 기간 : 25.09.01 시작하여 26.02.11 까지 약 6개월, 전일제 교육</li>
</ul>

<h3 id="지원-자격과-인재상-에-대한-분석">지원 자격과 ‘인재상’ 에 대한 분석</h3>
<ol>
  <li>전일제, 집중, 몰입의 요구: 기본적으로 내용을 통해 확실하게 알 수 있는 것은 ‘쉽지 않을 것이라는’ 각오를 요구하는 내용이라고 판단했다.</li>
  <li>코어 타임의 참여 요청: 이 역시 1번을 다시 강조하는 말이리라</li>
  <li>끝을 보는 ‘덕질’의 성향: 결국 문제는 지속적으로 나타날 것이고, 그 내용을 단순히 스펙 쌓기로 생각하는게 아니라, 분야에대한 집요함을 묻는다는 의미.</li>
  <li>‘협업과 커뮤니케이션에 책임감’: 이 역시 1, 3과 함께 하는 거지만, 특히나 중요한 이유는 결국 AI 라는 영역이 한 사람이 해결할 수 없다는 사실을 여실히 보여주는 것이리라 싶다.</li>
</ol>

<p>결론적으로 정리하면 네이버 재단에서 원하는 인재란, 결국 위에서 언급한 상황, 현실적인 기업의 요구사항과는 다소 차이는 있다고 보인다. 하지만 대기업, 혹은 잠재 가치를 봤을 때 가장 ‘비싼’ 몸값의 인재 양성이 반드시 필요하다고 생각한다는 점을 느낄 수 있었다.</p>

<h3 id="해야-할-일">해야 할 일</h3>
<p>후기를 뒤져보고, 이들을 종합해보니 다음과 같이 해야 것들, 준비해야할 것들이 보였다.</p>

<p><strong>1. 프리코스는 반드시 해라</strong> : 프리코스의 콘텐츠가 온라인 테스트의 핵심 필수 사항이라는 이야기가 있다. 물론 파이썬 기초, AI 기초에 대한 내용이라 이미 숙지한 사람이라면 들을 필요가 있나? 했을 때 약간 갸웃둥 해지긴 하나, 공식 시험 가이드라 생각하고 그래도 보는 것은 괜찮다고 본다. 특히 결정적으로 가산점을 준다는 사실만 봐도, 안하는 건 99% 손해이리라 싶다.</p>

<p><strong>2. 지원서 준비는 미리미리</strong> : 이건 사실 강조할 필요가 있을까? 싶지만, 결국 인재상에 맞는 인재라는 것은 글에서부터 ‘묻어나오는 깊이감’이 있을 것이다. 그리고 그것은 어딜 가나 사람이 인정받는 시작점이며, 거기서 생각이 얕고, 준비가 부족하다면 결국은 ‘시작 조차 하지 못한다’고 보는게 맞을 것이다. 자신의 가치를 경험과 연결하여 구체적으로 작성하고, 도전 과정에서 배운 것들, 어려움과 실패에서 무얼 얻었는지도 중요할 것이며, 무엇보다 진정성과 열정이 느껴지고, 그것을 실재 만드려는 그 내용 전체의 첫 인상이 지원서에서 시작한다는 점은 어떤 후기를 보더라도 필요해보인다.</p>

<p><strong>3. 온라인 문제 해결력 테스트</strong> : 확인해보니 AI와 CS 지식, 코딩역량을 한번에 평가가 기존에 여러 차례 했던 것과는 다르게, 완전히 통합되어 진행된다고 한다. 핵심 주제는 다음 내용 위주로 보인다.</p>

<ul>
  <li>AI 및 CS 지식 테스트 영역 포함 사항들
    <ul>
      <li>선형대수 : 벡터 및 행렬 연산, 고유값(Eigenvalues), 주성분 분석(PCA) 등</li>
      <li>확률 및 통계 : 확률 분포, 조건부 확률, 편향-분산 트레이드 오프 등</li>
      <li>머신러닝 / 딥러닝 기초 : 경사 하강법(Gradient Descent), 활성화 함수(Activation Function), 과적합(Overfitting), 정규화(Regularization), 평가 지표(Evaluation Metrics) 등</li>
      <li>컴퓨터 과학 기초 : OS, 네트워크, 자료구조 등 기초 CS 문제 (단 후기들이 공통적으로 나오는 요소는 아니다)</li>
      <li>난이도 : 단순 암기만으로 풀기 어려운, 개념에 대한 이해를 요구되는 문제 출제 됨. 프리코스를 충실히 학습하고 개념을 완벽히 소화 하는 것이 중요</li>
    </ul>
  </li>
  <li>코딩 테스트
    <ul>
      <li>사용 가능 언어 : C++, Java, Python 3 (당연한 이야기지만 Python3가 가장 낫다)</li>
      <li>난이도나 경향성 : 전체적으로 과거 후기들을 보면, 백준 실버 ~ 백준 골드 ~ 플레티넘, 프로그래머스 1 ~ 3 정도로 고루 나오는 것으로 보는게 맞아 보인다.</li>
      <li>단, 0 또는 1문제를 풀고도 합격 사례 =&gt; 단순히 코딩 성적이 곧 과락을 의미하진 않음으로 보인다.</li>
      <li>주요 문제 유형
        <ul>
          <li>구현 / 시뮬레이션 : 문제의 요구사항을 꼼꼼히 읽고 그대로 코드로 옮기는 능력을 요구하는 문제가 빈번하게 출제된다. 복잡한 알고리즘 지식보다 독해력과 꼼꼼함이 중요</li>
          <li>핵심 알고리즘 : 깊이/너비 우선 탐색(DFS/BFS), 동적 계획법(DP), 그래프 탐색, 스택/큐 등 기본적인 자료구조 및 알고리즘 활용 문제가 꾸준히 언급된다</li>
          <li>CS 지식 융합형 : 일부 기수에서는 CS 지식을 문제 해결 과정에 직접적으로 적용해야 하는 융합형 문제가 출제</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="그래서-왜-네이버냐">그래서 왜 네이버냐?</h2>
<p>당연한 이야기지만 네이버 AI 부스트 캠프의 후기로 취업을 잘했다, 이직을 잘했다 이런 이야기가 아니라는 점은 다수의 후기에서 언급하는 부분이다. 그도 그럴 것이다. 개발자 시장의 과포화, 능력 상향 평준화, AI의 손쉬운 사용으로 신입을 뽑지 않는 환경 등을 고려한다면 그저 부스트캠프를 나왔다고 연봉이 올라간다, 취업이 손쉽게 된다는 것은 당연히 아니다.</p>

<p>뿐만 아니라 AI 가 나에겐 ‘메인’이냐? 라고 하면 그것도 아닐 수 있다. 그러다보니 들어가면 분명히 완벽히 낙제생 포지션이 될 수 밖에 없을 것이고, 가서 아주 잘하면 75점을 받을 수 있을까? 분명 그 이하일 것은 팩트이다 😂</p>

<p>하지만 내가 들어가야 하는 이유이자, 거기서 준비해야 할 것이 무엇인가? 에 대해서는 다음과 같이 정리 할 수 있다.</p>

<p><strong>1) AI 에 대한 제대로된 지식을 기반으로 시작하여 백엔드에 적용하는 AI의 키워드 :</strong></p>

<p>AI 만으로 개발자가 될 수도 없으며, AI 라는 툴이 결국 만나야 하는 것은 기존의 전통적인 영역들의 기술이다. 그 기술을 포함하지 않고 AI 는 비즈니스의 시장에 생명의 불꽃이 되진 못한다. 그러니 나는 AI 를 어떻게 백엔드에 적용하고, 또 반대로 어떤 지점에서 백엔드가 필요한지를 확실하게 파악할 수 있고, 그럴 수요에 부합하는 인재가 될 것이다. 이는 그 내부에서 나의 필요성을 보여줄 수도 있으며, 반대로 내가 AI에게 뭘 요구해야할지 알 수 있을 것이다.</p>

<p><strong>2) 정말 괜찮은 개발자 네트워크와 리소스의 ‘철저한 활용’ :</strong></p>

<p>6개월의 전념. 나같은 이직 준비를 하는 사람이 얼마나 될지는 모르겠다. 하지만 확실한 건 신입이든, 아니든 간에 여기에 들어가기까지 걸린 시간이나 고생한 것을 고려한다면 그들의 마음이나 자세는 분명하게 보인다. 그리고 그런 이들을 아는 것, 그리고 나 역시 그들과 함께 하는 것은 앞으로 나의 꿈, 혹은 그들의 꿈을 구현하는데 더 가까워지는 것이다. 그것은 앞으로의 엄청난 내 자산이 되리라 확신한다.</p>

<p><strong>3) 고급 백엔드 기술의 도입의 기회 마련 :</strong></p>

<p>들어가기만 하면 네이버의 고성능 AI 리소스를 쓸 기회가 생긴다. 뿐만 아니라 설령 리소스를 무제한으로 쓴다고 하더라도 효과적이고 효율적인걸 고려한다고 하면 DevOps 관점, 백엔드 개발자의 관점은 당연히 필요할 것이며, 무엇보다 백엔드의 효과적인 구조, CICD 구현 등 결국 고급 기술들을 적용해야만 AI 기반의 서비스 구현에 어려움이 없을 것이다. 이런 점에서 네이버란 기회는 오히려 더 많은 백엔드 기술 연마와 포트폴리오 준비를 가능케 할 것이라는 건 안봐도 비디오인 상황이다.</p>

<p>완전 AI 지향으로 가는 것에 비하면 나의 목표는 다소 애매(?) 할 수도 있다고 생각한다. 하지만 8월이란 기회는 와버렸고, 스스로 준비하는 것의 한계를 뛰어넘을 기회라는 확신은 있다. 건강도 챙겨야 하다보니 ‘완벽하게’ 라는 수식어를 42서울 처럼 붙이긴 어려울 것 같지만, 그럼에도 여길 발판으로 삼아, 내년에는 정말 AI DevOps Backend 이 키워드 세가지의 전문가로 확실하게 자리 매김을 할 수 있기를 기대해본다.</p>

<p>42서울을 통해 2.0을 만들었었고, 2.x 버전이던 시기를 거쳐 이제는 AI 를 통해 버전 3 라는 매력적인 순간을 차지해보자. 😎</p>]]></content><author><name>Paul2021-R</name></author><category term="생각정리" /><category term="AI" /><category term="LLM" /><category term="생각정리" /><category term="이직" /><category term="학습" /><summary type="html"><![CDATA[들어가면서 AI, AI, AI…]]></summary></entry><entry><title type="html">AI Breakfast Ep 8 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/30/AI-trend-with-google-08.html" rel="alternate" type="text/html" title="AI Breakfast Ep 8 생각정리" /><published>2025-07-30T00:00:00+00:00</published><updated>2025-07-30T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/30/AI-trend-with-google-08</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/30/AI-trend-with-google-08.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=BrR5CQuH7Hs"><img src="https://i.ytimg.com/vi/BrR5CQuH7Hs/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>‘AI Breakfast’의 여덟 번째 에피소드는 ‘개발자의 관점: AI는 좋은 질문을 기다린다, 답이 아니라’라는 주제로 진행된 대담이다. 인공지능 환경을 둘러싼 개발 전반에 대해 이야기했다.</p>

<ul>
  <li><strong>지능과 인공지능의 본질</strong>:
    <ul>
      <li>현재의 인공지능은 인간이 만들어낸 지능이며, 특히 <strong>언어적인 유창함</strong> 때문에 지능으로 오해하는 경향이 크다.</li>
      <li>아직 학습하지 않은 부분에 대해서는 ‘환각(hallucination)’ 현상이 많고 올바른 답을 내지 못하는 한계는 여전하다.</li>
    </ul>
  </li>
  <li><strong>LLM의 안전성과 제어를 위한 노력</strong>:
    <ul>
      <li>LLM(대규모 언어 모델)은 현재 <strong>제어 가능한 범위 내에서 제어 가능한 결과를 얻기 때문에</strong> 창발적인 결과를 얻기 어렵다.</li>
      <li>구글은 <strong>세이프티 필터링</strong>을 통해 도전적인 프롬프팅에 안전하게 대응한다.</li>
      <li>모델 출시 전 사람이 직접 개입하여 질문과 답의 경량성을 평가하고 세이프티 가이던스를 정책으로 적용하는 노력을 기울인다.</li>
      <li>일부 안전성 제어 또한 자동화는 가능하지만, 질문과 답에 대한 평가 결과는 아직 사람이 개입하는 것이 효율적이라고 본다.</li>
    </ul>
  </li>
  <li><strong>AI 모델 출시 전략과 플랫폼 활용</strong>:
    <ul>
      <li>사용자들은 특정 페르소나 부여에 적합한 ‘Anthropic Sonnet’이나 의도된 결과 도출에 적합한 ‘Gemini’ 등 <strong>목적에 맞춰 다양한 AI 모델을 혼용</strong>하여 사용한다.</li>
      <li>‘Vertex AI’와 같은 플랫폼이 다양한 모델을 활용하는 데 큰 도움이 된다.</li>
    </ul>
  </li>
  <li><strong>개발자들의 AI 활용</strong>:
    <ul>
      <li>개발자들 사이에서 가장 인기 있는 AI 서비스는 <strong>LLM과의 채팅</strong>과 <strong>이미지 생성</strong>이다.</li>
      <li>AI 코딩 도구(예: Google의 Code Assist, JetBrains, Cursor, Windsurf)가 개발 생산성을 크게 향상시키고 있으며, Gemini와 Code Assistant를 활용하여 <strong>두 달 만에 Unity로 게임 데모를 개발</strong>한 경험을 공유했다.</li>
      <li>AI가 개발자의 생산성에 미치는 영향은 천차만별이며, 특히 <strong>새롭거나 익숙하지 않은 API 연동과 같은 작업에서 두세 배의 생산성 향상</strong>을 가져올 수 있다.</li>
      <li>그러나 익숙한 로직을 작성하거나 짧은 함수를 만들 때는 AI의 도움이 덜할 수도 있다고 한다.</li>
      <li><strong>자신이 어떤 상황에 처했고 무엇을 해결하려는지 상세하게 넘겨줄수록</strong> 올바른 답을 받을 확률이 높아진다.</li>
      <li>결론적으로 AI는 <strong>숙련가가 본인의 능률을 보다 향상시키는 데 굉장히 좋은 도구</strong>로 기능할 수 있다.</li>
    </ul>
  </li>
  <li><strong>AI 의존과 커리어에 대한 생각</strong>:
    <ul>
      <li>현 시점에서 인공지능에 전적으로 기대어 커리어의 단계를 뛰어넘으려는 것은 바람직하지 않다.</li>
      <li>어떤 도메인이든 잘하는 사람은 AI를 잘 이용하고, 못하는 사람은 잘 이용하지 못한다.</li>
      <li>생성형 AI를 잘 활용하려면 배우고자 하는 열정, 실수해도 일어서는 끈기, 많은 시간 투입 등의 요건이 필요하다.</li>
      <li>LLM이 생성한 코드를 검증 없이 코드 리뷰에 올리는 경우, 리뷰해야 하는 사람들의 감정 소모와 비효율을 초래할 수 있다. 오히려 협업에 독이 되는 경우가 발생하는 것이다.</li>
      <li><strong>AI 도구는 사용자가 통제할 수 있는 영역에서 다뤄야 하며</strong>, 그렇지 않으면 주변 사람들까지 힘들게 할 수 있다.</li>
    </ul>
  </li>
  <li><strong>AI와 1인 개발자 및 콘텐츠 스튜디오</strong>:
    <ul>
      <li>생성형 AI(이미지, 비디오, 문장 생성)는 <strong>1인 개발자가 스튜디오의 역할을 수행할 수 있도록</strong> 돕는다.</li>
      <li>성우나 스토리 작가 없이도 게임 제작이 가능해지며, <strong>여러 AI에 페르소나를 부여하여 서로 대화하게 함으로써 결과물을 얻는 방식</strong>도 상상해 볼 수 있다.</li>
      <li>유튜브 등 콘텐츠 플랫폼에서 얼굴이나 목소리 노출 없이 AI로 영상, 내레이션 등을 만들어 쇼츠를 생산하고 수익화하는 사례가 증가하고 있다.</li>
      <li>AI가 플랫폼의 알고리즘을 학습하여 <strong>최적의 콘텐츠를 만들어낼 수도 있을 것</strong>이라는 전망이 있다.</li>
      <li>Google의 <strong>Veo(영상), Imagen(이미지), 음성 모델, 음악 생성, DJing 도구</strong> 등은 상상력이 닿는 데까지 모든 것을 만들 수 있게 한다.</li>
      <li>사용자들은 음악보다는 영상이나 이미지 생성에 더 큰 관심을 보이며, Veo 등을 활용하여 개인 뮤직비디오를 만드는 것도 충분히 가능하다고 한다.</li>
      <li>AI는 문화재 복원(벽화, 유화, 소실된 영화 필름 복원)과 같이 <strong>인류의 가치 있는 미디어를 복원하는 데도 도움</strong>을 줄 수 있다.</li>
    </ul>
  </li>
  <li><strong>AI 창작물에 대한 구글의 철학 및 대응 방식</strong>:
    <ul>
      <li>Veo를 통해 만들어진 영상에는 눈에 보이지 않는 <strong>워터마크(SynthID)</strong>가 삽입된다.</li>
      <li>SynthID는 오남용을 방지하고, AI가 만든 것임을 쉽게 판독, 나아가선 순수 창작자들을 위해 개발되었다.</li>
      <li>구글은 <strong>순수 창작자를 보호</strong>하기 위해 이 기술을 개발했으며, 원작자의 화풍을 모방하여 콘텐츠를 생성하는 것을 방지하는 데 활용된다.</li>
      <li>구글의 AI 원칙에는 <strong>구글 플랫폼에서 생성된 결과물이 제삼자의 저작권을 침해할 경우 구글이 책임지겠다는 면책 조항</strong>도 포함되어 있다.</li>
      <li>구글은 사용자들의 <strong>생산성 향상과 인류의 근본적인 문제 해결</strong>에 초점을 맞춰 기술을 개발하며, 재미 요소보다는 실용성에 중점을 둔다.</li>
      <li>Gemini는 챗GPT와 달리 ‘건조하고 할 말만 한다’는 특징을 가지며, 이는 <strong>기술의 본질적인 가치에 집중</strong>하는 구글의 방향성을 보여준다.</li>
    </ul>
  </li>
  <li><strong>구글 워크스페이스에서의 생산성 향상</strong>:
    <ul>
      <li>구글 워크스페이스(Docs, Slides)의 AI는 <strong>기존 업무 환경에서 점진적으로 생산성을 향상</strong>시키도록 설계되었다.</li>
      <li>비즈니스 목적에 사용되기 때문에 의도하지 않은 결과가 나오지 않도록 <strong>엄중한 가이드라인</strong>을 지키며, 둔하더라도 신뢰할 수 있는 방향으로 개발된다.</li>
      <li><strong>구글 미트의 회의 요약 기능</strong>은 회의 내용을 시간순으로 배열하고, 누가 누구에게 무엇을 요청했는지 요약하여 업무 누락을 방지하는 데 혁신적인 도움을 준다.</li>
    </ul>
  </li>
  <li><strong>AI 에이전트의 보안</strong>:
    <ul>
      <li>Google의 <strong>Agent2Agent(A2A)</strong>는 기업 환경에서 사용할 수 있도록 <strong>엔터프라이즈 그레이드 보안 및 인증 체계를 갖추는 데 중점</strong>을 두어 개발되었다.</li>
      <li>이를 통해 과거 MCP(Messaging, Content, and Platform)와 같은 우려를 상당 부분 해소할 수 있을 것으로 기대한다.</li>
    </ul>
  </li>
  <li><strong>개발자로서 AI를 통한 미래 기대</strong>:
    <ul>
      <li>AI 도구를 활용하여 개인의 <strong>개발 생산성을 높이고, 나아가 팀과 조직의 생산성을 끌어올려 비즈니스 성공에 기여</strong>할수 있다고 생각한다.</li>
      <li>AI 코드 리뷰는 개발자가 급박하게 돌아가는 개발 과정에서 감정 소모를 줄이고, 사소한 지적을 AI가 대신하여 <strong>효율적인, 객관적인 코드 검토</strong>가 가능하게 한다.</li>
      <li>궁극적으로 AI는 개인의 생산성을 늘리기 위한 도구로 사용될 것이며, 구글의 서비스도 이러한 가치에 부합하는 결과를 목표로 한다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>이번 내용은 AI에 대한 보다 개발자적인 내용들이 위주로 나오면서 좀더 생산적이게 느껴졌다.</p>

<p>특히나 실질적인 사례들이나, 기존에 나도 생각하던 부분, AI에게 얼마나 어떻게 세이프티를 채울 것인가.</p>

<p>그리고 그 세이프티와 함께 AI 를 다루는 사람들은 어떻게 생각하면 좋을까 같은 다소 어려운 주제들이, 상당히 나와 유사한 생각의 형태로 이어졌다.</p>

<p>내가 AI 라는 소재에 매력을 느끼는 건 뭐 때문인가.</p>

<p>생각해보면 그냥 트렌드니까, 돈이 되니까, 그런 영역으로 끝나는 문제는 아니라고 생각한다.</p>

<p>AI 는 날개다.</p>

<p>좋은 질문, 효과적인 상황에서 사용 시 사람의 한계를 뛰어넘는데 발판 역할을 해줄 수 있을 뿐 아니라, 그걸 기준으로 하면 사람이 가지는 감정,</p>

<p>새로운거 배우는게 쉽지 않은 그 감정을 이겨낼 수도 있다는 점에선 AI 는 사람의 다음 그 이상을 만들어줄 거라는 그런 기대를 하게 된다.</p>

<p>실제로 나의 1년의 서버 개발자로의 삶에서도, 결국 AI 가 있었기에 지금 수준의 성과, 지금 수준의 속도, 지금 수준의 자신감을 가질수 있었으니까 말이다.</p>

<p>그나저나 확실한 건 얼른 VertextAI 를 비롯해서 구글의 AI 를 위한 플랫폼에 대한 서비스 이해도가 높아질 필요가 있어 보인다….</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI Breakfast Ep 7 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/29/AI-trend-with-google-07.html" rel="alternate" type="text/html" title="AI Breakfast Ep 7 생각정리" /><published>2025-07-29T00:00:00+00:00</published><updated>2025-07-29T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/29/AI-trend-with-google-07</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/29/AI-trend-with-google-07.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=113tJcX0io8"><img src="https://i.ytimg.com/vi/113tJcX0io8/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>이번 최신화는 AI 시대의 업무와 삶의 혁신에 대한 논의를 다루고 있다.</p>

<ul>
  <li>
    <p><strong>Vertex AI 스튜디오</strong>: 구글 클라우드 내에 있는 서비스로, 기업 고객과 개발자들이 <strong>직접 AI 서비스를 만들 수 있는 도구</strong>이다. 이는 단순히 코드를 입력하는 개발 도구가 아니라, 노트북LM이나 제미나이 같은 다양한 AI 서비스를 접목하여 챗봇, 기업 맞춤형 제미나이, 비디오 및 음악 생성 등 새로운 서비스를 창의적으로 만들 수 있도록 돕는다. 또한, 고객이 직접 <strong>레고 조립하듯이 본인의 서비스를 만들 수 있는 도구</strong>로 비유되며, 이는 밀키트 판매보다는 음식 프랜차이즈를 기획하고 만드는 과정에 필요한 도구와 같다고 설명된다.</p>
  </li>
  <li><strong>구글 클라우드</strong>의 강점:
    <ul>
      <li><strong>확장성</strong>과 <strong>연결성</strong>이 매우 중요하며, 구글 클라우드는 AI 서비스의 가장 아래 단계인 모델(제미나이, 클라우드 소넷 등)부터 코드를 만들고 서비스를 제공하는 환경까지 <strong>전 포트폴리오</strong>를 제공하는 업계 유일의 서비스 제공자이다.</li>
      <li>구글 워크스페이스 같은 생산성 도구와 <strong>유기적인 데이터 교환 및 연동</strong>이 가능하여, 워크스페이스의 데이터를 Vertex AI 학습에 활용하거나 Vertex AI에서 생성된 데이터를 워크스페이스에서 참조할 수 있다. 이는 구글의 가장 큰 강점으로 꼽힌다.</li>
    </ul>
  </li>
  <li><strong>AI 도입 진입 장벽</strong>을 낮추기 위한 전략:
    <ul>
      <li>사용자가 AI를 <strong>자연스럽게 받아들이도록 유도</strong>하는 방향을 지향한다. 예를 들어, 구글링이나 이메일, 문서 작업 중 자연스럽게 AI 검색 결과나 제미나이 같은 기능이 등장하여 익숙해지도록 하는 방식이다.</li>
      <li>구글은 <strong>변화 관리 방법론</strong>을 가지고 있는데, 이는 사용자들이 A에서 B로 변화할 때 겪는 어려움을 최소화하고 마치 게임의 점진적인 업데이트처럼 사용자들이 눈치채지 못할 정도로 부드럽게 변화를 경험하도록 돕는다.</li>
      <li>이 방법론은 기업이 새로운 기술을 도입할 때 발생하는 <strong>기술 부채를 탕감</strong>해주는 역할을 한다. 기업의 현재 상황을 진단하고, 기존의 좋은 문화를 유지하면서 유연한 도구를 통해 개선할 수 있는 부분을 제안하며, <strong>작은 성공부터 맛보며 변화</strong>할 수 있도록 돕는다. 이는 “긁어 부스럼 만들지 말자”는 기업의 인식을 “변화를 눈치채지 못할 것”이라는 접근 방식으로 설득하는 데 사용된다.</li>
    </ul>
  </li>
  <li><strong>AI의 미래 발전 방향과 역할</strong>:
    <ul>
      <li>구글은 AI가 <strong>생산성 증강</strong>과 인간의 능력을 증강시켜 주는 방향으로 개발되고 있다고 밝힌다.</li>
      <li><strong>멀티모달리티</strong>를 추구하는 <strong>프로젝트 아스트라</strong>를 통해 렌즈, 음성, 소리를 통해 제미나이와 자연스러운 상호작용이 가능하며, 이는 시각 장애인 지원이나 학습 도구로 활용될 수 있다.</li>
      <li>AI가 발전할수록 우리 생활 속에 스며들어 마치 스마트폰처럼 <strong>본질은 같지만 접근 방식이 달라지는 도구</strong>가 될 것이며, 혁신적인 삶을 살아도 사용자들은 이를 당연하게 여기고 예전과 비슷하게 느낄 것이다.</li>
      <li>단기적으로는 <strong>개인 맞춤화</strong>된 AI가 발전할 것이며, 사용자의 업무 패턴이나 선호도를 기반으로 맞춤형 결과물을 제공할 것이다.</li>
      <li>더 나아가 <strong>자연스러운 인터랙션</strong>을 넘어, AI가 사용자의 모든 것을 지켜보다가 필요할 때 알아서 해주는 <strong>‘시키지도 않는 AI’</strong> 단계에 도달할 것이라는 예측도 있다. 이는 자동화와 자율 기능 부여 사이의 딜레마를 내포하고 있으며, 구글은 <strong>책임감 있는 AI</strong>를 만드는 것을 가장 중요한 가치로 삼고 있다.</li>
    </ul>
  </li>
  <li>
    <p><strong>AI의 핵심 가치</strong>는 <strong>시간 절약</strong>이다. AI는 개인이 업무에 소요되는 시간을 단축시켜 삶의 질을 높이는 데 기여한다.</p>
  </li>
  <li><strong>교육 현장</strong>에서의 AI:
    <ul>
      <li>AI는 학생들에게 양질의 정보를 쉽게 접하고 궁금증을 해결할 수 있는 새로운 채널을 제공한다.</li>
      <li>선생님들의 행정 업무 부담을 줄여주고, 아이들의 눈높이에 맞는 학습 자료나 과제 아이디어를 얻는 데 도움을 준다.</li>
      <li>AI는 <strong>숙제 개념 변화</strong>를 가져올 수 있으며, 미래 사회는 AI를 쓰는 능력이 필수가 될 것이기에 <strong>AI 숙련</strong>이 중요해진다.</li>
      <li>구글의 <strong>노트북LM</strong>은 학교 현장에서 <strong>할루시네이션</strong>(환각) 우려를 줄이고 <strong>데이터 소스 검증</strong> 능력을 키워주는 등 학생 학습과 교사 콘텐츠 준비에 높은 활용도를 제공한다.</li>
    </ul>
  </li>
  <li>학생들의 <strong>안전한 AI 사용</strong>:
    <ul>
      <li>어린 학생들의 경우, 판단 기준이 아직 확립되지 않았으므로 AI 도입은 <strong>점진적</strong>이어야 하며, 긍정적/부정적 변화를 평가할 시간이 필요하다. 정책적인 고려가 이루어지고 있다.</li>
      <li>AI가 아이들에게 칭찬을 많이 해줌으로써 학습 동기를 부여하는 등 긍정적인 학습 방법으로도 활용될 수 있다.</li>
    </ul>
  </li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>이제 슬슬 구글의 서비스들에 생각 이상으로 이해가 되는, 자체 구글 홍보(?) 같은 일을 내가 하고 있는가 싶다.</p>

<p>구글의 전략, 구글에 대한 이해도가 높아지고 있지만 그러는 한 편으로 AI 관련해서 구글의 전략에 대해서만 이해도가 높아져선 공평하지 않으니(?) 향후에 AWS, MS 등 웹프로바이져들을 중심으로 그 전략을, 그리고 특히나 Naver나 kakao, KT Cloud에 SKT까지는 알아봐야 하지 않을까 생각이 든다.</p>

<p>내용의 핵심인 요는 결국 ‘변화’의 바람에 떠밀듯이 회사도, 조직도, 학교도 적용될 것이지만, 문제는 그것을 어떻게 얼마나 플랫폼으로써 확장 될 수 있을까? 그리고 그 기반, 즉 공기나 물과 같은 위치를 구글의 서비스나 모델들이 확장될 수 있는가를 구글은 고민하고 있다는게 느껴진다.</p>

<p>변화는 좋은 것이지만, 그 결과가 명확하지 않을 때, 도전적인 이들도 있지만, 사실 생각해보면 대부분의 케이스 기존의 것들이 좋다는 관념적인 움직임이이 태반일 것이며 실제로도 그런 이들이 ‘어 바꿨나?’ 싶을 정도로 자연스럽게 녹아들고, 그 서비스에 락인(lock-in)될 때 그것이 진짜 플랫폼이 되는게 아닐까?</p>

<p>플랫폼 사업의 노하우, 그리고 그 앞을 바라보는 시선을 보면 왜 구글이 인터넷 춘추전국시대를 지나, 그 왕자를 분명 뺏을 만한 강자들이 있었음에도 그 강자들 사이에서 압도적일 수 있었는가에 대한 비전, 안목, 그리고 깊이감이 느껴지는 대담이 어제와 오늘자 내용이었다고 생각이 든다.</p>

<p>특히나 노트북LM, 이런 서비스에 대한 지속적인 노출이나, 교육 서비스, 워크 스페이스와의 연동 등은 어쩌면 그런 ‘가랑비에 옷 젖는’ 그리고 동시 ‘숨쉬듯’ 사용하기 위한 서비스이자, 특히나 ‘어떤 결과가 초래될지 모른다’라는 AI의 대중들의 거부감보다는 신뢰감, 효과성을 어필하려는 구글의 노력이 무엇인가를 새삼 느끼게 만드는 것 같다.</p>

<p>결국 내가 AI 와 관련되어 전문성을 얻어야 하는 지점은 어디일까?</p>

<p>어쩌면 일상의 생활에 얼마나 AI를 통해 자연스럽게 녹아들게 만들것인가. 그리고 그 과정을 단순히 백엔드의 절차적 사고를 통해서만 구현해내는 것이 아니라, 얼마나 통합된 구조를 만들 것인가?</p>

<p>궤도님의 발언처럼, 향후를 고려하여 미리 예측하여 결과를 만들어두는 것과 같이 전통적이지만 좀더 효율성이 있는 서비스로의 성장(물론, 지금 AI 산업의 구조나 하드웨어적 상황으론 거의 불가능할 것 같다만)에 도움이 되는 로직, 구조, 그리고 코드로 살려낼 수 있어야 한다는 생각, 그러려면 그런 서비스의 본질을 이해해야 한다는 생각이다.</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI Breakfast Ep 6 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/28/AI-trend-with-google-06.html" rel="alternate" type="text/html" title="AI Breakfast Ep 6 생각정리" /><published>2025-07-28T00:00:00+00:00</published><updated>2025-07-28T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/28/AI-trend-with-google-06</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/28/AI-trend-with-google-06.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://youtu.be/t3OuoheRiTU?si=KMR8Xvpq0Nma9XI7"><img src="https://i.ytimg.com/vi/t3OuoheRiTU/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>dd</p>

<h2 id="내-생각-정리">내 생각 정리</h2>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI Breakfast Ep 5 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/25/AI-trend-with-google-05.html" rel="alternate" type="text/html" title="AI Breakfast Ep 5 생각정리" /><published>2025-07-25T00:00:00+00:00</published><updated>2025-07-25T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/25/AI-trend-with-google-05</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/25/AI-trend-with-google-05.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=Osk6h0ionM0"><img src="https://i.ytimg.com/vi/Osk6h0ionM0/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>이번 최신화는 에이전트 기술이 기업에 도입되는 현황과 미래에 대한 내용을 다루었다.</p>

<ul>
  <li><strong>기업들의 에이전트 도입 현황</strong>: 기업들은 이미 자체 서비스나 제품에 에이전트 개념을 많이 도입하였다. 예를 들어, LG유플러스의 콜 에이전트 서비스인 익시오나 카카오헬스케어의 혈당 관리 앱 파스타 등이 이에 해당한다. 그러나 자체 직원들을 위한 에이전트 도입은 아직 초기 단계에 있으며, 소수의 선구자들이 스스로 사용하고 만들어보는 단계이다.</li>
  <li><strong>업무 패러다임의 변화</strong>: 코로나19로 인한 재택근무와 온라인 협업의 시대에서 이제는 에이전트를 통해 개개인의 업무 생산성을 극대화하는 자동화의 시대로 전환되고 있다.</li>
  <li><strong>에이전트 스페이스</strong>: 구글은 이러한 변화에 대응하기 위해 ‘에이전트 스페이스’라는 제품을 출시 준비 중이다. 구글 직원들은 이미 6개월 전부터 에이전트 스페이스를 내부적으로 사용하여, 제품 출시 전 실제 사용 환경에서 문제점을 발견하고 피드백을 제공하는 ‘독푸딩(dogfooding)’ 개념으로 검증하고 있다. 구글 직원들은 에이전트 스페이스 없이는 일할 수 없을 정도의 높은 생산성을 경험하고 있다고 한다.</li>
  <li><strong>생산성 향상 경험</strong>: 과거에는 비효율적으로 일했지만 그 당시에는 인지하지 못했던 부분들이 에이전트를 사용하면서 명확해졌다. 한 번 에이전트를 사용하면 예전 방식으로 돌아가기 매우 어렵다는 점이 강조되었다. 예를 들어, ‘노트북LM’과 같은 에이전트 기술을 통해 방대한 데이터를 기반으로 자연어 대화 및 질의응답이 가능해지면서 자료를 찾아보는 시간을 대폭 절약할 수 있다.</li>
  <li><strong>에이전트가 그릴 미래</strong>: 에이전트가 많은 시간을 절약하고 업무를 대신하면서, 인간의 역할은 관리 감독, 결과 판단, 의사 결정 등으로 변화할 것이다. 인간은 에이전트의 역량을 자신의 역량으로 받아들여 더 많은 일을 할 수 있는 ‘강화형 인간’이 될 수 있다. 미래에는 단순 작업을 수행하는 에이전트를 넘어 에이전트를 관리하거나 다른 에이전트들의 상호 작용을 조율하고 학습하여 개선하는 ‘메타 에이전트’로 발전할 가능성이 있다. 궁극적으로 기업의 업무 생산성은 상상할 수 없는 수준으로 올라가 핵심 의사 결정이나 중요한 태스크에 시간을 집중할 수 있게 될 것이 예상된다.</li>
  <li><strong>에이전트 스페이스의 딥 리서치 기능</strong>: 에이전트 스페이스는 기업형 제품으로, 사용자가 가진 데이터 소스를 기반으로 딥 리서치를 수행한다. 예를 들어, 최근 AI 동향 조사를 요청하면 1분에서 10분 이내에 보고서를 생성할 수 있는데, 이는 사람이 며칠 또는 몇 주가 걸릴 일을 단축하는 것이다. 이를 통해 업무량은 늘어나더라도 더 어렵고 복잡한 일을 맡아 유능한 직원이 될 수 있다.</li>
  <li><strong>기업의 에이전트 도입 판단 기준</strong>: 에이전트 도입은 이미 많은 기업에서 생산성 도구로서 논의가 시작된 단계이며, ‘시기상조’인 기업은 거의 없다. 특히 인사, 재무, 백 오피스 지원 프로세스 등 명확한 ‘페인 포인트(Pain Point)’를 가진 기업은 에이전트 스페이스를 빠르게 테스트해보고 업무 효율성을 경험할 수 있다.</li>
  <li><strong>에이전트와 조직 변화</strong>: 에이전트 도입은 업무 프로세스를 자동화하여 위임하는 과정을 통해 이루어지며, 사람의 역할은 관리 감독과 판단 및 의사 결정으로 변화한다. 조직 관점에서는 중간 관리자의 취합 및 보고 업무가 자동화되어, 사람들은 관리보다는 실제 일하는 인력으로서 수평적인 역할을 하게 될 가능성이 있다. 또한, 마케팅, 영업, 크리에이팅 등을 혼자서도 할 수 있게 되어 1인 기업과 같은 새로운 기업 유형이 많이 생겨날 것으로 예상된다.</li>
  <li><strong>변화 관리의 중요성</strong>: 새로운 도구와 기술 도입에 있어 ‘변화 관리’가 가장 중요하다. 기업의 임원부터 실무자까지 모든 직무와 레벨에서 지원이 필요하며, 이를 위해 각 부서의 ‘챔피언’을 양성하여 에이전트의 성공 경험을 만들고 내부적으로 전파해야 한다.</li>
  <li><strong>에이전트 활용 분야</strong>: 에이전트는 반복적이고 정형화된 업무 프로세스를 가진 직무나 분야에 가장 먼저 도입될 수 있다. 일반적인 사무직 업무, 예를 들어 이메일 교환을 통한 가격 취합 및 계약서 작성 지원 등이 해당된다. 반면, 영업과 같이 다양한 감정 교류, 비언어적 의사소통, 눈치 싸움이 필요한 분야나 한 번의 잘못된 의사 결정이 큰 영향을 미치는 업무(예: 국가 지도자의 역할)에서는 에이전트가 완전히 대체하기 어렵다. 이러한 영역에서는 에이전트가 도움은 줄 수 있으나, 최종 의사 결정은 사람이 해야 한다.</li>
  <li><strong>에이전트 보안 및 신뢰성 확보</strong>: 구글은 에이전트 시스템의 보안을 다각도로 접근하고 있다. 인프라 측면에서는 모든 네트워크 통신과 데이터 사용이 암호화된 보안 채널을 통해 이루어진다. 또한, ‘IAM(Identity Access Management)’을 통해 누가 어떤 정보에 접근할 수 있는지를 세분화하여 관리하며, 에이전트 스페이스는 개개인의 접근 권한을 물고 들어와 각 직무나 팀에 따라 안전하게 정보를 검색하고 업무를 수행할 수 있는 엔터프라이즈 환경을 제공한다. 구글은 이러한 보안 측면에서 큰 사고가 발생한 적이 없다는 점을 강조한다.</li>
  <li><strong>에이전트 생태계의 미래</strong>: 에이전트가 할 수 있는 일은 지능과 툴 통합을 통해 계속 늘어날 것이다. 미래에는 사람들이 에이전트를 사용하는지조차 의식하지 못하고 공기처럼 자연스럽게 생활의 기반 기술처럼 사용하게 될 가능성이 크다. 직업 생태계는 에이전트와의 협업을 통해 변화하며, 에이전트가 마치 다른 부서처럼 여겨질 수도 있다. 멀티모달리티의 대세화로 AI와의 상호작용이 증가할 것이며, 스마트폰의 앱 생태계처럼 특정 태스크를 해결하는 다양한 에이전트들이 등장하는 ‘에이전트 생태계’가 열릴 것이다. 이 생태계에서는 책임감 있고 안정적인 에이전트 배포가 중요한 쟁점이 될 것으로 예상된다. 이러한 변화는 매우 빠르게 다가오고 있다고 예측된다.</li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>오늘 후반부의 내용은 정신이 번쩍 뜨이는 대목이었다.</p>

<p>첨단 기업의 ‘첨단’ 이란 말이 어떤 건지 새삼 깨달았다.</p>

<p>언론에서는 다양한 AI 관련된 소식을 빠르게 전한다고 하지만, 생각해보면 그러한 기술은 결국 엔드 유저의 관심을 사기 위한 것들이지, 실제 기업의 위치를 가르쳐주지는 않는 다는 내 나름의 오랜 깨달음을 알고 있었음에도 다시 한 번 뒤통수를 맞은 느낌이었다.</p>

<p>에이전트 플랫폼의 활성화, B2B 시장에만 열려 있는 Agent Space, 그리고 이를 준비하기 위한 ADK 와 노코드 툴.</p>

<p>세상의 AI의 등장과 흐름은 이미 시작된지 오래였고, 구글의 준비는 사실 언론이나, 커뮤니티의 정도를 이미 뛰어 넘었구나- 라는 생각을 했다.</p>

<p>백엔드 개발자이자, AI 개발자로 성장을 꿈꿔오고 있지만, 그런 것에 비하면 실제 비즈니스 시장과 구글과 같은 기업들이 어디까지 계획과 상황을 고려하고 있는지를 보면, 정말 침착하게, 대신 치열하게 준비해야 하는 것인지, 새삼 느낄 수 있었다.</p>

<p>이런 상황의 대처, 준비, 기업이 꿈꾸는 형태를 모르는데 어떻게 전문가가 될 수 있겠는가? 그리고 거기서도 핵심 기술로 보이는 ADK 와 같은 것들, 파이썬과 자바를 제대로 다시 공부하는게 필요하고, 그렇게 해서 ADK 적 방법론을 제대로 배워야 할 것이라 생각한다.</p>

<p>Human-in-the-loop 키워드를 비롯해서, adk, 플랫폼이 되는 언어 python 에 대한 키워드 등… 대응해야할 키워드가 보다 선명해지는 것이 느껴진다.</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI Breakfast Ep 4 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/23/AI-trend-with-google-04.html" rel="alternate" type="text/html" title="AI Breakfast Ep 4 생각정리" /><published>2025-07-23T00:00:00+00:00</published><updated>2025-07-23T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/23/AI-trend-with-google-04</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/23/AI-trend-with-google-04.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://www.youtube.com/watch?v=bhNhy44jy5E"><img src="https://i.ytimg.com/vi/bhNhy44jy5E/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>유튜브 채널 "Google Cloud APAC"의 "AI Breakfast | Episode 4 - Agent로 일하는 시대가 이미 와버렸다 (Part 2)" 영상은 에이전트 기술의 발전과 구글의 관련 전략을 자세히 다루고 있다.</p>

<p><strong>에이전트의 정의와 역할</strong></p>
<ul>
  <li>에이전트는 자율적이고 통합된 대규모 언어 모델(LLM)을 의미한다. 단순히 똑똑한 것을 넘어 실제 업무를 수행하는 ‘일하는 존재’로 진화하고 있으며, 실제 직원의 모습과 유사하게 발전하고 있다.</li>
</ul>

<p><strong>에이전트 작동에 필요한 기술적 기반</strong>
에이전트가 제대로 기능하기 위해서는 다음과 같은 기술적 토대가 필요하다:</p>
<ul>
  <li><strong>두뇌, 즉 LLM:</strong> 가장 중요한 부분은 LLM이다. 제미니 2.5(Gemini 2.5)와 같은 강력한 기반 모델이 여기에 해당하며, 이들은 ‘생각하는’ 모델로서 답변을 생성하기 전에 추론 과정을 거쳐 스스로 답을 설명할 수 있는 능력을 갖추고 있다. 제미니 2.5는 에이전트 벤치마크 리더보드에서 오랜 기간 1위를 유지하고 있으며, 에이전트의 가장 근본적인 기반이자 오케스트레이터 모델로서 단단히 자리 잡아야 한다.</li>
  <li><strong>도구 사용 능력:</strong> 에이전트는 검색 기능이나 외부 예약 시스템 관리와 같은 도구를 활용할 수 있어야 한다. 다양한 사양과 접근 방식을 가진 시스템을 보다 보편적인 방식으로 다룰 수 있는 능력이 요구된다.</li>
  <li><strong>정보 탐색 능력 (Grounding):</strong> 정보를 잘 찾아내는 능력이 에이전트에게는 매우 중요하다. 구글은 ‘Grounding with Google Search’ 개념을 통해 제미니가 구글 검색의 방대한 정보를 활용하여 실시간 정보나 기업/개인이 보유하지 않은 정보까지 찾아 종합적인 답변을 제공하도록 한다. 나아가 ‘Grounding with Maps’를 통해 구글 지도의 방대한 실제 세계 정보(리뷰 데이터, 사진 데이터 등)를 활용하여 좋은 평점을 받은 식당을 추천하는 등의 판단도 가능하게 준비하고 있다.</li>
  <li><strong>다중 모드(Multimodality):</strong> 에이전트가 인간처럼 사고하고 판단하기 위해서는 세상을 인지할 수 있어야 하며, 이는 텍스트뿐만 아니라 시각, 청각 등 다양한 유형의 정보를 동시에 인지하고 처리하는 능력을 의미한다. 구글의 ‘프로젝트 아스트라(Project Astra)’는 정의된 LLM에 다중 모드와 구글 검색을 활용한 도구 사용 능력을 통합하여 시연한 사례이다.</li>
</ul>

<p><strong>최신 에이전트 트렌드</strong></p>
<ul>
  <li><strong>MCP (Model Card Protocol):</strong> 도구 사용과 관련하여 표준화가 시작되고 있다. MCP는 AI 애플리케이션과 외부 소스 및 도구 간의 연결을 표준화하는 공개 프로토콜이다. 이 프로토콜은 도구의 기능과 호출 규칙을 정의하여 LLM이 도구를 더 쉽게 이해하고 사용함으로써 오류 발생 가능성을 줄여준다. 앤트로픽(Anthropic)이 처음 제안했으며, 오픈AI(OpenAI)를 거쳐 구글 제미니도 MCP를 사용할 수 있다고 발표되었다.</li>
  <li><strong>A2A (Agent-to-Agent) 프로토콜:</strong> 멀티 에이전트 시대에 맞춰 구글이 발표한 기술로, 구글 클라우드 내의 에이전트뿐만 아니라 다른 벤더 플랫폼이나 프레임워크를 사용하는 에이전트 간에도 서로를 식별하고 직접 통신할 수 있도록 한다. 이는 하나의 에이전트가 할 수 있는 작업의 범위를 확장시켜주며, 나아가 사물 인터넷(IoT) 시대에는 가전제품들도 서로 연결되어 명령을 주고받을 수 있도록 할 예정이며, 이는 이미 일부 고객사와 논의 중이다.</li>
</ul>

<p><strong>구글 에이전트 전략의 핵심 플랫폼: Agent Space</strong></p>
<ul>
  <li><strong>Human-in-the-loop의 중요성:</strong> 에이전트의 자율성과 도구 사용 능력이 확장됨에 따라 인간의 감독과 관리가 매우 중요해진다. 에이전트가 특정 역할을 수행하기 전에 인간에게 선택지를 제시하고 허락을 구하는 <code class="language-plaintext highlighter-rouge">Human-in-the-loop</code> 개념이 안전장치로서 필수적이다.</li>
  <li><strong>Agent Space 출시:</strong> 기업 환경에서 에이전트 간의 상호 작용을 처리하고 에이전트 생태계를 효과적으로 활용할 수 있도록 구글이 출시한 플랫폼이다. 이는 구글이 수십 년 만에 처음으로 출시한 SaaS(Software as a Service) 제품이며, 에이전트와 함께 일하는 시대를 위한 엔터프라이즈 맞춤형 플랫폼이다.</li>
  <li><strong>목표:</strong> 기업들이 평균 9개 이상의 애플리케이션과 수많은 데이터 소스를 사용하는 복잡한 환경에서 발생하는 어려움을 해결하기 위해 만들어졌다. Agent Space는 이러한 분리된 데이터 소스들을 연결하고 에이전트 간의 통신을 통해 통합 검색과 인사이트를 제공하여 업무 효율성을 높이는 것을 목표로 한다.</li>
  <li><strong>주요 기능 및 특징:</strong>
    <ul>
      <li><strong>커넥터 제공:</strong> 다양한 데이터 소스를 연결하기 위한 약 150개의 커넥터가 이미 개발되어 있으며, 이를 통해 통합 검색과 자연어 질의응답이 가능하다.</li>
      <li><strong>행동 기반 자동화:</strong> 단순히 정보를 찾는 것을 넘어, 에이전트가 자동으로 이메일을 보내거나, 메시지를 전송하거나, 이벤트를 예약하는 등 실제 업무를 수행할 수 있도록 한다.</li>
      <li><strong>에이전트 갤러리 및 마켓플레이스:</strong> 구글이 미리 개발한 ‘Deep Research Agent’, ‘Data Science Agent’ 등 업무 기능별 에이전트들을 제공하며, 기업이 자체 에이전트를 구축하여 업로드하거나 마켓플레이스를 통해 다른 에이전트들을 찾아 사용할 수 있는 생태계를 조성한다.</li>
      <li><strong>에이전트 제작 용이성:</strong> 코딩 지식이 없는 사람도 에이전트 목표와 사용 도구를 자연어로 작성하면 에이전트로 등록하고 실행할 수 있는 ‘Agent Designer’ 기능(노코드)이 포함되어 있다. 개발자를 위해서는 더 세밀한 작업을 위한 ‘Agent Development Kit(ADK)’도 제공되며, 이는 제미니뿐만 아니라 타사 LLM, 랭체인(LangChain)이나 크루AI(CrewAI) 같은 다양한 프레임워크와도 호환되는 오픈소스 기반이다. ADK로 개발된 에이전트는 ‘Agent Engine’에 배포된 후 Agent Space에 등록된다.</li>
    </ul>
  </li>
  <li><strong>대상:</strong> 현재 Agent Space는 기업을 위한 B2B 솔루션으로만 제공된다.</li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>오늘 후반부의 내용은 정신이 번쩍 뜨이는 대목이었다.</p>

<p>첨단 기업의 ‘첨단’ 이란 말이 어떤 건지 새삼 깨달았다.</p>

<p>언론에서는 다양한 AI 관련된 소식을 빠르게 전한다고 하지만, 생각해보면 그러한 기술은 결국 엔드 유저의 관심을 사기 위한 것들이지, 실제 기업의 위치를 가르쳐주지는 않는 다는 내 나름의 오랜 깨달음을 알고 있었음에도 다시 한 번 뒤통수를 맞은 느낌이었다.</p>

<p>에이전트 플랫폼의 활성화, B2B 시장에만 열려 있는 Agent Space, 그리고 이를 준비하기 위한 ADK 와 노코드 툴.</p>

<p>세상의 AI의 등장과 흐름은 이미 시작된지 오래였고, 구글의 준비는 사실 언론이나, 커뮤니티의 정도를 이미 뛰어 넘었구나- 라는 생각을 했다.</p>

<p>백엔드 개발자이자, AI 개발자로 성장을 꿈꿔오고 있지만, 그런 것에 비하면 실제 비즈니스 시장과 구글과 같은 기업들이 어디까지 계획과 상황을 고려하고 있는지를 보면, 정말 침착하게, 대신 치열하게 준비해야 하는 것인지, 새삼 느낄 수 있었다.</p>

<p>이런 상황의 대처, 준비, 기업이 꿈꾸는 형태를 모르는데 어떻게 전문가가 될 수 있겠는가? 그리고 거기서도 핵심 기술로 보이는 ADK 와 같은 것들, 파이썬과 자바를 제대로 다시 공부하는게 필요하고, 그렇게 해서 ADK 적 방법론을 제대로 배워야 할 것이라 생각한다.</p>

<p>Human-in-the-loop 키워드를 비롯해서, adk, 플랫폼이 되는 언어 python 에 대한 키워드 등… 대응해야할 키워드가 보다 선명해지는 것이 느껴진다.</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry><entry><title type="html">AI Breakfast Ep 3 생각정리</title><link href="http://0.0.0.0:4000/ai/2025/07/22/AI-trend-with-google-03.html" rel="alternate" type="text/html" title="AI Breakfast Ep 3 생각정리" /><published>2025-07-22T00:00:00+00:00</published><updated>2025-07-22T00:00:00+00:00</updated><id>http://0.0.0.0:4000/ai/2025/07/22/AI-trend-with-google-03</id><content type="html" xml:base="http://0.0.0.0:4000/ai/2025/07/22/AI-trend-with-google-03.html"><![CDATA[<h2 id="영상-보기">영상 보기</h2>
<p><a href="https://youtu.be/pvbdNwysPBs?si=kcO1mQCCRE1_1t3H"><img src="https://i.ytimg.com/vi/pvbdNwysPBs/hq720.jpg" alt="비디오 제목" /></a></p>

<h2 id="요약">요약</h2>
<p>다음은 ‘AI Breakfast | Episode 3 - Agent로 일하는 시대가 이미 와버렸다 (Part 1)’ 영상 내용에 대한 요약이다.</p>

<hr />
<h3 id="ai-에이전트-시대의-도래와-구글의-접근-방식">AI 에이전트 시대의 도래와 구글의 접근 방식</h3>

<p>‘AI Breakfast’ 3화에서는 <strong>AI 에이전트로 일하는 시대가 이미 시작되었음</strong>을 강조하며, 에이전트의 정의, LLM과의 차이점, 그리고 에이전트의 발전 과정 및 구글의 관련 전략을 다루고 있다. 구글 클라우드 팀의 한지은 AI 비즈니스 담당자와 심대열 엔지니어가 에이전트 시대에 대한 구글의 시각을 설명한다. 한지은은 AI 고 투 마켓 전략 수립 및 엔터프라이즈 기업 지원을 담당하며, 심대열은 고객들이 아이디어를 빠르게 구현할 수 있도록 MVP 프로덕트 프로토타이핑을 지원한다.</p>

<p><strong>1. 에이전트의 정의와 특징</strong></p>
<ul>
  <li><strong>에이전트란</strong> 특정 목표 달성을 위해 스스로 판단하고 행동하는 똑똑한 비서이다. 예를 들어, 날씨 확인, 회의 일정 잡기, 관심 뉴스 제공 등 사용자를 대신하여 스스로 검색하고 학습하여 정보를 제공하는 역할을 한다.</li>
  <li>기술적으로는 <strong>툴을 활용</strong>하고, 검색 결과를 평가하여 필요시 다른 툴을 사용하는 등 복합적인 요소를 포함한다.</li>
  <li>에이전트는 <strong>자율성 수준</strong>에 따라 등급이 나뉘며, 완전 자동화된 에이전트부터 초보적인 에이전트까지 다양하다.</li>
  <li>구글은 에이전트를 <strong>어떤 목표를 달성하기 위해 세상을 관찰하고, 주어진 툴을 활용하여 액션을 취하는 시스템</strong>으로 정의한다. 이는 인간이 해오던 업무를 인공지능이 수행할 수 있게 되었음을 의미한다.</li>
</ul>

<p><strong>2. LLM과 에이전트의 차별점</strong></p>
<ul>
  <li><strong>기존 LLM의 사용성</strong>은 사용자의 질문에 LLM이 알고 있는 선에서 즉각적으로 답변하는 방식이다. 예를 들어, “세종대왕이 맥북을 던졌나”라는 질문에 LLM은 그럴듯한 시나리오를 제시할 수 있지만, 사실 여부 확인은 전적으로 사용자의 몫이었다. 이러한 한계는 “환각(hallucination)” 효과를 유발하기도 한다.</li>
  <li><strong>에이전트</strong>는 다르다. 하나의 목적을 받았을 때, <strong>스스로 검색</strong>을 수행하여 관련 정보를 찾고, LLM이 그 정보를 분석하여 중요 포인트를 파악한다. 필요한 경우 추가 질문을 생성하여 정보를 수집하고, 최종적으로 정확하고 심층적인 답변을 제공한다.</li>
  <li>에이전트는 단순히 답변을 찾는 것을 넘어, <strong>기억하고, 도구를 활용하며, 그 결과에 대해 스스로 자아성찰</strong>하여 올바른 방향으로 나아가는 과정을 포함한다.</li>
  <li>LLM은 에이전트의 <strong>두뇌 역할</strong>을 하지만, 에이전트는 LLM을 활용하여 특정 작업을 효과적으로 수행하고, 사고 과정을 거쳐 전문성을 발휘하는 시스템 자체를 의미한다.</li>
</ul>

<p><strong>3. 에이전트 개념의 발전 과정</strong></p>
<ul>
  <li>초기 LLM은 학습된 시점 이후의 정보를 알지 못하는 한계가 있었다 (예: 2021년 4월까지 학습된 모델은 그 이후 정보를 모름).</li>
  <li>이러한 한계를 극복하기 위해 <strong>RAG(검색 증강 생성)</strong> 기법이 등장했다. 이는 자동화된 툴이나 사람이 최신 정보를 검색하여 LLM에 제공함으로써 답변의 정확도를 높이는 방식이다.</li>
  <li>RAG의 유용성이 확인되면서, LLM의 한계를 돌파하기 위해 <strong>다양한 외부 툴(예: 인터넷 검색)</strong>을 활용하는 개념으로 확장되었다.</li>
  <li>이러한 툴 활용을 위한 <strong>워크플로우</strong>는 초기에는 사람이 직접 설정했지만, LLM의 <strong>추론 능력과 계획 수립 능력</strong>이 발전하면서, 특정 태스크 요청 시 최적의 답변을 생성하기 위해 스스로 추론하고 계획을 세워 도구를 활용(예: 검색 증강)하는 에이전트 역할이 가능해졌다.</li>
  <li>결과적으로 AI 자체가 LLM부터 시작하여 필요한 기능들을 계속 보완하고 발전하면서 <strong>‘에이전트’라고 부를 수 있는 단계</strong>에 이른 것이다.</li>
</ul>

<p><strong>4. 자율적 수행과 통합의 중요성</strong></p>
<ul>
  <li>에이전트에 <strong>‘자율적 수행(Autonomous Execution)’</strong>과 <strong>‘통합(Integration)’</strong>이라는 단어가 붙는 것은 LLM의 능력이 크게 향상되었기 때문이다.</li>
  <li><strong>자율적 수행</strong>은 LLM이 스스로 계획을 세우고 도구를 자율적으로 활용할 수 있게 되었음을 의미한다.</li>
  <li><strong>통합</strong>은 LLM이 도구를 활용하기 위해 해당 도구와 통합되어 있어야 하며, 다른 에이전트나 툴과의 협업을 통해서도 LLM의 능력이 대폭 향상될 수 있음을 나타낸다.</li>
  <li>이 두 가지 특성(자율적 수행과 통합)은 에이전트의 가장 큰 장점을 표현하는 핵심 개념으로, <strong>항상 함께 움직인다</strong>고 볼 수 있다.</li>
  <li>구글은 에이전트를 연결하는 <strong>‘오케스트레이션 모델’</strong> 또는 <strong>‘통합 에이전트’</strong> 개념을 제시하며, 이는 에이전트들이 사람처럼 다양한 업무를 통합적으로 수행할 수 있도록 돕는 역할을 한다.</li>
  <li><strong>멀티 에이전트 시스템</strong>은 하나의 에이전트가 모든 일을 처리하는 것이 아니라, HR 에이전트, 개발 에이전트, 리뷰 에이전트와 같이 <strong>특정 목적과 전문성으로 역할을 분리</strong>하여 구성한 다음, 이를 통합하거나 관리하는 방식이다. 이는 마치 신입사원이 어떤 부서에 배치되어도 전문가가 될 수 있는 잠재력을 가진 것과 유사하다.</li>
</ul>

<p><strong>5. 구글의 5가지 에이전트 범주와 Creative Agent</strong></p>
<ul>
  <li>구글은 이미 작년에 에이전트를 다섯 가지 범주로 정의한 바 있다:
    <ul>
      <li><strong>Employee Agent:</strong> 임직원 지원.</li>
      <li><strong>Customer Agent:</strong> 고객 인터랙션 지원.</li>
      <li><strong>Data Agent:</strong> 데이터 분석 지원.</li>
      <li><strong>Creative Agent:</strong> 미디어 생성 지원 (예: 비디오, 이미지, 오디오).</li>
      <li><strong>Security Agent:</strong> 보안 영역 지원.</li>
    </ul>
  </li>
</ul>

<p><strong>6. 저작권 및 안전성 문제에 대한 구글의 접근</strong></p>
<ul>
  <li>구글은 생성형 AI 모델 출시를 서두르지 않고, <strong>엔터프라이즈 기업들이 믿고 신뢰할 수 있도록</strong> 오랜 기간 정책을 준비했다.</li>
  <li>구글은 자사의 Gen AI 미디어 모델(Veo 2, Imagen 3, Lyria 등)을 통해 생성된 결과물에 대해 <strong>면책 조항(Indemnification)</strong>을 제공한다. 이는 사용자가 고의적으로 저작권을 침해하는 프롬프트를 입력하지 않는 한, 문제가 발생할 경우 구글이 책임지겠다는 약속이다.</li>
  <li>구글은 다양한 <strong>안전 필터(Safety Filter)</strong> 계층을 통해 문제가 될 수 있는 콘텐츠 생성을 최대한 막고 있다. 엔터프라이즈 고객의 특정 요구사항이 있을 경우, 구글의 <strong>7가지 AI 원칙</strong>에 따라 안전 필터를 완화하는 조치를 취하기도 한다.</li>
  <li>또한, AI가 생성한 콘텐츠에는 <strong>워터마크</strong>를 제공하여 AI 생성 여부를 확인할 수 있도록 하는 장치를 마련했다.</li>
  <li>구글은 <strong>‘책임감 있는 AI(Responsible AI)’</strong> 구축을 목표로 하며, 이는 AI 시대에 구글이 차별점을 가져갈 수 있는 중요한 부분으로 강조된다. 기존 창작자들의 거부감을 해소하고 AI 생태계를 건강하게 구축하는 것이 목표이다.</li>
</ul>

<h2 id="내-생각-정리">내 생각 정리</h2>
<p>나는 소비자와 기업이라는 관점에서 AI 의 고객을 생각했었다. 개발자니까, 그렇다면 거기서 필요한게 뭘까 하는 생각을 하기위해서였다. 하지만, 역시나 일까. 단순히 엔드 소비자와 기업이라는 관점만으론 부족했다는게 이번 내용에서 깨닫는 부분이다.</p>

<p>기업 내부에서도 결국 필요시 되는 건 결정권자들, 그리고 실무진이 다르며, 그들의 핵심이 어디서 어떤 것드을 제공해 주어야 하는지를 구글은 너무나 잘, 아주 함축적으로 파악하고 있다고 생각한다. 이게 역시 안목이라는 걸까.</p>

<p>에이전트 구축에 있어 어떤 방향성으로 좀더 명확해 져야 할지, 스스로 생각해 볼 수 있는 영역이었다.</p>]]></content><author><name>Paul2021-R</name></author><category term="AI" /><category term="AI" /><category term="DevOps" /><category term="Google" /><category term="생각정리" /><summary type="html"><![CDATA[영상 보기]]></summary></entry></feed>